<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3084454</article-id>
      <article-id pub-id-type="pmid">20347998</article-id>
      <article-id pub-id-type="publisher-id">YNIMG7178</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2010.03.059</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Multivariate models of inter-subject anatomical variability</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Ashburner</surname>
            <given-names>John</given-names>
          </name>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="cr0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Klöppel</surname>
            <given-names>Stefan</given-names>
          </name>
          <xref rid="af0010" ref-type="aff">b</xref>
        </contrib>
      </contrib-group>
      <aff id="af0005"><label>a</label>Wellcome Trust Centre for Neuroimaging, 12 Queen Square, London, WC1N 3BG, UK</aff>
      <aff id="af0010"><label>b</label>Department of Psychiatry and Psychotherapy, Section of Gerontopsychiatry and Neuropsychology, Freiburg Brain Imaging, University Hospital Freiburg, Freiburg, Germany</aff>
      <author-notes>
        <corresp id="cr0005"><label>⁎</label>Corresponding author. Fax: +44 20 78131420.</corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>15</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>15</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <volume>56</volume>
      <issue>2-10</issue>
      <fpage>422</fpage>
      <lpage>439</lpage>
      <history>
        <date date-type="received">
          <day>30</day>
          <month>10</month>
          <year>2009</year>
        </date>
        <date date-type="rev-recd">
          <day>22</day>
          <month>1</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>19</day>
          <month>3</month>
          <year>2010</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 Elsevier Inc.</copyright-statement>
        <copyright-year>2010</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>This paper presents a very selective review of some of the approaches for multivariate modelling of inter-subject variability among brain images. It focusses on applying probabilistic kernel-based pattern recognition approaches to pre-processed anatomical MRI, with the aim of most accurately modelling the difference between populations of subjects. Some of the principles underlying the pattern recognition approaches of Gaussian process classification and regression are briefly described, although the reader is advised to look elsewhere for full implementational details. Kernel pattern recognition methods require matrices that encode the degree of similarity between the images of each pair of subjects. This review focusses on similarity measures derived from the relative shapes of the subjects' brains. Pre-processing is viewed as generative modelling of anatomical variability, and there is a special emphasis on the diffeomorphic image registration framework, which provides a very parsimonious representation of relative shapes. Although the review is largely methodological, excessive mathematical notation is avoided as far as possible, as the paper attempts to convey a more intuitive understanding of various concepts. The paper should be of interest to readers wishing to apply pattern recognition methods to MRI data, with the aim of clinical diagnosis or biomarker development. It also tries to explain that the best models are those that most accurately predict, so similar approaches should also be relevant to basic science. Knowledge of some basic linear algebra and probability theory should make the review easier to follow, although it may still have something to offer to those readers whose mathematics may be more limited.</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="s0005">
      <title>Introduction</title>
      <p>In recent years, the neuroimaging field has begun to see an increasing popularity in the use of modelling approaches that are multivariate over space. Rather than testing hypotheses about regionally specific effects using mass-univariate statistical models, such techniques attempt to combine all the data into the same model. Such an approach may be able to uncover unpredicted patterns that could otherwise be overlooked. The field of multivariate modelling is extremely large, so the current manuscript will be limited to a small subset of approaches for classification and regression. One particular strategy for modelling inter-subject anatomical variability will also be emphasised. Practical real world applications of pattern recognition models are obvious, but their contribution to our understanding of neuroanatomical variability may be less clear, so a small section on visualising differences is included.</p>
      <p>Scientific research is usually dichotomised into the domains of <italic>basic</italic> (also known as <italic>fundamental</italic> or <italic>pure</italic>) and <italic>applied</italic> research. More recently, the concept of <italic>translational</italic> research has arisen within biomedical sciences, which is an alternative paradigm based upon a more seamless integration of the two traditionally separate domains of basic and applied research. Many consider basic research as simply “not-yet-applied”, which broadly agrees with the mission statements of the bodies that fund neuroimaging research.</p>
      <p>When science is applied, it generally involves the use of models to make predictions, where these predictions may inform some decision making process. The ability to predict the behaviour of a system should enable interventions to be made that are more likely to cause favourable outcomes, where the favourability may be defined explicitly according to some utility function. For example, in a medical situation the objective would be to treat the patient to optimise life expectancy and quality of life measures, as well as financial and other considerations. Clinical intuition often conflicts with the optimal approach to decision making (<xref rid="bb0205" ref-type="bibr">Elstein and Schwarz, 2002</xref>), although evidence based medicine prescribes the use of Bayes theorem in order to overcome the various cognitive biases. The ability to predict is also useful for other translational areas such as pharmaceutical development, where decisions need to be made, such as those about which candidate drugs are most likely to succeed. One of the areas where brain imaging appears to offer the greatest potential contribution to translation, is in the area of imaging biomarkers.<xref rid="fn0005" ref-type="fn">1</xref> A useful imaging biomarker would have the ability to predict the eventual outcome of treatment, before the final end point criterion is reached.</p>
      <p>Biology is not an exact science, so ideally such predictions should be probabilistic in order to encode the distribution of possible results. By predicting the probability over which events may occur, a model is also saying which events ought not to occur, or are less probable. Model predictions are therefore needed to ensure that claims are falsifiable. This paper will present a Bayesian perspective for validating claims, which involves comparing alternative models and selecting the one with the greatest evidence.</p>
      <p>This journal is largely about basic neuroscience research, where the aim is to model the brain at the systems level. Having an accurate model of the system allows perturbations to be made to the model so the effects of similar perturbations may be anticipated in the real world. The usual aim of systems biology is to take a holistic view of modelling, which attempts to integrate data from a diverse range of sources. The various “omics” techniques, form a key component of systems biology — along with the associated informatics and data mining procedures required for identifying hidden patterns in the data (<xref rid="bb0345" ref-type="bibr">Kitano, 2002</xref>). Systems biology essentially involves an attempt to reverse engineer the system under study, where the end result is an accurate and useful model (<xref rid="bb0425" ref-type="bibr">Markram, 2006</xref>). Typically, it takes several decades for basic research to become applied, and the development of fully integrated models of the brain is still in the very tentative stages (<xref rid="bb0440 bb0510 bb0600 bb0605" ref-type="bibr">Mazziotta et al., 2001; Oishi et al., 2008; Smith et al., 2009; Stephan et al., 2001</xref>). Every claim made by a scientist is in the context of some model or other, so findings pertaining to differences among populations of subjects need to be interpreted within the context of a model of inter-subject variability.</p>
      <p>Many models can be thought of as <italic>generative models</italic>, as they allow samples to be generated from the probability density they encode. Such samples may be considered as realisations of the data, as simulated by a Bayesian model. There are plenty of arguments in favour of adopting a Bayesian view of modelling. Through the use of Dutch Book arguments, Bruno de Finetti showed that the Bayesian probabilistic framework provides the optimally coherent system for predictive inference (see e.g. <xref rid="bb0320" ref-type="bibr">Jaynes and Bretthorst (2003)</xref>). Within de Finetti's framework, Bayesian models can be conceptualised as a way of encoding probabilistic predictions about future observations, such that probabilities are represented over a whole range of possible outcomes. Probability densities learned by the models may be made more “biologically plausible” by including realistic assumptions. These assumptions are largely derived empirically, but some aspects of good models may be induced from first principles. For example, it is a necessary (but not sufficient) assumption that models should be formulated in a way that is internally consistent. Principles such as symmetry and invariance, which have played a large part in the induction processes of physicists, may eventually become more commonplace within other branches of science.</p>
      <p>Currently, the scale of neuroimaging data is too large for a completely coherent Bayesian generative model of inter-subject variability to be adopted. In practice, Bayesian modellers need to make a number of assumptions in order to properly deal with the uncertainty with which parameters may be estimated. Even the simplest of these approximations (the Laplace approximation) is currently too computationally expensive for the scale of model needed for anatomical MRI scans. However, such models are being developed for relatively small datasets (<xref rid="bb0015" ref-type="bibr">Allassonnière et al., 2007</xref>) and the exponential growth in computer power may make them practical within a few more years. Fully Bayesian generative models, such as Deep Belief Nets (<xref rid="bb0290" ref-type="bibr">Hinton et al., 2006</xref>), that currently work well with lots of two dimensional images of order 32 × 32,<xref rid="fn0010" ref-type="fn">2</xref> may eventually become a reality for MRI data, which contain about 10,000 times as many pixels. Until then though, a reasonable compromise is likely to be from a feed-forward approach, where features are identified using approximate generative modelling strategies (i.e. not fully Bayesian), and these features are fed into a pattern recognition model.</p>
      <p>There are several approaches that simply estimate the most probable values of model parameters, which are known as <italic>maximum a posteriori</italic> (MAP) estimates. Although formulated from a generative modelling perspective, they are not truly Bayesian because they do not properly consider the uncertainties of the parameter estimates. Modelling this uncertainty is necessary for making accurate probabilistic predictions, or for making inferences about levels of significance. Currently, the most widely used data analysis strategy within the neuroimaging field involves using a series of models, such that information derived from fitting a lower-level model is fed as input into the model at the next level. These models are colloquially known as “tools”, and each application of a tool is a pre-processing step in an analysis pipeline. The final step in the pipeline (the highest-level model) is the one that answers the question posed by the investigator, which is often formulated within the SPM framework (<xref rid="bb0235" ref-type="bibr">Friston et al., 1994</xref>). In such approaches, information about the question of interest is not fed backwards into the pre-processing steps. For example, when spatially normalising images prior to comparing a number of populations of subjects, the scans would all be treated identically and aligned with the same template — irrespective of their group memberships. In principle, the effects that will later be modelled as confounds in the general linear model could be fed back without biasing the findings, but unless a fully Bayesian approach is adopted, including knowledge about effects of interest would lead to incorrect inferences.</p>
      <p>Similar approaches will be described in this review, whereby approximate generative models are fitted to the original data in order to capture useful lower-level features encoding inter-subject variability. This is done without feedback from the top level, so there is no influence from information pertaining to the effects of interest. Features derived from this model are then entered into a completely independent pattern recognition scheme to characterise those aspects of inter-subject variability that are of most interest to the investigator.</p>
      <p>The paper is aimed at investigators who wish to model their data, but whose areas of expertise may lie elsewhere. Relatively little mathematical notation is used, but appropriate references are provided for those wishing to read further. Wherever possible, we have attempted to explain the ideas in an intuitive way using graphical illustrations. The next section will describe some of the principles behind multivariate pattern recognition, but with an emphasis on probabilistic approaches. This will be followed by a section about some of the kinds of generative models that may be used for extracting features for use in multivariate modelling of inter-subject variability.</p>
    </sec>
    <sec id="s0010">
      <title>Multivariate pattern recognition</title>
      <p>Many of the analyses of anatomical MRI data are carried out by clinical researchers, where the emphasis is often towards translational or applied research. In many cases, the goal involves characterising the anatomical difference between two populations of subjects. A commonly used approach is to localise volumetric differences of particular brain structures or tissue types, for example by using voxel-based morphometry (VBM) (<xref rid="bb0700" ref-type="bibr">Wright et al., 1995</xref>). Approaches such as this allow the investigator to identify regions of significant difference among the pre-processed data. In the case of VBM, providing the tissue classification and inter-subject alignment models are sufficiently accurate, findings may be interpreted as regional volumetric differences (<xref rid="bb0035" ref-type="bibr">Ashburner and Friston, 2001</xref>).</p>
      <p>Other ways of characterising differences exist (<xref rid="bb0530" ref-type="bibr">Petersson et al., 1999</xref>), which do not require the features to be discretely localised. Sometimes such characterisation may be formulated to answer different kinds of questions, such as those about the link between patterns of brain asymmetry and schizophrenia (e.g. <xref rid="bb0145" ref-type="bibr">Chance et al., 2005</xref>), or the extreme male brain theory of autism (<xref rid="bb0065" ref-type="bibr">Baron-Cohen, 2002</xref>). In terms of meeting the aims of a study, the empirical success of a model could be defined in terms of how well it is able to separate the populations. By removing the artificial assumption of independence among brain regions, it is often possible to achieve much greater accuracy. The independence assumption is convenient for localising differences, but empiricism shows that it is not always realistic (<xref rid="bb0450 bb0705 bb0590" ref-type="bibr">Mechelli et al., 2005; Xu et al., 2008; Seeley et al., 2009</xref>). Some forms of anatomical variability cannot be localised to specific regions. Consider distinguishing male from female human faces as a typical example for understanding biological variability. This is something that most of us can do intuitively, without being explicitly aware of the pattern that separates them. Buried among all the inter-subject variability that is unrelated to sex, there is a global pattern of difference based on proportions of various measurements, which cannot be localised to particular parts of the face. Similarly, much of the anatomical variability among brains cannot be localised. For example, where would one localise a pattern of difference where the total volume of the left hemisphere is inversely correlated with the volume of the right hemisphere? Volumes of structures are correlated among different brain regions, especially between homotopic regions in the contralateral hemisphere (<xref rid="bb0450" ref-type="bibr">Mechelli et al., 2005</xref>). Patterns of growth are partially predicted by patterns of gene expression, and the gene expression maps at, for example, the Allen Brain Atlas<xref rid="fn0015" ref-type="fn">3</xref> show spatially distributed patterns. Darwin noted that there is correlation of growth in his <italic>Origin of Species</italic>, so such pleiotropic effects should be expected. Connectivity among brain regions, as well as numerous other factors, is also likely to lead to such spatially distributed correlations. Findings from localisation approaches are relatively simple to explain within the constraints of the journal paper format, but they may only provide approximate summaries of the real pattern of difference.</p>
      <sec id="s0015">
        <title>Multivariate models</title>
        <p>Orthodox linear multivariate techniques such as Principal Component Analysis (PCA), Canonical Correlation Analysis (CCA) and Multivariate Analysis of Variance (MANOVA), have been used by the brain imaging field for a number of years, for modelling both functional (<xref rid="bb0215 bb0240 bb0445" ref-type="bibr">Fletcher et al., 1996; Friston et al., 1996; McIntosh et al., 1996</xref>) and structural (<xref rid="bb0120 bb0045" ref-type="bibr">Bookstein, 1996; Ashburner et al., 1998</xref>) data. Similarly, morphometric applications of multivariate models have existed for many years, and there are several textbooks available on the subject (<xref rid="bb0595 bb0125 bb0195 bb0335 bb0175 bb0385 bb0365 bb0190" ref-type="bibr">Small, 1996; Bookstein, 1997; Dryden and Mardia, 1998; Kendall et al., 1999; da Fontoura Costa and Cesar, 2001; Lele and Richtsmeier, 2001; Krim and Yezzi, 2006; Davies et al., 2008</xref>). Earlier morphometric approaches involved the application of multivariate statistics to manually defined landmarks or surfaces, often after correcting the data for pose and size using a <italic>Procrustes analysis</italic>. These techniques were considered revolutionary at the time (<xref rid="bb0005" ref-type="bibr">Adams et al., 2004</xref>), but they are relatively naïve when compared with some of the current state-of-the-art computational anatomy models. The re-discovery of Bayesian methods, as well as the additional computer power that has become available, has both contributed to many of the advances. What was once PCA, is now probabilistic PCA (<xref rid="bb0625 bb0105" ref-type="bibr">Tipping and Bishop, 1999b; Bishop, 1999</xref>). CCA has now been re-formulated as probabilistic CCA (<xref rid="bb0055" ref-type="bibr">Bach and Jordan, 2005</xref>). Many of these models are now treated as components to much larger models, so there are now mixtures of PCAs (<xref rid="bb0620 bb0250" ref-type="bibr">Tipping and Bishop, 1999a; Ghahramani and Beal, 2000</xref>) and a very wide variety of other models (<xref rid="bb0555" ref-type="bibr">Roweis and Ghahramani, 1999</xref>) that generally fall under the domain of <italic>machine learning</italic>. Pattern recognition is the form of machine learning that will be touched on in this review. Interested readers, requiring more depth, are referred to some of the many good textbooks on the subject (<xref rid="bb0200 bb0115" ref-type="bibr">Duda et al., 2001; Bishop et al., 2006</xref>).</p>
        <p>The basic idea behind pattern recognition approaches is that a number of examples of training data are presented to the model, where each of the examples has some label associated with it. The algorithm then attempts to learn the relationship among data and labels, so that it may predict the desired labels if novel examples of data are presented. A practical application may involve the data being some set of image features for each of a number of subjects, and the labels may be either zero or one, depending on some disease status. In this situation, the model would attempt to automatically make diagnoses based on the image features of the new subjects. Similar approaches have been used for functional data, for which introductory and tutorial papers such as <xref rid="bb0480" ref-type="bibr">Mitchell et al. (2004)</xref> and <xref rid="bb0525" ref-type="bibr">Pereira et al. (2009)</xref> may be helpful.</p>
        <p>It is useful to consider each subject's set of features as a single point (a vector) in a high-dimensional space. This is much easier to visualise in situations where there are only two features per subject, as the points can be plotted in two dimensions. Visualisation with three features is also possible, but it becomes extremely difficult if there are four or more dimensions to conceptualise.</p>
        <p>In addition to classification into discrete categories, pattern recognition may be used to predict continuous variables. This is known as regression, and <xref rid="f0005" ref-type="fig">Fig. 1</xref> provides a simple illustration. After fitting the model to the training data, predictions for new data may be made by <italic>y</italic> = <bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> + <italic>b</italic>, where <bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> is a dot-product operation, illustrated in <xref rid="f0010" ref-type="fig">Fig. 2</xref>. Rather than simply predict the most probable value of <italic>y</italic>, more advanced regression methods would predict a distribution, which may be encoded by the mean and standard deviation of a Gaussian.</p>
        <p>Many principles will be illustrated for the case of classification, and <xref rid="f0015 f0020 f0025" ref-type="fig">Figs. 3, 4 and 5</xref> will show schematics for a simple two dimensional example. White circles are intended to denote subjects in group 0, and black circles denote those in group 1. The two axes represent the values of the two features, where the features could be measurements such as the volumes of particular structures. Data for a new subject could then be plotted, whose group membership is unknown. If a subject's data is closer to the white circles, then it may be more likely to belong to group 0. If it is closer to the black ones, then group 1 may be more likely. In the case of a simple comparison between two groups of subjects, the objective would be to partition the space into two regions. New data falling into the first region would be assigned membership to the first group, whereas if it falls into the second region then it would be assigned to the second group. In practice, these assignments may not be made unambiguously, so the partitioning would be probabilistic.</p>
      </sec>
      <sec id="s0020">
        <title>Generative and discriminative models</title>
        <p>Fisher's Linear Discriminant Analysis (FLDA) is a commonly used, but simple, framework for multivariate modelling of data. FLDA is a special case of Canonical Correlation Analysis (<xref rid="bb0055" ref-type="bibr">Bach and Jordan, 2005</xref>), but it may also be viewed as a special case of a Mixture of Gaussians (MoG), which in turn is a special case of other more complicated models. Essentially, FLDA involves a model whereby there are two populations of data, both sharing the same multivariate Gaussian variance. FLDA can be considered a <italic>generative model</italic>, as it attempts to encode a probability density of the entire dataset. Referring to the illustration in <xref rid="f0015" ref-type="fig">Fig 3</xref>, a generative model would encode the probability density of the two classes of data. In the case of FLDA, this involves representing them as multivariate Gaussian distributions, shown in the two sub-figures at the top. The probability of belonging to a particular class is then obtained by dividing by the probability density of the data itself, which is simply the sum of the probabilities of belonging to the various classes (two in this example). This is a simple application of Bayes rule:<disp-formula id="fo0005"><mml:math id="M1" altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="true">|</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="true">|</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="true">|</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mtext>.</mml:mtext></mml:mrow></mml:math></disp-formula></p>
        <p>Modelling the difference between one group of data and the other requires the within group variance and covariance to be modelled. For this reason, it is often necessary to use some form of dimensionality reduction. Images may consist of millions of voxels, whereas the number of subjects in a study is usually much fewer than this. For FLDA to work effectively, the millions of voxels would need to be reduced to fewer features than there are subjects. This problem is known as the <italic>curse of dimensionality</italic>, and there are a number of techniques that may be used for factorising a large dataset into its most salient components. PCA is a commonly used approach for this, but there are a number of more principled alternative models that could be chosen. For such studies, the within group variability is not of primary concern, and all that is required is an accurate characterisation of the salient differences among the groups.</p>
        <p>Rather than use a generative model, it is possible to directly estimate the separation between the groups using a <italic>discriminative model</italic>. Within population variance is not usually considered interesting, and modelling it requires additional parameters that are difficult to deal with optimally. An analogy to using a generative model for classification would be needing to learn both Mandarin and German in order to distinguish between spoken versions of the two languages. It is simpler to directly identify the distinguishing features. The approaches are also known as the <italic>diagnostic paradigm</italic> (discriminative) and the <italic>sampling paradigm</italic> (generative) (<xref rid="bb0285" ref-type="bibr">Hand, 2001</xref>). In most practical situations, discriminative models are more accurate and robust than generative models (<xref rid="bb0115" ref-type="bibr">Bishop et al., 2006</xref>) (except for small training datasets), so they should provide more accurate characterisations of the differences among populations of subjects.</p>
        <p>Generative models for discrimination do offer some advantages over discriminative models (<xref rid="bb0375" ref-type="bibr">Lasserre et al., 2006</xref>). In particular, for probabilistic approaches it is much more straightforward to make use of additional unlabelled data within a generative modelling framework. <xref rid="bb0735 bb0150" ref-type="bibr">Zhu and Goldberg (2009) and Chapelle et al. (2006)</xref> provide useful references for such semi-supervised learning strategies. A related situation occurs when group memberships of training data are not known with 100% confidence, where it may be helpful to use probabilistic labels for training the model. For example, definitive diagnosis of Alzheimer's disease (AD) is only possible from post-mortem samples. Training a system to identify AD may be more optimal if the labels are able to encode the fact that (for example) some subjects have an 80% probability of having the disease. By considering FLDA within a MoG framework, it should become possible to assign probabilistic labels to the training data in much the same way as tissue probability maps are currently used to provide priors for tissue classification (<xref rid="bb0030 bb0650" ref-type="bibr">Ashburner and Friston, 1997; Van Leemput et al., 1999</xref>). Discriminative models may also be able to make use of such probabilistic labels, but the authors are not yet aware of any related work. It is often easier to formulate domain knowledge about a system using generative modelling strategies, and there is now an increasing degree of interest in combining generative and discriminative training (<xref rid="bb0375 bb0110 bb0580" ref-type="bibr">Lasserre et al., 2006; Bishop and Lasserre, 2007; Schmah et al., 2008</xref>), such that the best attributes of both may be exploited.</p>
        <p>Domain knowledge is often incorporated by pre-processing, which is a form of generative modelling. It is then possible to use the model to compute similarity measures among the pre-processed observations, using concepts from <italic>Information Geometry</italic> (<xref rid="bb0020" ref-type="bibr">Amari and Nagaoka, 2007</xref>), such as <italic>Fisher kernels</italic> (<xref rid="bb0315 bb0300" ref-type="bibr">Jaakkola et al., 2000; Holub et al., 2008</xref>). The relationship between geometry and shape analysis is clear, but it may not be so apparent that the Information Geometry framework also extends to other generative models used for pre-processing. Fully Bayesian generative models, which combine pre-processing and classification into the same probabilistic model, could offer advantages in terms of feeding information back to lower levels of the model (<xref rid="bb0490 bb0500 bb0290" ref-type="bibr">Mumford, 1994, 2002; Hinton et al., 2006</xref>).</p>
      </sec>
      <sec id="s0025">
        <title>Probabilistic approaches</title>
        <p>For classification, the objective is sometimes simply to divide the space of possible data into binary regions, such that new data is categorised as belonging to one group, or the other. There are various approaches to do this, which include the support-vector machine (SVM) (<xref rid="bb0130 bb0165 bb0585" ref-type="bibr">Boser et al., 1992; Cristianini and Shawe-Taylor, 2000; Schölkopf and Smola, 2002</xref>) that is applied increasingly to anatomical neuroimaging data (<xref rid="bb0260 bb0255 bb0180 bb0370 bb0265 bb0210 bb0360 bb0660 bb0185 bb0410 bb0245" ref-type="bibr">Golland et al., 2001; Golland, 2002; Davatzikos et al., 2004; Lao et al., 2004; Golland et al., 2005; Fan et al., 2005; Kloppel et al., 2008b; Vemuri et al., 2008; Davatzikos et al., 2008; Magnin et al., 2009; Gerardin et al., 2009</xref>). SVMs are based on Vapnik's <italic>Statistical Learning Theory</italic> (<xref rid="bb0655" ref-type="bibr">Vapnik, 1999</xref>), and often perform very well in binary classification problems. The principles behind SVMs have been described in many neuroimaging papers, so no further details will be provided here. Other approaches, such as relevance vector classifiers (RVCs) (<xref rid="bb0615" ref-type="bibr">Tipping, 2001</xref>) and other logistic regression techniques, attempt to provide probabilistic predictions. Examples of such approaches, applied to the same data as in <xref rid="f0015" ref-type="fig">Fig. 3</xref>, are illustrated in <xref rid="f0020" ref-type="fig">Fig. 4</xref>. For linear methods, such classifications are performed by <italic>y</italic> = <italic>f</italic>(<bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> + <italic>b</italic>), where <italic>f</italic>() is some non-linear function. The function would be a simple thresholding procedure for SVM classification, whereas it would be a logistic function for logistic regression models (<xref rid="f0010" ref-type="fig">Fig. 2</xref>). Whether a new datum is assigned to one class or the other, will depend on which side of a separating hyperplane it falls. In two dimensions, such a hyperplane is one dimensional, whereas in three dimensions, it is two dimensional. It always has one less dimension than the dimensionality of the data, and is essentially defined by the vector orthogonal to it (<bold>a</bold>), and a scalar that indicates where it intersects the vector (<italic>b</italic>). Refinements can be made to the simple logistic regression model, as well as to RVCs, in order to make their predicted probabilities more accurate. Without the refinements, although they attempt to make probabilistic predictions, these models tend to be over-confident for novel data that is far from any encountered during training (<xref rid="bb0540" ref-type="bibr">Rasmussen and Quinonero-Candela, 2005</xref>). <xref rid="f0025" ref-type="fig">Fig. 5</xref> attempts to show that by integrating out the uncertainty in the estimation of the discriminative direction, it is possible to counteract this over-confidence.</p>
        <p>These illustrations were only for two dimensional data, and there were many more data points than dimensions in the data. Linear regression involved fitting a general linear model, where the aim is to determine the optimal linear combination of data that best predict the labels. For logistic regression, estimating the separating hyperplane could be done by using a general<italic>ised</italic> linear model (GLZ) to fit the data to the labels. This is similar to fitting a general linear model (GLM), except that it involves the use of a link function to squash the output within the range of zero and one (see <xref rid="f0010" ref-type="fig">Fig. 2</xref>). Finding the solution requires an iterative approach, which is typically an iterative re-weighted least squares. It is also worth noting that the logistic regression model can be generalised to discriminate among multiple classes, by fitting a Softmax function (<xref rid="bb0115" ref-type="bibr">Bishop et al., 2006</xref>).</p>
      </sec>
      <sec id="s0030">
        <title>Gaussian process models</title>
        <p>The usual approach for modelling neuroimaging data involves fitting a linear combination of columns in a design matrix (independent data) to fit a single vector of image data (dependent data). For pattern recognition, the model is reversed because training involves modelling the independent data by a linear combination of the dependent data (see e.g. <xref rid="bb0225" ref-type="bibr">Friston et al. (2008)</xref> for further explanations). Unlike the case for non-linear models (<xref rid="bb0230 bb0305" ref-type="bibr">Friston and Ashburner, 2004; Hoyer et al., 2009</xref>), it makes no difference to most linear models whether the independent and dependent data are swapped around, providing any confounding effects are properly modelled. When making predictions about subjects from their image data, it is not possible to use a simple GLM (for regression) or GLZ (for classification), as each image has far more voxels than there are images in the dataset. This is the curse of dimensionality, which was touched on earlier, and requires some form of regularisation in order to resolve the fact that the model is under-determined. As mentioned previously, one form of regularisation involves reducing the data to a smaller number of salient features. A more elegant strategy involves penalising the coefficients in the GLM using a ridge-regression technique, which essentially adds additional prior knowledge into the system of equations. The objective then becomes one of optimising the fit to the label data, while simultaneously keeping the sum of squares of the coefficients as small as possible. This involves a trade-off between bias and variance in the model's ability to generalise to new data, which is controlled by the hyper-parameters of the model (see <xref rid="f0030" ref-type="fig">Fig. 6</xref>). With too little regularisation, the model will fit the training data very well, but the predictions for new data may not be accurate because it has over-fitted the training data. In contrast, with too much regularisation, the model will be strongly biased towards classifying everything with 50% probability (or whatever the proportions of group members are in the training data). Achieving an optimal solution involves determining the optimal balance between fitting the training data and penalising the magnitudes of the coefficients. The older literature suggested a number of ad hoc methods for this, but the Bayesian framework provides a more elegant solution in the form of the evidence framework (<xref rid="bb0400" ref-type="bibr">MacKay, 1992</xref>) (which is the same as type-II maximum likelihood, empirical Bayes and restricted maximum likelihood). By integrating out the uncertainty with which the coefficients (parameters) are estimated, the evidence framework essentially estimates only hyper-parameters.</p>
        <p>For regression, estimating the hyper-parameters is equivalent to maximising the probability of the <italic>N</italic> training labels (<bold>y</bold>) under the assumption that they are drawn from a zero mean Gaussian distribution, where the covariance matrix (<bold>C</bold>) is computed as some function of the training data. The covariance matrix is parameterised by the hyper-parameters, which are determined by maximising the probability according to the equation for a multivariate Gaussian distribution:<disp-formula id="fo0010"><mml:math id="M2" altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo stretchy="true">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>C</mml:mi></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mrow><mml:msup><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfenced><mml:mi>N</mml:mi></mml:msup><mml:mo stretchy="true">|</mml:mo><mml:mo>det</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>C</mml:mi></mml:mstyle><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>exp</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mi>C</mml:mi></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:mfenced><mml:mtext>.</mml:mtext></mml:mrow></mml:math></disp-formula></p>
        <p>There are many ways of parameterising the covariance matrix, but the main criterion is that it needs to be symmetric and positive semi-definite. A simple model with three hyper-parameters is:<disp-formula id="fo0015"><alternatives><textual-form specific-use="jats-markup"><bold>C</bold> = <italic>θ</italic><sub>0</sub><bold>I</bold> + <italic>θ</italic><sub>1</sub> + <italic>θ</italic><sub>2</sub><bold>X</bold><bold>X</bold><sup><italic>T</italic></sup>.</textual-form><mml:math id="M3" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">I</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mtext>.</mml:mtext></mml:mrow></mml:math></alternatives></disp-formula></p>
        <p>In this case, <italic>θ</italic><sub>0</sub> would add some amount of a diagonal matrix of ones to the covariance matrix, which models residual variance. A constant offset in the regression is accounted for by the <italic>θ</italic><sub>1</sub> term, which models the variance of the <italic>b</italic> in <italic>y</italic> = <bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> + <italic>b</italic>. The <italic>θ</italic><sub>2</sub> term encodes the variance of the regression coefficients (<bold>a</bold>). If there are <italic>N</italic> subjects in the training data, then the matrix <bold>XX</bold><sup><italic>T</italic></sup> is an <italic>N</italic> × <italic>N</italic> matrix, which encodes the similarities among the scans. Each set of features may be treated as a row vector, and these <italic>N</italic> rows would be stacked together to form the matrix <bold>X</bold>. The matrix <bold>XX</bold><sup><italic>T</italic></sup> contains the dot-product of each of the <italic>N</italic> feature sets, with each other feature set in the training data. Training involves finding the values for <italic>θ</italic><sub>0</sub>, <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> that maximise the probability of <bold>y</bold>. After training, it is then possible to use those estimated values to build a larger covariance matrix, encompassing both the training feature sets as well as the features to test. The augmented covariance matrix, in conjunction with the training labels, can then be used to predict the unknown labels. This is the Gaussian process regression framework (<xref rid="bb0690" ref-type="bibr">Williams and Rasmussen, 1996</xref>), and is nicely described in textbooks such as <xref rid="bb0405" ref-type="bibr">MacKay (2003)</xref>,<xref rid="fn0020" ref-type="fn">4</xref> <xref rid="bb0545" ref-type="bibr">Rasmussen and Williams (2006)</xref><xref rid="fn0025" ref-type="fn">5</xref> or <xref rid="bb0115" ref-type="bibr">Bishop et al. (2006)</xref>. There is also a related framework for classification (<xref rid="bb0685" ref-type="bibr">Williams and Barber, 1998</xref>), although practical implementation is not so straightforward, and often involves a number of approximations.<xref rid="fn0030" ref-type="fn">6</xref> The important point here, is that Gaussian process classification also requires a covariance matrix, which is formulated in the same way as that for regression.</p>
        <sec id="s0035">
          <title>Feature selection</title>
          <p>If some features of the data are known to be less informative than others, then it is possible to down-weight their importance. Similarly, if it is known, a priori, that a sparse set of features are likely to provide the most accurate predictions, then the pattern recognition algorithm may be modified such that it is more likely to select a sparse set of features. A number of authors have devised feature selection procedures for applying pattern recognition to imaging data. The objective of feature selection is to ignore, or down-weight, those features that provide relatively less discriminatory signal. Within the Gaussian process framework, this would be analogous to ignoring the contribution made, by those features, to the matrix of dot-products.</p>
          <p>This kind of naïve feature selection may be formulated using a diagonal matrix, <bold>W</bold>, which is a function of several, non-negative, hyper-parameters (<italic>θ</italic><sub>2</sub>, <italic>θ</italic><sub>3</sub>, etc). The limiting case of this framework would be the situation where each element on the diagonal of <bold>W</bold> was one of the hyper-parameters. This is known as <italic>automatic relevance determination</italic>, and usually results in sparse solutions as some of the hyper-parameters fall to zero. Solutions obtained from this model are equivalent to those described in <xref rid="bb0225" ref-type="bibr">Friston et al. (2008)</xref>. For this kind of model, the covariance matrix would be given by:<disp-formula id="fo0020"><label>(1)</label><alternatives><textual-form specific-use="jats-markup"><bold>C</bold> = <italic>θ</italic><sub>0</sub><bold>I</bold> + <italic>θ</italic><sub>1</sub> + <bold>X</bold><bold>W</bold>(<italic>θ</italic><sub>2</sub>, <italic>θ</italic><sub>3</sub>…)<bold>X</bold><sup><italic>T</italic></sup>.</textual-form><mml:math id="M4" altimg="si4.gif" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">I</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi><mml:mi mathvariant="bold">W</mml:mi></mml:mstyle><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>…</mml:mo></mml:mrow></mml:mfenced><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mtext>.</mml:mtext></mml:mrow></mml:math></alternatives></disp-formula></p>
          <p>Sparsity may be over space, but this need not be the case. It is possible that pre-processing models, such as independent component analysis (<xref rid="bb0100" ref-type="bibr">Bell and Sejnowski, 1995</xref>), could transform the data into the kind of features whereby selecting a sparse subset would add biological plausibility to the discrimination. Similarly, there are other factorisation models that could prove useful for defining the kinds of features where sparsity would be advantageous. One such example may be non-negative matrix factorisation (<xref rid="bb0380" ref-type="bibr">Lee and Seung, 1999</xref>).</p>
          <p>There is no reason why <bold>W</bold> should be limited to the diagonal case. For example, if the features consist of image data that have been pre-processed in some way, then <bold>W</bold> could encode a convolution function, such that the algorithm may determine the optimal degree of spatial blurring. It is often the case that low spatial frequencies contain proportionally more informative signal than do the higher frequencies, so more accurate predictions may be obtained by blurring the data by some optimal amount.</p>
          <p>Later, the paper will explain a possible framework for this type of approach, whereby a similar <bold>W</bold> matrix may be used to obtain a trade-off between information pertaining to shape, and information pertaining to image intensity.</p>
        </sec>
        <sec id="s0040">
          <title>Going non-linear</title>
          <p>Sometimes, it is not possible to achieve accurate predictions using a linear separation method, in which case non-linear methods may be required. For example, a particular disorder may be characterised by a number of alternative types of variability. A simple example would be a disorder that either causes atrophy in the left or in the right hemisphere. A linear model would only be able to encode one mode of variability, whereas a non-linear model may be able to capture both modes.</p>
          <p>Non-linear models work by projecting the data into a higher number of dimensions, where they can be fitted using a linear model (see e.g., <xref rid="bb0165 bb0115" ref-type="bibr">Cristianini and Shawe-Taylor (2000), Bishop et al. (2006)</xref>). This is similar to the use of polynomial expansions for simple non-linear fitting of data. There is a class of methods, known as <italic>kernel methods</italic>, that is ideally suited to this approach. These methods use the <italic>kernel trick</italic>, which involves replacing the matrix of dot-products (<bold>XX</bold><sup><italic>T</italic></sup>) by some other symmetric and positive semi-definite matrix, which is a function of the data. One of the most widely used forms for this matrix is one based on radial basis functions (RBF), which requires distances between all pairs of feature vectors. It is possible to derive distances from matrices of dot-products because (<italic>x</italic><sub>1</sub> − <italic>x</italic><sub>2</sub>)<sup>2</sup> = <italic>x</italic><sub>1</sub><sup>2</sup> + <italic>x</italic><sub>2</sub><sup>2</sup> − 2<italic>x</italic><sub>1</sub><italic>x</italic><sub>2</sub>. Each element of the matrix would then be replaced by <inline-formula><mml:math id="M5" altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mo>exp</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mo>−</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msubsup><mml:mi>d</mml:mi><mml:mi mathvariant="italic">mn</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:math></inline-formula>, where <italic>d</italic> is the distance between feature set <italic>m</italic> and feature set <italic>n</italic>, and <italic>θ</italic> is a hyper-parameter controlling the width of the kernel.</p>
          <p>Rather than use simple Euclidean distances between each pair of feature sets, it is also possible to use other measures of distance within the RBF framework. The only requirement is that the measures must satisfy the requirements for being a <italic>metric</italic>, which are:<list list-type="simple"><list-item><label>1.</label><p>They must be greater than or equal to zero.</p></list-item><list-item><label>2.</label><p>They may only be equal to zero if the features are identical.</p></list-item><list-item><label>3.</label><p>The distance between <bold>x</bold><sub><italic>m</italic></sub> and <bold>x</bold><sub><italic>n</italic></sub> must be equal to the distance between <bold>x</bold><sub><italic>n</italic></sub> and <bold>x</bold><sub><italic>m</italic></sub>.</p></list-item><list-item><label>4.</label><p>The distance between <bold>x</bold><sub><italic>m</italic></sub> and <bold>x</bold><sub><italic>n</italic></sub> must not be greater than the sum of those between <bold>x</bold><sub><italic>m</italic></sub> and <bold>x</bold><sub><italic>k</italic></sub>, and between <bold>x</bold><sub><italic>k</italic></sub> and <bold>x</bold><sub><italic>n</italic></sub>.</p></list-item></list></p>
          <p>A strategy for deriving metrics between shapes will be described later. Many pattern recognition procedures can be formulated as kernel methods, but several other algorithms can also be kernelised.</p>
          <p>Non-linear methods allow more complicated separations to be achieved, but they also make it easier for the model to over-fit the training data. As in the case of the previous examples, the hyper-parameter(s) controlling the degree of non-linearity may be automatically determined using the evidence framework. Also, interpreting the mechanism by which separation is achieved is much more difficult when non-linear methods are used (<xref rid="bb0255" ref-type="bibr">Golland, 2002</xref>). Ideally, linear methods would be used whenever possible, but this may require representing the features in a form that allows easier separation using a linear method.</p>
          <p>Real data often falls in manifold-like patterns within the high-dimensional space (see e.g. <xref rid="bb0060" ref-type="bibr">Baloch and Davatzikos (2009)</xref>), but the careful use of generative models may allow much of this pattern to be modelled. A simple example would be an image of a brain that is rigidly transformed by various amounts. There are six parameters controlling the rigid transform, so the transformed versions of the image would fall as points on a six-dimensional manifold. Rigid-body alignment could be used to bring all the points on the manifold back to a single point. Similarly, inter-subject registration methods are able to model out some of the manifold-like patterns within MRI data. Unlike the rigid-body alignment case, the way that the spatial transformation is encoded is also of interest because it describes the shape of the brain. To be as powerful as possible, pattern recognition for studies of inter-subject variability should be formulated to work both with shape descriptors, and also with the variability that cannot be modelled out by alignment.</p>
        </sec>
      </sec>
      <sec id="s0045">
        <title>Measuring empirical success</title>
        <p>Many classification methods are able to fully separate the training data, whereas they may generalise poorly to novel data. Often, cross-validation is used to assess how accurately the characterisation separates the populations.<xref rid="fn0035" ref-type="fn">7</xref> This may involve fitting the model to all subjects' data except for one, and then assessing the accuracy of the prediction about the subject that was left out. The procedure would be repeated by leaving out the next subject's data, and so on. Reports of sensitivity and specificity, using measures such as the area under the receiver operating characteristic (ROC) curve (see e.g. <xref rid="bb0740" ref-type="bibr">Zou et al. (2007)</xref>), can be compared with those of human experts. Human expertise is still considered to be the gold standard to beat for most models encoding image understanding (<xref rid="bb0355" ref-type="bibr">Kloppel et al., 2008a</xref>). This situation may change over the next few years, as computing power will probably continue to grow exponentially (“Moore's Law”), thus allowing new levels of algorithmic sophistication.</p>
        <p>In other situations, the comparisons tend to be among computer models, and cross-validation is less likely to be used. Measures, such as the Bayesian model evidence, minimum description length (MDL), Bayesian information criterion (BIC) and the Akaike information criterion (AIC), may be used for assessing how well models encode probability densities, thus allowing the evidence for different models to be compared, so that the best model for each particular dataset may be selected. Real Bayesian modellers do not use cross-validation, and the neuroimaging field is seeing the increasing use of evidence measures for choosing among models (<xref rid="bb0520 bb0070 bb0220 bb0095 bb0225 bb0340" ref-type="bibr">Penny et al., 2004; Beckmann and Smith, 2004; Friston et al., 2007; Behrens et al., 2007; Friston et al., 2008; Kiebel et al., 2008</xref>). Providing all the model assumptions are met, Bayesian strategies for model selection are more efficient – both in terms of computational complexity, and in terms of the available degrees of freedom (<xref rid="bb0545" ref-type="bibr">Rasmussen and Williams, 2006</xref>) – than cross-validation for selecting the optimal model from a number of candidates.</p>
        <p>Cross-validation is often used for optimising feature selection, or for adjusting other settings in the model. If there are not too many settings to adjust, then a grid search strategy can be used, where a range of settings are tried, and the most successful is chosen. However, within the Bayesian modelling framework, this type of approach can be greatly streamlined. The best model is the one with the highest model evidence, and the model fitting procedures are geared towards searching over the space of possible hyper-parameters in order to maximise this measure.</p>
      </sec>
      <sec id="s0050">
        <title>Large datasets</title>
        <p>Some investigators object to the Bayesian view of modelling because it involves the use of prior knowledge. Other approaches, such as orthodox statistical techniques, also involve some form of subjectivity — but this subjectivity is usually hidden. For example, what is so special about a value of 0.05 when assessing the significance of a <italic>p</italic> value? Should a correction for multiple comparisons be used when interpreting findings from multiple studies? For Bayesian methods, the relative effect of the priors becomes less important for large datasets, so findings become less subjective as more data are modelled.</p>
        <p>Bayesian model selection strategies try to identify the most appropriate model for the data, and the optimal choice relates to the quantity and quality of data. As more becomes available, the complexity of the optimal model will continue to increase until it reaches that of the system under study. In the case of biological systems, this complexity is likely to exceed that of typical datasets. For this reason (and others), the sharing and re-utilisation of valuable and well characterised data is likely to become increasingly important for the integrative models that are required for research in both systems biology and for translational work (<xref rid="bb0645" ref-type="bibr">Van Horn and Toga, 2009</xref>). Relatively few investigators build on primary data from previous fMRI studies because of the subjectivity of the stimuli used, and the difficulties inherent in attempting to organise the experiments into any useful structure. In contrast, as demonstrated by ADNI (<xref rid="bb0485 bb0140" ref-type="bibr">Mueller et al., 2005; Butcher, 2007</xref>) and other similar projects (<xref rid="bb0420" ref-type="bibr">Marcus et al., 2007</xref>), the primary data required for studies of anatomical variability tend to be re-used and built on extensively. Just as data generated by the Human Genome Project would be relatively worthless if only one investigator had access to it, the same may be true of primary data from large studies of neuroanatomical variability. If data is of sufficiently high quality and relevant, then others will wish to use it. Measures such as the <italic>h</italic>-index are becoming increasingly important as measures of productivity (rather than simply the numbers of publications) (<xref rid="bb0295" ref-type="bibr">Hirsch, 2007</xref>). Not only would data-sharing increase transparency and reproducibility of the scientific process, but it is also a way to help maximise the impact of work. Many funding bodies now require some sharing of primary data, and terms such as “mega-analysis” are beginning to enter the vocabularies of neuroimagers (<xref rid="bb0570" ref-type="bibr">Salimi-Khorshidi et al., 2009</xref>). Inevitably, some researchers will object to mixing data from different scanners, sequences etc, claiming that models of data collected on one scanner cannot be generalised to data from another. This is not an argument against pooling data, but is instead a quite different one.</p>
        <p>Given the exponentially increasing ease with which genes can be sequenced (and the exponentially decreasing cost), sharing primary data is likely to become especially important for future studies attempting to link genotype with phenotype. A search through hundreds of thousands, or even millions, of single nucleotide polymorphisms (or – within a few years – entire genomes) presents a colossal multiple comparisons problem. For this type of work, the aim would be to find those alleles that have the greatest measurable effect (any effect) on brain anatomy (or function). Identifying those genetic associations that best predict neuroanatomical variability will require multivariate modelling of very large datasets. Another approach to finding further clues about the causes of various disorders would be to generate a multivariate characterisation of the typical pattern of deviation from a control population. This pattern may be expressed to various degrees in the healthy population, which leads to the possibility of probing for the pattern in a large population of genetically characterised subjects.<xref rid="fn0040" ref-type="fn">8</xref></p>
      </sec>
    </sec>
    <sec id="s0055">
      <title>Generative modelling</title>
      <p>Data are usually pre-processed by modelling them generatively in order to derive useful features, which are subsequently fed into the discriminative framework. This section deals with certain aspects of <italic>Pattern Theory</italic>, which is a generative modelling framework that begins with the premise that real world patterns are complex, and that encoding this complexity should be allowed (<xref rid="bb0495 bb0500 bb0270" ref-type="bibr">Mumford, 1996; Mumford, 2002; Grenander and Miller, 2007</xref>). Simplifying organisational principles may emerge from such complex models, but these would not be discovered unless the data is modelled in all its complexity. Currently, much of Pattern Theory concerns shape modelling, although it is an area of research that is likely to expand and subsume a wider variety of probabilistic models. In principle, Pattern Theory is not really so different from other reputable Bayesian modelling strategies, but its ambitions may be greater in that it was formulated to deal with the kind of complexity encountered in biological systems. The ideas proposed within this review differ from the Pattern Theory perspective in that the generative modelling is treated as a pre-curser to a discriminative modelling step. Pattern Theory would involve a single unifying generative model for everything.</p>
      <p>Models based on Pattern Theory are also formulated to accommodate various symmetries and invariances. In this respect, the models are closer to those used by theoretical physicists, but allowing for a much greater amount of complexity. A framework for deriving metrics from <italic>diffeomorphic</italic> mappings will be introduced later. This framework is a component of Pattern Theory, and is based on a kind of <italic>exponential mapping</italic> procedure. First though, some simple illustrations of ordinary exponentiation will be presented.</p>
      <sec id="s0060">
        <title>Allometry</title>
        <p>Linear regression or classification based on original data is not always possible. Sometimes, some form of modelling can be used to transform it so that linear (or less non-linear) methods can be successfully applied. This section introduces the use of logarithms as a very simple pre-processing procedure, which, in turn, is a prelude to a later section of the paper.</p>
        <p>A widely used and convenient marker for obesity is Quetelet's Body Mass Index (BMI), which is defined as the weight of the subject (in kg) divided by the square of their height (in m). <xref rid="f0035" ref-type="fig">Fig. 7</xref> shows contours for different BMIs, which appear curved on a plot of height against weight, but straight when the logarithm of height is plotted against the logarithm of weight. We may also note that weights are not scaled with the cube of height (i.e. the relationship is not isometric), so ideal body proportions differ in a systematic and predictable way according to size. The relationship among the data can be expressed in a way that would be more intuitive for prediction by a multivariate model.<disp-formula id="fo0025"><alternatives><textual-form specific-use="jats-markup">log <italic>B</italic><italic>M</italic><italic>I</italic> = log <italic>w</italic><italic>e</italic><italic>i</italic><italic>g</italic><italic>h</italic><italic>t</italic> − 2log <italic>h</italic><italic>e</italic><italic>i</italic><italic>g</italic><italic>h</italic><italic>t</italic>.</textual-form><mml:math id="M6" altimg="si6.gif" overflow="scroll"><mml:mrow><mml:mo>log</mml:mo><mml:mspace width="0.12em"/><mml:mstyle mathvariant="monospace"><mml:mi>B</mml:mi><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>log</mml:mo><mml:mspace width="0.12em"/><mml:mstyle mathvariant="monospace"><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>log</mml:mo><mml:mspace width="0.12em"/><mml:mstyle mathvariant="monospace"><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mtext>.</mml:mtext></mml:mrow></mml:math></alternatives></disp-formula></p>
        <p>The field of studying the relationship among logarithms of measures is known as <italic>allometry</italic>. Unconstrained growth can be considered a process of self-replication (<xref rid="bb0310" ref-type="bibr">Huxley, 1993</xref>), and the logarithms of volumes, lengths etc can be seen as revealing more about the “causes” of the measurements, than the measures do themselves. The final shape of an organ can be modelled as the result of some pattern of differential growth rates, and the logarithms tell us something about these rates. When relating the magnitude of one measurement (<italic>y</italic>) to another (<italic>x</italic>), it is common to express the relationship by <italic>y</italic> = <italic>bx</italic><sup><italic>k</italic></sup>, where <italic>k</italic> and <italic>b</italic> are constants. An alternative way of expressing the relationship is by log <italic>y</italic> = log <italic>b</italic> + <italic>k</italic> log <italic>x</italic>. The parameter <italic>b</italic> is of little biological significance, whereas <italic>k</italic> (the exponent) can be considered as a measure of the relative growth.</p>
        <p>A number of investigators have related brain weight with body weight among different species. For example, (<xref rid="bb0435" ref-type="bibr">Martin, 1981</xref>) noted that from a sample of 309 species of placental mammals, log<sub>10</sub> <italic>y</italic> = 1.77 + 0.76 log<sub>10</sub> <italic>x</italic>, where <italic>y</italic> is brain weight and <italic>x</italic> is body weight. For a sample of 11 species of anthropoid primates, the relationship between brain volume and body weight was found to be log<sub>10</sub> <italic>y</italic> = 1.36 + 0.71 log<sub>10</sub> <italic>x</italic> (<xref rid="bb0550" ref-type="bibr">Rilling, 2006</xref>). <xref rid="bb0550" ref-type="bibr">Rilling (2006)</xref> also noted that the exponent of allometry relating cortical surface area and brain volume of primate brains is around 0.8, which is greater than the value of 0.67 that would be expected if brains varied isometrically. This work relates to that of (<xref rid="bb0730" ref-type="bibr">Zhang and Sejnowski, 2000</xref>), who devised an allometric model for grey and white matter volumes in mammalian brains. Larger brains contain proportionally more white matter, which has been confirmed using MR scans of human brains by (<xref rid="bb0395" ref-type="bibr">Luders et al., 2002</xref>). Sometimes, simple patterns can emerge from complex systems. One of the essential assumptions in allometric scaling theory is that convergent evolution leads to nearly optimal systems with similar gross characteristics (<xref rid="bb0680 bb0170 bb0675" ref-type="bibr">West et al., 2001; Csete and Doyle, 2002; West and Brown, 2005</xref>).</p>
        <p>In situations where no prior data are available, the Bayesian framework allows the use of uninformative priors. Where variables are real values that may be negative as well as positive, an uninformative prior would assume that all values, both positive and negative, are equally possible.<xref rid="fn0045" ref-type="fn">9</xref> Where variables may only be positive, a different strategy is used for assigning priors. Here, the probability of a value being between one and 10 is equal to the probability of it being between 10 and 100, or 0.001 and 0.01. This type of prior is uniformly flat for the logarithm of the variable. It should be noted that the products of positive real values are also positive real values, and that the sum of the logarithms of positive real values is also the logarithm of a positive real value. In other words, they form what, in mathematics, is called a <italic>group</italic>. Group theory provides a principled mechanism by which to assign priors (<xref rid="bb0320" ref-type="bibr">Jaynes and Bretthorst, 2003</xref>), and is one of the cornerstones of Pattern Theory.</p>
        <p>The use of logarithms to transform the measurements may allow the discovery of interesting relationships among data, via the application of linear pattern recognition. Where there are multiple measurements, the multivariate relationship could be expressed by log <italic>y</italic> = log <italic>b</italic> + ∑ <sub><italic>j</italic></sub> <sub>=</sub> <sub>1</sub><sup><italic>J</italic></sup> <italic>w</italic><sub><italic>j</italic></sub> log <italic>x</italic><sub><italic>j</italic></sub>. Unfortunately, there are certain problems in applying a simple allometric model to shape measures, which occur because growth is not unconstrained, and neighbouring or overlapping structures need to grow together. <xref rid="bb0310" ref-type="bibr">Huxley (1993)</xref> pointed out that the logarithm of the volume/mass of a structure should be related to the volume/mass of the whole organism minus that of the structure. Similar concerns were identified by (<xref rid="bb0730" ref-type="bibr">Zhang and Sejnowski, 2000</xref>), who related grey matter volume to white matter volume, and also grey matter volume to the sum of grey and white matter volume. If the relationship that log <italic>y</italic> = log <italic>b</italic> + <italic>k</italic> log <italic>x</italic> holds, then it is not possible for log <italic>y</italic> = log <italic>b</italic>′ + <italic>k</italic>′log(<italic>x</italic> + <italic>y</italic>) also to hold. Resolving this inconsistency requires a different model to account for such correlations. That model may be the one based on the group of diffeomorphisms.</p>
      </sec>
      <sec id="s0065">
        <title>Identical functions of very different coordinate systems</title>
        <p>Merriam-Webster's Medical Dictionary defines <italic>morphometry</italic> as the quantitative measurement of the form especially of living systems or their parts, where <italic>form</italic> means the shape and structure of something as distinguished from its material. The study of form is largely derived from the generative model of D'Arcy Thompson (<xref rid="bb0610" ref-type="bibr">Thompson and Bonner, 1942</xref>), who stated that ‘diverse and dissimilar fish [brains] can be referred as a whole to identical functions of very different coordinate systems, this fact will of itself constitute a proof that a comprehensive “law of growth” has pervaded the whole structure in its integrity, and that some more or less simple and recognizable system of forces has been at work’.</p>
        <p>Conventionally, the neuroimaging field treats inter-subject variability as different functions of near-identical coordinate systems. fMRI studies, involving comparisons among populations of subjects, usually attribute their findings to what may be referred to as “functional variability”, whereas many of the results could equally be attributable to variability of the underlying anatomy. Interpretations of exactly what is meant by functional variability may include variability of the magnitude of activations, or activations occurring within non-homologous structures. Unfortunately, the very definition of what constitutes a homology is unclear, which makes it difficult to draw any sharp distinction between “functional” and “anatomical” variability.</p>
        <p>Literal adherence to Thompson's model would have implications for how functional data should be used to further our understanding of inter-subject variability. Such a model would require that fMRI be used as a way of labeling the various regions of functional specialization, thereby allowing image registration procedures to bring these labeled regions into alignment (<xref rid="bb0575 bb0565" ref-type="bibr">Saxe et al., 2006; Sabuncu et al., 2009</xref>). Studies of inter-subject variability could then be based upon the relative shapes of the brains, as estimated by registration algorithms.</p>
        <p>Similarly, diffusion weighted MRI could provide information that allows more accurate measurement of relative shape (<xref rid="bb0085 bb0090 bb0350 bb0325" ref-type="bibr">Behrens et al., 2003, 2006; Klein et al., 2007; Johansen-Berg et al., 2005</xref>). Under an assumption that brains all have the same pattern of major tracts, it would appear reasonable to align the brains based on their tracts and simply compare the resulting shapes. A number of approaches are already being developed to align brains using diffusion data (<xref rid="bb0010 bb0280 bb0560 bb0515 bb0725" ref-type="bibr">Alexander et al., 1999; Guimond et al., 2002; Ruiz-Alzola, 2002; Park et al., 2003; Zhang et al., 2006</xref>). It is common for investigators to want to compare the positions of tracts among spatially normalised images, but findings from such an analysis would essentially be about mis-registration. This is useful for evaluating image registration models, but would not necessarily be considered interesting from a physiological perspective.</p>
        <p>In reality, the pure D'Arcy Thompson model may over-exaggerate the importance of form to our understanding of variability. Language lateralization provides a clear example of where such a model would fail, as it involves patterns of functional specialization that could clearly not be modelled by shape differences alone. Because the term “homologous” is only vaguely defined, future advances to our understanding of variability may be more likely to arise from models that have the potential to combine form-like and function-like variance, in an elegant and parsimonious manner.</p>
        <p>Shape models are an important component of the feature sets used for pattern recognition (<xref rid="bb0260 bb0265" ref-type="bibr">Golland et al., 2001, 2005</xref>), but features based on residual differences after registration are also of potential importance (<xref rid="bb0415" ref-type="bibr">Makrogiannis et al., 2007</xref>), particularly if information from fMRI or diffusion imaging is to be included within the model. It is possible that increased power may be achieved by using a more sophisticated model for these patterns of residual variability (<xref rid="bb0630" ref-type="bibr">Trouvé and Younes, 2005</xref>). There is much that could be said on the subject of template models of the brain and how they relate to this pattern, but it would be beyond the scope of this review. In the next sections, we will try to explain how the residual differences after registration can actually be used to encode deformations (<xref rid="bb0710" ref-type="bibr">Younes, 2007</xref>). The registration model that is needed for achieving this goal appears rather more complicated than most, but it may have the potential to simplify the feature sets used for multivariate analysis.</p>
      </sec>
      <sec id="s0070">
        <title>Diffeomorphic shape models</title>
        <p>A <italic>diffeomorphism</italic> is a smooth, one-to-one mapping, and the diffeomorphic framework developed by Miller, Younes, Grenander and others (<xref rid="bb0455 bb0275 bb0460 bb0270 bb0465" ref-type="bibr">Miller et al., 1997; Grenander and Miller, 1998; Miller, 2004; Grenander and Miller, 2007; Miller and Qiu, 2009</xref>) is potentially very useful for modelling shapes of brains. There is a large literature on mathematical shape models, but much of it is aimed at mathematicians, and may not be accessible to investigators who do not have a solid mathematical background. In this section, we try to provide a more intuitive understanding of some of the principles that underlie these developments, attempting to convey their importance with as little mathematical notation as possible. To further simplify the explanations, the principles will be illustrated using the simple two dimensional example images shown in <xref rid="f0040" ref-type="fig">Fig. 8</xref>. These images were aligned to their common average shape, where this involved iteratively alternating between recomputing a template and re-estimating the warps that map between the template and the original data. With this simple model, computing the template image involved generating a pixel-wise weighted average of the warped images, where the weighting is by the Jacobian determinants of the warps. These Jacobians indicate the amount of local expansion or contraction incurred by the non-linear deformations. After registration, the volume of a structure in each of the original images can be estimated by summing the Jacobians over the region of template containing the structure. A key feature of diffeomorphic registration methods is that the Jacobians cannot become negative, which ensures that estimated volumes are also never negative.</p>
        <p>In theory, diffeomorphic deformations have a number of useful properties. When two diffeomorphic deformations are composed together, then the result is diffeomorphic. If multiple diffeomorphisms are composed, then it does not matter whether it is done as <italic>A</italic> ∘ (<italic>B</italic> ∘ <italic>C</italic>) or (<italic>A</italic> ∘ <italic>B</italic>) ∘ <italic>C</italic>. A diffeomorphic mapping that is conceptually useful sometimes, is the identity transform. When this is used to warp an image, then the image remains the same. With diffeomorphic registration, there should be no folds in the deformations and all Jacobian determinants should be positive. Folding would indicate that the one-to-one mappings have broken down (<xref rid="bb0155" ref-type="bibr">Christensen et al., 1995</xref>). Because they encode one-to-one mappings, diffeomorphisms also have inverses. All these properties mean that diffeomorphisms form a mathematical group.</p>
        <p>For a pair of numbers close to one, it is possible to approximate multiplying them together by subtracting one from each of them, adding the results together and adding back one. For example, the result of 1.02 × 0.995 × 1.003 can be approximated by 0.02 − 0.005 + 0.003 + 1 (to give 1.018, instead of 1.0179447). This approximation becomes less accurate as the numbers deviate further away from one. The small deformation framework, which most investigators use for working with deformations, is similar to this approximation. It involves subtracting an identity transform, working with some linear model of the resulting displacement fields and then adding the identity transform back again. This approximation may be reasonable when displacements are very small, but is less accurate when the deformations are larger — a point illustrated in <xref rid="f0045" ref-type="fig">Fig. 9</xref>. Shapes are the ultimate non-linear sort of thing (<xref rid="bb0500" ref-type="bibr">Mumford, 2002</xref>), and building accurate models requires some more sophisticated mathematics.</p>
        <p>Allometry involves treating an original measurement of length, area, volume etc as the exponential of a growth rate. If a structure begins with a volume of one, and grows at a constant rate of <italic>k</italic>, then its final value after one unit of time will be exp(<italic>k</italic>). Similarly, the framework for diffeomorphisms involves treating the deformation of objects as a kind of exponential mapping (<italic>Riemannian exponential mapping</italic> — see e.g. <xref rid="bb0720" ref-type="bibr">Younes et al., 2009</xref>). In this case, the deformation begins as an identity transform (no deformation), and the object deforms at a constant rate over unit time. The procedure considers the evolving deformation as a dynamical system, and the rate of deformation can be considered analogous to the logarithms in the allometric framework.</p>
        <sec id="s0075">
          <title>Distance measures for non-linear pattern recognition</title>
          <p>One technique for comparing shapes in a non-linear multivariate way is to use metrics (<xref rid="bb0635" ref-type="bibr">Trouvé and Yu, 2001</xref>). These are measures of distance between points, which satisfy a number of requirements. Often when we consider distances, we are dealing with linear spaces, but there are many instances when the underlying space is curved (non-linear). A simple example would be a distance between two world cities, where the shortest path between them, tangential to the surface of the globe, would serve as a metric (see earlier). The earth's surface can be thought of as a two dimensional manifold, embedded within a three dimensional Euclidean space. The paths would follow <italic>geodesics</italic>, which are defined as the (locally) shortest distances between points in a curved space. When working with scans of different subjects, the idea would be to have a measure of distance between each pair of scans. Such metrics lend themselves easily to the use of radial basis function kernel pattern recognition algorithms, as the elements of the kernel matrix are simply a function of distance between pairs of images. Alternatively, there are ways of classifying a new point based on finding the closest points in the training data, and making the assignment based on which group they belong to (K-nearest neighbour).</p>
          <p>Pattern recognition and other multivariate methods have been applied to metrics derived by inter-subject registration (<xref rid="bb0475" ref-type="bibr">Miller et al., 2008</xref>). These metrics may be thought of as measures of the distance travelled by one brain as it is warped to the shape of another, but they are not based on simple lengths of trajectories of the voxels. Instead, the measures consider the relationships among the trajectories of neighbouring voxels. For example, if a set of neighbouring voxels move in parallel with each other, the distance is likely to be shorter than if they move in different directions. If their motion remains parallel, then this is simply a uniform displacement — rather than a shape change. If they move in different directions, then this results in a change of shape. Defining distances this way provides a measure of smoothness of the deformations, and hence the amount of distortion. There are many ways to specify metrics between anatomies, and the choice may depend on the application (<xref rid="bb0505" ref-type="bibr">Mumford, 2005</xref>). Shapes can vary in different ways, and the accuracy of pattern recognition algorithms can be helped by knowing what kind of measures are most likely to be informative. This is the <italic>Ugly Duckling Theorem</italic><xref rid="fn0050" ref-type="fn">10</xref> (<xref rid="bb0670" ref-type="bibr">Watanabe, 1969</xref>), which says that all objects are equally similar to each other, unless the importance of certain distinguishing features is known a priori.</p>
          <p>Image registration algorithms such as <italic>Large Deformation Diffeomorphic Metric Mapping</italic> (LDDMM) (<xref rid="bb0080" ref-type="bibr">Beg et al., 2005</xref>) may be used for measuring these distances between shapes. LDDMM is a volumetric image registration procedure, which aligns images by minimising the sum of squares difference between them, while keeping a metric distance as short as possible. Although LDDMM was formulated in a continuous way, it can be conceptualised as an algorithm that estimates a series of small deformations, which are composed together to give a large diffeomorphic deformation. The objective is to estimate the entire series of deformations, such that the total measure of “energy” in the small deformations is as small as possible. Elegant mathematics underlying the formulation of LDDMM mean that the locally shortest distance (<italic>geodesic distance</italic>) may be found by minimising this total energy. These distances may serve as metrics, which may be used for non-linear pattern recognition.</p>
          <p>With current technology, such an approach is too computationally expensive for routine use, as it requires each pair of images to be registered together. For example, if there are 100 subjects in a study, then 5050 registrations are needed to obtain the metric between each pair of subjects' data. For this reason, this review will focus on a slightly different framework, which is based on approximating the curved space by assuming that it is locally flat (i.e. working on the <italic>tangent space</italic>).</p>
        </sec>
        <sec id="s0080">
          <title>Local linear approximation methods</title>
          <p>Approximating a curved space by a linear (flat) space involves introducing distortions, which need to be overcome as far as possible. For example, projections of the globe on to a flat two dimensional map (e.g. by the Mercator projection) incur distortions, but the centre of the map tends to be less distorted than those regions towards the edges. Reducing the amount of distortion in a linear approximation can involve centering the origin of the flat coordinate system at a suitable location. When considering shapes as points on some manifold, the least distortion would be achieved by centering the origin at the “average” of those shapes (<xref rid="bb0695" ref-type="bibr">Woods, 2003</xref>). It would seem intuitive that warping individual subjects to an average shaped template would reduce bias in an analysis, rather more than warping all subjects to match a randomly selected individual from the group (<xref rid="bb0075" ref-type="bibr">Beg and Khan, 2006</xref>). However, an average in a non-linear space is more difficult to compute than an average in a Euclidean (flat) space, and can be achieved by minimising the sum of squares of the geodesic distances (metrics) between the mean, and each of the individual points. This approach is implicitly used by a number of group-wise volumetric registration models (e.g. <xref rid="bb0330 bb0050 bb0390" ref-type="bibr">Joshi et al., 2004; Avants and Gee, 2004; Lorenzen et al., 2005</xref>).</p>
          <p>Once all images have been aligned with their average shaped template, interesting features may then be derived from them. Diffeomorphic mappings have a number of properties that makes them potentially useful for analysis of inter-subject variability. The LDDMM algorithm estimates a mapping between images by minimising a geodesic distance between them, but estimating the same mapping can be formulated from a different perspective. Using a procedure is known as <italic>geodesic shooting</italic>, it is possible to derive the entire mapping from the initial velocity with which the template would be deformed at a constant rate over unit time. The mathematics are too deep to enter into details here, but <xref rid="f0050" ref-type="fig">Fig. 10</xref> attempts to illustrate the evolution of the dynamical system for one of the images in <xref rid="f0040" ref-type="fig">Fig. 8</xref>. The underlying mathematics are explained, from a number of perspectives, by <xref rid="bb0470" ref-type="bibr">Miller et al. (2006)</xref>, <xref rid="bb0160" ref-type="bibr">Cotter and Holm (2006)</xref>, <xref rid="bb0430 bb0710 bb0715 bb0720" ref-type="bibr">Marsland and McLachlan (2007), Younes (2007), and Younes et al. (2008, 2009)</xref>. Referring to <xref rid="f0050" ref-type="fig">Fig. 10</xref>, it is possible to conceptualise the evolving deformation as the composition of a series of very small deformations. The last two columns of the figure show the evolving deformation, and the relative amount of expansion or contraction incurred at each point. The displacements of each small deformation are given by the velocity fields shown in the seventh and eighth columns of the figure. The velocity is a vector field, with horizontal and vertical components, and is obtained from the “momentum” by convolving it with a suitably smooth function (<xref rid="bb0135" ref-type="bibr">Bro-Nielsen and Cotin, 1996</xref>).</p>
          <p>The main point to be made here, is that the momentum may be computed from a map of residual differences multiplied (voxel by voxel) by the spatial gradients of the template. The same template is warped into alignment with each of the images, so its contribution to the initial velocity is the same for all of the individual images. The thing that differs among individuals is the map of residuals. Given the template, the individual images are fully specified (give or take some interpolation error) by their associated residuals. <xref rid="f0055" ref-type="fig">Fig. 11</xref> shows these residuals for all the individual images. It should be noted that much of the information in these maps of residuals is in alignment across images. This and the fact that they are scalar rather than a vector fields, along with their sparsity over space, would suggest that they offer a very parsimonious way of encoding the variability of the deformations (<xref rid="bb0710" ref-type="bibr">Younes, 2007</xref>). Not only do these maps encode deformations, but they also encode the residual differences after alignment.</p>
          <p>At this point, it is important to stress that the simple residual images do not offer the most optimal shape-based features. In other words, simple dot-products among pairs of residual images would not generate a kernel matrix that would lead to the most accurate pattern recognition. A measure of similarity between the shapes of two objects would be computed from the dot-product of the initial velocity for one shape, and the initial momentum of the other. Momentum may be derived via a matrix multiplication of the residuals by a matrix <bold>G</bold> (where the matrix consists of diagonal matrices containing the gradients of the template). Similarly, the convolution operation for computing initial velocity from initial momentum may also be conceptualised as a multiplication with matrix <bold>K</bold>. For further details of this approach, see e.g. <xref rid="bb0640 bb0665" ref-type="bibr">Vaillant et al. (2004), Wang et al., 2007</xref>, and <xref rid="bb0535" ref-type="bibr">Qiu and Miller (2008)</xref>. Returning to the Gaussian process modelling framework, the similarity among shapes may be expressed as <bold>XWX</bold><sup><italic>T</italic></sup>, where <bold>X</bold> encodes the residual differences and <bold>W</bold> subsumes all the matrices for generating the necessary dot-products of momentum and velocity: <bold>W</bold> = <bold>GKG</bold><sup><italic>T</italic></sup>. In principle, the above framework could be extended further such that other aspects of the residuals could also contribute. A simple example would be <bold>W</bold>(<italic>θ</italic><sub>2</sub>, <italic>θ</italic><sub>3</sub>) = <italic>θ</italic><sub>2</sub><bold>GKG</bold><sup><italic>T</italic></sup> + <italic>θ</italic><sub>3</sub><bold>I</bold>, where <bold>I</bold> is an identity matrix. Many variations on this same theme could be developed.</p>
          <p>A similar framework is also applicable for other objective functions used as matching criteria (<xref rid="bb0720" ref-type="bibr">Younes et al., 2009</xref>). For example, fMRI or diffusion MR data could be included within the registration procedure, which would allow the inter-subject variability of both form and function to be combined within the same model. Previously, (<xref rid="bb0415 bb0060" ref-type="bibr">Makrogiannis et al., 2007; Baloch and Davatzikos, 2009</xref>) used a pattern recognition framework, whereby both maps of residual differences between warped individuals and the template, as well as deformation fields were used as features. A balance was sought between the contributions made by the residual differences between aligned tissue class images and template, and the deformation fields. This section has tried to show that the residual differences themselves, after scaling by the Jacobian determinants of the deformations, are enough to encode the deviation of the original images from the template.</p>
          <p>Brain images can be registered volumetrically using this way of encoding relative shape, and an example of an average is shown in <xref rid="f0060" ref-type="fig">Fig. 12</xref>. The entire dataset<xref rid="fn0055" ref-type="fn">11</xref> from the EPSRC funded IXI dataset were diffeomorphically aligned, except for subjects IXI012 and IXI050. Registration used a similar procedure to that described by (<xref rid="bb0040" ref-type="bibr">Ashburner and Friston, 2009</xref>), except that the opimised parameters encoded initial velocities for geodesic shooting, rather than the constant velocity parameterisation used by Dartel (<xref rid="bb0025" ref-type="bibr">Ashburner, 2007</xref>). When averaging, the images were intensity normalised so that their average intensities were identical, and the Jacobian determinants were used to weight the average. Note that regions outside the brain appear blurred as registration was only based on simultaneous alignment of grey and white matter.</p>
        </sec>
      </sec>
      <sec id="s0085">
        <title>Visualising differences</title>
        <p>One of the major problems of multivariate techniques is in interpreting the pattern of findings. Unlike mass-univariate approaches, these are global and not localised to discrete regions. For various reasons, the neuroimaging field may be reluctant to accept such a framework, but multivariate morphometric approaches are widely accepted within other biological domains for making comparisons among species. A model of anatomical variability that works well between species should also be applicable within species.</p>
        <p>Although it has not yet been clearly demonstrated for anatomical brain images, it is likely that models that are multivariate over space may be more accurate than those that model each voxel independently. The main challenge to be overcome for multivariate morphometric studies concerns visualising and communicating the findings, which is probably why so many geometric morphometric studies of the brain have focussed on simple two dimensional structures such as the corpus collosum. Three dimensional volumes are quite difficult to visualise, especially within the limited space of most journals. This is further complicated by the fact that patterns of difference are often vector or tensor fields, which are quite difficult to visualise in two dimensions, but in three dimensions the problem becomes much worse. In comparison, differences localised by voxelwise methods can be easily presented in the form of statistical parametric maps, particularly if relatively few differences are identified. Although the reasons may appear trivial, voxelwise models will probably continue to dominate because their results can be explained and presented much more easily.</p>
        <p>For linear classifiers, it is possible to represent the discriminative direction (<xref rid="bb0255 bb0265" ref-type="bibr">Golland, 2002; Golland et al., 2005</xref>) by a vector that has the same dimensionality as the data features of each individual. This would be the vector <bold>a</bold> in the expression <italic>y</italic> = <italic>f</italic>(<bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> + <italic>b</italic>). Non-linear classification presents an additional problem, in that any attempt at encoding a discriminative direction will only be an approximation (<xref rid="bb0255" ref-type="bibr">Golland, 2002</xref>). The reason for this is that the separating hyperplane is curved, so the direction perpendicular to it will vary from place to place.</p>
        <p>Representations of shape differences from surface-based models may often be visualised more easily, especially if relatively simple structures are modelled. For example, (<xref rid="bb0260" ref-type="bibr">Golland et al., 2001</xref>) shows displacements by first projecting them in the directional perpendicular to the surface (see <xref rid="f0010" ref-type="fig">Fig. 2</xref>). In fact, with the appropriate diffeomorphic registration model, any momentum differences will be perpendicular.</p>
        <p>So far, relatively little work has been carried out on how best to visualise and communicate multivariate patterns of difference. One possible approach may be to generate caricatures. <xref rid="f0065" ref-type="fig">Fig. 13</xref> shows exaggerated versions of male and female brains from the IXI dataset (<xref rid="f0060" ref-type="fig">Fig. 12</xref>), which were generated using a geodesic shooting method. Pattern recognition was by fitting a regularised logistic regression model using a linear kernel matrix, based on dot-products of initial momentum and initial velocity (<xref rid="bb0640 bb0665" ref-type="bibr">Vaillant et al., 2004; Wang et al., 2007</xref>). Scans in the IXI dataset were collected on three different scanners. Scanner and subject ages were included as a confounds within the model (so three subjects with unknown ages were excluded), so the optimisation involved parameterising a covariance matrix by<disp-formula id="fo0030"><alternatives><textual-form specific-use="jats-markup"><bold>C</bold> = <italic>θ</italic><sub>0</sub><bold>I</bold> + <italic>θ</italic><sub>1</sub> + <italic>θ</italic><sub>2</sub><bold>X</bold><bold>G</bold><bold>K</bold><bold>G</bold><sup><italic>T</italic></sup><bold>X</bold><sup><italic>T</italic></sup> + <italic>θ</italic><sub>3</sub><bold>S</bold><bold>S</bold><sup><italic>T</italic></sup> + <italic>θ</italic><sub>4</sub><bold>a</bold><bold>a</bold><sup><italic>T</italic></sup></textual-form><mml:math id="M7" altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">C</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">I</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi><mml:mi mathvariant="bold">G</mml:mi><mml:mi mathvariant="bold">K</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">G</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">X</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">S</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">S</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">a</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold">a</mml:mi></mml:mstyle><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></disp-formula>where <bold>X</bold> encodes the residuals, <bold>S</bold> encodes which scanner was used and <bold>a</bold> encodes the ages of the subjects. Multiplication with matrix <bold>K</bold> is essentially the same as convolving with the same smooth function used by the image registration algorithm. The discriminating direction was identified from the model, in terms of an initial velocity. From this, it was possible to determine how far to deform the average shaped brains along the discriminating direction, such that the shape was either male or female, with 99.99999% probability. A geodesic shooting method was used to evolve the shapes, which meant that the exaggerated deformations did not lose their one-to-one mapping.</p>
      </sec>
    </sec>
    <sec id="s0090">
      <title>Conclusion</title>
      <p>This paper has emphasised a Pattern Theoretic perspective on modelling neuroimaging data, with some compromises in terms of treating the parts of the model for “pre-processing” separately from those parts used for making statistical inference. Fully Bayesian generative models of inter-subject variability are not yet practically feasible. Instead, a generative model is used for pre-processing, and a discriminative model is used for making predictions.</p>
      <p>It usually requires several decades for basic science to become applied science, so it is worth considering which basic science approaches have the greatest potential for translation. Over the shorter term, translation is likely to require accurate models of inter-subject variability in order to fully utilise the information that is available within MR scans. Some of the more immediate applications are for diagnostics and biomarkers, and for localising abnormalities. Other applications may involve registering useful atlas-based information on to scans of individuals for the purpose of pre-surgical planning. All these examples require accurate models of inter-subject variability, as well as a useful framework in which to formulate a variety of questions.</p>
      <p>Computer power is currently doubling approximately every year and a half, which implies a ten-fold increase in speed every five years. If this trend continues, processing speeds will increase by a factor of one hundred in ten years, ten thousand in twenty years, and by a million in thirty years. So far, only a few tentative steps have been made towards applying machine learning techniques to neuroscience and medicine. Given enough processing power and good scientists working together to develop increasingly accurate models, there is no reason why computers could not play a much larger role in future.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bb0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adams</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Rohlf</surname>
              <given-names>F.J.</given-names>
            </name>
            <name>
              <surname>Slice</surname>
              <given-names>D.E.</given-names>
            </name>
          </person-group>
          <article-title>Geometric morphometrics: ten years of progress following the revolution</article-title>
          <source>Ital. J. Zool.</source>
          <volume>710</volume>
          <issue>1</issue>
          <year>2004</year>
          <fpage>5</fpage>
          <lpage>16</lpage>
        </element-citation>
      </ref>
      <ref id="bb0010">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Alexander</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Gee</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bajcsy</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <chapter-title>Elastic matching of diffusion tensor MRIs</chapter-title>
          <source>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 1</source>
          <year>1999</year>
          <fpage>244</fpage>
          <lpage>249</lpage>
        </element-citation>
      </ref>
      <ref id="bb0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Allassonnière</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Amit</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Towards a coherent statistical framework for dense deformable template estimation</article-title>
          <source>J. R. Stat. Soc. B Methodol.</source>
          <volume>690</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>3</fpage>
          <lpage>29</lpage>
        </element-citation>
      </ref>
      <ref id="bb0020">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Amari</surname>
              <given-names>S.I.</given-names>
            </name>
            <name>
              <surname>Nagaoka</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <chapter-title>Methods of Information Geometry</chapter-title>
          <year>2007</year>
          <publisher-name>AMS Bookstore</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>A fast diffeomorphic image registration algorithm</article-title>
          <source>Neuroimage</source>
          <volume>380</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>95</fpage>
          <lpage>113</lpage>
          <pub-id pub-id-type="pmid">17761438</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Multimodal image coregistration and partitioning—a unified framework</article-title>
          <source>Neuroimage</source>
          <volume>60</volume>
          <issue>3</issue>
          <year>1997</year>
          <fpage>209</fpage>
          <lpage>217</lpage>
          <pub-id pub-id-type="pmid">9344825</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Why voxel-based morphometry should be used</article-title>
          <source>Neuroimage</source>
          <volume>140</volume>
          <issue>6</issue>
          <year>2001</year>
          <fpage>1238</fpage>
          <lpage>1243</lpage>
          <pub-id pub-id-type="pmid">11707080</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Computing average shaped tissue probability templates</article-title>
          <source>NeuroImage</source>
          <volume>450</volume>
          <issue>2</issue>
          <year>2009</year>
          <fpage>333</fpage>
          <lpage>341</lpage>
          <pub-id pub-id-type="pmid">19146961</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hutton</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Johnsrude</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Identifying global anatomical differences: deformation-based morphometry</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>60</volume>
          <issue>5–6</issue>
          <year>1998</year>
          <fpage>348</fpage>
          <lpage>357</lpage>
          <pub-id pub-id-type="pmid">9788071</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Avants</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Gee</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Geodesic estimation for large deformation anatomical shape averaging and interpolation</article-title>
          <source>Neuroimage</source>
          <volume>23</volume>
          <year>2004</year>
          <fpage>139</fpage>
          <lpage>150</lpage>
        </element-citation>
      </ref>
      <ref id="bb0055">
        <mixed-citation publication-type="other">Bach, F.R., Jordan, M.I. A probabilistic interpretation of canonical correlation analysis. <italic>Dept. Statist., Univ. California, Berkeley, CA, Tech. Rep</italic>, 688, 2005.</mixed-citation>
      </ref>
      <ref id="bb0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baloch</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Morphological appearance manifolds in computational anatomy: groupwise registration and morphological analysis</article-title>
          <source>Neuroimage</source>
          <volume>450</volume>
          <issue>1S1</issue>
          <year>2009</year>
          <fpage>73</fpage>
          <lpage>85</lpage>
        </element-citation>
      </ref>
      <ref id="bb0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baron-Cohen</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The extreme male brain theory of autism</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>60</volume>
          <issue>6</issue>
          <year>2002</year>
          <fpage>248</fpage>
          <lpage>254</lpage>
          <pub-id pub-id-type="pmid">12039606</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic independent component analysis for functional magnetic resonance imaging</article-title>
          <source>IEEE Trans. Med. Imaging</source>
          <volume>230</volume>
          <issue>2</issue>
          <year>2004</year>
          <fpage>137</fpage>
          <lpage>152</lpage>
          <pub-id pub-id-type="pmid">14964560</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0075">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Beg</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Computing an average anatomical atlas using LDDMM and geodesic shooting</chapter-title>
          <source>3rd IEEE International Symposium on Biomedical Imaging: Nano to Macro</source>
          <year>2006</year>
          <fpage>1116</fpage>
          <lpage>1119</lpage>
        </element-citation>
      </ref>
      <ref id="bb0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beg</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Computing large deformation metric mappings via geodesic flows of diffeomorphisms</article-title>
          <source>Int. J. Comput. Vis.</source>
          <volume>610</volume>
          <issue>2</issue>
          <year>2005</year>
          <fpage>139</fpage>
          <lpage>157</lpage>
        </element-citation>
      </ref>
      <ref id="bb0085">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Johansen-Berg</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Wheeler-Kingshott</surname>
              <given-names>C.A.M.</given-names>
            </name>
            <name>
              <surname>Boulby</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Barker</surname>
              <given-names>G.J.</given-names>
            </name>
            <name>
              <surname>Sillery</surname>
              <given-names>E.L.</given-names>
            </name>
            <name>
              <surname>Sheehan</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Ciccarelli</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Non-invasive mapping of connections between human thalamus and cortex using diffusion imaging</article-title>
          <source>Nat. Neurosci.</source>
          <volume>60</volume>
          <issue>7</issue>
          <year>2003</year>
          <fpage>750</fpage>
          <lpage>757</lpage>
          <pub-id pub-id-type="pmid">12808459</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Jenkinson</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Robson</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Johansen-Berg</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>A consistent relationship between local white matter architecture and functional specialisation in medial frontal cortex</article-title>
          <source>Neuroimage</source>
          <volume>300</volume>
          <issue>1</issue>
          <year>2006</year>
          <fpage>220</fpage>
          <lpage>227</lpage>
          <pub-id pub-id-type="pmid">16271482</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Berg</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Jbabdi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rushworth</surname>
              <given-names>M.F.S.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic diffusion tractography with multiple fibre orientations: what can we gain?</article-title>
          <source>Neuroimage</source>
          <volume>340</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>144</fpage>
          <lpage>155</lpage>
          <pub-id pub-id-type="pmid">17070705</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bell</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Sejnowski</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>An information-maximization approach to blind separation and blind deconvolution</article-title>
          <source>Neural Comput.</source>
          <volume>70</volume>
          <issue>6</issue>
          <year>1995</year>
          <fpage>1129</fpage>
          <lpage>1159</lpage>
          <pub-id pub-id-type="pmid">7584893</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0105">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
          </person-group>
          <chapter-title>Variational principal components</chapter-title>
          <source>Artificial Neural Networks. ICANN 99. Ninth International Conference on (Conf. Publ. No. 470), volume 1</source>
          <year>1999</year>
        </element-citation>
      </ref>
      <ref id="bb0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Lasserre</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Generative or discriminative? Getting the best of both worlds</article-title>
          <source>Bayesian Stat.</source>
          <volume>8</volume>
          <year>2007</year>
          <fpage>3</fpage>
          <lpage>24</lpage>
        </element-citation>
      </ref>
      <ref id="bb0115">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
          </person-group>
          <chapter-title>Pattern Recognition and Machine Learning</chapter-title>
          <year>2006</year>
          <publisher-name>New York</publisher-name>
          <publisher-loc>Springer</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0120">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bookstein</surname>
              <given-names>F.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Biometrics and brain maps: the promise of the morphometric synthesis</chapter-title>
          <source>Neuroinformatics: an Overview of the Human Brain Project</source>
          <year>1996</year>
        </element-citation>
      </ref>
      <ref id="bb0125">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bookstein</surname>
              <given-names>F.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Morphometric Tools for Landmark Data: Geometry and Biology</chapter-title>
          <year>1997</year>
          <publisher-name>Cambridge Univ. Pr</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0130">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Boser</surname>
              <given-names>B.E.</given-names>
            </name>
            <name>
              <surname>Guyon</surname>
              <given-names>I.M.</given-names>
            </name>
            <name>
              <surname>Vapnik</surname>
              <given-names>V.N.</given-names>
            </name>
          </person-group>
          <chapter-title>A training algorithm for optimal margin classifiers</chapter-title>
          <source>Proceedings of the Fifth Annual Workshop on Computational Learning Theory</source>
          <year>1992</year>
          <publisher-name>ACM New York</publisher-name>
          <publisher-loc>NY, USA</publisher-loc>
          <fpage>144</fpage>
          <lpage>152</lpage>
        </element-citation>
      </ref>
      <ref id="bb0135">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bro-Nielsen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cotin</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <chapter-title>Real-time volumetric deformable models for surgery simulation using finite elements and condensation</chapter-title>
          <source>Computer Graphics Forum, volume 15</source>
          <year>1996</year>
          <fpage>57</fpage>
          <lpage>66</lpage>
        </element-citation>
      </ref>
      <ref id="bb0140">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Butcher</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Alzheimer's researchers open the doors to data sharing</article-title>
          <source>Lancet Neurol.</source>
          <volume>60</volume>
          <issue>6</issue>
          <year>2007</year>
          <fpage>480</fpage>
          <lpage>481</lpage>
          <pub-id pub-id-type="pmid">17509479</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chance</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Esiri</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Crow</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>Macroscopic brain asymmetry is changed along the antero-posterior axis in schizophrenia</article-title>
          <source>Schizophr. Res.</source>
          <volume>740</volume>
          <issue>2–3</issue>
          <year>2005</year>
          <fpage>163</fpage>
          <lpage>170</lpage>
          <pub-id pub-id-type="pmid">15721996</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0150">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Chapelle</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Schölkopf</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Zien</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Semi-Supervised Learning</chapter-title>
          <year>2006</year>
        </element-citation>
      </ref>
      <ref id="bb0155">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Christensen</surname>
              <given-names>G.E.</given-names>
            </name>
            <name>
              <surname>Rabbitt</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Joshi</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Grenander</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Coogan</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <chapter-title>Topological properties of smooth anatomic maps</chapter-title>
          <source>Information processing in medical imaging</source>
          <year>1995</year>
          <fpage>101</fpage>
          <lpage>112</lpage>
        </element-citation>
      </ref>
      <ref id="bb0160">
        <mixed-citation publication-type="other">Cotter, C.J., Holm, D.D., Singular solutions, momentum maps and computational anatomy. <italic>Arxiv preprint nlin.SI/0605020</italic>, 2006.</mixed-citation>
      </ref>
      <ref id="bb0165">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Cristianini</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Shawe-Taylor</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <chapter-title>An Introduction to Support Vector Machines: and Other Kernel-Based Learning Methods</chapter-title>
          <year>2000</year>
          <publisher-name>Cambridge Univ Pr</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0170">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Csete</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Doyle</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <chapter-title>Reverse Engineering of Biological Complexity</chapter-title>
          <year>2002</year>
        </element-citation>
      </ref>
      <ref id="bb0175">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>da Fontoura Costa</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Cesar</surname>
              <given-names>R.M.</given-names>
            </name>
          </person-group>
          <chapter-title>Shape Analysis and Classification: Theory and Practice</chapter-title>
          <year>2001</year>
          <publisher-name>CRC</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0180">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Lao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Karacali</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <chapter-title>Morphological classification of medical images using nonlinear support vector machines</chapter-title>
          <source>IEEE International Symposium on Biomedical Imaging: Nano to Macro</source>
          <year>2004</year>
          <fpage>587</fpage>
          <lpage>590</lpage>
        </element-citation>
      </ref>
      <ref id="bb0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Fan</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Resnick</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Detection of prodromal Alzheimer's disease via pattern classification of magnetic resonance imaging</article-title>
          <source>Neurobiol. Aging</source>
          <volume>290</volume>
          <issue>4</issue>
          <year>2008</year>
          <fpage>514</fpage>
          <lpage>523</lpage>
          <pub-id pub-id-type="pmid">17174012</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0190">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Davies</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Twining</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <chapter-title>Statistical Models of Shape: Optimisation and Evaluation</chapter-title>
          <year>2008</year>
          <publisher-name>Springer-Verlag New York Inc</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0195">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Dryden</surname>
              <given-names>I.L.</given-names>
            </name>
            <name>
              <surname>Mardia</surname>
              <given-names>K.V.</given-names>
            </name>
          </person-group>
          <chapter-title>Statistical Shape Analysis</chapter-title>
          <year>1998</year>
          <publisher-name>Wiley</publisher-name>
          <publisher-loc>New York</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0200">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Duda</surname>
              <given-names>R.O.</given-names>
            </name>
            <name>
              <surname>Hart</surname>
              <given-names>P.E.</given-names>
            </name>
            <name>
              <surname>Stork</surname>
              <given-names>D.G.</given-names>
            </name>
          </person-group>
          <chapter-title>Pattern Classification</chapter-title>
          <year>2001</year>
          <publisher-name>Wiley</publisher-name>
          <publisher-loc>New York</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0205">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Elstein</surname>
              <given-names>A.S.</given-names>
            </name>
            <name>
              <surname>Schwarz</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Clinical Problem Solving and Diagnostic Decision Making: Selective Review of the Cognitive Literature</chapter-title>
          <year>2002</year>
        </element-citation>
      </ref>
      <ref id="bb0210">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Fan</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <source>Classification of structural images via high-dimensional image warping, robust feature extraction, and SVM</source>
          <series>Lect. Notes Comput. Sci.</series>
          <volume>3749</volume>
          <year>2005</year>
          <fpage>1</fpage>
        </element-citation>
      </ref>
      <ref id="bb0215">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fletcher</surname>
              <given-names>P.C.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Shallice</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Is multivariate analysis of PET data more revealing than the univariate approach? Evidence from a study of episodic memory retrieval</article-title>
          <source>NeuroImage</source>
          <volume>30</volume>
          <issue>3</issue>
          <year>1996</year>
          <fpage>209</fpage>
          <lpage>215</lpage>
          <pub-id pub-id-type="pmid">9345492</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0220">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Mattout</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Trujillo-Barreto</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Variational free energy and the Laplace approximation</article-title>
          <source>NeuroImage</source>
          <volume>340</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>220</fpage>
          <lpage>234</lpage>
          <pub-id pub-id-type="pmid">17055746</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0225">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Mourão-Miranda</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hulme</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian decoding of brain images</article-title>
          <source>Neuroimage</source>
          <volume>390</volume>
          <issue>1</issue>
          <year>2008</year>
          <fpage>181</fpage>
          <lpage>205</lpage>
          <pub-id pub-id-type="pmid">17919928</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Generative and recognition models for neuroanatomy</article-title>
          <source>NeuroImage</source>
          <volume>230</volume>
          <issue>1</issue>
          <year>2004</year>
          <fpage>21</fpage>
          <lpage>24</lpage>
          <pub-id pub-id-type="pmid">15325348</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0235">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Worsley</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
          </person-group>
          <article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>20</volume>
          <issue>4</issue>
          <year>1994</year>
          <fpage>189</fpage>
          <lpage>210</lpage>
        </element-citation>
      </ref>
      <ref id="bb0240">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
          </person-group>
          <article-title>A multivariate analysis of PET activation studies</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>40</volume>
          <issue>2</issue>
          <year>1996</year>
        </element-citation>
      </ref>
      <ref id="bb0245">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gerardin</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Chételat</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Chupin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cuingnet</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Desgranges</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>H.S.</given-names>
            </name>
            <name>
              <surname>Niethammer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dubois</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Lehéricy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Garnero</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Multidimensional classification of hippocampal shape features discriminates Alzheimer's disease and mild cognitive impairment from normal aging</article-title>
          <source>Neuroimage</source>
          <year>2009</year>
        </element-citation>
      </ref>
      <ref id="bb0250">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ghahramani</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Beal</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <source>Variational inference for Bayesian mixtures of factor analysers</source>
          <series>Adv. Neural. Inf. Process. Syst.</series>
          <volume>12</volume>
          <year>2000</year>
          <fpage>449</fpage>
          <lpage>455</lpage>
        </element-citation>
      </ref>
      <ref id="bb0255">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Golland</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Discriminative direction for kernel classifiers</article-title>
          <source>Adv. Neural Inf. Proces. Syst.</source>
          <volume>1</volume>
          <year>2002</year>
          <fpage>745</fpage>
          <lpage>752</lpage>
        </element-citation>
      </ref>
      <ref id="bb0260">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Golland</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Grimson</surname>
              <given-names>W.E.L.</given-names>
            </name>
            <name>
              <surname>Shenton</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Kikinis</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Deformation analysis for shape based classification</article-title>
          <source>Lect. Notes Comput. Sci.</source>
          <year>2001</year>
          <fpage>517</fpage>
          <lpage>530</lpage>
        </element-citation>
      </ref>
      <ref id="bb0265">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Golland</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Grimson</surname>
              <given-names>W.E.L.</given-names>
            </name>
            <name>
              <surname>Shenton</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Kikinis</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Detection and analysis of statistical differences in anatomical shape</article-title>
          <source>Med. Image Anal.</source>
          <volume>90</volume>
          <issue>1</issue>
          <year>2005</year>
          <fpage>69</fpage>
          <lpage>86</lpage>
          <pub-id pub-id-type="pmid">15581813</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0270">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Grenander</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <chapter-title>Pattern Theory: from Representation to Inference</chapter-title>
          <year>2007</year>
          <publisher-name>Oxford University Press</publisher-name>
          <publisher-loc>USA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0275">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grenander</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Computational anatomy: an emerging discipline</article-title>
          <source>Q. Appl. Math.</source>
          <volume>560</volume>
          <issue>4</issue>
          <year>1998</year>
          <fpage>617</fpage>
          <lpage>694</lpage>
        </element-citation>
      </ref>
      <ref id="bb0280">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Guimond</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Guttmann</surname>
              <given-names>C.R.G.</given-names>
            </name>
            <name>
              <surname>Warfield</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Westin</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <chapter-title>Deformable registration of DT-MRI data based on transformation invariant tensor characteristics</chapter-title>
          <source>Proc. ISBI, volume 2</source>
          <year>2002</year>
        </element-citation>
      </ref>
      <ref id="bb0285">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hand</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Measuring diagnostic accuracy of statistical prediction rules</article-title>
          <source>Stat. Neerl.</source>
          <volume>550</volume>
          <issue>1</issue>
          <year>2001</year>
          <fpage>3</fpage>
          <lpage>16</lpage>
        </element-citation>
      </ref>
      <ref id="bb0290">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hinton</surname>
              <given-names>G.E.</given-names>
            </name>
            <name>
              <surname>Osindero</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Teh</surname>
              <given-names>Y.W.</given-names>
            </name>
          </person-group>
          <article-title>A fast learning algorithm for deep belief nets</article-title>
          <source>Neural Comput.</source>
          <volume>180</volume>
          <issue>7</issue>
          <year>2006</year>
          <fpage>1527</fpage>
          <lpage>1554</lpage>
          <pub-id pub-id-type="pmid">16764513</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0295">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hirsch</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Does the <italic>h</italic> index have predictive power?</article-title>
          <source>Proc. Natl Acad. Sci. U. S. A.</source>
          <volume>1040</volume>
          <issue>49</issue>
          <year>2007</year>
          <fpage>19193</fpage>
          <pub-id pub-id-type="pmid">18040045</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0300">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holub</surname>
              <given-names>A.D.</given-names>
            </name>
            <name>
              <surname>Welling</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Perona</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Hybrid generative-discriminative visual categorization</article-title>
          <source>Int. J. Comput. Vis.</source>
          <volume>770</volume>
          <issue>1</issue>
          <year>2008</year>
          <fpage>239</fpage>
          <lpage>258</lpage>
        </element-citation>
      </ref>
      <ref id="bb0305">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hoyer</surname>
              <given-names>P.O.</given-names>
            </name>
            <name>
              <surname>Janzing</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Mooij</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Peters</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Scholkopf</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Nonlinear causal discovery with additive noise models</article-title>
          <source>Adv. Neural. Inf. Process. Syst.</source>
          <volume>21</volume>
          <year>2009</year>
          <fpage>689</fpage>
          <lpage>696</lpage>
        </element-citation>
      </ref>
      <ref id="bb0310">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Huxley</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <chapter-title>Problems of Relative Growth</chapter-title>
          <year>1993</year>
          <publisher-name>Johns Hopkins University Press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0315">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jaakkola</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Diekhans</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Haussler</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>A discriminative framework for detecting remote protein homologies</article-title>
          <source>J. Comput. Biol.</source>
          <volume>70</volume>
          <issue>1–2</issue>
          <year>2000</year>
          <fpage>95</fpage>
          <lpage>114</lpage>
          <pub-id pub-id-type="pmid">10890390</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0320">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Jaynes</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Bretthorst</surname>
              <given-names>G.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Probability Theory: the Logic of Science</chapter-title>
          <year>2003</year>
          <publisher-name>Cambridge University Press</publisher-name>
          <publisher-loc>Cambridge UK</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0325">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johansen-Berg</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Sillery</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ciccarelli</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Thompson</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Matthews</surname>
              <given-names>P.M.</given-names>
            </name>
          </person-group>
          <article-title>Functional–anatomical validation and individual variation of diffusion tractography-based segmentation of the human thalamus</article-title>
          <source>Cereb. Cortex</source>
          <volume>150</volume>
          <issue>1</issue>
          <year>2005</year>
          <fpage>31</fpage>
          <lpage>39</lpage>
          <pub-id pub-id-type="pmid">15238447</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0330">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Joshi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Davis</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Jomier</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gerig</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Unbiased diffeomorphic atlas construction for computational anatomy</article-title>
          <source>NeuroImage</source>
          <volume>23</volume>
          <year>2004</year>
          <fpage>151</fpage>
          <lpage>160</lpage>
        </element-citation>
      </ref>
      <ref id="bb0335">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Kendall</surname>
              <given-names>D.G.</given-names>
            </name>
            <name>
              <surname>Barden</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Carne</surname>
              <given-names>T.K.</given-names>
            </name>
            <name>
              <surname>Le</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <chapter-title>Shape and Shape Theory</chapter-title>
          <year>1999</year>
          <publisher-name>Wiley</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0340">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Daunizeau</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Phillips</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Variational Bayesian inversion of the equivalent current dipole model in EEG/MEG</article-title>
          <source>NeuroImage</source>
          <volume>390</volume>
          <issue>2</issue>
          <year>2008</year>
          <fpage>728</fpage>
          <lpage>741</lpage>
          <pub-id pub-id-type="pmid">17951076</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0345">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kitano</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Computational systems biology</article-title>
          <source>Nature</source>
          <volume>4200</volume>
          <issue>6912</issue>
          <year>2002</year>
          <fpage>206</fpage>
          <lpage>210</lpage>
          <pub-id pub-id-type="pmid">12432404</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0350">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Klein</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Robson</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Mackay</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Higham</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Johansen-Berg</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Connectivity-based parcellation of human cortex using diffusion MRI: establishing reproducibility, validity and observer independence in BA 44/45 and SMA/pre-SMA</article-title>
          <source>Neuroimage</source>
          <volume>340</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>204</fpage>
          <lpage>211</lpage>
          <pub-id pub-id-type="pmid">17023184</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0355">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kloppel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Stonnington</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Barnes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Good</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Mader</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Anne Mitchell</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>C.C.</given-names>
            </name>
          </person-group>
          <article-title>Accuracy of dementia diagnosis—a direct comparison between radiologists and a computerized method</article-title>
          <source>Brain</source>
          <year>2008</year>
        </element-citation>
      </ref>
      <ref id="bb0360">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kloppel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Stonnington</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Draganski</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Scahill</surname>
              <given-names>R.I.</given-names>
            </name>
            <name>
              <surname>Rohrer</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>N.C.</given-names>
            </name>
            <name>
              <surname>Jack</surname>
              <given-names>C.R.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
          </person-group>
          <article-title>Automatic classification of MR scans in Alzheimer's disease</article-title>
          <source>Brain</source>
          <volume>681</volume>
          <issue>3</issue>
          <year>2008</year>
        </element-citation>
      </ref>
      <ref id="bb0365">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Krim</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Yezzi</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <chapter-title>Statistics and Analysis of Shapes</chapter-title>
          <year>2006</year>
          <publisher-name>Birkhauser</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0370">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lao</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Karacali</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Resnick</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Morphological classification of brains via high-dimensional shape transformations and machine learning methods</article-title>
          <source>Neuroimage</source>
          <volume>210</volume>
          <issue>1</issue>
          <year>2004</year>
          <fpage>46</fpage>
          <lpage>57</lpage>
          <pub-id pub-id-type="pmid">14741641</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0375">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Lasserre</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Minka</surname>
              <given-names>T.P.</given-names>
            </name>
          </person-group>
          <chapter-title>Principled hybrids of generative and discriminative models</chapter-title>
          <source>2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 1</source>
          <year>2006</year>
        </element-citation>
      </ref>
      <ref id="bb0380">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>D.D.</given-names>
            </name>
            <name>
              <surname>Seung</surname>
              <given-names>H.S.</given-names>
            </name>
          </person-group>
          <article-title>Learning the parts of objects by non-negative matrix factorization</article-title>
          <source>Nature</source>
          <volume>4010</volume>
          <issue>6755</issue>
          <year>1999</year>
          <fpage>788</fpage>
          <lpage>791</lpage>
          <pub-id pub-id-type="pmid">10548103</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0385">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Lele</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Richtsmeier</surname>
              <given-names>J.T.</given-names>
            </name>
          </person-group>
          <chapter-title>An invariant Approach to Statistical Analysis of Shapes</chapter-title>
          <year>2001</year>
          <publisher-name>CRC Pr I Llc</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0390">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lorenzen</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Davis</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Joshi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Unbiased atlas formation via large deformations metric mapping</article-title>
          <source>Lect. Notes Comput. Sci.</source>
          <volume>3750</volume>
          <year>2005</year>
          <fpage>411</fpage>
        </element-citation>
      </ref>
      <ref id="bb0395">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Luders</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Steinmetz</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Jancke</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Brain size and grey matter volume in the healthy human brain</article-title>
          <source>Neuroreport</source>
          <volume>130</volume>
          <issue>17</issue>
          <year>2002</year>
          <fpage>2371</fpage>
          <pub-id pub-id-type="pmid">12488829</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0400">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>MacKay</surname>
              <given-names>D.J.C.</given-names>
            </name>
          </person-group>
          <article-title>The evidence framework applied to classification networks</article-title>
          <source>Neural Comput.</source>
          <volume>40</volume>
          <issue>5</issue>
          <year>1992</year>
          <fpage>720</fpage>
          <lpage>736</lpage>
        </element-citation>
      </ref>
      <ref id="bb0405">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>MacKay</surname>
              <given-names>D.J.C.</given-names>
            </name>
          </person-group>
          <chapter-title>Information Theory, Inference, and Learning Algorithms</chapter-title>
          <year>2003</year>
          <publisher-name>Cambridge Univ Pr</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0410">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Magnin</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Mesrob</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Kinkingnéhun</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pélégrini-Issac</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Colliot</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Sarazin</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dubois</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Lehéricy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Benali</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Support vector machine-based classification of Alzheimer's disease from whole-brain anatomical MRI</article-title>
          <source>Neuroradiology</source>
          <volume>510</volume>
          <issue>2</issue>
          <year>2009</year>
          <fpage>73</fpage>
          <lpage>83</lpage>
          <pub-id pub-id-type="pmid">18846369</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0415">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Makrogiannis</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Verma</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Karacali</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Anatomical equivalence class: a morphological analysis framework using a lossless shape descriptor</article-title>
          <source>IEEE Trans. Med. Imaging</source>
          <volume>26</volume>
          <issue>4</issue>
          <year>2007</year>
          <fpage>619</fpage>
          <lpage>631</lpage>
          <pub-id pub-id-type="pmid">17427746</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0420">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Marcus</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>T.H.</given-names>
            </name>
            <name>
              <surname>Parker</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Csernansky</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
          </person-group>
          <article-title>Open Access Series of Imaging Studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>190</volume>
          <issue>9</issue>
          <year>2007</year>
          <fpage>1498</fpage>
          <lpage>1507</lpage>
          <pub-id pub-id-type="pmid">17714011</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0425">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Markram</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>The blue brain project</article-title>
          <source>Nat. Rev. Neurosci.</source>
          <volume>70</volume>
          <issue>2</issue>
          <year>2006</year>
          <fpage>153</fpage>
          <lpage>160</lpage>
          <pub-id pub-id-type="pmid">16429124</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0430">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Marsland</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>McLachlan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>A Hamiltonian particle method for diffeomorphic image registration</article-title>
          <source>Lect. Notes Comput. Sci.</source>
          <volume>4584</volume>
          <year>2007</year>
          <fpage>396</fpage>
        </element-citation>
      </ref>
      <ref id="bb0435">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Martin</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <article-title>Relative brain size and basal metabolic rate in terrestrial vertebrates</article-title>
          <source>Nature</source>
          <volume>293</volume>
          <year>1981</year>
          <fpage>57</fpage>
          <lpage>60</lpage>
          <pub-id pub-id-type="pmid">7266659</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0440">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mazziotta</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Toga</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Evans</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Lancaster</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Zilles</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Woods</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Paus</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Simpson</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Pike</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>A probabilistic atlas and reference system for the human brain: International Consortium for Brain Mapping (ICBM)</article-title>
          <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source>
          <volume>3560</volume>
          <year>2001</year>
          <fpage>1293</fpage>
          <pub-id pub-id-type="pmid">11545704</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0445">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McIntosh</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Bookstein</surname>
              <given-names>F.L.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Grady</surname>
              <given-names>C.L.</given-names>
            </name>
          </person-group>
          <article-title>Spatial pattern analysis of functional brain images using partial least squares</article-title>
          <source>Neuroimage</source>
          <volume>30</volume>
          <issue>3</issue>
          <year>1996</year>
          <fpage>143</fpage>
          <lpage>157</lpage>
          <pub-id pub-id-type="pmid">9345485</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0450">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mechelli</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Structural covariance in the human cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>250</volume>
          <issue>36</issue>
          <year>2005</year>
          <fpage>8303</fpage>
          <lpage>8310</lpage>
          <pub-id pub-id-type="pmid">16148238</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0455">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Banerjee</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Christensen</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Joshi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Khaneja</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Grenander</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Matejic</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Statistical methods in computational anatomy</article-title>
          <source>Stat. Meth. Med. Res.</source>
          <volume>60</volume>
          <issue>3</issue>
          <year>1997</year>
          <fpage>267</fpage>
        </element-citation>
      </ref>
      <ref id="bb0460">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Computational anatomy: shape, growth, and atrophy comparison via diffeomorphisms</article-title>
          <source>NeuroImage</source>
          <volume>23</volume>
          <year>2004</year>
          <fpage>19</fpage>
          <lpage>33</lpage>
        </element-citation>
      </ref>
      <ref id="bb0465">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The emerging discipline of Computational Functional Anatomy</article-title>
          <source>Neuroimage</source>
          <volume>450</volume>
          <issue>1S1</issue>
          <year>2009</year>
          <fpage>16</fpage>
          <lpage>39</lpage>
        </element-citation>
      </ref>
      <ref id="bb0470">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Geodesic shooting for computational anatomy</article-title>
          <source>J. Math. Imaging Vis.</source>
          <volume>240</volume>
          <issue>2</issue>
          <year>2006</year>
          <fpage>209</fpage>
          <lpage>228</lpage>
          <pub-id pub-id-type="pmid">20613972</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0475">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Priebe</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fischl</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Kolasny</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Park</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Ratnanather</surname>
              <given-names>J.T.</given-names>
            </name>
            <name>
              <surname>Busa</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Jovicich</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Collaborative computational anatomy: an MRI morphometry study of the human brain via diffeomorphic metric mapping</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>300</volume>
          <issue>7</issue>
          <year>2008</year>
          <fpage>2132</fpage>
          <lpage>2141</lpage>
        </element-citation>
      </ref>
      <ref id="bb0480">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mitchell</surname>
              <given-names>T.M.</given-names>
            </name>
            <name>
              <surname>Hutchinson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Niculescu</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Pereira</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Just</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Newman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Learning to decode cognitive states from brain images</article-title>
          <source>Mach. Learn.</source>
          <volume>570</volume>
          <issue>1</issue>
          <year>2004</year>
          <fpage>145</fpage>
          <lpage>175</lpage>
        </element-citation>
      </ref>
      <ref id="bb0485">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mueller</surname>
              <given-names>S.G.</given-names>
            </name>
            <name>
              <surname>Weiner</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Thal</surname>
              <given-names>L.J.</given-names>
            </name>
            <name>
              <surname>Petersen</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Jack</surname>
              <given-names>C.R.</given-names>
            </name>
            <name>
              <surname>Jagust</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Trojanowski</surname>
              <given-names>J.Q.</given-names>
            </name>
            <name>
              <surname>Toga</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Beckett</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Ways toward an early diagnosis in Alzheimer's disease: the Alzheimer's Disease Neuroimaging Initiative (ADNI)</article-title>
          <source>Alzheimers Dement. J. Alzheimer's Assoc.</source>
          <volume>10</volume>
          <issue>1</issue>
          <year>2005</year>
          <fpage>55</fpage>
          <lpage>66</lpage>
        </element-citation>
      </ref>
      <ref id="bb0490">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Neuronal architectures for pattern-theoretic problems</chapter-title>
          <source>Large-scale neuronal theories of the brain</source>
          <year>1994</year>
          <fpage>125</fpage>
          <lpage>152</lpage>
        </element-citation>
      </ref>
      <ref id="bb0495">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Pattern theory: a unifying perspective</chapter-title>
          <source>Perception as Bayesian inference</source>
          <year>1996</year>
          <fpage>25</fpage>
          <lpage>62</lpage>
        </element-citation>
      </ref>
      <ref id="bb0500">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Pattern theory: the mathematics of perception</chapter-title>
          <source>Proceedings of the International Congress of Mathematicians, volume 3</source>
          <year>2002</year>
        </element-citation>
      </ref>
      <ref id="bb0505">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Empirical statistics and stochastic models for visual signals</chapter-title>
          <source>New Directions in Statistical Signal Processing: From Systems to Brain</source>
          <year>2005</year>
        </element-citation>
      </ref>
      <ref id="bb0510">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oishi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zilles</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Amunts</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Faria</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Akhter</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Hua</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Woods</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Toga</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Human brain white matter atlas: identification and assignment of common anatomical structures in superficial white matter</article-title>
          <source>Neuroimage</source>
          <volume>430</volume>
          <issue>3</issue>
          <year>2008</year>
          <fpage>447</fpage>
          <lpage>457</lpage>
          <pub-id pub-id-type="pmid">18692144</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0515">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Park</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Kubicki</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Shenton</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Guimond</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McCarley</surname>
              <given-names>R.W.</given-names>
            </name>
            <name>
              <surname>Maier</surname>
              <given-names>S.E.</given-names>
            </name>
            <name>
              <surname>Kikinis</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Jolesz</surname>
              <given-names>F.A.</given-names>
            </name>
            <name>
              <surname>Westin</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <article-title>Spatial normalization of diffusion tensor MRI using multiple channels</article-title>
          <source>Neuroimage</source>
          <volume>200</volume>
          <issue>4</issue>
          <year>2003</year>
          <fpage>1995</fpage>
          <lpage>2009</lpage>
          <pub-id pub-id-type="pmid">14683705</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0520">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Penny</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Mechelli</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Comparing dynamic causal models</article-title>
          <source>NeuroImage</source>
          <volume>220</volume>
          <issue>3</issue>
          <year>2004</year>
          <fpage>1157</fpage>
          <lpage>1172</lpage>
          <pub-id pub-id-type="pmid">15219588</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0525">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pereira</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Mitchell</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Botvinick</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Machine learning classifiers and fMRI: a tutorial overview</article-title>
          <source>Neuroimage</source>
          <volume>450</volume>
          <issue>1S1</issue>
          <year>2009</year>
          <fpage>199</fpage>
          <lpage>209</lpage>
        </element-citation>
      </ref>
      <ref id="bb0530">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Petersson</surname>
              <given-names>K.M.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.P.</given-names>
            </name>
          </person-group>
          <article-title>Statistical limitations in functional neuroimaging. I. Non-inferential methods and statistical models</article-title>
          <source>Philos. Trans. R. Soc. Biol. Sci.</source>
          <volume>3540</volume>
          <issue>1387</issue>
          <year>1999</year>
          <fpage>1239</fpage>
          <lpage>1260</lpage>
        </element-citation>
      </ref>
      <ref id="bb0535">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Qiu</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Multi-structure network shape analysis via normal surface momentum maps</article-title>
          <source>Neuroimage</source>
          <volume>420</volume>
          <issue>4</issue>
          <year>2008</year>
          <fpage>1430</fpage>
          <lpage>1438</lpage>
          <pub-id pub-id-type="pmid">18675553</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0540">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Rasmussen</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Quinonero-Candela</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <chapter-title>Healing the relevance vector machine through augmentation</chapter-title>
          <source>Machine Learning-International Workshop Then Conference, volume 22</source>
          <year>2005</year>
          <fpage>689</fpage>
        </element-citation>
      </ref>
      <ref id="bb0545">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Rasmussen</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>C.K.I.</given-names>
            </name>
          </person-group>
          <chapter-title>Gaussian Processes for Machine Learning</chapter-title>
          <year>2006</year>
          <publisher-name>Springer</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0550">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rilling</surname>
              <given-names>J.K.</given-names>
            </name>
          </person-group>
          <article-title>Human and nonhuman primate brains: are they allometrically scaled versions of the same design?</article-title>
          <source>Evol. Anthropol.: Issues News Rev.</source>
          <volume>150</volume>
          <issue>2</issue>
          <year>2006</year>
        </element-citation>
      </ref>
      <ref id="bb0555">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Roweis</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ghahramani</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <article-title>A unifying review of linear Gaussian models</article-title>
          <source>Neural Comput.</source>
          <volume>110</volume>
          <issue>2</issue>
          <year>1999</year>
          <fpage>305</fpage>
          <lpage>345</lpage>
          <pub-id pub-id-type="pmid">9950734</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0560">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ruiz-Alzola</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Westin</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Warfield</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Alberola</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Maier</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kikinis</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Nonrigid registration of 3D tensor medical data</article-title>
          <source>Med. Image Anal.</source>
          <volume>60</volume>
          <issue>2</issue>
          <year>2002</year>
          <fpage>143</fpage>
          <lpage>161</lpage>
          <pub-id pub-id-type="pmid">12045001</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0565">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sabuncu</surname>
              <given-names>M.R.</given-names>
            </name>
            <name>
              <surname>Singer</surname>
              <given-names>B.D.</given-names>
            </name>
            <name>
              <surname>Conroy</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Bryan</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Ramadge</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
          </person-group>
          <article-title>Function-based intersubject alignment of human cortical anatomy</article-title>
          <source>Cereb. Cortex</source>
          <volume>20</volume>
          <year>2010</year>
          <fpage>130</fpage>
          <lpage>140</lpage>
          <pub-id pub-id-type="pmid">19420007</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0570">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Salimi-Khorshidi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Keltner</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Wager</surname>
              <given-names>T.D.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
          </person-group>
          <article-title>Meta-analysis of neuroimaging data: a comparison of image-based and coordinate-based pooling of studies</article-title>
          <source>Neuroimage</source>
          <volume>450</volume>
          <issue>3</issue>
          <year>2009</year>
          <fpage>810</fpage>
          <lpage>823</lpage>
          <pub-id pub-id-type="pmid">19166944</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0575">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saxe</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Brett</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kanwisher</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Divide and conquer: a defense of functional localizers</article-title>
          <source>Neuroimage</source>
          <volume>300</volume>
          <issue>4</issue>
          <year>2006</year>
          <fpage>1088</fpage>
          <lpage>1096</lpage>
          <pub-id pub-id-type="pmid">16635578</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0580">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schmah</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Hinton</surname>
              <given-names>G.E.</given-names>
            </name>
            <name>
              <surname>Zemel</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Small</surname>
              <given-names>S.L.</given-names>
            </name>
            <name>
              <surname>Strother</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Generative versus discriminative training of RBMs for classification of fMRI images</article-title>
          <source>NIPS</source>
          <year>2008</year>
        </element-citation>
      </ref>
      <ref id="bb0585">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Schölkopf</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Smola</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <chapter-title>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</chapter-title>
          <year>2002</year>
          <publisher-name>the MIT Press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0590">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seeley</surname>
              <given-names>W.W.</given-names>
            </name>
            <name>
              <surname>Crawford</surname>
              <given-names>R.K.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>B.L.</given-names>
            </name>
            <name>
              <surname>Greicius</surname>
              <given-names>M.D.</given-names>
            </name>
          </person-group>
          <article-title>Neurodegenerative diseases target large-scale human brain networks</article-title>
          <source>Neuron</source>
          <volume>620</volume>
          <issue>1</issue>
          <year>2009</year>
          <fpage>42</fpage>
          <lpage>52</lpage>
          <pub-id pub-id-type="pmid">19376066</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0595">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Small</surname>
              <given-names>C.G.</given-names>
            </name>
          </person-group>
          <chapter-title>The Statistical Theory of Shape</chapter-title>
          <year>1996</year>
          <publisher-name>Springer Verlag</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0600">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>P.T.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Glahn</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>P.M.</given-names>
            </name>
            <name>
              <surname>Mackay</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Filippini</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Watkins</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Toro</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Laird</surname>
              <given-names>A.R.</given-names>
            </name>
          </person-group>
          <article-title>Correspondence of the brain's functional architecture during activation and rest</article-title>
          <source>Proc. Natl Acad. Sci. U. S. A.</source>
          <volume>1060</volume>
          <issue>31</issue>
          <year>2009</year>
          <fpage>13040</fpage>
          <pub-id pub-id-type="pmid">19620724</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0605">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Kamper</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Bozkurt</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Burns</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Kotter</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Advanced database methodology for the Collation of Connectivity data on the Macaque brain (CoCoMac)</article-title>
          <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source>
          <volume>356</volume>
          <year>2001</year>
          <fpage>1159</fpage>
          <lpage>1186</lpage>
          <pub-id pub-id-type="pmid">11545697</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0610">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Thompson</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bonner</surname>
              <given-names>J.T.</given-names>
            </name>
          </person-group>
          <chapter-title>On Growth and Form</chapter-title>
          <year>1942</year>
          <publisher-name>Cambridge University Press</publisher-name>
          <publisher-loc>Cambridge</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0615">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tipping</surname>
              <given-names>M.E.</given-names>
            </name>
          </person-group>
          <article-title>Sparse Bayesian learning and the relevance vector machine</article-title>
          <source>Journal of Machine Learning Research</source>
          <volume>1</volume>
          <year>2001</year>
          <fpage>211</fpage>
          <lpage>244</lpage>
        </element-citation>
      </ref>
      <ref id="bb0620">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tipping</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
          </person-group>
          <article-title>Mixtures of probabilistic principal component analyzers</article-title>
          <source>Neural Comput.</source>
          <volume>110</volume>
          <issue>2</issue>
          <year>1999</year>
          <fpage>443</fpage>
          <lpage>482</lpage>
          <pub-id pub-id-type="pmid">9950739</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0625">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tipping</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Bishop</surname>
              <given-names>C.M.</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic principal component analysis</article-title>
          <source>J. R. Stat. Soc. B Stat. Methodol.</source>
          <year>1999</year>
          <fpage>611</fpage>
          <lpage>622</lpage>
        </element-citation>
      </ref>
      <ref id="bb0630">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Metamorphoses through lie group action</article-title>
          <source>Found. Comput. Math.</source>
          <volume>50</volume>
          <issue>2</issue>
          <year>2005</year>
          <fpage>173</fpage>
          <lpage>198</lpage>
        </element-citation>
      </ref>
      <ref id="bb0635">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Metric similarities learning through examples: an application to shape retrieval</article-title>
          <source>Lect. Notes Comput. Sci.</source>
          <volume>50–62</volume>
          <year>2001</year>
        </element-citation>
      </ref>
      <ref id="bb0640">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vaillant</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Trouvé</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Statistics on diffeomorphisms via tangent space representations</article-title>
          <source>NeuroImage</source>
          <volume>23</volume>
          <year>2004</year>
          <fpage>161</fpage>
          <lpage>169</lpage>
        </element-citation>
      </ref>
      <ref id="bb0645">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Van Horn</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Toga</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Is it time to re-prioritize neuroimaging databases and digital repositories?</article-title>
          <source>Neuroimage</source>
          <year>2009</year>
        </element-citation>
      </ref>
      <ref id="bb0650">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Van Leemput</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Maes</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Vandermeulen</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Suetens</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Automated model-based tissue classification of MR images of the brain</article-title>
          <source>IEEE Trans. Med. Imaging</source>
          <volume>180</volume>
          <issue>10</issue>
          <year>1999</year>
          <fpage>897</fpage>
          <lpage>908</lpage>
          <pub-id pub-id-type="pmid">10628949</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0655">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vapnik</surname>
              <given-names>V.N.</given-names>
            </name>
          </person-group>
          <article-title>An overview of statistical learning theory</article-title>
          <source>IEEE Transact. Neural Netw.</source>
          <volume>100</volume>
          <issue>5</issue>
          <year>1999</year>
          <fpage>988</fpage>
          <lpage>999</lpage>
        </element-citation>
      </ref>
      <ref id="bb0660">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vemuri</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Gunter</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Senjem</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Whitwell</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Kantarci</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Knopman</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Boeve</surname>
              <given-names>B.F.</given-names>
            </name>
            <name>
              <surname>Petersen</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Jack</surname>
              <given-names>C.R.</given-names>
            </name>
          </person-group>
          <article-title>Alzheimer's disease diagnosis in individual subjects using structural MR images: validation studies</article-title>
          <source>Neuroimage</source>
          <volume>390</volume>
          <issue>3</issue>
          <year>2008</year>
          <fpage>1186</fpage>
          <lpage>1197</lpage>
          <pub-id pub-id-type="pmid">18054253</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0665">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Beg</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Ratnanather</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Ceritoglu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Csernansky</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Large deformation diffeomorphism and momentum based hippocampal shape discrimination in dementia of the Alzheimer type.</article-title>
          <source>IEEE Trans. Med. Imaging</source>
          <volume>260</volume>
          <issue>4</issue>
          <year>2007</year>
          <fpage>462</fpage>
          <lpage>470</lpage>
          <pub-id pub-id-type="pmid">17427733</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0670">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Watanabe</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <chapter-title>Knowing and Guessing: a Quantitative Study of Inference and Information</chapter-title>
          <year>1969</year>
          <publisher-name>John Wiley &amp; Sons</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0675">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>West</surname>
              <given-names>G.B.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>J.H.</given-names>
            </name>
          </person-group>
          <source>The Origin of Allometric Scaling Laws in Biology from Genomes to Ecosystems: Towards a Quantitative Unifying Theory of Biological structure and Organization</source>
          <year>2005</year>
        </element-citation>
      </ref>
      <ref id="bb0680">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>West</surname>
              <given-names>G.B.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Enquist</surname>
              <given-names>B.J.</given-names>
            </name>
          </person-group>
          <article-title>A general model for ontogenetic growth</article-title>
          <source>Nature</source>
          <volume>4130</volume>
          <issue>6856</issue>
          <year>2001</year>
          <fpage>628</fpage>
          <lpage>631</lpage>
          <pub-id pub-id-type="pmid">11675785</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0685">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Williams</surname>
              <given-names>C.K.I.</given-names>
            </name>
            <name>
              <surname>Barber</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian classification with Gaussian processes</article-title>
          <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
          <volume>200</volume>
          <issue>12</issue>
          <year>1998</year>
          <fpage>1342</fpage>
          <lpage>1351</lpage>
        </element-citation>
      </ref>
      <ref id="bb0690">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Williams</surname>
              <given-names>C.K.I.</given-names>
            </name>
            <name>
              <surname>Rasmussen</surname>
              <given-names>C.E.</given-names>
            </name>
          </person-group>
          <article-title>Gaussian processes for regression</article-title>
          <source>Adv. Neural. Inf. Process. Syst.</source>
          <volume>8</volume>
          <year>1996</year>
        </element-citation>
      </ref>
      <ref id="bb0695">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Woods</surname>
              <given-names>R.P.</given-names>
            </name>
          </person-group>
          <article-title>Characterizing volume and surface deformations in an atlas framework: theory, applications, and implementation</article-title>
          <source>NeuroImage</source>
          <volume>180</volume>
          <issue>3</issue>
          <year>2003</year>
          <fpage>769</fpage>
          <lpage>788</lpage>
          <pub-id pub-id-type="pmid">12667854</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0700">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wright</surname>
              <given-names>I.C.</given-names>
            </name>
            <name>
              <surname>McGuire</surname>
              <given-names>P.K.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Travere</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>A voxel-based method for the statistical analysis of gray and white matter density applied to schizophrenia</article-title>
          <source>Neuroimage</source>
          <volume>20</volume>
          <issue>4</issue>
          <year>1995</year>
          <fpage>244</fpage>
          <lpage>252</lpage>
          <pub-id pub-id-type="pmid">9343609</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0705">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Xu</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Adali</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>V.D.</given-names>
            </name>
          </person-group>
          <chapter-title>Source based morphometry using structural MRI phase images to identify sources of gray matter and white matter relative differences in schizophrenia versus controls</chapter-title>
          <source>IEEE International Conference on Acoustics, Speech and Signal Processing, 2008</source>
          <series>ICASSP 2008</series>
          <year>2008</year>
          <fpage>533</fpage>
          <lpage>536</lpage>
        </element-citation>
      </ref>
      <ref id="bb0710">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Jacobi fields in groups of diffeomorphisms and applications</article-title>
          <source>Q. Appl. Math.</source>
          <volume>650</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>113</fpage>
          <lpage>134</lpage>
        </element-citation>
      </ref>
      <ref id="bb0715">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Qiu</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Winslow</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Transport of relational structures in groups of diffeomorphisms</article-title>
          <source>J. Math. Imaging Vis.</source>
          <volume>320</volume>
          <issue>1</issue>
          <year>2008</year>
          <fpage>41</fpage>
          <lpage>56</lpage>
          <pub-id pub-id-type="pmid">19809583</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0720">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Younes</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Arrate</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Evolutions equations in computational anatomy</article-title>
          <source>Neuroimage</source>
          <volume>450</volume>
          <issue>1S1</issue>
          <year>2009</year>
          <fpage>40</fpage>
          <lpage>50</lpage>
        </element-citation>
      </ref>
      <ref id="bb0725">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Yushkevich</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Alexander</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Gee</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Deformable registration of diffusion tensor MR images with explicit orientation optimization</article-title>
          <source>Med. Image Anal.</source>
          <volume>100</volume>
          <issue>5</issue>
          <year>2006</year>
          <fpage>764</fpage>
          <lpage>785</lpage>
          <pub-id pub-id-type="pmid">16899392</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0730">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Sejnowski</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>A universal scaling law between gray matter and white matter of cerebral cortex</article-title>
          <source>Proc. Natl Acad. Sci. U. S. A.</source>
          <volume>970</volume>
          <issue>10</issue>
          <year>2000</year>
          <fpage>5621</fpage>
          <lpage>5626</lpage>
          <pub-id pub-id-type="pmid">10792049</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0735">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Goldberg</surname>
              <given-names>A.B.</given-names>
            </name>
          </person-group>
          <article-title>Introduction to Semi-Supervised Learning</article-title>
          <source>Synth. Lect. Artif. Intell. Mach. Learn.</source>
          <volume>30</volume>
          <issue>1</issue>
          <year>2009</year>
          <fpage>1</fpage>
          <lpage>130</lpage>
        </element-citation>
      </ref>
      <ref id="bb0740">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zou</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>O'Malley</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Mauri</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Receiver-operating characteristic analysis for evaluating diagnostic tests and predictive models</article-title>
          <source>Circulation</source>
          <volume>1150</volume>
          <issue>5</issue>
          <year>2007</year>
          <fpage>654</fpage>
          <pub-id pub-id-type="pmid">17283280</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <ack>
      <title>Acknowledgments</title>
      <p>JA is funded by the Wellcome Trust. Many thanks to Karl Friston for correcting a draught of this document.</p>
    </ack>
    <fn-group>
      <fn id="fn0005">
        <label>1</label>
        <p>This was the main conclusion of the New York Academy of Sciences “What Do We Want to See in Brain Imaging?” meeting (London, UK. 3–4 December, 2007).</p>
      </fn>
      <fn id="fn0010">
        <label>2</label>
        <p>See <ext-link ext-link-type="uri" xlink:href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</ext-link> for the accuracy with which handwritten digits can be recognized using various pattern recognition approaches.</p>
      </fn>
      <fn id="fn0015">
        <label>3</label>
        <p><ext-link ext-link-type="uri" xlink:href="http://humancortex.alleninstitute.org/">http://humancortex.alleninstitute.org/</ext-link>.</p>
      </fn>
      <fn id="fn0020">
        <label>4</label>
        <p>This book is freely available at <ext-link ext-link-type="uri" xlink:href="http://www.inference.phy.cam.ac.uk/mackay/itila/">http://www.inference.phy.cam.ac.uk/mackay/itila/</ext-link>.</p>
      </fn>
      <fn id="fn0025">
        <label>5</label>
        <p>This book is freely available at <ext-link ext-link-type="uri" xlink:href="http://www.gaussianprocess.org/gpml/chapters/">http://www.gaussianprocess.org/gpml/chapters/</ext-link>.</p>
      </fn>
      <fn id="fn0030">
        <label>6</label>
        <p>See <ext-link ext-link-type="uri" xlink:href="http://www.gaussianprocess.org/">http://www.gaussianprocess.org/</ext-link> for some implementations, and other useful information.</p>
      </fn>
      <fn id="fn0035">
        <label>7</label>
        <p>Cross-validation is exactly analogous to the hypothesis testing approach that is commonly accepted within the field, except that the hypotheses have been learned by a pattern recognition algorithm.</p>
      </fn>
      <fn id="fn0040">
        <label>8</label>
        <p>Geoffrey Tan, personal communication.</p>
      </fn>
      <fn id="fn0045">
        <label>9</label>
        <p>Technically, these priors are “improper”. Probability densities must integrate to one, so a probability density allowing an infinite range of possible values must have zero probability everywhere.</p>
      </fn>
      <fn id="fn0050">
        <label>10</label>
        <p>It is called the “Ugly Duckling Theorem” because a swan and a duckling are just as similar to each other as two swans.</p>
      </fn>
      <fn id="fn0055">
        <label>11</label>
        <p><ext-link ext-link-type="uri" xlink:href="http://www.ixi.org.uk">http://www.ixi.org.uk</ext-link>.</p>
      </fn>
    </fn-group>
  </back>
  <floats-group>
    <fig id="f0005">
      <label>Fig. 1</label>
      <caption>
        <p>A two dimensional illustration of a regression model, whereby the horizontal and vertical positions of the squares denote the values of pairs of features, and the numbers in the squares indicate labels to be predicted. After fitting the model, prediction is achieved by projecting the data.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="f0010">
      <label>Fig. 2</label>
      <caption>
        <p>Left: A dot-product can be conceptualised as projecting one vector on to another. Projecting on to the discriminating direction is by <bold>a</bold><sup><italic>T</italic></sup><bold>x</bold> = |<bold>a</bold>||<bold>x</bold>| cos(<italic>θ</italic>), where <italic>θ</italic> is the angle between <bold>a</bold> and <bold>x</bold>. Right: A logistic function is used for squashing the results into the range of zero to one (because they are probabilities).</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="f0015">
      <label>Fig. 3</label>
      <caption>
        <p>A two dimensional illustration of the generative model used by Fisher's linear discriminant analysis.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="f0020">
      <label>Fig. 4</label>
      <caption>
        <p>This figure shows a selection of some of the approaches that can be used for linear discrimination. Top-left: Ground truth is based on the probability densities of the two Gaussians from which data were simulated. The line shows the discriminant direction for the underlying model. Top-right: Fisher's Linear Discrimination, also including the resulting discriminant direction. Bottom-left: Linear Support Vector Classification results. Bottom-right: A simple logistic ridge-regression model.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="f0025">
      <label>Fig. 5</label>
      <caption>
        <p>This figure illustrates a Bayesian approach to logistic regression. Top-left: Contours of probability from a naïve implementation of logistic regression, where the contours remain parallel (see <xref rid="f0020" ref-type="fig">Fig. 4</xref>). Top-right: The discriminating direction is estimated with uncertainty, which is illustrated by a random sample of possible separating hyperplanes. Accurate inference requires this uncertainty to be integrated into the predictive model. Bottom-left: Predictive probabilities are made more accurate by incorporating uncertainty. Bottom-right: By integrating out the uncertainty, the contours properly reflect the loss of accuracy further away from the training data.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="f0030">
      <label>Fig. 6</label>
      <caption>
        <p>A poorly-determined general linear model may have a number of columns in the design matrix that is high, compared to the number of rows (left). The conditioning of the problem may be improved by augmenting the design matrix (centre and right). In this situation, fitting the GLM involves a trade-off between fitting the data and keeping the coefficients small. If the regularisation part is small (centre), the trade-off is towards the former, whereas if it is large (right), then model will tend towards the latter.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="f0035">
      <label>Fig. 7</label>
      <caption>
        <p>An illustration of allometric relationships using BMI as an example.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <fig id="f0040">
      <label>Fig. 8</label>
      <caption>
        <p>The original images used for this illustration are shown in (a). After alignment with their common average, they are shown in (b). Note that exact alignment is not achieved, especially for the white hole in the middle of two of the images. Decreasing the amount of regularisation used by the registration would have allowed the hole to be closed further, but its area would never reach exactly zero (a singularity). The Jacobian determinants indicate the relative volumes before and after non-linear registration. Lighter colours indicate areas of expansion, where the Jacobians are smaller. Darker colours indicate contraction, and larger Jacobians. A Jacobian determinant of one would indicate no volume change. The Jacobians of the mapping from the original images to the warped versions are shown in (c). The diffeomorphic framework allows deformations to be invertible, so mappings from the warped images to the originals can also be generated. The Jacobians of these mappings are shown in (d). The deformations and their inverses are shown in (e) and (f). Spatially normalised versions of the individual images were generated by resampling them according to (f), whereas (e) could be used to overlay the template on to the original images. The forward and inverse mappings can be composed together, in which case the results should be identity transforms (which would appear as a regular grid).</p>
      </caption>
      <graphic xlink:href="gr8"/>
    </fig>
    <fig id="f0045">
      <label>Fig. 9</label>
      <caption>
        <p>The small deformation framework is not accurate for larger deformations. This figure shows the sum of the forward and backward displacement fields shown in <xref rid="f0040" ref-type="fig">Fig. 8</xref>. The results are clearly not identity transforms.</p>
      </caption>
      <graphic xlink:href="gr9"/>
    </fig>
    <fig id="f0050">
      <label>Fig. 10</label>
      <caption>
        <p>Deformations can be generated from the residuals as illustrated here (<xref rid="bb0710" ref-type="bibr">Younes, 2007</xref>). The top row shows the initial state of the system, and each subsequent row shows it at the next time point during the evolution. The bottom row shows the final state. The first three columns show the template and its spatial gradients as it evolves to match the individual image. The next column shows the residual difference between the template and warped image, scaled to account for contraction and expansion.</p>
      </caption>
      <graphic xlink:href="gr10"/>
    </fig>
    <fig id="f0055">
      <label>Fig. 11</label>
      <caption>
        <p>This figure shows residual differences between the warped images and the template, which are scaled at each point by the Jacobian determinant. In conjunction with the template, these residuals encode the information needed to reconstruct the original images (apart from a small amount of information lost through inexact interpolation). Dividing the residuals by the Jacobian determinants and adding the template will give warped versions of the originals, which can then be unwarped by resampling with the appropriate deformation. The deformations and Jacobians needed to perform these operations are actually encoded by the residuals (illustrated in <xref rid="f0050" ref-type="fig">Fig. 10</xref>).</p>
      </caption>
      <graphic xlink:href="gr11"/>
    </fig>
    <fig id="f0060">
      <label>Fig. 12</label>
      <caption>
        <p>Average of 450 T1-weighted scans from the IXI dataset, which have been aligned using a geodesic shooting model. The left side of the brain is shown towards the left of the image.</p>
      </caption>
      <graphic xlink:href="gr12"/>
    </fig>
    <fig id="f0065">
      <label>Fig. 13</label>
      <caption>
        <p>Exaggerated versions of female (left) and male (right) average brains, which correspond to 99.99999% probabilities. Note that the caricatures were generated by warping the average brain shown in <xref rid="f0060" ref-type="fig">Fig. 12</xref>, and that the deformations outside the brain are less accurate (so skull thicknesses etc are not accurately represented). The left side of the brain is shown towards the left of the image.</p>
      </caption>
      <graphic xlink:href="gr13"/>
    </fig>
  </floats-group>
</article>