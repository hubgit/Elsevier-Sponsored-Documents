<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="brief-report">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Curr Biol</journal-id>
      <journal-title-group>
        <journal-title>Current Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0960-9822</issn>
      <issn pub-type="epub">1879-0445</issn>
      <publisher>
        <publisher-name>Cell Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3093611</article-id>
      <article-id pub-id-type="pmid">21514158</article-id>
      <article-id pub-id-type="publisher-id">CURBIO8767</article-id>
      <article-id pub-id-type="doi">10.1016/j.cub.2011.03.031</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Report</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Visual Motion Induces a Forward Prediction of Spatial Pattern</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Roach</surname>
            <given-names>Neil W.</given-names>
          </name>
          <email>nwr@psychology.nottingham.ac.uk</email>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="cor1" ref-type="corresp">∗</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>McGraw</surname>
            <given-names>Paul V.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Johnston</surname>
            <given-names>Alan</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">2</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>1</label>Visual Neuroscience Group, School of Psychology, The University of Nottingham, Nottingham NG7 2RD, UK</aff>
      <aff id="aff2"><label>2</label>Department of Cognitive, Perceptual and Brain Sciences and CoMPLEX, University College London, London WC1H 0AP, UK</aff>
      <author-notes>
        <corresp id="cor1"><label>∗</label>Corresponding author <email>nwr@psychology.nottingham.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>10</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>10</day>
        <month>5</month>
        <year>2011</year>
      </pub-date>
      <volume>21</volume>
      <issue>9</issue>
      <fpage>740</fpage>
      <lpage>745</lpage>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>1</month>
          <year>2011</year>
        </date>
        <date date-type="rev-recd">
          <day>2</day>
          <month>3</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>10</day>
          <month>3</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 ELL &amp; Excerpta Medica.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <title>Summary</title>
        <p>Cortical motion analysis continuously encodes image velocity but might also be used to predict future patterns of sensory input along the motion path. We asked whether this predictive aspect of motion is exploited by the human visual system. Targets can be more easily detected at the leading as compared to the trailing edge of motion [<xref rid="bib1" ref-type="bibr">1</xref>], but this effect has been attributed to a nonspecific boost in contrast gain at the leading edge, linked to motion-induced shifts in spatial position [<xref rid="bib1 bib2 bib3 bib4" ref-type="bibr">1–4</xref>]. Here we show that the detectability of a local sinusoidal target presented at the ends of a region containing motion is phase dependent at the leading edge, but not at the trailing edge. These two observations rule out a simple gain control mechanism that modulates contrast energy and passive filtering explanations, respectively. By manipulating the relative orientation of the moving pattern and target, we demonstrate that the resulting spatial variation in detection threshold along the edge closely resembles the superposition of sensory input and an internally generated predicted signal. These findings show that motion induces a forward prediction of spatial pattern that combines with the cortical representation of the future stimulus.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Highlights</title>
        <p>► The human visual system uses motion information to construct a forward model ► Sensory thresholds depend on superposition of internal prediction and sensory input ► Constructive interference improves detectability of stimuli matching prediction ► Destructive interference reduces detectability of stimuli inconsistent with prediction</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <title>Results and Discussion</title>
      <p>We measured changes in observers' ability to detect a small drifting target pattern when it was presented at the end of an inducer stimulus drifting in the same direction and at the same speed. In different conditions, we manipulated whether the target pattern was positioned at the trailing or leading edge of the inducer (see <xref rid="fig1" ref-type="fig">Figure 1</xref>A) as well as the relative phase of the two stimuli (see <xref rid="fig1" ref-type="fig">Figure 1</xref>B). As shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>C, detection thresholds at the trailing edge were elevated relative to a baseline condition with no inducer (mean suppression = 0.17 log units or 49%). No systematic variation of performance with stimulus phase was evident, consistent with previous reports of surround suppression effects [<xref rid="bib5 bib6 bib7" ref-type="bibr">5–7</xref>]. At the leading edge, however, we found that performance was highly phase dependent. Thresholds for target patterns that were in phase with the inducer matched baseline performance (mean suppression = 0.01 log units or 2%), whereas thresholds for antiphase test patterns were highly elevated (mean suppression = 0.31 log units or 106%). The fact that phase dependence occurs at the leading edge but not at the trailing edge means that it cannot be due to the introduction of a discontinuity in the luminance profile at the target/inducer border. Neurones with receptive field centers beyond the edge of the moving stimulus may respond to the inducer, but passive spatial filtering cannot explain the different pattern of results at the trailing and leading edges. Our results are also incompatible with any mechanism that might generally improve or impair performance, such as shifts in spatial attention [<xref rid="bib8 bib9" ref-type="bibr">8, 9</xref>], induction of eye movements [<xref rid="bib10" ref-type="bibr">10</xref>], or flank facilitation [<xref rid="bib11 bib12" ref-type="bibr">11, 12</xref>]. Instead, our results suggest an anticipatory modulation of the signal-to-noise ratio ahead of moving patterns: suppression is released for targets with a form that is consistent with continued motion of the inducer along its trajectory but intensified for targets that are inconsistent.</p>
      <p>How does the visual system accomplish such a highly specific adjustment of sensitivity? One possibility is that a predictive signal generated by a forward model representing the likely future pattern of visual input is simply added to the incoming test pattern, thereby boosting compatible signals and reducing threshold. Superposition would increase the effective contrast of targets that are in phase with the inducer (through constructive interference) and decrease the effective contrast of targets that are in antiphase (destructive interference). Note that this proposed interaction between the prediction and the signal implies they must have the same type of neural representation, making addition a permissible operation.</p>
      <p>To test this idea, we next investigated the possibility of creating more complex modulations of sensitivity by inducing predictions at a different angle to the target pattern. <xref rid="fig2" ref-type="fig">Figure 2</xref>A shows a stimulus configuration in which the orientation of a large drifting inducer pattern has been rotated 30° clockwise relative to that of a smaller target. In this situation, the correspondence between target and prediction will depend on the position of the target stimulus along the inducer's edge. This is illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>B, which shows the spatial interference pattern produced by simply summing an extended version of the target pattern with a prediction formed by extrapolation of the inducer grating. Regions of high and low contrast indicate target positions at which interference is expected to be constructive and destructive, respectively. If the brain combines sensory input with internally generated predictions in this manner, observers' ability to detect the target should modulate with a predictable period as it is moved along the edge of the inducer. In addition, by manipulating the initial phase of the target, it should be possible to alter the phase of this space-variant modulation (see <xref rid="fig2" ref-type="fig">Figure 2</xref>C). As shown in <xref rid="fig2" ref-type="fig">Figure 2</xref>D, the experimental results clearly supported these hypotheses. Observers' thresholds modulated systematically as a function of target position, mirroring the expected interference between sensory and predicted input. To test the generality of this effect, the experiment was repeated using an inducer pattern that was rotated by 15° relative to the target. This broadened the spatial modulation, both in the theoretical interference profile and the threshold measurements (<xref rid="fig2" ref-type="fig">Figure 2</xref>E). Together with our initial findings, these results provide strong evidence that stimulus detectability in the region of space ahead of a moving object is determined by the sum of sensory input and a predictive signal. Moreover, the fact that interference occurs between these entities implies that the brain must treat its own predictions like real sensory signals.</p>
      <p>Our approach provides a direct and versatile tool for quantifying predictive modeling in the visual system and revealing the characteristics of the underlying mechanisms. To determine the extent of the spatial region over which motion information is pooled to form a prediction, we repeated our original experiment while systematically manipulating the length of the inducer stimuli. Performance for in-phase (black symbols) and antiphase (green symbols) targets presented at the leading edge of the inducer is shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>A. Thresholds for the two conditions rapidly diverged with increasing inducer length, before reaching an asymptotic level beyond approximately 1° of visual angle. This suggests that the predictive model is supported by computations occurring within a local region of the visual field. We also determined how far the prediction extends in space by measuring the effect of introducing a gap between inducer and target stimuli. This produced a graded attenuation of the interference effect over a similarly narrow spatial range (see <xref rid="fig3" ref-type="fig">Figure 3</xref>B). The local support and projection of the predictive model, coupled with its high degree of phase specificity, suggest that it is most likely implemented at a relatively early stage of visual processing where neuronal receptive fields are small and information about contrast polarity is retained [<xref rid="bib13 bib14" ref-type="bibr">13, 14</xref>]. Manipulation of stimulus duration further revealed the dynamic nature of the predictive model (see <xref rid="fig3" ref-type="fig">Figure 3</xref>C). Interference was evident for stimulus presentations as brief as 50 ms and continued to grow over a period of approximately 500 ms.</p>
      <p>To better isolate the stage of processing at which the predictive model is formed, we next investigated the effect of presenting inducer and target stimuli to different eyes. Because signals from the two eyes converge only after the input layers of primary visual cortex (V1) [<xref rid="bib13 bib14" ref-type="bibr">13, 14</xref>], measurement of interocular transfer provides a means of assessing whether the predictive model has a cortical or subcortical locus. <xref rid="fig3" ref-type="fig">Figure 3</xref>D compares observers' performance when inducer and target stimuli were presented either to the same eye (monocular) or to different eyes (dichoptic). Differences between the detectability of in-phase and antiphase targets were evident in both conditions, suggesting that predictions formed on the basis of visual input to one eye can interfere with input to the other. Thus, we can be confident that generation of the predictive model must involve visual cortex. Although precise determination of the neural circuitry involved requires further investigation using neurophysiological techniques, our combined psychophysical results point toward a likely stage of processing at or soon after the output layers of V1. We also introduced retinal motion using static stimuli by having observers track a fixation cross that translated across the screen (see <xref rid="app2" ref-type="sec">Figure S3</xref> available online). For retinal motion induced by tracking, we found no differences in detection threshold for in-phase targets compared with antiphase targets at the leading edge of the inducer. This implies that prediction is based on object motion rather than retinal motion.</p>
      <p>Motion can induce a shift in the perceived position of a Gaussian-windowed sine function [<xref rid="bib15" ref-type="bibr">15</xref>]. However, our data allow us to rule out the possibility that the target stimulus is simply added to a spatially shifted version of the inducer, because the phase of the modulation in threshold would include this shift, whereas our interference data suggest superposition with an in-phase extension of the inducer. Several characteristics of motion-induced spatial shifts and motion-induced predictions also differ: the former increases with viewing eccentricity [<xref rid="bib15" ref-type="bibr">15</xref>], varies nonmonotonically as a function of duration [<xref rid="bib2" ref-type="bibr">2</xref>], and is demonstrable with contrast-defined motion [<xref rid="bib16" ref-type="bibr">16</xref>] whereas the latter decreases with eccentricity (see <xref rid="app2" ref-type="sec">Figure S4</xref>), has a monotonic relationship with duration (<xref rid="fig3" ref-type="fig">Figure 3</xref>C), and is absent for contrast-defined motion (see <xref rid="app2" ref-type="sec">Figure S5</xref>). We can therefore distinguish between these motion-related phenomena, which would appear to have different underlying mechanisms.</p>
      <p>Forward models have been successful in explaining how skilled action can be accomplished without the delays inherent in closed-loop feedback circuits [<xref rid="bib17 bib18" ref-type="bibr">17, 18</xref>]. They may play a similar role in sensory systems. Discrepancies between sensory predictions and sensory input could be used as an internal error signal for recalibrating local motion detectors. This would provide the visual system with a means of maintaining the accuracy of velocity estimates and help optimize observers' ability to interact with their dynamic surroundings. Forward models of motor actions are also thought to allow the brain to cancel the reafferent sensory feedback that results from self-movement [<xref rid="bib19 bib20" ref-type="bibr">19, 20</xref>]. In contrast to attenuating predicted sensory signals, however, our results suggest that the visual system employs forward modeling to maintain its ability to detect predictably moving objects. Constructive interference produced by the superposition of sensory signals with well-matching forward predictions acts to counteract surround suppression. This clearing of the path ahead of moving objects may contribute to the impressive sensitivity of the human visual system to predictable motion trajectories [<xref rid="bib21 bib22 bib23" ref-type="bibr">21–23</xref>]. The magnitude of any improvements in sensitivity obtained via this mechanism may need to be tempered against the detrimental effects of destructive interference, occurring when the form of sensory input differs from internal predictions. One situation in which this problem could manifest is when an object's form changes as it moves. Indeed, it has recently been shown that motion impairs the ability of observers to perceive changes in object characteristics [<xref rid="bib24" ref-type="bibr">24</xref>].</p>
      <p>This study adds to a growing body of work suggesting that, rather than simply analyzing sensory information in a passive manner, the brain exploits contextual information to actively predict the nature of input it receives [<xref rid="bib25 bib26 bib27" ref-type="bibr">25–27</xref>]. Our findings are also broadly consistent with previous suggestions that the visual system attempts to extrapolate the position of moving objects [<xref rid="bib28 bib29" ref-type="bibr">28, 29</xref>]. What our results demonstrate for the first time is that forward predictions formed based on motion information precisely specify the pattern (i.e., phase and orientation) of expected future visual input. Moreover, we show that these internally generated predictions interfere with representations of actual visual input in a lawful manner, providing a direct and objective means of studying forward modeling in the visual system.</p>
    </sec>
    <sec sec-type="methods" id="sec2">
      <title>Experimental Procedures</title>
      <sec id="sec2.1">
        <title>Observers</title>
        <p>Eleven observers aged from 21 to 41 participated in the study: two of the authors (N.W.R. and P.V.M.) plus nine individuals who were naive to the specific purpose of the experiments. All had normal or corrected-to-normal visual acuity and gave informed consent.</p>
      </sec>
      <sec id="sec2.2">
        <title>Apparatus</title>
        <p>Stimuli were presented on a gamma-corrected 100 Hz Mitsubishi Diamond Pro 2045U monitor driven by a Cambridge Research Systems ViSaGe with 14-bit resolution. The display was viewed binocularly from a distance of 65 cm, with head position maintained using a chin rest.</p>
      </sec>
      <sec id="sec2.3">
        <title>Phase Dependence of Suppression at Leading and Trailing Edges</title>
        <p>Observers (n = 5) were instructed to detect a small target grating (width = 1°, height = 1°, spatial frequency = 1 c/°) presented for 1000 ms at a location either 2° to the left or right of a small fixation cross. The target drifted upward or downward (randomly selected on each trial) with a temporal frequency of 5 Hz.</p>
        <p>Two high-contrast inducer gratings were displayed either above or below the potential target locations and drifted in the same direction and at the same speed as the target (width = 1°, height = 6.67°, spatial frequency = 1 c/°, temporal frequency = 5 Hz, Michelson contrast = 100%). This arrangement ensured that the target abutted one of the inducer stimuli on any given trial but that the inducers provided no cue as to the location of the target. As depicted in <xref rid="fig1" ref-type="fig">Figure 1</xref>A, manipulation of the stimulus configuration allowed comparison of performance where the target abutted either the leading or trailing edge of the nearest inducer. Across different conditions, the waveform of the target was either in phase with the inducer (indicated by a relative phase of 0 or 2π) or advanced by one-quarter (π/2), half (π), or three-quarters (3π/2) of a cycle. <xref rid="fig1" ref-type="fig">Figure 1</xref>B shows space-time profiles of a downward-drifting target stimulus (low-contrast region) presented at the leading edge of an inducer positioned above it (high-contrast region). Performance was also assessed in a baseline condition with no inducer stimuli. To avoid the introduction of spatial and/or temporal uncertainty, we used thin (2 arcmin) line cues to mimic the vertical edges of the pair of inducers present in other conditions.</p>
        <p>Target detectability was measured using the method of constant stimuli, with 120 trial presentations for each of seven equally log-spaced Michelson contrast levels (840 trials contributing to each threshold estimate). Individual psychometric functions were fitted with a logistic function, and contrast detection thresholds were defined as the Michelson contrast (expressed as a percentage) yielding 75% correct performance. Trials for leading-edge and trailing-edge conditions were randomly interleaved in blocks with a fixed phase difference.</p>
      </sec>
      <sec id="sec2.4">
        <title>Spatial Interference Profiles</title>
        <p>An example of the stimulus configuration used to measure spatial interference patterns is shown in <xref rid="app2" ref-type="sec">Figure S2</xref>. The target (0.5 c/°, 5 Hz, 2° × 2°) was presented at an eccentricity of 4° to the left or right of a small fixation cross. The target was vertically oriented and drifted toward fixation (i.e., rightward when presented on the left and vice versa). The directions of the two inducer gratings (width = 10°, height = 10°, spatial frequency 0.5 c/°, temporal frequency = 5 Hz, Michelson contrast = 100%) were rotated by either 30° or 15° with respect to that of each potential target (indicated by θ in <xref rid="fig2" ref-type="fig">Figure 2</xref>A). Across different blocks of trials, the relative position of target and inducer was controlled by vertically displacing the inducers (target positions remained constant). In the example shown in <xref rid="app2" ref-type="sec">Figure S1</xref>, the inducers were displaced upward by 4°, corresponding to a center-to-center offset of +4°, as displayed in <xref rid="fig2" ref-type="fig">Figures 2</xref>C and 2D. Conditions with targets differing in phase by half a cycle were interleaved within each block. Contrast detection thresholds were estimated using methods identical to those described above for three observers.</p>
      </sec>
      <sec id="sec2.5">
        <title>Properties of the Predictive Model</title>
        <p>Methods were comparable to those described above for the phase-dependence experiment, with the exception that target stimuli were always presented at the leading edge of the inducer. In-phase and antiphase target conditions were randomly interleaved within each run of trials.</p>
        <sec id="sec2.5.1">
          <title>Spatial Support</title>
          <p>The length of the inducer stimuli was varied between 0.067° (4 arcmin) and 3.33°.</p>
        </sec>
        <sec id="sec2.5.2">
          <title>Spatial Projection</title>
          <p>Inducer stimuli (length = 6.67°) were shifted vertically to introduce a spatial gap between inducer and target of between 0.067° (4 arcmin) and 3.33°. Note that the phase of the inducer stimuli was adjusted to accommodate the gap, such that for in-phase conditions, the form of the targets remained consistent with extrapolation of the inducer in space and time.</p>
        </sec>
        <sec id="sec2.5.3">
          <title>Time Course</title>
          <p>The duration of all stimuli (target and inducer) was manipulated between 20 ms and 2000 ms.</p>
        </sec>
        <sec id="sec2.5.4">
          <title>Interocular Transfer</title>
          <p>Stimuli for the two eyes were presented in different regions of a single monitor and viewed using a mirror stereoscope. The viewing field for each eye was framed by a rectangular peripheral fusion lock. In monocular conditions, both target and inducer stimuli were presented to the same eye, which was randomly determined on each trial. In dichoptic conditions, the target was presented to one eye (randomly determined) while the inducer stimuli were presented to the other.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <label>1</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>DeAngelis</surname>
              <given-names>G.C.</given-names>
            </name>
            <name>
              <surname>Freeman</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Ohzawa</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Length and width tuning of neurons in the cat's primary visual cortex</article-title>
          <source>J. Neurophysiol.</source>
          <volume>71</volume>
          <year>1994</year>
          <fpage>347</fpage>
          <lpage>374</lpage>
          <pub-id pub-id-type="pmid">8158236</pub-id>
        </element-citation>
      </ref>
      <ref id="bib2">
        <label>2</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bair</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Cavanaugh</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Time course and time-distance relationships for surround suppression in macaque V1 neurons</article-title>
          <source>J. Neurosci.</source>
          <volume>23</volume>
          <year>2003</year>
          <fpage>7690</fpage>
          <lpage>7701</lpage>
          <pub-id pub-id-type="pmid">12930809</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <label>3</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Petrov</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>McKee</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The effect of spatial configuration on surround suppression of contrast sensitivity</article-title>
          <source>J. Vis.</source>
          <volume>6</volume>
          <year>2006</year>
          <fpage>224</fpage>
          <lpage>238</lpage>
          <pub-id pub-id-type="pmid">16643092</pub-id>
        </element-citation>
      </ref>
      <ref id="bib4">
        <label>4</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Arnold</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Thompson</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Johnston</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Motion and position coding</article-title>
          <source>Vision Res.</source>
          <volume>47</volume>
          <year>2007</year>
          <fpage>2403</fpage>
          <lpage>2410</lpage>
          <pub-id pub-id-type="pmid">17643464</pub-id>
        </element-citation>
      </ref>
      <ref id="bib5">
        <label>5</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chung</surname>
              <given-names>S.T.L.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>S.S.</given-names>
            </name>
            <name>
              <surname>Bedell</surname>
              <given-names>H.E.</given-names>
            </name>
            <name>
              <surname>Yilmaz</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Spatial and temporal properties of the illusory motion-induced position shift for drifting stimuli</article-title>
          <source>Vision Res.</source>
          <volume>47</volume>
          <year>2007</year>
          <fpage>231</fpage>
          <lpage>243</lpage>
          <pub-id pub-id-type="pmid">17190608</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <label>6</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yilmaz</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Tripathy</surname>
              <given-names>S.P.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>S.S.</given-names>
            </name>
            <name>
              <surname>Ogmen</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Attraction of flashes to moving dots</article-title>
          <source>Vision Res.</source>
          <volume>47</volume>
          <year>2007</year>
          <fpage>2603</fpage>
          <lpage>2615</lpage>
          <pub-id pub-id-type="pmid">17697692</pub-id>
        </element-citation>
      </ref>
      <ref id="bib7">
        <label>7</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kirschfeld</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kammer</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>The Fröhlich effect: A consequence of the interaction of visual focal attention and metacontrast</article-title>
          <source>Vision Res.</source>
          <volume>39</volume>
          <year>1999</year>
          <fpage>3702</fpage>
          <lpage>3709</lpage>
          <pub-id pub-id-type="pmid">10746140</pub-id>
        </element-citation>
      </ref>
      <ref id="bib8">
        <label>8</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carrasco</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Penpeci-Talgar</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Eckstein</surname>
              <given-names>M.P.</given-names>
            </name>
          </person-group>
          <article-title>Spatial covert attention increases contrast sensitivity across the CSF: Support for signal enhancement</article-title>
          <source>Vision Res.</source>
          <volume>40</volume>
          <year>2000</year>
          <fpage>1203</fpage>
          <lpage>1215</lpage>
          <pub-id pub-id-type="pmid">10788636</pub-id>
        </element-citation>
      </ref>
      <ref id="bib9">
        <label>9</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cameron</surname>
              <given-names>E.L.</given-names>
            </name>
            <name>
              <surname>Tai</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Carrasco</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Covert attention affects the psychometric function of contrast sensitivity</article-title>
          <source>Vision Res.</source>
          <volume>42</volume>
          <year>2002</year>
          <fpage>949</fpage>
          <lpage>967</lpage>
          <pub-id pub-id-type="pmid">11934448</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <label>10</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schütz</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>Delipetkos</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Braun</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Kerzel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Gegenfurtner</surname>
              <given-names>K.R.</given-names>
            </name>
          </person-group>
          <article-title>Temporal contrast sensitivity during smooth pursuit eye movements</article-title>
          <source>J. Vis.</source>
          <volume>7</volume>
          <year>2007</year>
          <fpage>1</fpage>
          <lpage>15</lpage>
        </element-citation>
      </ref>
      <ref id="bib11">
        <label>11</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Polat</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Sagi</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>The architecture of perceptual spatial interactions</article-title>
          <source>Vision Res.</source>
          <volume>34</volume>
          <year>1994</year>
          <fpage>73</fpage>
          <lpage>78</lpage>
          <pub-id pub-id-type="pmid">8116270</pub-id>
        </element-citation>
      </ref>
      <ref id="bib12">
        <label>12</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Polat</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Sagi</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Lateral interactions between spatial channels: Suppression and facilitation revealed by lateral masking experiments</article-title>
          <source>Vision Res.</source>
          <volume>33</volume>
          <year>1993</year>
          <fpage>993</fpage>
          <lpage>999</lpage>
          <pub-id pub-id-type="pmid">8506641</pub-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <label>13</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hubel</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Wiesel</surname>
              <given-names>T.N.</given-names>
            </name>
          </person-group>
          <article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex</article-title>
          <source>J. Physiol.</source>
          <volume>160</volume>
          <year>1962</year>
          <fpage>106</fpage>
          <lpage>154</lpage>
          <pub-id pub-id-type="pmid">14449617</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <label>14</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hubel</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Wiesel</surname>
              <given-names>T.N.</given-names>
            </name>
          </person-group>
          <article-title>Receptive fields and functional architecture of monkey striate cortex</article-title>
          <source>J. Physiol.</source>
          <volume>195</volume>
          <year>1968</year>
          <fpage>215</fpage>
          <lpage>243</lpage>
          <pub-id pub-id-type="pmid">4966457</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <label>15</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>De Valois</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>De Valois</surname>
              <given-names>K.K.</given-names>
            </name>
          </person-group>
          <article-title>Vernier acuity with stationary moving Gabors</article-title>
          <source>Vision Res.</source>
          <volume>31</volume>
          <year>1991</year>
          <fpage>1619</fpage>
          <lpage>1626</lpage>
          <pub-id pub-id-type="pmid">1949630</pub-id>
        </element-citation>
      </ref>
      <ref id="bib16">
        <label>16</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bressler</surname>
              <given-names>D.W.</given-names>
            </name>
            <name>
              <surname>Whitney</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Second-order motion shifts perceived position</article-title>
          <source>Vision Res.</source>
          <volume>46</volume>
          <year>2006</year>
          <fpage>1120</fpage>
          <lpage>1128</lpage>
          <pub-id pub-id-type="pmid">16359721</pub-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <label>17</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miall</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Weir</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Wolpert</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Stein</surname>
              <given-names>J.F.</given-names>
            </name>
          </person-group>
          <article-title>Is the cerebellum a Smith predictor?</article-title>
          <source>J. Mot. Behav.</source>
          <volume>25</volume>
          <year>1993</year>
          <fpage>203</fpage>
          <lpage>216</lpage>
          <pub-id pub-id-type="pmid">12581990</pub-id>
        </element-citation>
      </ref>
      <ref id="bib18">
        <label>18</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miall</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Wolpert</surname>
              <given-names>D.M.</given-names>
            </name>
          </person-group>
          <article-title>Forward models for physiological motor control</article-title>
          <source>Neural Netw.</source>
          <volume>9</volume>
          <year>1996</year>
          <fpage>1265</fpage>
          <lpage>1279</lpage>
          <pub-id pub-id-type="pmid">12662535</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <label>19</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Von Holst</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Relations between the central nervous system and the peripheral organs</article-title>
          <source>Br. J. Anim. Behav.</source>
          <volume>2</volume>
          <year>1954</year>
          <fpage>89</fpage>
          <lpage>94</lpage>
        </element-citation>
      </ref>
      <ref id="bib20">
        <label>20</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Webb</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Neural mechanisms for prediction: Do insects have forward models?</article-title>
          <source>Trends Neurosci.</source>
          <volume>27</volume>
          <year>2004</year>
          <fpage>278</fpage>
          <lpage>282</lpage>
          <pub-id pub-id-type="pmid">15111010</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <label>21</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watamaniuk</surname>
              <given-names>S.N.J.</given-names>
            </name>
            <name>
              <surname>McKee</surname>
              <given-names>S.P.</given-names>
            </name>
          </person-group>
          <article-title>Seeing motion behind occluders</article-title>
          <source>Nature</source>
          <volume>377</volume>
          <year>1995</year>
          <fpage>729</fpage>
          <lpage>730</lpage>
          <pub-id pub-id-type="pmid">7477261</pub-id>
        </element-citation>
      </ref>
      <ref id="bib22">
        <label>22</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Verghese</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Watamaniuk</surname>
              <given-names>S.N.J.</given-names>
            </name>
            <name>
              <surname>McKee</surname>
              <given-names>S.P.</given-names>
            </name>
            <name>
              <surname>Grzywacz</surname>
              <given-names>N.M.</given-names>
            </name>
          </person-group>
          <article-title>Local motion detectors cannot account for the detectability of an extended trajectory in noise</article-title>
          <source>Vision Res.</source>
          <volume>39</volume>
          <year>1999</year>
          <fpage>19</fpage>
          <lpage>30</lpage>
          <pub-id pub-id-type="pmid">10211392</pub-id>
        </element-citation>
      </ref>
      <ref id="bib23">
        <label>23</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Verghese</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>McKee</surname>
              <given-names>S.P.</given-names>
            </name>
          </person-group>
          <article-title>Predicting future motion</article-title>
          <source>J. Vis.</source>
          <volume>2</volume>
          <year>2002</year>
          <fpage>413</fpage>
          <lpage>423</lpage>
          <pub-id pub-id-type="pmid">12678655</pub-id>
        </element-citation>
      </ref>
      <ref id="bib24">
        <label>24</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Suchow</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Alvarez</surname>
              <given-names>G.A.</given-names>
            </name>
          </person-group>
          <article-title>Motion silences awareness of visual change</article-title>
          <source>Curr. Biol.</source>
          <volume>21</volume>
          <year>2011</year>
          <fpage>140</fpage>
          <lpage>143</lpage>
          <pub-id pub-id-type="pmid">21215632</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <label>25</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>On the computational architecture of the neocortex. I. The role of the thalamo-cortical loop</article-title>
          <source>Biol. Cybern.</source>
          <volume>65</volume>
          <year>1991</year>
          <fpage>135</fpage>
          <lpage>145</lpage>
          <pub-id pub-id-type="pmid">1912004</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <label>26</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rao</surname>
              <given-names>R.P.N.</given-names>
            </name>
            <name>
              <surname>Ballard</surname>
              <given-names>D.H.</given-names>
            </name>
          </person-group>
          <article-title>Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects</article-title>
          <source>Nat. Neurosci.</source>
          <volume>2</volume>
          <year>1999</year>
          <fpage>79</fpage>
          <lpage>87</lpage>
          <pub-id pub-id-type="pmid">10195184</pub-id>
        </element-citation>
      </ref>
      <ref id="bib27">
        <label>27</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Enns</surname>
              <given-names>J.T.</given-names>
            </name>
            <name>
              <surname>Lleras</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>What's next? New evidence for prediction in human vision</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>12</volume>
          <year>2008</year>
          <fpage>327</fpage>
          <lpage>333</lpage>
          <pub-id pub-id-type="pmid">18684660</pub-id>
        </element-citation>
      </ref>
      <ref id="bib28">
        <label>28</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nijhawan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Motion extrapolation in catching</article-title>
          <source>Nature</source>
          <volume>370</volume>
          <year>1994</year>
          <fpage>256</fpage>
          <lpage>257</lpage>
          <pub-id pub-id-type="pmid">8035873</pub-id>
        </element-citation>
      </ref>
      <ref id="bib29">
        <label>29</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nijhawan</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Compensating time delays with neural predictions: Are predictions sensory or motor?</article-title>
          <source>Philos. Transact. A Math. Phys. Eng. Sci.</source>
          <volume>367</volume>
          <year>2009</year>
          <fpage>1063</fpage>
          <lpage>1078</lpage>
          <pub-id pub-id-type="pmid">19218151</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="app2" sec-type="supplementary-material">
      <title>Supplemental Information</title>
      <p>
        <supplementary-material content-type="local-data" id="mmc1">
          <caption>
            <title>Document S1. Five Figures</title>
          </caption>
          <media xlink:href="mmc1.pdf" mimetype="application" mime-subtype="pdf"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was supported by the Wellcome Trust and the UK Biotechnology and Biological Sciences Research Council.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="fig1">
      <label>Figure 1</label>
      <caption>
        <p>Phase-Dependent Suppression of Contrast Sensitivity at the Leading Edge of a Moving Stimulus</p>
        <p>(A) Stimulus configuration. Observers were required to indicate whether a small target pattern was presented to the left or right of fixation. Two high-contrast inducer gratings were positioned adjacent to the potential target locations. Each drifted in the same direction and at the same speed as the target. Manipulation of the stimulus configuration allowed comparison of performance when the target was positioned at either the trailing (red box) or leading (black box) edge of the inducer.</p>
        <p>(B) Space-time plots depicting different phase relationships between inducing (high-contrast region) and target (low-contrast region) stimuli. Note that in-phase(0 or 2π) targets are consistent with a continuation of the inducer waveform in space and time, albeit at a lower contrast.</p>
        <p>(C) Detection thresholds for trailing-edge (red symbols) and leading-edge (black symbols) conditions, plotted as a function of the relative phase of target and inducer stimuli. Open symbols indicate thresholds for a baseline condition with no inducers present. The mean performance of five observers is displayed in the upper left panel, with the remaining panels showing individual data. Error bars indicate ± 1 standard error, calculated either across observers (mean plots) or via bootstrapping (individual thresholds).</p>
        <p>See also <xref rid="app2" ref-type="sec">Figure S1</xref>.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Figure 2</label>
      <caption>
        <p>Interference between Sensory Input and Internally Generated Predictions</p>
        <p>(A) Example of a stimulus configuration in which the drift direction of a large inducer grating has been rotated by 30° relative to a small, rightward-drifting target.</p>
        <p>(B) Computation of the theoretical spatial interference profile produced by superposition of the target and a forward model of the inducer. The stimulus panel represents the target at all possible positions along the inducer's edge. Summing this with a prediction formed by extrapolating the inducer pattern results in a spatial interference profile. Locations at which target detectability is expected to benefit from constructive interference are indicated by regions of higher contrast (e.g., upper dashed box), whereas locations at which detectability is expected to be hampered by destructive interference are indicated by lower contrasts (e.g., lower dashed box). Calculating the local contrast in the interference profile at each target location allows an approximation of the expected modulation of target detectability along the edge of the inducer.</p>
        <p>(C) Shifting the starting phase of the target by half a cycle, while holding all other factors constant, produces a concomitant shift in the theoretical spatial interference profile.</p>
        <p>(D) Comparison of theoretical (upper panel) and empirical (lower panel) spatial interference profiles for an inducer rotated by 30°. Theoretical interference profiles are reproduced from (B) (black symbols) and (C) (green symbols). Mean detection thresholds for three observers are shown, plotted as a function of the target's position relative to the vertical midpoint of the inducer (see <xref rid="sec2" ref-type="sec">Experimental Procedures</xref> for details).</p>
        <p>(E) Comparison of theoretical (upper panel) and empirical (lower panel) spatial interference profiles for an inducer rotated by 15°. Error bars indicate ± 1 standard error.</p>
        <p>See also <xref rid="app2" ref-type="sec">Figure S2</xref>.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Figure 3</label>
      <caption>
        <p>Properties of the Predictive Model</p>
        <p>(A) Spatial support. Upper panel shows mean detection thresholds of three observers for in-phase (black) and antiphase (green) targets, plotted as a function of inducer length. For comparison, the open symbol shows performance with no inducer stimuli. The growth of the interference effect is summarized in the lower panel, which shows the difference between in-phase and antiphase thresholds along with the best-fitting exponential function (semisaturation space constant = 15 arcmin).</p>
        <p>(B) Spatial projection. Thresholds are shown as a function of the size of the spatial gap introduced between target and inducer stimuli. The interference effect is restricted to a small spatial region ahead of the inducer (space constant of exponential fit = 25 arcmin).</p>
        <p>(C) Time course. Thresholds plotted as a function of the duration of target and inducer stimuli reveal the buildup of the interference effect over time (temporal semisaturation constant = 122 ms).</p>
        <p>(D) Interocular transfer. Comparison of performance in conditions where target and inducer stimuli were presented either to the same eye (monocular) or to different eyes (dichoptic) suggests that predictions formed based on motion information presented to one eye can interfere with visual input to the other.</p>
        <p>Error bars indicate ± 1 standard error.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
  </floats-group>
</article>