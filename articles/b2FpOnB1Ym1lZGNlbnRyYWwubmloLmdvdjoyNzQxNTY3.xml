<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Vision Res</journal-id>
      <journal-title>Vision Research</journal-title>
      <issn pub-type="ppub">0042-6989</issn>
      <issn pub-type="epub">1878-5646</issn>
      <publisher>
        <publisher-name>Elsevier Science Ltd.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2741567</article-id>
      <article-id pub-id-type="pmid">19555705</article-id>
      <article-id pub-id-type="publisher-id">VR5701</article-id>
      <article-id pub-id-type="doi">10.1016/j.visres.2009.06.016</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Psychophysical evidence for a non-linear representation of facial identity</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Dakin</surname>
            <given-names>Steven C.</given-names>
          </name>
          <email>s.dakin@ucl.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Omigie</surname>
            <given-names>Diana</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line><sup>a</sup>UCL Institute of Ophthalmology, University College London, EC1V 9EL London, UK</addr-line>
      </aff>
      <aff id="aff2">
        <addr-line><sup>b</sup>Department of Psychology, Goldsmiths, University of London, SE14 6NW London, UK</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author. <email>s.dakin@ucl.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <day>09</day>
        <month>9</month>
        <year>2009</year>
      </pub-date>
      <volume>49</volume>
      <issue>18</issue>
      <fpage>2285</fpage>
      <lpage>2296</lpage>
      <history>
        <date date-type="received">
          <day>11</day>
          <month>2</month>
          <year>2009</year>
        </date>
        <date date-type="rev-recd">
          <day>17</day>
          <month>6</month>
          <year>2009</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2009 Elsevier Ltd.</copyright-statement>
        <copyright-year>2009</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</p>
        </license>
      </permissions>
      <abstract>
        <title>Abstract</title>
        <p>It has been proposed that faces are represented in the visual brain as points within a multi-dimensional “face space”, with the average at its origin. We adapted a psychophysical procedure that measures non-linearities in contrast transduction (by measuring discrimination around different reference/pedestal levels of contrast) to examine the encoding of facial-identity within such a notional space. Specifically we had subjects perform identity discrimination at various pedestal levels of identity (varying from average/0% to caricature/125% identity) to derive “identity dipper functions”. Results indicate that subjects are generally best at spotting identity change in neither average nor full-identity faces, but rather in faces containing an intermediate level of identity (which varies from face-to-face). The overall pattern of results is consistent with the neural encoding of faces involving a single modest non-linear transformation of identity that is consistent across faces and subjects, but that it scaled according to the <italic>distinctiveness</italic> of the face.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Face perception</kwd>
        <kwd>Discrimination</kwd>
        <kwd>Identity</kwd>
        <kwd>Dipper function</kwd>
        <kwd>Average face</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec>
      <label>1</label>
      <title>Introduction</title>
      <p>Recently, progress has been made in understanding how humans encode facial-identity, using the concept of <italic>face space</italic>, where each face is represented as a point within a multi-dimensional space centred on the average face (e.g. <xref rid="bib22" ref-type="bibr">Valentine, 1991</xref>), and where more distinctive faces fall further from the average/centre. Conceptually, this framework can, for example, explain people’s difficulty in differentiating between members of ethnic groups other than their own (<xref rid="bib13" ref-type="bibr">Lindsay, Jack, et al., 1991</xref>) based on the notion that own-race faces occupy high-density regions around the average while other-race faces lie within a cluster some distance away (<xref rid="bib22" ref-type="bibr">Valentine, 1991</xref>). Similarly, arguing that distinctiveness is related to a face’s distance from the mean has been used to explain our superior recognition of distinctive compared to more typical unfamiliar faces (<xref rid="bib5" ref-type="bibr">Hancock, Burton, et al., 1996</xref>).</p>
      <p>With respect to the neural encoding of identity, a key concept is the <italic>identity trajectory</italic> (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), a trajectory in face space passing through an individual face and the average. Faces on this trajectory each contain some percentage of the face’s identity. If it is greater than 100% the face is a caricature, which exaggerates differences between the individual and the average. Such faces are identified more accurately and quickly than the original face (<xref rid="bib8 bib15" ref-type="bibr">Lee, Byatt, et al., 2000; Rhodes, Brennan, et al., 1987</xref>). Conversely <italic>anti-faces</italic> – which fall on the identity trajectory on the opposite side of the average face – contain a negative percentage of identity and are effectively “opposites” of the original. The main evidence for the psychological importance of the identity axes comes from psychophysical studies of adaptation. It is known that prolonged exposure to an adapting face shifts the perceived facial categories of a subsequently viewed (test) face away from the adaptor, e.g. prolonged viewing of a happy face makes a subsequently viewed emotionally-neutral face appear sad (<xref rid="bib25" ref-type="bibr">Webster, Kaping, et al., 2004</xref>). In the case of identity, adaptation to an anti-face shifts the appearance of an average test-face towards the identity of the original (<xref rid="bib10" ref-type="bibr">Leopold, O’Toole, et al., 2001</xref>), and the magnitude of such adaptation is greater for anti-faces than for faces that are equally dissimilar to the test (<xref rid="bib16" ref-type="bibr">Rhodes &amp; Jeffery, 2006</xref>). Furthermore, effects transfer (at least partially) when the appearance of the test has been transformed via changes in expression (<xref rid="bib1" ref-type="bibr">Benton &amp; Burgess, 2008</xref>), although there is weaker transfer when the adapting and test-faces have different poses (<xref rid="bib2 bib6" ref-type="bibr">Benton, Jennings, et al., 2006; Jeffery, Rhodes, et al., 2006</xref>) or orientations (e.g., if the adapter is rotated compared to the test (<xref rid="bib24" ref-type="bibr">Watson &amp; Clifford, 2006</xref>). This would seem to indicate that adaptation, at least in part, taps into a higher-level facial-coding mechanism.</p>
      <p><xref rid="bib14" ref-type="bibr">Loffler, Yourganov, et al. (2005)</xref> used fMRI to examine if the coding strategy employed by neurons in the human brain operates relative to some average/norm. The BOLD signal from the fusiform face area (<xref rid="bib7" ref-type="bibr">Kanwisher, McDermott, et al., 1997</xref>) increased with the degree of deviation from average for faces falling along a single identity trajectory. Furthermore, presenting faces that deviated along axes that were <italic>orthogonal</italic> to the identity axis did not lead to a comparable increase in BOLD response. <xref rid="bib9" ref-type="bibr">Leopold, Bondar, et al. (2006)</xref> measured response of single neurons in the macaque inferotemporal (IT) cortex in response to a range of photographic facial stimuli spanning nine points in an identity trajectory from average (0% identity), to an individual’s face (100% identity), to a caricature (160% identity). Neurons exhibited a marked tendency to show tuning centred on the average face and for their firing rates to increase near-linearly with increasing identity-strength. These findings are broadly consistent with an average-based encoding of facial identity.</p>
      <p>Two studies examining how distance from the average face affects subjects’ ability to discriminate between faces, have produced contradictory results. <xref rid="bib26" ref-type="bibr">Wilson, Loffler, et al. (2002)</xref> report that discrimination between morphed faces is more difficult when they are further away from the mean face. This could reflect chronic adaptation to near-average faces (which might improve sensitivity) an idea <xref rid="bib17" ref-type="bibr">Rhodes, Maloney, et al. (2007)</xref> tested using three tasks probing face processing either near or far from the average. Subjects’ ability to judge inter-ocular spacing was unchanged with distance from the mean, whereas perceived similarity (assessed using ratings) and perceptual difference scaling both indicated <italic>reduced</italic> sensitivity to facial difference for near-average faces. We sought to explore this issue in detail by using behavioural psychophysics to examine the nature of neural encoding of faces along the identity axis. Our specific aim is to infer the full underlying <italic>identity response functions</italic> (IRFs) that support discrimination of faces differing in identity-level. To do this we rely on previous paradigms that use psychophysically measured thresholds to infer underlying response functions for stimulus <italic>contrast</italic> (<xref rid="bib29" ref-type="bibr">Zenger-Landolt &amp; Heeger, 2003</xref>). Specifically we used a <italic>pedestal paradigm</italic>, measuring how much extra identity had to be added to a face for it to be just discriminable from two reference/distracter faces (which are presented at a fixed pedestal identity level). We also sought to compare discrimination for inverted and polarity-inverted faces (which are matched to the upright stimuli in terms of the physical distortion applied.) The advantage of a pedestal paradigm is that it provides a full mapping of discriminability as a function of identity-level allowing one to infer the underlying response function that supports such discrimination, as illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref> (for a recent review of this paradigm see <xref rid="bib19" ref-type="bibr">Solomon (2009)</xref>).</p>
    </sec>
    <sec>
      <label>2</label>
      <title>General methods</title>
      <sec>
        <label>2.1</label>
        <title>Stimuli</title>
        <p>We obtained full-face uniformly-lit photographs of 64 male subjects (e.g. <xref rid="fig3" ref-type="fig">Fig. 3</xref>c) and manually located 32 key-points (around the eyes, nose, etc.) using digital versions of these images. We co-registered all faces by first averaging all key-point sets and then morphing each face into registration with this averaged set (e.g. <xref rid="fig3" ref-type="fig">Fig. 3</xref>b). Morphing was done using custom software written in the MatLab programming environment (MathWorks) relying on built-in 2D bilinear interpolation routines (interp2) to perform image stretching. Averaging the resulting 64 morphed images gives the “average face” (<xref rid="fig3" ref-type="fig">Fig. 3</xref>f). All our stimuli were constructed by morphing this average face into registration with different sets of key-points. Morphing the average back to the original set of key-points for a given face gives a 100% identity stimulus (<xref rid="fig3" ref-type="fig">Fig. 3</xref>g). We could also generate faces that had various identity “strengths” by morphing the average into registration with an arbitrary positive or negative proportion of the difference between the average key-points and the individual key-points:<disp-formula><label>(1)</label><mml:math id="M1" altimg="si1.gif" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>morph</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>average</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>average</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>face</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p>
        <p>Here <mml:math id="M2" altimg="si2.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>face</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math> represents key-points from an individual face, and <mml:math id="M3" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext>average</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math> the key-points from the average.</p>
        <p><italic>W</italic> is the identity strength, where for example, −100% represents the anti-face, 0% the average, 100% the original identity and 150% a caricature. Examples of such stimuli are shown in <xref rid="fig3" ref-type="fig">Fig. 3e–h</xref>. Using morphed averages rather than morphed originals has the advantage that all faces are matched for colouration and texture, (which cannot be easily parameterised) so that the only differences between stimuli are attributable to changes in face geometry due to the morphing.</p>
      </sec>
      <sec>
        <label>2.2</label>
        <title>Equipment</title>
        <p>Stimuli were presented on a Lacie CRT monitor attached to an Apple iMac computer. The display had 1280 × 960 pixel resolution and operated at a refresh rate of 75 Hz. The monitor was viewed at a distance of 1 m. Subjects responded using a numeric keypad.</p>
      </sec>
      <sec>
        <label>2.3</label>
        <title>Subjects</title>
        <p><italic>Rating experiment</italic>: Subjects were 12 members of staff at the UCL Institute of Ophthalmology with normal or corrected-to-normal vision, unfamiliar with the face-set.</p>
        <p><italic>Detection and discrimination experiments</italic>: In the discrimination experiments the two authors (SCD and DEO) served as subjects along with two naïve subjects (JRC and DAK). Three of our subjects were male Caucasians, including two (SCD and DAK) native UK residents, and one (JRC) Australian who had been resident in the UK for a year at the time of testing. The fourth subject (DEO) was a female of mixed (Nigerian-English) ethnic origin resident in the UK for 8 years prior to testing. Thus all of our subjects would have been exposed continuously to specifically British Caucasian faces for at least a year prior to testing. Subjects in both experiments had normal or corrected-to-normal vision acuity. All were experienced at participating in psychophysical experiments.</p>
      </sec>
      <sec>
        <label>2.4</label>
        <title>Procedure</title>
        <sec>
          <label>2.4.1</label>
          <title>Rating experiment</title>
          <p>Random subsets of 16 out of the 64 possible greyscale (morphed average) face images were presented on the monitor in a 4 × 4 grid (<xref rid="fig4" ref-type="fig">Fig. 4</xref>a). Each face image was 300 × 200 pixels so the 4 × 4 grid subtended 7.4° (width) by 9.8° (height). Subjects were presented with a randomly selected face-grid displayed on a grey background and required to indicate “Which face is the most distinctive?” by clicking on it using the mouse. No time limit was given and reaction times were not recorded. Once clicked, faces were occluded with a grey block, and the subjects made their judgment using the remaining faces until only one face remained. Subjects performed this task on a total of eight grids each containing a new subset of 16 faces. If a face was clicked first it achieved a score of 16, if it was clicked second, it achieved a score of 15 and so on. Ratings were compiled by averaging each face’s score across presentations and subjects.</p>
        </sec>
        <sec>
          <label>2.4.2</label>
          <title>Discrimination experiments</title>
          <p>The first time a given test-face was used within any experimental session subjects studied the 100% identity <italic>test-face</italic> for at least two minutes, in order to familiarise themselves with it, prior to commencement of testing. These test-faces were selected to span the space of rated distinctiveness. Experimental runs consisted of 64 trials. On each trial a triplet of faces was presented; two reference faces (baseline stimuli) and a target-face. The three faces were randomly positioned on an annulus such that they maintained a constant distance from central fixation (4.2°) and from one another. Faces appeared simultaneously on a uniform grey field for a duration of 500 ms (<xref rid="fig4" ref-type="fig">Fig. 4</xref>b). Each face subtended 3.7° (width) by 4.9° (height). After 500 ms – an exposure duration selected to avoid subjects being able to scrutinise local differences between faces – all faces were replaced with boxes labelled “1”, “2” and “3” where they had stood. Observers were instructed to indicate “which face was the odd-man-out?” by hitting keys “1”, “2” or “3”. There was no time limit for responses but observers rarely took more than 2–3 s to respond. The observers’ response initiated the next trial. Observers were aware that two faces were always identical (the reference faces) and one always different (the target).</p>
          <p>The target was made of the average face with some proportion of the test-face identity added to it. The amount of identity contained in the target was adjusted from trial-to-trial using an adaptive staircase (<xref rid="bib23" ref-type="bibr">Watson &amp; Pelli, 1983</xref>) to determine the <italic>threshold identity level</italic> (i.e. one supporting 82% correct performance). After detection thresholds were measured for a subset of about 12 faces, four were selected that spanned the range of rated distinctiveness and physical distance from the average, while at the same time having detection thresholds of varying magnitude. These faces were then presented not just as averages but with some (variable) level of “pedestal” identity added to them. Pedestal identity was varied (across runs) from 0% to 125% in steps of 12.5%. Subjects indicated the odd-man-out using the detection procedure. Runs were performed (in random-order) using: (a) upright/positive-polarity faces, (b) inverted/positive-polarity faces and (c) upright/negative-polarity faces. Examples of these stimuli are shown in <xref rid="fig5" ref-type="fig">Fig. 5</xref>.</p>
        </sec>
      </sec>
    </sec>
    <sec>
      <label>3</label>
      <title>Psychophysical estimation of the identity response function</title>
      <p>We measured the discriminability of faces falling on a given identity axis, as they varied in identity-strength; examples of two experimental trials, with corresponding pedestal levels of 0% and 50%, are shown in <xref rid="fig6" ref-type="fig">Fig. 6</xref>a,b. Both of the odd-men-out (dashed frames) have 25% more identity than the distractor faces which have identity levels of (left) 0% and (right) 50%. It is easier to spot the odd-man-out on the right when the “pedestal” identity levels of the distractors are higher. This tendency is borne out in the full threshold-versus-identity (TvI) curves shown in <xref rid="fig7 fig8 fig9" ref-type="fig">Figs. 7–9</xref>.</p>
      <p>TvI curves from the three presentation conditions (upright, inverted and polarity-inverted) and the four faces (averaged across 3–6 runs) are presented for three observers in <xref rid="fig7 fig8 fig9" ref-type="fig">Figs. 7–9</xref>. Subjects were generally better at identifying the target (i.e. thresholds were lower indicating less additional identity was required) as the reference faces had more identity introduced into them. This is consistent with earlier work using faces morphed along the identity axis (<xref rid="bib17" ref-type="bibr">Rhodes et al., 2007</xref>) However, for the upright face conditions, data showed a shallow “dipper” shape: at low identity levels thresholds initially drop with increasing pedestal identity, but then steadily rise at higher identity pedestals. In terms of an underlying identity response function (IRF) these findings are consistent with a non-linear transduction of identity level. Dips were particularly evident for face #28 (in all subjects), face #43 (for experienced observers) but were generally much weaker for face #3 (for all subjects). Below we explore the possibility that these differences are attributable to differences in the distinctiveness of faces. By contrast, performance with inverted and contrast-polarity inverted faces was generally poorer at low pedestal identity levels (i.e. for tasks close to standard detection) and exhibited straightforward improvement with increasing identity level (i.e. inverse Weber’s law behaviour) with no dips. The overall pattern of results led to discrimination around high pedestal identity levels being almost identical across upright and inverted/polarity-inverted faces. This is a rather counter-intuitive finding we return to in the Discussion. The monotonic trend in thresholds we observe in inverted/polarity-inverted conditions is important because such stimuli contain similar physical distortions to the upright face condition. Our not finding dips with inverted/polarity-inverted stimuli demonstrates that non-linear discrimination performance is related to face perception and not to, e.g. subjects general ability to detect changes in image distortion.</p>
    </sec>
    <sec id="sec1">
      <label>4</label>
      <title>Modelling the identity response function (IRF)</title>
      <p>Identity response functions (IRFs) were obtained by integrating the psychophysical threshold versus identity (TvI) curves. First the thresholds were converted to sensitivity values and were cumulatively summed. Results were then fit with a Naka–Rushton function:<disp-formula><label>(2)</label><mml:math id="M4" altimg="si4.gif" overflow="scroll"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula></p>
      <p>using the fmins function in Matlab. Within this expression the parameter <mml:math id="M5" altimg="si5.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math> scales the overall response, <italic>b</italic> sets the semi-saturation point, and <italic>n</italic> set the degree of non-linearity of the response function. <xref rid="fig10 fig11" ref-type="fig">Figs. 10 and 11</xref> show response functions derived from the threshold versus identity curves for experienced observers DEO and SCD, respectively. Note that the response functions obtained, showed a slight non-linearity (<italic>n</italic> = 1.1–1.5) as a result of the dips in TvI functions. We next used a bootstrapping procedure to determine the statistical significance of these dips. For each observer we used the mean and variance of the thresholds obtained at each identity level to generate random threshold distributions. We then generated a new data set by drawing one sample from each of these random distributions at each identity level and repeated this procedure to generate 1024 artificial data sets. We transformed each of these data sets into cumulative sensitivity values (in the manner described above), fit them with a Naka–Rushton function and recorded the distributions of fit values obtained over the 1024 sets. The percentage of values of <italic>n</italic> falling below 1 (i.e. indicating a fit that was inconsistent with a dip) gives a measure of statistical significance of the dips (<italic>p</italic>). These estimates are tabulated below <xref rid="fig10 fig11" ref-type="fig">Figs. 10a and 11</xref>a for subjects DEO and SCD, respectively. Dips were statistically significant in 8/12 conditions tested. Specifically they were significant in all but one case for DEO (when <italic>p</italic> approached significance at 6.4%). For SCD the dip was not significantly significant for face 3, approached significance for face 25 (<italic>p</italic> = 7%) and was highly significant for remaining faces. For the naïve subjects, each tested on faces 3 and 28, <italic>p</italic> was 2.5% and 7.5% (JRC) and 1% and 0.5% (DAK), respectively.</p>
      <p>We wondered if differences between IRFs (across conditions and subjects) could be accounted for by scaling of a single underlying IRF. Scaling simply consists of re-plotting response functions on a new <italic>x</italic>-axis that is a scaled version of the identity pedestal-level. <xref rid="fig10 fig11" ref-type="fig">Figs. 10 and 11</xref> also show the IRFs from both experienced subjects’ for the four faces, re-plotted using <italic>x</italic>-axes that have been normalised using four different values:<list list-type="simple"><list-item><label>(1)</label><p>The detection threshold for each face (i.e. the threshold with a 0% pedestal).</p></list-item><list-item><label>(2)</label><p>The pedestal value that induced the minimum discrimination threshold.</p></list-item><list-item><label>(3)</label><p>The minimum discrimination threshold (obtained experimentally).</p></list-item><list-item><label>(4)</label><p>The estimated minimum discrimination threshold. (This is estimated by using the best fitting response function, taking its inverse and derivative to predict the TvI, and then estimating the minimum threshold that would be obtained with the optimal pedestal. This is similar to (3) but uses all the experimental data and is therefore less prone to sampling limitations).</p></list-item></list></p>
      <p>From <xref rid="fig10 fig11" ref-type="fig">Figs 10 and 11</xref> it is evident first that rescaling by detection threshold for each face does a poor job of co-registering the response functions, calling into question the role of the average face as a natural “origin” for our discrimination data. However, rescaling the <italic>x</italic>-axis using the estimated minimum threshold brings the response functions from the four faces into close registration, for all subjects. Error values were consistently lowest using this scheme. Note also the similarity of the estimates of the three parameters of the best fitting single IRF to both subjects (1.0, 1.1, and 1.5 for DEO versus 1.0, 1.1, 1.4 for SCD) suggesting that the underlying IRF may be common across subjects as well as across faces.</p>
      <p>These results indicate that subjects’ performance on the pedestal experiment were consistent with a modest non-linear transduction of stimulus identity. In addition our data are consistent with a single underlying identity response function that was simply scaled by the estimated lowest discrimination threshold for an individual face. To further validate our use of a generic scaled IRF, we used it to go back and predict the original thresholds (TvI function) for each subject. By taking the derivative of the scaled (using estimated minimum threshold) best fitting scaled IRF for each subject, and inverting it, we were able to generate such predicted thresholds. <xref rid="fig12" ref-type="fig">Fig. 12</xref> shows the result of doing this. For subjects SCD and DEO, the line of best fit (solid grey line) and the predicted TvI function (broken black line) show substantial agreement. This is impressive given that the fits for each subject now use only 7 parameters (3 for the generic response function +4 scaling parameters for each face) compared to the original 12 (4 × 3-parameter independent fits). Arguably four of the seven parameters in the generic model fits are not free since they were derived empirically.</p>
    </sec>
    <sec>
      <label>5</label>
      <title>The role of distinctiveness in determining the identity response function</title>
      <p>The last section demonstrated that identity response functions appear to be scaled by the minimum detectable change in identity for a given face. What property of faces sets this value? We next asked if this property might be related to facial distinctiveness by relating our earlier results to distinctiveness ratings for all the faces used so far. <xref rid="fig13" ref-type="fig">Fig. 13</xref> plots detection thresholds and estimated minimum discrimination thresholds (EM; from Section <xref rid="sec1" ref-type="sec">4</xref>) against rated distinctiveness. Note that both detection thresholds and EMs generally fall with increasing distinctiveness. A second-order polynomial fit to these data (solid and dashed lines in <xref rid="fig10" ref-type="fig">Fig. 10</xref>) account for 50% and 29% of the variance in the discrimination and detection data, respectively. A more reliable trend is evident in the relationship between EM and rated distinctiveness.</p>
    </sec>
    <sec>
      <label>6</label>
      <title>Discussion</title>
      <p>To summarise, we have shown three things:<list list-type="simple"><list-item><label>(1)</label><p>Discrimination based on identity strength improves (for upright and inverted faces) as the stimuli move away from the average.</p></list-item><list-item><label>(2)</label><p>Best discrimination of upright faces occurs around intermediate levels of identity, consistent with a modestly non-linear transduction of identity.</p></list-item><list-item><label>(3)</label><p>Results are consistent with a single underlying identity response function that is scaled by a parameter related to distinctiveness.</p></list-item></list></p>
      <sec>
        <label>6.1</label>
        <title>Morphing and image distortion</title>
        <p>When faces are morphed, one essentially imposes a form of image distortion or disorder. In general our ability to detect disorder shows a Weber’s law dependence (i.e. becomes more difficult) as a function of increasing image-disorder (e.g. <xref rid="bib11" ref-type="bibr">Levi, Klein, et al., 2000</xref>), but this is typically assessed using arrays of regularly spaced elements all of which undergo disruption from the same probability density function. We propose that the finding that our ability to detect facial-image distortion increases with increasing pedestal distortion (point 1) likely arises from subjects increasingly being able identify the <italic>local-features</italic> undergoing the largest distortions (since the distortion applied under morphing will be highly non-uniform across the face). As pedestal distortion increases, all images appear “strange”, allowing one to identify the <italic>most distorted</italic> features in those images, and so to make an essentially local-feature comparison amongst stimuli. This would explain a counter-intuitive outcome of the first experiment – that thresholds for inverted and upright faces could converge at high identity levels. Stimuli morphed beyond the 150% identity level (e.g. <xref rid="fig3" ref-type="fig">Fig. 3</xref>d) quickly stop resembling physically realistic faces, so that subjects will rely less and less on strategies related to face perception (which are decreasingly appropriate at identity levels beyond 100%) and switch to trying to spot gross physical distortion of the stimulus. Such strategies must be more related to local structure (since subjects would be unlikely to have previously encountered the particular combination of distorted features presented) i.e. will depend less on the holistic structure of faces that is thought to confer the advantage on upright faces. A move to increasingly local processing would also explain why IRFs for inverted faces are shallower i.e. show less dependence on image distortion; inverted faces are thought to be processed in a less holistic/more local manner to start with (<xref rid="bib4 bib18 bib27" ref-type="bibr">Goffaux &amp; Rossion, 2006; Rossion, 2008; Yin, 1969</xref>).</p>
        <p>Consistent with the view that effects of identity strength are contingent on tasks tapping into global/holistic processing, <xref rid="bib17" ref-type="bibr">Rhodes et al. (2007)</xref> failed to find an effect of identity-strength on subjects ability to judge eye-separation (an essentially local judgement). Later experiments in the same paper did use more global tasks (similarity ratings and perceptual difference scaling) and reported that processing was generally poorer around the average. This closely accords with our overall finding (point 1) of an inverse Weber’s law dependence on identity strength.</p>
        <p>Contrary to this position, <xref rid="bib26" ref-type="bibr">Wilson et al. (2002)</xref> has shown that faces further from the mean are <italic>more difficult</italic> to discriminate from one another than typical faces. Using <italic>face cubes</italic> – face subspaces comprised of four faces made mutually orthogonal with respect to any given face – Wilson et al. showed that discrimination thresholds are about 1.45 times larger for face cubes centred away from the mean than from those centred at the mean. The authors reasoned that if most faces we experience are similar to the mean, then it is most necessary to be able to discriminate among this population and thus lower thresholds would be observed near to the mean than further away from the mean. By contrast, our findings showed improved discrimination of faces with increasing distance from the mean. However, while Wilson et al. measured discrimination between faces of different identities, our experiments looked at discrimination between faces of similar identity (<xref rid="fig14" ref-type="fig">Fig. 14</xref>a). These, it seems, are very different tasks, and in part to clarify that our results were particular to movement along the identity axis, we carried out a control experiment using a procedure modified from the previous discrimination experiment. Specifically we measured the minimum % of face 43 (a face that previously generated strong dips for subjects SCD and DEO; <xref rid="fig7 fig8" ref-type="fig">Figs. 7 and 8</xref>) that had to be added to a pedestal to produce reliable performance on an odd-man-out task. However, now the pedestal was no longer face 43 (at different identity levels) but another face (28) at different identity levels. Thus the subject still had to determine which face was most like face 43, but now the reference faces frequently looked like face 28, and the target was a mixture of 43 and 28. <xref rid="fig14" ref-type="fig">Fig. 14</xref>b plots data from this experiment (open symbols, subject SCD) and compares them to results from the last experiment (solid line). Results are unequivocal. Now we observe a steady rise in thresholds with increasing identity level of the pedestal which now serves only to mask the identity of the target; there is no indication of non-linearity beyond a modest saturation of thresholds at the highest level of pedestal identity. Thus we have produced a similar finding to <xref rid="bib26" ref-type="bibr">Wilson et al. (2002)</xref> – it is harder to spot identity change in faces further from the mean. Combined with our earlier results we can conclude that the discriminability of faces depends not only on the distance they are from the average, <italic>but the direction one pushes them in face space</italic>. Our results indicate that pushing an average along an identity axis (broadly) improves discriminability, whereas <xref rid="bib26" ref-type="bibr">Wilson et al.‘s (2002)</xref> findings indicate that pushing in directions which transform one face into another are most noticeable when applied to average faces.</p>
        <p>It is interesting to consider our findings in the light of evidence indicating categorical processes in face perception. In particular, if one makes a morph continuum going from face A to face B (i.e. faces are mixtures of the identities of A and B in some proportion) and takes pairs of faces differing by 20% in the contribution of each face (e.g. [0.1A + 0.9B, 0.3A + 0.7B] or [0.7A + 0.3B, 0.9A + 0.1B]) then observers are best at categorising the members of faces-pairs as A or B when the pairing straddles a category boundary (e.g. [0.4A + 0.6B,0.6A + 0.4B] assuming that the category boundary is at 0.5A + 0.5B) (<xref rid="bib12" ref-type="bibr">Levin &amp; Beale, 2000</xref>). This is a highly counter-intuitive result since one might expect best categorisation when one of the faces was clearly either A or B. A reviewer of this paper suggested subjects might be treating the target-face and the average as separate categories, and that optimal discrimination arises at intermediate identity levels arises because we don’t have to push faces very far along the identity axis in order to get them to fall into another distinct category. At present our experiments are unable to separate the predictions of a model based on faces being represented in a continuous space or according to categories; indeed we suggest that non-linearities in a continuous space could be the basis of such categorical effects.</p>
      </sec>
      <sec>
        <label>6.2</label>
        <title>Relationship to neural response</title>
        <p>An aim of our experiment was to compare IRFs to results from previous fMRI (<xref rid="bib14" ref-type="bibr">Loffler et al., 2005</xref>) and electrophysiology (<xref rid="bib9" ref-type="bibr">Leopold et al., 2006</xref>) studies. <xref rid="bib9" ref-type="bibr">Leopold et al. (2006)</xref> showed that single neurons in the inferotemporal cortex increase their firing rate near-linearly as a function of increasing identity (up to 160%) in facial stimuli. In addition, <xref rid="bib14" ref-type="bibr">Loeffler, et al. (2005</xref>) located a region of the inferotemporal cortex which responded more to faces than to other presented objects e.g. houses by presenting faces with varying <italic>geometric distance</italic> from the mean to subjects while measuring fMRI BOLD signal. Under these conditions, BOLD response follows a sigmoidal response to increasing identity that Loffler et al. reason may in part reflect intrinsic properties of the haemodynamic response. These authors conclude that there is likely a monotonic but non-linear relationship of BOLD response to increasing identity. Our inferred underlying response functions for upright faces, exhibit just such a monotonic but non-linear transduction of identity.</p>
        <p>Our results indicate that the mapping from identity-level to the dimensions of face space is modestly non-linear, but that this mapping is broadly consistent across faces, being scaled only by the distinctiveness of faces. How might this non-linearity be related to neural responses? We speculate that our findings might be explicable based on the following three assumptions:<list list-type="simple"><list-item><label>(1)</label><p>Single neurons are broadly tuned to facial identity and exhibit a near-linear dependence of spike rate on identity level (<xref rid="bib28" ref-type="bibr">Young &amp; Yamane, 1992</xref>).</p></list-item><list-item><label>(2)</label><p>Face processing uses a sparse population code using the joint contribution of neural sub-populations, composed of elements with properties similar to Assumption 1 (<xref rid="bib28" ref-type="bibr">Young &amp; Yamane, 1992</xref>).</p></list-item><list-item><label>(3)</label><p>Discrimination is based on the pooled activity of a set of IT neurons that are prone to multiplicative noise (i.e. becoming more variable as they become more active) (<xref rid="bib3 bib20" ref-type="bibr">Carandini, 2004; Tolhurst, Movshon, et al., 1981</xref>).</p></list-item></list></p>
        <p>The final point is key in proposing that overall activity determines discrimination, and that the more active neurons are, the less reliable their responses become. It is a consequence of such a view that best discrimination occurs with stimuli eliciting low levels of neural activity. Under this hypothesis near-average faces elicit a modest amount of activity from a large number of broadly tuned face sensitive cells (since, by definition, the average face is less different from a neurons preferred face than any other face); this is <italic>dense-low</italic> activity. As the level of identity increases, this activity decreases (as the face stimuli are now decreasingly well matched to the preference of many neurons) leading to correspondingly better discrimination performance (based on the argument that less active neurons produce more reliable signals). As identity level increases beyond the optimal point for discrimination, inappropriately-tuned neurons shut down leaving the sub-population of neurons encoding a particular facial identity to become more and more active and so increasingly dominate activity. An increasingly <italic>sparse-high</italic> pattern of activity will lead to a drop in overall performance (less reliable discrimination) as a result of the increasingly noisy firing of finely tuned neurons at extreme levels of identity. In short we propose that dips arise at the point of optimised, low neural activity, between the extremes of unselective broadly tuned neurons firing at low levels of identity and finely-tuned identity neurons firing very strongly (but unreliably) at extreme levels of identity.</p>
        <p>What of the steady increase we observe as we increase the identity level of inverted faces? Above we suggested that this could be due to a reliance on local analysis in inverted faces, which is increasingly suitable at high levels of identity/distortion. We further speculate that this strategy may arise from local components of inverted faces eliciting dense-low activity by weakly stimulating neurons tuned to upright faces. Activity drops with increasing identity as local components becomes more identity-specific and so discrimination improves. We do not observe a subsequent deterioration in performance (as we would for the rising part of a dipper) simply because there are no cells tuned to code the identity of full-identity inverted stimuli, and so no way for the system to switch into a sparse-high state. Instead we simply observe a steady improvement in discrimination as activity falls. Although speculative these are testable hypotheses via examination of the activity of population of neurons in candidate face coding areas in the primate cortex (<xref rid="bib21" ref-type="bibr">Tsao, Freiwald, et al., 2006</xref>).</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>SCD is supported by the Wellcome Trust. We are grateful to John Cass, Meike Ramon and Roger Watt for constructive discussion of this work, and to Peter Hancock for providing the face stimuli.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Benton</surname>
              <given-names>C.P.</given-names>
            </name>
            <name>
              <surname>Burgess</surname>
              <given-names>E.C.</given-names>
            </name>
          </person-group>
          <article-title>The direction of measured face after effects</article-title>
          <source>Journal of Vision</source>
          <year>2008</year>
          <volume>8</volume>
          <issue>15</issue>
          <fpage>1</fpage>
          <lpage>6</lpage>
          <pub-id pub-id-type="pmid">19146285</pub-id>
        </citation>
      </ref>
      <ref id="bib2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Benton</surname>
              <given-names>C.P.</given-names>
            </name>
            <name>
              <surname>Jennings</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>Viewpoint dependence in adaptation to facial identity</article-title>
          <source>Vision Research</source>
          <year>2006</year>
          <volume>46</volume>
          <issue>20</issue>
          <fpage>3313</fpage>
          <lpage>3325</lpage>
          <pub-id pub-id-type="pmid">16844181</pub-id>
        </citation>
      </ref>
      <ref id="bib3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carandini</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Amplification of trial-to-trial response variability by neurons in visual cortex</article-title>
          <source>PLoS Biology</source>
          <year>2004</year>
          <volume>2</volume>
          <issue>9</issue>
          <fpage>E264</fpage>
          <pub-id pub-id-type="pmid">15328535</pub-id>
        </citation>
      </ref>
      <ref id="bib4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Goffaux</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Faces are “spatial”–holistic face perception is supported by low spatial frequencies</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <year>2006</year>
          <volume>32</volume>
          <issue>4</issue>
          <fpage>1023</fpage>
          <lpage>1039</lpage>
          <pub-id pub-id-type="pmid">16846295</pub-id>
        </citation>
      </ref>
      <ref id="bib5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hancock</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Face processing: Human perception and principal components analysis</article-title>
          <source>Memory and Cognition</source>
          <year>1996</year>
          <volume>24</volume>
          <issue>1</issue>
          <fpage>21</fpage>
          <lpage>40</lpage>
        </citation>
      </ref>
      <ref id="bib6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jeffery</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Rhodes</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>View-specific coding of face shape</article-title>
          <source>Psychological Science</source>
          <year>2006</year>
          <volume>17</volume>
          <issue>6</issue>
          <fpage>501</fpage>
          <lpage>505</lpage>
          <pub-id pub-id-type="pmid">16771800</pub-id>
        </citation>
      </ref>
      <ref id="bib7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kanwisher</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>McDermott</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>The fusiform face area: A module in human extrastriate cortex specialized for face perception</article-title>
          <source>Journal of Neuroscience</source>
          <year>1997</year>
          <volume>17</volume>
          <issue>11</issue>
          <fpage>4302</fpage>
          <lpage>4311</lpage>
          <pub-id pub-id-type="pmid">9151747</pub-id>
        </citation>
      </ref>
      <ref id="bib8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Byatt</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Caricature effects, distinctiveness, and identification: Testing the face-space framework</article-title>
          <source>Psychological Science</source>
          <year>2000</year>
          <volume>11</volume>
          <issue>5</issue>
          <fpage>379</fpage>
          <lpage>385</lpage>
          <pub-id pub-id-type="pmid">11228908</pub-id>
        </citation>
      </ref>
      <ref id="bib9">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leopold</surname>
              <given-names>D.A.</given-names>
            </name>
            <name>
              <surname>Bondar</surname>
              <given-names>I.V.</given-names>
            </name>
          </person-group>
          <article-title>Norm-based face encoding by single neurons in the monkey inferotemporal cortex</article-title>
          <source>Nature</source>
          <year>2006</year>
          <volume>442</volume>
          <issue>7102</issue>
          <fpage>572</fpage>
          <lpage>575</lpage>
          <pub-id pub-id-type="pmid">16862123</pub-id>
        </citation>
      </ref>
      <ref id="bib10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leopold</surname>
              <given-names>D.A.</given-names>
            </name>
            <name>
              <surname>O’Toole</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Prototype-referenced shape encoding revealed by high-level aftereffects</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <issue>1</issue>
          <fpage>89</fpage>
          <lpage>94</lpage>
        </citation>
      </ref>
      <ref id="bib11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Levi</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Klein</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Detecting disorder in spatial vision</article-title>
          <source>Vision Research</source>
          <year>2000</year>
          <volume>40</volume>
          <issue>17</issue>
          <fpage>2307</fpage>
          <lpage>2327</lpage>
          <pub-id pub-id-type="pmid">10927117</pub-id>
        </citation>
      </ref>
      <ref id="bib12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Levin</surname>
              <given-names>D.T.</given-names>
            </name>
            <name>
              <surname>Beale</surname>
              <given-names>J.M.</given-names>
            </name>
          </person-group>
          <article-title>Categorical perception occurs in newly learned faces, other-race faces, and inverted faces</article-title>
          <source>Perception and Psychophysics</source>
          <year>2000</year>
          <volume>62</volume>
          <issue>2</issue>
          <fpage>386</fpage>
          <lpage>401</lpage>
          <pub-id pub-id-type="pmid">10723217</pub-id>
        </citation>
      </ref>
      <ref id="bib13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lindsay</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Jack</surname>
              <given-names>P.C.</given-names>
            </name>
          </person-group>
          <article-title>Other-race face perception</article-title>
          <source>Journal of Applied Psychology</source>
          <year>1991</year>
          <volume>76</volume>
          <issue>4</issue>
          <fpage>587</fpage>
          <lpage>589</lpage>
          <pub-id pub-id-type="pmid">1917773</pub-id>
        </citation>
      </ref>
      <ref id="bib14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Loffler</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Yourganov</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>FMRI evidence for the neural representation of faces</article-title>
          <source>Nature Neuroscience</source>
          <year>2005</year>
          <volume>8</volume>
          <issue>10</issue>
          <fpage>1386</fpage>
          <lpage>1390</lpage>
        </citation>
      </ref>
      <ref id="bib15">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rhodes</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Brennan</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Identification and ratings of caricatures: Implications for mental representations of faces</article-title>
          <source>Cognitive Psychology</source>
          <year>1987</year>
          <volume>19</volume>
          <issue>4</issue>
          <fpage>473</fpage>
          <lpage>497</lpage>
          <pub-id pub-id-type="pmid">3677584</pub-id>
        </citation>
      </ref>
      <ref id="bib16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rhodes</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Jeffery</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Adaptive norm-based coding of facial identity</article-title>
          <source>Vision Research</source>
          <year>2006</year>
          <volume>46</volume>
          <issue>18</issue>
          <fpage>2977</fpage>
          <lpage>2987</lpage>
          <pub-id pub-id-type="pmid">16647736</pub-id>
        </citation>
      </ref>
      <ref id="bib17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rhodes</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Maloney</surname>
              <given-names>L.T.</given-names>
            </name>
          </person-group>
          <article-title>Adaptive face coding and discrimination around the average face</article-title>
          <source>Vision Research</source>
          <year>2007</year>
          <volume>47</volume>
          <issue>7</issue>
          <fpage>974</fpage>
          <lpage>989</lpage>
          <pub-id pub-id-type="pmid">17316740</pub-id>
        </citation>
      </ref>
      <ref id="bib18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Picture-plane inversion leads to qualitative changes of face perception</article-title>
          <source>Acta Psychologica (Amsterdam)</source>
          <year>2008</year>
          <volume>128</volume>
          <issue>2</issue>
          <fpage>274</fpage>
          <lpage>289</lpage>
        </citation>
      </ref>
      <ref id="bib19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Solomon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>The history of dipper functions</article-title>
          <source>Attention Perception &amp; Psychophysics</source>
          <year>2009</year>
          <volume>71</volume>
          <issue>3</issue>
          <fpage>435</fpage>
          <lpage>443</lpage>
        </citation>
      </ref>
      <ref id="bib20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tolhurst</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>The dependence of response amplitude and variance of cat visual cortical neurones on stimulus contrast</article-title>
          <source>Experimental Brain Research</source>
          <year>1981</year>
          <volume>41</volume>
          <issue>3–4</issue>
          <fpage>414</fpage>
          <lpage>419</lpage>
        </citation>
      </ref>
      <ref id="bib21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tsao</surname>
              <given-names>D.Y.</given-names>
            </name>
            <name>
              <surname>Freiwald</surname>
              <given-names>W.A.</given-names>
            </name>
          </person-group>
          <article-title>A cortical region consisting entirely of face-selective cells</article-title>
          <source>Science</source>
          <year>2006</year>
          <volume>311</volume>
          <issue>5761</issue>
          <fpage>670</fpage>
          <lpage>674</lpage>
          <pub-id pub-id-type="pmid">16456083</pub-id>
        </citation>
      </ref>
      <ref id="bib22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Valentine</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>A unified account of the effects of distinctiveness, inversion, and race in face recognition</article-title>
          <source>The Quarterly Journal of Experimental Psychology Section A</source>
          <year>1991</year>
          <volume>43</volume>
          <issue>2</issue>
          <fpage>161</fpage>
          <lpage>204</lpage>
        </citation>
      </ref>
      <ref id="bib23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watson</surname>
              <given-names>A.B.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D.G.</given-names>
            </name>
          </person-group>
          <article-title>QUEST: A Bayesian adaptive psychometric method</article-title>
          <source>Perception &amp; Psychophysics</source>
          <year>1983</year>
          <volume>33</volume>
          <issue>2</issue>
          <fpage>113</fpage>
          <lpage>120</lpage>
          <pub-id pub-id-type="pmid">6844102</pub-id>
        </citation>
      </ref>
      <ref id="bib24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watson</surname>
              <given-names>T.L.</given-names>
            </name>
            <name>
              <surname>Clifford</surname>
              <given-names>C.W.</given-names>
            </name>
          </person-group>
          <article-title>Orientation dependence of the orientation-contingent face aftereffect</article-title>
          <source>Vision Research</source>
          <year>2006</year>
          <volume>46</volume>
          <issue>20</issue>
          <fpage>3422</fpage>
          <lpage>3429</lpage>
          <pub-id pub-id-type="pmid">16723149</pub-id>
        </citation>
      </ref>
      <ref id="bib25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Webster</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Kaping</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Adaptation to natural facial categories</article-title>
          <source>Nature</source>
          <year>2004</year>
          <volume>428</volume>
          <issue>6982</issue>
          <fpage>557</fpage>
          <lpage>561</lpage>
          <pub-id pub-id-type="pmid">15058304</pub-id>
        </citation>
      </ref>
      <ref id="bib26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wilson</surname>
              <given-names>H.R.</given-names>
            </name>
            <name>
              <surname>Loffler</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Synthetic faces, face cubes, and the geometry of face space</article-title>
          <source>Vision Research</source>
          <year>2002</year>
          <volume>42</volume>
          <issue>27</issue>
          <fpage>2909</fpage>
          <lpage>2923</lpage>
          <pub-id pub-id-type="pmid">12450502</pub-id>
        </citation>
      </ref>
      <ref id="bib27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yin</surname>
              <given-names>R.K.</given-names>
            </name>
          </person-group>
          <article-title>Looking at upside-down faces</article-title>
          <source>Journal of Experimental Psychology</source>
          <year>1969</year>
          <volume>81</volume>
          <fpage>141</fpage>
          <lpage>145</lpage>
        </citation>
      </ref>
      <ref id="bib28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Yamane</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Sparse population coding of faces in the inferotemporal cortex</article-title>
          <source>Science</source>
          <year>1992</year>
          <volume>256</volume>
          <issue>5061</issue>
          <fpage>1327</fpage>
          <lpage>1331</lpage>
          <pub-id pub-id-type="pmid">1598577</pub-id>
        </citation>
      </ref>
      <ref id="bib29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zenger-Landolt</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Response suppression in v1 agrees with psychophysics of surround masking</article-title>
          <source>Journal of Neuroscience</source>
          <year>2003</year>
          <volume>23</volume>
          <issue>17</issue>
          <fpage>6884</fpage>
          <lpage>6893</lpage>
          <pub-id pub-id-type="pmid">12890783</pub-id>
        </citation>
      </ref>
    </ref-list>
  </back>
  <floats-wrap>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>A schematic representation of face space (<xref rid="bib10" ref-type="bibr">Leopold, O’Toole, et al., 2001</xref>). Identities are coded relative to an average in the centre. Faces falling on a single “identity trajectory“ are framed in solid black. As one moves along the ID trajectory, distinctiveness decreases, progressing from caricatures through the original, to the (minimally distinctive) average. Passing beyond the average along the same ID trajectory leads to anti-faces that may be similar to real faces (as indicated by the example of the real face in a dashed framed).</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>Logic of the approach. Notional neural response (dashed line) elicited by different stimulus strengths (either contrast or facial identity). The width of the bars indicate the amount of extra stimulus strength required to elicit a constant change in response (bar-height) at different points along the response function. Bars are collapsed in the lower left graph to highlight that, for this response function, there is an optimal baseline (<italic>pedestal</italic>) stimulus strength (falling on the steepest part of the response function) that requires only a small change in stimulus strength to elicit this response change. Plotting the change in stimulus strength supporting a constant response change, as a function of baseline stimulus strength, gives the profile shown in the bottom right. Assuming that discrimination requires a constant change in response, the solid black line is the predicted change in stimulus strength supporting a just-noticable difference at differing baseline levels of stimulus strength. By psychophysically estimating the minimum additional stimulus strength that can be reliably noticed by observers, at different baseline (pedestal) levels of stimulus strength, one can essentially integrate the resulting data to infer the underlying response function.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p>(a–d) Photographic stimuli morphed into registration with key-points consistent with a varying amount of identity: (a) −150%, (b) 0%, (c) 100%, (d) +150%, (e–h) same but showing morphed versions of the <italic>average face</italic> (f).</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>A typical trial from (a) the rating and (b) the detection experiment. (b) The odd-man-out (dashed frame) has an identity level of 75%; the other two faces are averages (identity level 0%).</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Fig. 5</label>
      <caption>
        <p>(a) Original image. (b–d) Examples of stimuli derived from this face, ranging from an average (0% identity strength) to a caricature (125% identity). Images shown are from (b) upright, (c), inverted and (d) contrast-polarity inverted conditions. Note how much harder it is to discriminate changes in the stimuli shown in (c) and (d), compared to (b).</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig6">
      <label>Fig. 6</label>
      <caption>
        <p>Examples of two typical discrimination trials. (a) Two identical reference faces which contained a ‘‘pedestal‘‘ level of identity (here 0%), and one target-face (dashed frame) whose identity-level was the pedestal plus some increment (0% + 25% = 25%). Subjects reported the ‘‘odd-man-out‘‘ (indicating the numeric label that replaced each face after 500 ms). (b) Is similar except that now the two references contained a pedestal identity level of 50% and the target (dashed frame) contained 50% + 25% = 75% identity. Although in both halves of the figure the target-face is defined by a 25% increase in identity (compared to the reference faces) it may be easier to spot the odd-manout in (b); the pedestal improves subjects‘ ability to spot an identity-increment. This is a signature of a ‘‘dipper. discrimination function shown in the lower right section of <xref rid="fig2" ref-type="fig">Fig. 2</xref>, i.e. of a non-linear representation of identity.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig7">
      <label>Fig. 7</label>
      <caption>
        <p>Threshold-versus-identity (TvI) curves for subject DEO: the minimum amount of additional identity supporting odd-man-out discrimination as a function of pedestal identity level, for four different faces. Thresholds are uniformly lower (indicating better performance) for upright, positive contrast-polarity faces compared to the other conditions and generally drop with increasing pedestal identity. Critically, TvI functions with upright positive-polarity faces shows a shallow “dipper” type pattern, consistent with non-linear representation of identity.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <fig id="fig8">
      <label>Fig. 8</label>
      <caption>
        <p>As <xref rid="fig7" ref-type="fig">Fig. 7</xref> for subject SCD.</p>
      </caption>
      <graphic xlink:href="gr8"/>
    </fig>
    <fig id="fig9">
      <label>Fig. 9</label>
      <caption>
        <p>As <xref rid="fig7" ref-type="fig">Fig. 7</xref> for two naïve subjects’ performance with faces #3 and #28.</p>
      </caption>
      <graphic xlink:href="gr9"/>
    </fig>
    <fig id="fig10">
      <label>Fig. 10</label>
      <caption>
        <p>(a) Circles show empirically derived (data from DEO) estimates of the identity response function for four faces, along with fits from the Naka–Rushton (NR) equation (solid lines). The boxed legend below the figure indicates the best fitting parameters for each individual NR fit to the data (<italic>R</italic><sub>max</sub>, <italic>b</italic>, and <italic>n</italic>); note the shallow sigmoidal shape of the response function as indicated by values of <italic>n</italic> consistently exceeding 1. The right part of the figure shows these response function re-plotted on <italic>x</italic>-axes that have been scaled by one of the four parameters indicated. Scaling by the estimated minimum threshold brings the curves into close registration.</p>
      </caption>
      <graphic xlink:href="gr10"/>
    </fig>
    <fig id="fig11">
      <label>Fig. 11</label>
      <caption>
        <p>As <xref rid="fig10" ref-type="fig">Fig. 10</xref> for subject SCD.</p>
      </caption>
      <graphic xlink:href="gr11"/>
    </fig>
    <fig id="fig12">
      <label>Fig. 12</label>
      <caption>
        <p>Graph showing thresholds obtained for the upright faces with line of best fit. (grey line) The broken line shows the derivative of the Naka–Ruston function of our model response function obtained by rescaling the <italic>x</italic>-axis of all four faces to their estimated minimum threshold.</p>
      </caption>
      <graphic xlink:href="gr12"/>
    </fig>
    <fig id="fig13">
      <label>Fig. 13</label>
      <caption>
        <p>Plots of rated distinctiveness against (open symbols) identity detection thresholds and (filled symbols) estimated minimum discrimination thresholds, for the four face images used in this study. Note that distinctiveness appears to be more closely related to the estimated minimum discrimination thresholds than the detection thresholds.</p>
      </caption>
      <graphic xlink:href="gr13"/>
    </fig>
    <fig id="fig14">
      <label>Fig. 14</label>
      <caption>
        <p>(a) Schematic face space showing the identity axis used to generate stimuli in this study along with the axes employed by <xref rid="bib26" ref-type="bibr">Wilson et al. (2002)</xref>. Dark grey and light grey discs indicate faces with a just-noticeable-difference (JND) in identity for this and the Wilson et al. study, respectively. Note the very small JND at an intermediate level of identity for this study, and that JNDs are greater at higher levels of identity in the Wilson et al. study. Because different projections were used to generate stimuli in both studies, their findings are not mutually inconsistent. (b) Results from a control experiment conducted to examine if dips in TvI functions depended on having the target-face as a pedestal. The solid line shows the non-linear TvI function derived in the earlier experiment, and the open symbols shows data collected using stimuli that were essentially identical except that the pedestal-face was now not matched to the target. As the identity level of the mismatched pedestal-face increases we observe a steady increase in masking (with no dips).</p>
      </caption>
      <graphic xlink:href="gr14"/>
    </fig>
  </floats-wrap>
</article>