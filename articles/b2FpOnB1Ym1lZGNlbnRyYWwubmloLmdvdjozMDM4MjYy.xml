<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3038262</article-id>
      <article-id pub-id-type="pmid">20303408</article-id>
      <article-id pub-id-type="publisher-id">YNIMG7155</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2010.03.036</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Dissociable responses to punishment in distinct striatal regions during reversal learning</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Robinson</surname>
            <given-names>Oliver J.</given-names>
          </name>
          <email>oliver.j.robinson@googlemail.com</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Frank</surname>
            <given-names>Michael J.</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Sahakian</surname>
            <given-names>Barbara J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Cools</surname>
            <given-names>Roshan</given-names>
          </name>
          <xref rid="aff4" ref-type="aff">d</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>a</label>Department of Psychiatry and Behavioural and Clinical Neuroscience Institute, University of Cambridge, Cambridge, Addenbrooke's Hospital, P. O. Box 189, Level E4, Hills Road, Cambridge, CB2 2QQ, UK</aff>
      <aff id="aff2"><label>b</label>Section on Neuroimaging in Mood and Anxiety Disorders, National Institute of Mental Health, National Institutes of Health, Bethesda, MD, USA</aff>
      <aff id="aff3"><label>c</label>Dept of Cognitive &amp; Linguistic Sciences, Dept of Psychology, Brown Institute for Brain Science, Dept of Psychiatry and Human Behavior, Brown University, USA</aff>
      <aff id="aff4"><label>d</label>Donders Institute for Brain, Cognition and Behaviour, Centre for Cognitive Neuroimaging, Department of Psychiatry, Radboud University Nijmegen Medical Centre, Nijmegen, The Netherlands</aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author. Department of Psychiatry and Behavioural and Clinical Neuroscience Institute, University of Cambridge, Cambridge, Addenbrooke's Hospital, P. O. Box 189, Level E4, Hills Road, Cambridge, CB2 2QQ, UK. <email>oliver.j.robinson@googlemail.com</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>15</day>
        <month>7</month>
        <year>2010</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>15</day>
        <month>7</month>
        <year>2010</year>
      </pub-date>
      <volume>51</volume>
      <issue>4-4</issue>
      <fpage>1459</fpage>
      <lpage>1467</lpage>
      <history>
        <date date-type="received">
          <day>11</day>
          <month>2</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>4</day>
          <month>3</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>11</day>
          <month>3</month>
          <year>2010</year>
        </date>
      </history>
      <abstract>
        <p>Adaptive behavior depends on the ability to flexibly alter our choices in response to changes in reward and punishment contingencies. One brain region frequently implicated in such behavior is the striatum. However, this region is functionally diverse and there are a number of apparent inconsistencies across previous studies. For instance, how can significant BOLD responses in the ventral striatum during punishment-based reversal learning be reconciled with the frequently demonstrated role of the ventral striatum in reward processing? Here we attempt to address this question by separately examining BOLD responses during reversal learning driven by reward and during reversal learning driven by punishment. We demonstrate simultaneous valence-specific and valence-nonspecific signals in the striatum, with the posterior dorsal striatum responding only to unexpected reward, and the anterior ventral striatum responding to both unexpected punishment as well as unexpected reward. These data help to reconcile conflicting findings from previous studies by showing that distinct regions of the striatum exhibit dissociable responses to punishment during reversal learning.</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <title>Introduction</title>
      <p>Adequate adaptation to the environment requires the anticipation of biologically relevant events by learning signals of their occurrence. In our constantly changing environment, however, this learning must be highly flexible. The experimental model that has been used most frequently to study the neurobiological mechanisms of this learning is the <italic>reversal learning</italic> paradigm in which subjects reverse choices when they unexpectedly receive punishment.</p>
      <p>Lesions of the striatum impair reversal learning in animals (<xref rid="bib18 bib47 bib1 bib46 bib7" ref-type="bibr">Divac et al., 1967; Taghzouti et al., 1985; Annett et al., 1989; Stern and Passingham, 1996; Clarke et al., 2008</xref>) and increased striatal BOLD signal is seen in humans during the punishment events that lead to reversal (<xref rid="bib10 bib19" ref-type="bibr">Cools et al., 2002; Dodds et al., 2008</xref>). This signal is disrupted by dopamine-enhancing drugs in both Parkinson's patients (PD) and healthy volunteers (<xref rid="bib11 bib19" ref-type="bibr">Cools et al., 2007; Dodds et al., 2008</xref>). However, the mechanism underlying punishment-related signal in the striatum during reversal learning is unclear.</p>
      <p>The role of dopamine and the striatum in <italic>punishment</italic> is receiving an increasing amount of attention (<xref rid="bib20 bib43 bib17 bib8" ref-type="bibr">Frank, 2005; Seymour et al., 2007b; Delgado et al., 2008; Cohen and Frank, 2009</xref>). <xref rid="bib20" ref-type="bibr">Frank (2005)</xref> has proposed that dopamine-induced impairment in punishment learning reflects disruption of striatal processing associated with punishment and subsequent suppression (NOGO) of actions associated with aversive outcomes (<xref rid="bib21 bib45 bib8" ref-type="bibr">Frank et al., 2004; Shen et al., 2008; Cohen and Frank, 2009</xref>). The striatum has been linked to aversive processing in animals (<xref rid="bib25 bib24 bib39" ref-type="bibr">Ikemoto and Panksepp, 1999; Horvitz, 2000; Schoenbaum et al., 2003</xref>), fMRI studies have demonstrated aversive prediction errors within the striatum (<xref rid="bib26 bib27 bib44 bib42 bib17" ref-type="bibr">Jensen et al., 2003, 2007; Seymour et al., 2005, 2007a; Delgado et al., 2008</xref>) and the effect of dopaminergic medication in PD on punishment learning is comparable to the effect on reward learning (<xref rid="bib21 bib12 bib4" ref-type="bibr">Frank et al., 2004; Cools et al., 2006; Bodi et al., 2009</xref>).</p>
      <p>However, it is possible that striatal activity during reversal learning reflects <italic>reward</italic> processing (<xref rid="bib11" ref-type="bibr">Cools et al., 2007</xref>). fMRI studies have reported greater-than-average activity in the striatum for reward prediction errors alongside less-than-average activity for punishment prediction errors (<xref rid="bib28 bib35 bib52 bib48" ref-type="bibr">Kim et al., 2006; Pessiglione et al., 2006; Yacubian et al., 2006; Tom et al., 2007</xref>). Many midbrain dopamine neurons exclusively exhibit reward-signed coding (<xref rid="bib41 bib50" ref-type="bibr">Schultz, 2002; Ungless, 2004</xref> but see <xref rid="bib6 bib29" ref-type="bibr">Brischoux et al., 2009; Matsumoto and Hikosaka, 2009</xref>) and baseline firing rates of dopamine neurons are relatively low, leaving little opportunity for decreases in firing to code negatively signed prediction errors (<xref rid="bib14 bib2" ref-type="bibr">Daw et al., 2002; Bayer and Glimcher, 2005</xref>; but see <xref rid="bib3" ref-type="bibr">Bayer et al., 2007</xref>). Disruption of striatal activity by dopaminergic drugs may represent abolition of activity related to reward anticipation or dopamine-induced potentiation of reward-related activity during the baseline correct rewarded responses (<xref rid="bib11" ref-type="bibr">Cools et al., 2007</xref>). Here we address the question whether striatal activity during reversal learning represents reward- or punishment-related processing.</p>
    </sec>
    <sec sec-type="materials|methods" id="sec2">
      <title>Materials and methods</title>
      <p>To disentangle these hypotheses, we assessed BOLD responses in the striatum during two intermixed types of reversal learning. Unlike previous instrumental reversal learning tasks, the received outcome in the present task did not depend on the subject's choice. Thus subjects could not work to gain positive and to avoid negative outcomes. Rather subjects were required to learn to predict the outcome (reward or punishment) for a series of stimuli. This set-up enabled us to assess striatal responses during reversals that were driven either by reward or by punishment, but which were otherwise matched exactly in terms of sensory and motor requirements. Thus one type of reversal required the detection and updating of outcome predictions in response to <italic>unexpected punishment</italic>, whereas the other type of reversal required the detection and updating of outcome predictions in response to <italic>unexpected reward</italic>. Unlike previous studies with instrumental contingencies, the reversal events in this experiment did not load highly on reward anticipation because they were not by definition followed by reward.</p>
    </sec>
    <sec>
      <title>Subjects</title>
      <p>Procedures were approved by the Cambridge Research Ethics Committee (07/Q0108/28) and were in accord with the Helsinki Declaration of 1975. Sixteen right-handed subjects (mean age 26; standard error 1; five female) participated in this study at the Wolfson Brain Imaging Centre (WBIC) in Cambridge, UK. They were screened for psychiatric and neurological disorders, gave written informed consent, and were compensated for participation. Exclusion criteria were all contraindications for fMRI scanning; cardiac, hepatic, renal, pulmonary, neurological, psychiatric or gastrointestinal disorders, and medication/drug use. All subjects successfully completed the study. Blocks that quit automatically (due to 10 consecutive errors, see below) or blocks that were interrupted by the subject (i.e. to go to the toilet) were excluded (between one and three blocks for four subjects).</p>
    </sec>
    <sec>
      <title>Behavioral measures</title>
      <sec>
        <title>Task description</title>
        <p>The paradigm was adapted from a previously developed paradigm and programmed using E-PRIME (Psychological Software Tools, Inc., Learning 2002; Research and Development Center, University of Pittsburgh, Pennsylvania).</p>
        <p>On each trial subjects were presented two vertically adjacent stimuli, one scene and one face (location randomized) on a screen viewed by means of a mirror attached to the head coil in the fMRI scanner. One of these two (face/scene) stimuli was associated with reward, whereas the other was associated with punishment. Subjects were required to learn these deterministic stimulus-outcome associations by trial and error. However, unlike standard reversal paradigms, the present task did not require the subjects to choose between the two stimuli. Instead subjects were instructed to predict whether a stimulus that was highlighted with a thick black border (randomized from trial to trial) would lead to reward or to punishment. They indicated their outcome prediction for the highlighted stimulus by pressing, with the index or middle finger of their dominant (right) hand, one of two buttons on a button box placed upon their abdomen. They pressed one button for reward and the other for punishment. The outcome-response mappings were counterbalanced between subjects (left or right reward; eight in each group). Subjects had up to 1500 ms in which to make their response. As soon as they responded, the outcome was presented for 500 ms in the center of the screen (between the two stimuli). Reward consisted of a green smiley face and punishment consisted of a red sad face. If they failed to make a response, “too late!” was displayed instead of feedback. After the outcome, the screen was cleared (except for a fixation cross) for an RT-dependent interval, so that the inter-stimulus-interval was jittered modestly between 3000 and 5000 ms. Specifically, the screen was cleared for 1500 ms minus the RT and remained clear until the next scanner pulse occurred. The pulse was followed by a jittered wait of either 500 or 1500 ms before the next two stimuli appeared on the screen (<xref rid="fig1" ref-type="fig">Fig. 1</xref>).</p>
        <p>After acquisition of preset learning criteria (see below) the stimulus-outcome contingencies reversed multiple times. Such reversals of contingencies were signaled to subjects either by an unexpected reward presented after the previously punished stimulus was highlighted, or by an unexpected punishment presented after the previously rewarded stimulus was highlighted. Unexpected reward and unexpected punishment events were interspersed within blocks.</p>
        <p>The stimulus that was highlighted after the unexpected outcome was randomly selected such that it was the same as the one paired, on the previous trial, with the unexpected outcome on 50% of trials (stimulus repetition). On the other 50% of trials, the highlighted stimulus was different from the one paired with the unexpected outcome (stimulus alternations). Subjects were required to reverse their predictions in both cases. However, after an unexpected outcome, stimulus-repetitions required response alternation, whereas stimulus-alternation required response repetition. Randomizing stimulus-repetition and stimulus-alternation prevented the potential confound of response anticipation after unexpected outcomes. Furthermore, it ensured that reward anticipation and response requirements such as response inhibition and response activation were minimized, and matched between unexpected reward and punishment trial types.</p>
        <p>During the scan session subjects completed six experimental blocks. Each experimental block consisted of one acquisition stage and a variable number of reversal stages. The task proceeded from one stage to the next following a specific number of consecutive correct trials as determined by a preset learning criterion. This criterion varied between stages (4, 5 or 6 correct responses) to prevent predictability of reversals. The average number of reversal stages per experimental block was 18 (see <xref rid="sec3" ref-type="sec">Results</xref>), although the block terminated automatically after completion of 150 trials (10 min), such that each subject performed 900 trials (six blocks) per experimental session (approximately 70 min including breaks). The task also terminated after 10 consecutive incorrect trials in order to avoid scanning blocks in which subjects were not performing the task correctly (e.g. due to forgetting of outcome-response mappings).</p>
        <p>Each subject performed a practice block prior to entering the fMRI scanner to familiarize them with the task. This practice task was identical to the main task with the exception that the stimuli were presented on a pace-blade tablet computer and responses were made on a computer keyboard.</p>
      </sec>
      <sec>
        <title>Behavioral analysis</title>
        <p>Errors were broken down into A) switch errors (<italic>incorrect responses on the trial after an unexpected outcome</italic>) and B) perseverative errors (<italic>the number of consecutive errors after the unexpected outcome [excluding the switch trial] before a correct response was made</italic>) and were stratified by the unexpected outcome preceding the trial, as well as by the newly associated (to be predicted) outcome. We also examined C) repetition errors (<italic>switch trials on which subjects should have repeated responses but alternated</italic>), D) alternation errors (<italic>switch trials on which subjects should have switched responses but repeated</italic>) and E) non-switch errors (<italic>stratified by the associated [to be predicted] outcome</italic>).</p>
        <p>Although subjects had no control over the outcomes, it is possible that they nevertheless exhibited valence-dependent response biases to aversive or appetitive predictions and outcomes that are immaterial to the delivery of the outcomes (<xref rid="bib16 bib15" ref-type="bibr">Dayan and Huys, 2008; Dayan and Seymour, 2008</xref>). We considered two possible types of biases:<list list-type="simple"><list-item><label>1)</label><p><italic>Win-stay, lose-shift strategy:</italic> subjects might exhibit approach in response to the receipt of rewards and withdrawal in response to the receipt of punishments. In our task, such responses might be expressed in terms of a tendency to repeat the same response after a reward, while alternating the response after a punishment.</p></list-item><list-item><label>2)</label><p><italic>Instrumental-like reward-focused action selection</italic>: subjects might attempt to recruit an instrumental learning strategy to solve the task, and work primarily towards the reward-associated action (i.e. pressing the ‘reward’ button), treating it as an approach response, while treating the punishment-associated action as the <italic>alternative</italic>, withdrawal response. In this strategy, a punishment-predictive stimulus would signal reward omission, and thus the need to avoid selecting the reward-associated approach action. This reward-focused instrumental learning strategy would be expressed in terms of poorer performance on punishment prediction trials than on reward prediction trials.</p></list-item></list></p>
        <p>The number of data points varied per trial type as a function of performance so errors were transformed into proportional scores (i.e. as a proportion of the total number of [reward or punishment] switch or non-switch trials depending upon the variable being examined). These proportions were then arcsine transformed (2 × arcsine(√<italic>x</italic>)) as is appropriate when the variance is proportional to the mean (<xref rid="bib54" ref-type="bibr">Howell, 2002</xref>).</p>
        <p>In addition to the error rate analysis, we also examined reaction times (RTs; milliseconds) for non-switch trials, switch trials, perseverative trials stratified by both <italic>preceding</italic> outcome and <italic>to be predicted</italic> outcome, response alternation trials and response repetition trials.</p>
      </sec>
    </sec>
    <sec>
      <title>Functional neuroimaging</title>
      <sec>
        <title>Image acquisition</title>
        <p>A Siemens TIM Trio 3 T scanner (Magnetom Trio, Siemens Medical Systems, Erlangen, Germany) was used to acquire structural and gradient-echo echo-planar functional images (repetition time = 2000 ms; echo time = 30 ms; 32 axial oblique slices; matrix size dimensions 64 × 64 × 32; voxel size 3 × 3 × 3.75; flip angle 78; slice acquisition orientation axial oblique T &gt; C-24.6; field of view: 192 mm; 6 sessions each of 312 volume acquisitions). The first 12 volumes from each session were discarded to avoid T1 equilibrium effects. In addition, an MPRAGE anatomical reference image of the whole brain was acquired for each subject (repetition time = 2300 ms; echo time = 2.98 ms; 176 slices; matrix size dimensions 240 × 256 × 176, voxel size 1 × 1 × 1) for spatial coregistration and normalization.</p>
      </sec>
      <sec>
        <title>Image analysis</title>
        <p>Images were pre-processed and analyzed using SPM5 (Statistical Parametric Mapping; Wellcome Department of Cognitive Neurology, London, UK). Preprocessing consisted of within-subject realignment, coregistration, segmentation, spatial normalization and spatial smoothing. Functional scans were coregistered to the MPRAGE structural image, which was processed using a unified segmentation procedure combining segmentation, bias correction and spatial normalization (<xref rid="bib55" ref-type="bibr">Ashburner and Friston, 2005</xref>); the same normalization parameters were then used to normalize the EPI images. Finally the EPI images were smoothed with a Gaussian kernel of 8 mm full width half maximum. The canonical hemodynamic response function and its temporal derivative were used as covariates in a general linear model. The parameter estimates, derived from the mean least-squares fit of the model to the data, reflect the strength of covariance between the data and the canonical response functions for given event-types (specified below) at each voxel. Individuals' contrast images were taken to second-level group analyses, in which <italic>t</italic> values were calculated for each voxel, treating inter-subject variability as a random effect. Movement parameters were included as covariates of no interest.</p>
        <p>We estimated a general linear model, for which parameter estimates were generated at the onsets of the expected and unexpected reward and punishment outcomes (with zero duration), which co-occurred with the response. An unexpected outcome was the first outcome of a new stage, presented after learning criterion had been obtained, i.e. the outcome signaling contingency reversal. All other outcomes were coded as expected outcomes. There were four trial-types (unexpected reward, unexpected punishment, expected reward, expected punishment) and a two by two factorial design was employed with valence and expectedness as within-subject factors. All four trial types were brought to the second level and whole brain effects were determined by contrasts between these factors at the second level. Reward-based reversal activity was determined by the 1 0 −1 0 (UR UP ER EP) contrast; punishment-based reversal activity was determined by the 0 1 0 −1 contrast; the valence-nonspecific signal was determined by the 1 1 −1 −1 contrast; the valence-specific signal was determined by the 1 −1 −1 1 contrast.</p>
        <p>For whole-brain analyses, statistical inference was performed at the voxel level, correcting for multiple comparisons using the family-wise error (FWE) over the whole brain (<italic>P</italic><sub>WB_FWE</sub> &lt; 0.05). For illustrative purposes we then extracted the betas from peak voxels using the MarsBar software (<xref rid="bib5" ref-type="bibr">Brett et al., 2002</xref>).</p>
      </sec>
    </sec>
    <sec id="sec3">
      <title>Results</title>
      <sec>
        <title>Behavioral</title>
        <p>Mean RTs and error rates are presented in <xref rid="tbl1" ref-type="table">Table 1</xref>. Each subject completed a mean of 107 (SD 18) reversals, of which 54 (SD 9) were signaled by unexpected reward and 54 (SD 9) by unexpected punishment. Error rates did not differ between reward prediction and punishment prediction trials (<italic>t</italic><sub>15</sub> = −0.38, <italic>P =</italic> 0.7). However, subjects were significantly faster to press the reward button than the punishment button across all trials (<italic>t</italic><sub>15</sub> = −3.12, <italic>P =</italic> 0.007).</p>
        <p>Subjects made significantly more switch errors than non-switch errors (<italic>F</italic><sub>1,15</sub> <italic>=</italic> 2378, <italic>P</italic> &lt; 0.001). There was no effect of the valence of the <italic>preceding</italic> (<italic>F</italic><sub>1,15</sub> = 0.24, <italic>P</italic> = 0.6) or the <italic>to be predicted</italic> (<italic>F</italic><sub>1,15</sub> = 0.23, <italic>P</italic> = 0.64) outcome on switch error rates and there was no interaction between the valence of the <italic>preceding</italic> and the <italic>to be predicted</italic> outcome (<italic>F</italic><sub>1,15</sub> = 0.34, <italic>P</italic> = 0.55). For RTs, there was an interaction between the <italic>preceding</italic> and <italic>to be predicted</italic> outcomes (<italic>F</italic><sub>1,15</sub> = 7.1, <italic>P</italic> = 0.018), which was driven by subjects being significantly faster to predict reward after unexpected reward, relative to both predicting punishment after unexpected reward (<italic>F</italic><sub>1,15</sub> = 7.2, <italic>P</italic> = 0.017) and relative to predicting reward after unexpected punishment (<italic>F</italic><sub>1,15</sub> <italic>=</italic> 17.1, <italic>P</italic> = 0.001).</p>
        <p>Subjects made an average of 11.7 (SD 3.6) response repetition errors and 12.6 (SD 3.9) response alternation errors, but there was no effect of the preceding outcome on response repetition error rates (<italic>t</italic><sub>15</sub> = −0.72, <italic>P =</italic> 0.48) or response alternation error rates (<italic>t</italic><sub>15</sub> = −0.13, <italic>P =</italic> 0.90). Thus subjects were not more likely to repeat responses after unexpected reward or switch responses after unexpected punishment. There was no difference in terms of reaction times between response repetition and response alternation trials (<italic>t</italic><sub>15</sub> = −1.1, <italic>P =</italic> 0.27).</p>
        <p>Subjects made an average of 5.6 (SD 3.4) perseverative errors, which did not differ as a function of the preceding outcome (main effect of <italic>preceding</italic>; <italic>F</italic><sub>1,15</sub> = 0.41, <italic>P</italic> = 0.53). However, perseverative errors were increased when subjects had to predict punishment relative to reward after any unexpected feedback (main effect of <italic>predicted</italic>; <italic>F</italic><sub>1,15</sub> = 4.9, <italic>P</italic> = 0.04; <xref rid="fig2" ref-type="fig">Fig. 2</xref>). There was no interaction between <italic>preceding</italic> and <italic>predicted</italic> outcome on perseverative errors (<italic>F</italic><sub>1,15</sub> <italic>=</italic> 1.5, <italic>P</italic> = 0.24) and the speed of perseverative responses was equal across trials (<italic>preceding</italic> [<italic>F</italic><sub>1,15</sub> <italic>=</italic> 2.2, <italic>P</italic> = 0.20]; <italic>to be predicted</italic> [<italic>F</italic><sub>1,15</sub> <italic>=</italic> 1.8, <italic>P</italic> = 0.24]; <italic>interaction</italic> [<italic>F</italic><sub>1,15</sub> = 0.34, <italic>P</italic> = 0.59]).</p>
        <p>In summary, subjects responded more slowly and exhibited increased perseveration on punishment prediction trials than on reward prediction trials. These results suggest that subjects might have adopted an instrumental-like reward focused action selection strategy (see <xref rid="sec2" ref-type="sec">Materials and methods</xref>). In particular, subjects may have evaluated whether to make a GO response to the reward button. If the evidence for reward was not above a certain threshold, then subjects may have withheld responses (NOGO) and made a delayed <italic>alternate</italic> response (i.e. pressed the punishment button). Furthermore the absence of a difference in reward and punishment repetition and alternation error rates suggests that subjects did not recruit a win-stay, lose-shift strategy.</p>
      </sec>
      <sec>
        <title>Functional imaging data</title>
        <p>Data are shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref> and <xref rid="tbl2 tbl3" ref-type="table">Tables 2 and 3</xref>. First, we assessed BOLD responses during the unexpected punishment events that signaled reversal (relative to the expected punishment events). This effect of punishment-based reversal was highly significant in a widespread network of regions, including the striatum, ventrolateral prefrontal cortex, dorsolateral prefrontal cortex, dorsomedial prefrontal cortex and posterior parietal cortex (<xref rid="tbl2" ref-type="table">Table 2</xref>; <xref rid="fig3" ref-type="fig">Fig. 3</xref>a). The network closely resembled that observed previously during instrumental reversal learning (<xref rid="bib10" ref-type="bibr">Cools et al., 2002</xref>) (<xref rid="bib33 bib10 bib32 bib34 bib37 bib23" ref-type="bibr">O'Doherty et al., 2001; Cools et al., 2002; O'Doherty et al., 2003; O'Doherty et al., 2004; Remijnse et al., 2005; Hampton and O'Doherty, 2007</xref>). Small volume analysis of the caudate nucleus and the putamen revealed that peaks were centered on the anterior ventral striatum (caudate nucleus: Talairach coordinates <italic>x</italic>, <italic>y</italic>, <italic>z =</italic> 12, 9, 4; <italic>T</italic> = 6.1, <italic>P</italic><sub>SV_FWE</sub> = 0 &lt; 0.001 and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −12, 9, 4; <italic>T</italic> = 5.8, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001; putamen: <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −15, 9, 4; <italic>T</italic> = 5.6, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001).</p>
        <p>Next we assessed BOLD responses during the unexpected reward events that signaled reversal (relative to the expected reward events). This contrast revealed a very similar network of regions to the unexpected punishment contrast (<xref rid="tbl3" ref-type="table">Table 3</xref>; <xref rid="fig3" ref-type="fig">Fig. 3</xref>b). However, the pattern of activity was more extensive. Furthermore small volume analyses of the caudate nucleus and the putamen revealed that peaks were centered on more dorsal and posterior parts of the striatum (caudate nucleus: <italic>x</italic>, <italic>y</italic>, <italic>z =</italic> 18, 9, 15, <italic>T</italic> = 9.2, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001 and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −18, 3, 19, <italic>T</italic> = 7.7, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001; putamen: <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −18, 0 .8, <italic>T</italic> = 7.5, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001).</p>
        <p>To further investigate these differences within the striatum, we also computed a direct contrast representing the difference between reward- and punishment-based reversal learning, i.e. the interaction between expectedness and valence. Consistent with the above analyses, this contrast revealed greater activity during unexpected reward (<italic>relative to</italic> expected reward) than during unexpected punishment (<italic>relative to</italic> expected punishment) in the more posterior and dorsal parts of the striatum, even at the whole-brain level (<italic>x</italic>, <italic>y</italic>, <italic>z =</italic> 18, −6, 8, <italic>T</italic> = 5.4, <italic>P</italic><sub>WB_FWE</sub> = 0.02), but in no other regions. Small volume analyses confirmed this observation and revealed peaks in the posterior and dorsal part of the bilateral caudate nucleus at <italic>x</italic>, <italic>y</italic>, <italic>z =</italic> 21, −3, 22 (<italic>T</italic> = 5.2, <italic>P</italic><sub>SV_FWE</sub> = 0.001) and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −12, −9, 15 (<italic>T</italic> = 3.9, <italic>P</italic><sub>SV_FWE</sub> = 0.02) as well as in the dorsolateral part of the bilateral putamen at <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −21, −6, 8 (<italic>T</italic> = 4.1, <italic>P</italic><sub>SV_FWE</sub> = 0.01) and 24, −6, 8 (<italic>T</italic> = 4.0, <italic>P</italic><sub>SV_FWE</sub> = 0.02).</p>
        <p>These analyses suggest that different parts of the striatum exhibit distinct responses to punishment, with the ventral and anterior striatum responding to both unexpected reward and unexpected punishment, in a valence-nonspecific fashion, but with the more dorsal and posterior striatum responding to unexpected reward in a valence-specific fashion. For illustration purposes, we have plotted, in <xref rid="fig4" ref-type="fig">Fig. 4</xref> signal change extracted from these striatal peaks of reward-signed activity (<xref rid="fig4" ref-type="fig">Fig. 4</xref>a), as well as that from striatal peaks of unsigned activity (<xref rid="fig4" ref-type="fig">Fig. 4</xref>b) [the latter obtained from a small volume analysis within the striatum of a fourth contrast representing the main effect of expectedness, i.e. differences between both types of unexpected outcomes and both types of expected outcomes (caudate nucleus: <italic>x</italic>, <italic>y</italic>, <italic>z =</italic> 15, 6 11, <italic>T</italic> = 8.7, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001 and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −12, 9, 4, <italic>T</italic> = 7.9, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001; putamen: <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −15, 9, 4, <italic>T</italic> = 7.6, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001)]. <xref rid="fig4" ref-type="fig">Fig. 4</xref> shows that the more anterior and ventral part of the striatum exhibits BOLD responses that are largely equally enhanced during unexpected reward and unexpected punishment. Conversely, the more posterior, dorsal and lateral parts of the striatum exhibit BOLD responses that are increased for unexpected reward, but not for unexpected punishment. There were no BOLD responses that were greater for unexpected punishment than for unexpected reward.</p>
        <p>Finally, given emphasis in prior literature on the amygdala in punishment processing, we also performed supplementary small volume analysis of the anatomically defined amygdala. This analysis revealed significantly greater activity during unexpected reward (<italic>relative to</italic> expected reward) than during unexpected punishment (<italic>relative to</italic> expected punishment) (<xref rid="fig3" ref-type="fig">Fig. 3</xref>c; expectedness × valence interaction in <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −24, 0, −26, <italic>T</italic> = 3.7, <italic>P</italic><sub>SV_FWE</sub> = 0.01 and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −24, −6, −11, <italic>T</italic> = 3.3, <italic>P</italic><sub>SV_FWE</sub> = 0.03). Extraction of data from these peaks revealed that this interaction was due to reduced activity during unexpected punishment, rather than due to increased activity during unexpected reward (<xref rid="fig4" ref-type="fig">Fig. 4</xref>c). Indeed small volume analyses of the amygdala in the contrasts subtracting unexpected outcomes from expected outcomes revealed that BOLD responses were below baseline only for unexpected punishment (right: <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = −24, −9, −15, <italic>T</italic> = 5.4, <italic>P</italic><sub>SV_FWE</sub> &lt; 0.001; <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = and left: <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = 27, −9, −15, <italic>T</italic> = 4.1, <italic>P</italic><sub>SV_FWE</sub> = 0.004 and <italic>x</italic>, <italic>y</italic>, <italic>z</italic> = 24, −3, −22, <italic>T</italic> = 3.5, <italic>P</italic><sub>SV_FWE</sub> = 0.02), but not for unexpected reward (no supra-threshold clusters).</p>
      </sec>
    </sec>
    <sec>
      <title>Discussion</title>
      <p>The present results reveal distinct responses to punishment in the anterior ventral and posterior dorsal/lateral striatum. Specifically, a subcortical region extending into the anterior ventral striatum exhibited BOLD responses during both unexpected reward and unexpected punishment whereas more posterior dorsal/lateral regions of the striatum exhibited BOLD responses only during unexpected reward. These data demonstrate that distinct parts of the striatum exhibit dissociable responses to punishment during reversal learning and provide a means of reconciling a number of previously disparate studies.</p>
      <p>The regional distribution of activity in the anterior ventral and posterior dorsal/lateral parts of the striatum is reminiscent of known anatomical subdivisions of the striatum (<xref rid="bib22 bib51" ref-type="bibr">Haber et al., 2000; Voorn et al., 2004</xref>), which have been associated with motivational versus cognitive/motor aspects of behavior respectively. Specifically, whereas the ventral striatum has been implicated in the prediction of biologically relevant events, such as rewards and punishments, in Pavlovian paradigms, the dorsal striatum has been implicated in the instrumental control of actions based on these predictions (<xref rid="bib31" ref-type="bibr">Montague et al., 1996</xref>) (<xref rid="bib53" ref-type="bibr">Yin et al., 2006</xref>). For example, <xref rid="bib34" ref-type="bibr">O'Doherty et al. (2004)</xref> have revealed dissociable reward prediction error responses in the ventral and dorsal striatum during Pavlovian and instrumental conditioning respectively. Thus the ventral striatum might be primarily concerned with Pavlovian <italic>states</italic>, whereas the dorsal striatum might participate in reinforcing instrumental <italic>actions</italic> that would act to improve the predicted state. Consistent with this hypothesis, the pattern of activity in the anterior ventral striatum was more pronounced than that in the posterior dorsal/lateral striatum during our Pavlovian task, which required the prediction of rewards and punishment. Whereas activity in the ventral striatum in the study by <xref rid="bib34" ref-type="bibr">O'Doherty et al. (2004)</xref> was reward-signed, our study revealed that this anterior ventral signal was mostly valence-nonspecific (<xref rid="fig4" ref-type="fig">Fig. 4</xref>b). Thus activity in this anterior ventral region was above average not only for unexpected reward but also for unexpected punishment. While the study by <xref rid="bib34" ref-type="bibr">O'Doherty et al. (2004)</xref> did not measure punishment-related activity, similar valence-nonspecific prediction error signals have been observed previously, albeit only in studies in which Pavlovian tasks were employed (<xref rid="bib44 bib42 bib27 bib17" ref-type="bibr">Seymour et al., 2005, 2007a; Jensen et al., 2007; Delgado et al., 2008</xref>). This pattern might reflect overlapping and/or inter-mingled representations of appetitive and aversive signals, as was the case in a recent study by <xref rid="bib42 bib43" ref-type="bibr">Seymour et al. (2007a,b)</xref>. The alternative hypothesis is that it reflects a single valence-independent signal, for example reflecting a mismatch between expected and actual outcomes (<xref rid="bib36 bib56" ref-type="bibr">Redgrave et al., 1999; Zink et al., 2003</xref>; <xref rid="bib27 bib29" ref-type="bibr">Jensen et al., 2007; Matsumoto and Hikosaka, 2009</xref>). However results from our previous pharmacological studies with this task (<xref rid="bib12 bib13" ref-type="bibr">Cools et al., 2006, 2009</xref>) have revealed valence-dependent drug effects, and dependency of the relative ability to learn from reward or punishment on striatal dopamine levels (<xref rid="bib13" ref-type="bibr">Cools et al., 2009</xref>). Specifically, the effect of dopaminergic manipulation was restricted to the unexpected punishment condition and we anticipate that this dopaminergic effect is accompanied by modulation of striatal signal change related to unexpected punishment. Such striatal signal change related to unexpected punishment was observed in the present study, but only in the ventral anterior part of the striatum. Therefore the valence-specificity of the previously observed behavioral effect suggests that the punishment-related signal change observed here is also valence-specific, but that it overlaps with the reward-related signal change. We are currently testing this hypothesis by examining the effects of dopaminergic manipulations on striatal signal change.</p>
      <p>In addition to the anterior ventral valence-nonspecific effect, we also observed a valence-specific signal in more posterior and dorsal/lateral parts of the striatum, which has been associated with outcome-guided action selection rather than outcome prediction. The behavioral performance pattern observed suggests that, in addition to the prediction mechanism, subjects might have additionally recruited an instrumental mechanism, which is likely driven primarily by a positive, reward-signed signal associated with the state in which punishment is not expected (i.e. (<xref rid="bib15" ref-type="bibr">Dayan and Seymour, 2008</xref>)). In the present task, subjects were much faster to repeat reward responses following unexpected reward and made considerably more perseverative errors following unexpected feedback when they had to predict punishment. These behavioral findings support the proposition that subjects tended to work towards the reward-associated action (i.e. pressing the ‘reward’ button), perhaps treating it as a GO response. In this strategy, a punishment-predictive stimulus would signal reward omission, and thus the need to avoid selecting that reward-associated GO action. The hypothesis that subjects treated the punishment-associated action as a NOGO response is consistent with the increased RTs on these trials.</p>
      <p>Our data reconcile a variety of prior, apparently contradictory, studies. Specifically, some studies have shown an increase in striatal activity during punishment in studies of Pavlovian aversive conditioning (<xref rid="bib44 bib27 bib30" ref-type="bibr">Seymour et al., 2005; Jensen et al., 2007; Menon et al., 2007</xref>), while other studies have demonstrated decreased activity during punishment after avoidance failure in studies of instrumental aversive conditioning (<xref rid="bib28 bib35 bib52" ref-type="bibr">Kim et al., 2006; Pessiglione et al., 2006; Yacubian et al., 2006</xref>). Unlike these prior studies, the present study demonstrates <italic>simultaneous</italic> reward-signed activity in the posterior dorsal/lateral striatum and absolute reward- <italic>and</italic> punishment-related activity in the anterior ventral striatum. These distinct activity patterns may reflect the simultaneous recruitment of Pavlovian prediction and instrumental action selection mechanisms. Distinct recruitment of one or both of these mechanisms by distinct behavioral tasks may explain the discrepancies across previous studies. That said, it should be noted that the recruitment of distinct mechanisms was not controlled experimentally in our paradigm and the design of the present task differs from that of these prior tasks in a number of ways. Accordingly, caution should be exercised when extrapolating across studies. In future studies, punishment-related signal change in the striatum should be compared directly using Pavlovian and instrumental paradigms to assess the speculation that controllable (instrumental) punishment and uncontrollable punishment implicate distinct parts of the striatum.</p>
      <p>Reward-signed signal change was also observed in the amygdala, although the pattern in the amygdala was qualitatively different from that seen in the posterior dorsal/lateral striatum. Specifically, activity in the amygdala decreased below baseline during unexpected punishment rather than increasing above baseline during unexpected reward. Together our pattern of unsigned activity in the ventral striatum and reward-signed activity in the amygdala matches that found previously (<xref rid="bib44" ref-type="bibr">Seymour et al., 2005</xref>) and further highlights the role of the amygdala in appetitive processing.</p>
      <p>Our findings have implications for understanding the mechanisms underlying the dopaminergic modulation of striatal BOLD responses seen in previous studies of reversal learning, which likely involve both Pavlovian and instrumental control mechanisms. In these prior studies, striatal activity, and the effect of dopamine during the punishment event that led to reversal, was centered on its anterior ventral rather than its posterior dorsal parts. Together with these prior results, the present data suggest that the striatal activity (and its reduction by dopamine) during punishment-driven reversal learning could be driven by (disruption of) processing associated with punishment, rather than a modulation of reward-related processing such as reward anticipation or reward-focused learning (see <xref rid="sec1" ref-type="sec">Introduction</xref>). However a pharmacological fMRI study with this paradigm which is presently underway will clarify this. Unlike our pharmacological fMRI studies of reversal learning (<xref rid="bib11 bib19" ref-type="bibr">Cools et al., 2007; Dodds et al., 2008</xref>), some recent studies of learning have failed to observe modulation by dopamine or Parkinson's disease of processing associated with punishment, or with the negative reward prediction error (<xref rid="bib35 bib40 bib38" ref-type="bibr">Pessiglione et al., 2006; Schonberg et al., 2009; Rutledge et al., 2009</xref>). Performance on these tasks might depend to different degrees on Pavlovian and/or instrumental control mechanisms. Although other neurotransmitters, like serotonin, should be considered as plausible candidates ((<xref rid="bib14 bib9" ref-type="bibr">Daw et al., 2002; Cools et al., 2008</xref>), it is possible that punishment-related activity in the striatum during reversal learning reflects dopaminergic influences from the midbrain. The current paradigm opens avenues for assessing the degree to which known opposite effects of dopaminergic drugs on punishment- and reward-based reversal learning (<xref rid="bib12 bib13" ref-type="bibr">Cools et al., 2006, 2009</xref>) are accompanied by opposite effects on punishment- and reward-related activity in the anterior ventromedial striatum.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Annett</surname>
              <given-names>L.E.</given-names>
            </name>
            <name>
              <surname>McGregor</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>The effects of ibotenic acid lesions of the nucleus accumbens on spatial learning and extinction in the rat</article-title>
          <source>Behav. Brain Res.</source>
          <volume>31</volume>
          <year>1989</year>
          <fpage>231</fpage>
          <lpage>242</lpage>
          <pub-id pub-id-type="pmid">2914074</pub-id>
        </element-citation>
      </ref>
      <ref id="bib55">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Unified segmentation</article-title>
          <source>NeuroImage</source>
          <volume>26</volume>
          <year>2005</year>
          <fpage>839</fpage>
          <lpage>851</lpage>
          <pub-id pub-id-type="pmid">15955494</pub-id>
        </element-citation>
      </ref>
      <ref id="bib2">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bayer</surname>
              <given-names>H.M.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title>
          <source>Neuron</source>
          <volume>47</volume>
          <year>2005</year>
          <fpage>129</fpage>
          <lpage>141</lpage>
          <pub-id pub-id-type="pmid">15996553</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bayer</surname>
              <given-names>H.M.</given-names>
            </name>
            <name>
              <surname>Lau</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Statistics of midbrain dopamine neuron spike trains in the awake primate</article-title>
          <source>J. Neurophysiol.</source>
          <volume>98</volume>
          <year>2007</year>
          <fpage>1428</fpage>
          <lpage>1439</lpage>
          <pub-id pub-id-type="pmid">17615124</pub-id>
        </element-citation>
      </ref>
      <ref id="bib4">
        <mixed-citation publication-type="other">Bodi, N., Keri, S., Nagy, H., Moustafa, A., Myers, C.E., Daw, N., Dibo, G., Takats, A., Bereczki, D., Gluck, M.A., 2009. Reward-learning and the novelty-seeking personality: a between- and within-subjects study of the effects of dopamine agonists on young Parkinson's patients. Brain 132 (9), 2385–2395.</mixed-citation>
      </ref>
      <ref id="bib5">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Brett</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Anton</surname>
              <given-names>J.-L.</given-names>
            </name>
            <name>
              <surname>Valabregue</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.-B.</given-names>
            </name>
          </person-group>
          <chapter-title>abstract</chapter-title>
          <source>Presented at the 8th International Conference on Functional Mapping of the Human Brain, Sendai, Japan Available on CD-ROM in NeuroImage Vol 16:abstract 497</source>
          <year>2002</year>
        </element-citation>
      </ref>
      <ref id="bib6">
        <mixed-citation publication-type="other">Brischoux, Fdr., Chakraborty, S., Brierley, D.I., Ungless, M.A., 2009. Phasic excitation of dopamine neurons in ventral VTA by noxious stimuli. PNAS 106, 4894–4899.</mixed-citation>
      </ref>
      <ref id="bib7">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Clarke</surname>
              <given-names>H.F.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>A.C.</given-names>
            </name>
          </person-group>
          <article-title>Lesions of the medial striatum in monkeys produce perseverative impairments during reversal learning similar to those produced by lesions of the orbitofrontal cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>10972</fpage>
          <lpage>10982</lpage>
          <pub-id pub-id-type="pmid">18945905</pub-id>
        </element-citation>
      </ref>
      <ref id="bib8">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cohen</surname>
              <given-names>M.X.</given-names>
            </name>
            <name>
              <surname>Frank</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Neurocomputational models of basal ganglia function in learning, memory and choice</article-title>
          <source>Behav. Brain Res.</source>
          <volume>199</volume>
          <year>2009</year>
          <fpage>141</fpage>
          <lpage>156</lpage>
          <pub-id pub-id-type="pmid">18950662</pub-id>
        </element-citation>
      </ref>
      <ref id="bib9">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>O.J.</given-names>
            </name>
            <name>
              <surname>Sahakian</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Acute tryptophan depletion in healthy volunteers enhances punishment prediction but does not affect reward prediction</article-title>
          <source>Neuropsychopharmacology</source>
          <volume>33</volume>
          <year>2008</year>
          <fpage>2291</fpage>
          <lpage>2299</lpage>
          <pub-id pub-id-type="pmid">17940553</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Owen</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>Defining the neural mechanisms of probabilistic reversal learning using event-related functional magnetic resonance imaging</article-title>
          <source>J. Neurosci.</source>
          <volume>22</volume>
          <year>2002</year>
          <fpage>4563</fpage>
          <lpage>4567</lpage>
          <pub-id pub-id-type="pmid">12040063</pub-id>
        </element-citation>
      </ref>
      <ref id="bib11">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sheridan</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jacobs</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>D'Esposito</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Impulsive personality predicts dopamine-dependent changes in frontostriatal activity during component processes of working memory</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>5506</fpage>
          <lpage>5514</lpage>
          <pub-id pub-id-type="pmid">17507572</pub-id>
        </element-citation>
      </ref>
      <ref id="bib12">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>S.J.G.</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Barker</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>L-DOPA disrupts activity in the nucleus accumbens during reversal learning in Parkinson's disease</article-title>
          <source>Neuropsychopharmacology</source>
          <volume>32</volume>
          <year>2006</year>
          <fpage>180</fpage>
          <lpage>189</lpage>
          <pub-id pub-id-type="pmid">16841074</pub-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Frank</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Gibbs</surname>
              <given-names>S.E.</given-names>
            </name>
            <name>
              <surname>Miyakawa</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jagust</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>D'Esposito</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Striatal dopamine predicts outcome-specific reversal learning and its sensitivity to dopaminergic drug administration</article-title>
          <source>J. Neurosci.</source>
          <volume>29</volume>
          <year>2009</year>
          <fpage>1538</fpage>
          <lpage>1543</lpage>
          <pub-id pub-id-type="pmid">19193900</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Daw</surname>
              <given-names>N.D.</given-names>
            </name>
            <name>
              <surname>Kakade</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Opponent interactions between serotonin and dopamine</article-title>
          <source>Neural Networks</source>
          <volume>15</volume>
          <year>2002</year>
          <fpage>603</fpage>
          <lpage>616</lpage>
          <pub-id pub-id-type="pmid">12371515</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <chapter-title>Values and actions in aversion</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Glimcher</surname>
            </name>
            <name>
              <surname>Camerer</surname>
            </name>
            <name>
              <surname>Fehr</surname>
            </name>
            <name>
              <surname>Poldrack</surname>
            </name>
          </person-group>
          <source>Neuroeconomics: Decision Making and the Brain</source>
          <year>2008</year>
        </element-citation>
      </ref>
      <ref id="bib16">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Huys</surname>
              <given-names>Q.J.M.</given-names>
            </name>
          </person-group>
          <article-title>Serotonin, inhibition, and negative mood</article-title>
          <source>PLoS Comput. Biol.</source>
          <volume>4</volume>
          <year>2008</year>
          <fpage>e4</fpage>
          <pub-id pub-id-type="pmid">18248087</pub-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <mixed-citation publication-type="other">Delgado, M.R., Li, J., Schiller, D., Phelps, E.A., 2008. The role of the striatum in aversive learning and aversive prediction errors. Phil. Trans. R. Soc. B 363 (1511), 3787–3800.</mixed-citation>
      </ref>
      <ref id="bib18">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Divac</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Rosvold</surname>
              <given-names>H.E.</given-names>
            </name>
            <name>
              <surname>Szwarcbart</surname>
              <given-names>M.K.</given-names>
            </name>
          </person-group>
          <article-title>Behavioral effects of selective ablation of the caudate nucleus</article-title>
          <source>J. Comp. Physiol. Psychol.</source>
          <volume>63</volume>
          <year>1967</year>
          <fpage>184</fpage>
          <lpage>190</lpage>
          <pub-id pub-id-type="pmid">4963561</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dodds</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Muller</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>van Loon</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Cools</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>Methylphenidate has differential effects on blood oxygenation level-dependent signal related to cognitive subprocesses of reversal learning</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>5976</fpage>
          <lpage>5982</lpage>
          <pub-id pub-id-type="pmid">18524902</pub-id>
        </element-citation>
      </ref>
      <ref id="bib20">
        <mixed-citation publication-type="other">Frank, M.J., 2005. Dynamic dopamine modulation in the basal ganglia: a neurocomputational account of cognitive deficits in medicated and nonmedicated Parkinsonism. J. Cogn. Neurosci. 17 (1), 51–72.</mixed-citation>
      </ref>
      <ref id="bib21">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Frank</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Seeberger</surname>
              <given-names>L.C.</given-names>
            </name>
            <name>
              <surname>O'Reilly</surname>
              <given-names>R.C.</given-names>
            </name>
          </person-group>
          <article-title>By carrot or by stick: cognitive reinforcement learning in Parkinsonism</article-title>
          <source>Science</source>
          <volume>306</volume>
          <year>2004</year>
          <fpage>1940</fpage>
          <lpage>1943</lpage>
          <pub-id pub-id-type="pmid">15528409</pub-id>
        </element-citation>
      </ref>
      <ref id="bib22">
        <mixed-citation publication-type="other">Haber, S.N., Fudge, J.L., McFarland, N.R., 2000. Striatonigrostriatal pathways in primates form an ascending spiral from the shell to the dorsolateral striatum. J. Neurosci. 20 (6), 2369–2382.</mixed-citation>
      </ref>
      <ref id="bib23">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hampton</surname>
              <given-names>A.N.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
          </person-group>
          <article-title>Decoding the neural substrates of reward-related decision making with functional MRI</article-title>
          <source>Proc. Natl. Acad. Sci.</source>
          <volume>104</volume>
          <year>2007</year>
          <fpage>1377</fpage>
          <lpage>1382</lpage>
          <pub-id pub-id-type="pmid">17227855</pub-id>
        </element-citation>
      </ref>
      <ref id="bib24">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Horvitz</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Mesolimbocortical and nigrostriatal dopamine responses to salient non-reward events</article-title>
          <source>Neuroscience</source>
          <volume>96</volume>
          <year>2000</year>
          <fpage>651</fpage>
          <lpage>656</lpage>
          <pub-id pub-id-type="pmid">10727783</pub-id>
        </element-citation>
      </ref>
      <ref id="bib54">
        <mixed-citation publication-type="other">Howell, D., 2002. Statistical Methods for Psychology. Fifth edn. Duxbury Press, Duxbury Press.</mixed-citation>
      </ref>
      <ref id="bib25">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ikemoto</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Panksepp</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>The role of nucleus accumbens dopamine in motivated behavior: a unifying interpretation with special reference to reward-seeking</article-title>
          <source>Brain Res. Rev.</source>
          <volume>31</volume>
          <year>1999</year>
          <fpage>6</fpage>
          <lpage>41</lpage>
          <pub-id pub-id-type="pmid">10611493</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jensen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>McIntosh</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Crawley</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Mikulis</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Remington</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Kapur</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Direct activation of the ventral striatum in anticipation of aversive stimuli</article-title>
          <source>Neuron</source>
          <volume>40</volume>
          <year>2003</year>
          <fpage>1251</fpage>
          <lpage>1257</lpage>
          <pub-id pub-id-type="pmid">14687557</pub-id>
        </element-citation>
      </ref>
      <ref id="bib27">
        <mixed-citation publication-type="other">Jensen, J., Smith, A.J., Willeit, M., Crawley, A.P., Mikulis, D.J., Vitcu, I., Kapur, S., 2007. Separate brain regions code for salience vs. valence during reward prediction in humans. Hum. Brain Mapp. 28 (4), 294–302.</mixed-citation>
      </ref>
      <ref id="bib28">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kim</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Shimojo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
          </person-group>
          <article-title>Is avoiding an aversive outcome rewarding? Neural substrates of avoidance learning in the human brain</article-title>
          <source>PLoS Biol.</source>
          <volume>4</volume>
          <year>2006</year>
          <fpage>e233</fpage>
          <pub-id pub-id-type="pmid">16802856</pub-id>
        </element-citation>
      </ref>
      <ref id="bib29">
        <mixed-citation publication-type="other">Matsumoto M, Hikosaka O (2009) Two types of dopamine neuron distinctly convey positive and negative motivational signals. Nature advanced online publication.</mixed-citation>
      </ref>
      <ref id="bib30">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Menon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jensen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Vitcu</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Graff-Guerrero</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Crawley</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Kapur</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Temporal difference modeling of the blood-oxygen level dependent response during aversive conditioning in humans: effects of dopaminergic modulation</article-title>
          <source>Biol. Psychiatry</source>
          <volume>62</volume>
          <year>2007</year>
          <fpage>765</fpage>
          <lpage>772</lpage>
          <pub-id pub-id-type="pmid">17224134</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Montague</surname>
              <given-names>P.R.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Sejnowski</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>A framework for mesencephalic dopamine systems based on predictive Hebbian learning</article-title>
          <source>J. Neurosci.</source>
          <volume>16</volume>
          <year>1996</year>
          <fpage>1936</fpage>
          <lpage>1947</lpage>
          <pub-id pub-id-type="pmid">8774460</pub-id>
        </element-citation>
      </ref>
      <ref id="bib32">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Critchley</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Deichmann</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociating valence of outcome from behavioral control in human orbital and ventral prefrontal cortices</article-title>
          <source>J. Neurosci.</source>
          <volume>23</volume>
          <year>2003</year>
          <fpage>7931</fpage>
          <lpage>7939</lpage>
          <pub-id pub-id-type="pmid">12944524</pub-id>
        </element-citation>
      </ref>
      <ref id="bib33">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kringelbach</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Rolls</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Hornak</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Andrews</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Abstract reward and punishment representations in the human orbitofrontal cortex</article-title>
          <source>Nat. Neurosci.</source>
          <volume>4</volume>
          <year>2001</year>
          <fpage>95</fpage>
          <lpage>102</lpage>
          <pub-id pub-id-type="pmid">11135651</pub-id>
        </element-citation>
      </ref>
      <ref id="bib34">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Deichmann</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>
          <source>Science</source>
          <volume>304</volume>
          <year>2004</year>
          <fpage>452</fpage>
          <lpage>454</lpage>
          <pub-id pub-id-type="pmid">15087550</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pessiglione</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Flandin</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
          </person-group>
          <article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>
          <source>Nature</source>
          <volume>442</volume>
          <year>2006</year>
          <fpage>1042</fpage>
          <lpage>1045</lpage>
          <pub-id pub-id-type="pmid">16929307</pub-id>
        </element-citation>
      </ref>
      <ref id="bib36">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Redgrave</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Prescott</surname>
              <given-names>T.J.</given-names>
            </name>
            <name>
              <surname>Gurney</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Is the short-latency dopamine response too short to signal reward error?</article-title>
          <source>Trends Neurosci.</source>
          <volume>22</volume>
          <year>1999</year>
          <fpage>146</fpage>
          <lpage>151</lpage>
          <pub-id pub-id-type="pmid">10203849</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Remijnse</surname>
              <given-names>P.L.</given-names>
            </name>
            <name>
              <surname>Nielen</surname>
              <given-names>M.M.A.</given-names>
            </name>
            <name>
              <surname>Uylings</surname>
              <given-names>H.B.M.</given-names>
            </name>
            <name>
              <surname>Veltman</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of a reversal learning task with an affectively neutral baseline: an event-related fMRI study</article-title>
          <source>Neuroimage</source>
          <volume>26</volume>
          <year>2005</year>
          <fpage>609</fpage>
          <lpage>618</lpage>
          <pub-id pub-id-type="pmid">15907318</pub-id>
        </element-citation>
      </ref>
      <ref id="bib38">
        <mixed-citation publication-type="other">Rutledge, R.B., Lazzaro, S.C., Lau, B., Myers, C.E., Mark A. Gluck, Glimcher, P.W., 2009. Dopaminergic drugs modulate learning rates and perseveration in Parkinson's. Patients in a dynamic foraging task. J. Neurosci. 29 (48), 15104–15114.</mixed-citation>
      </ref>
      <ref id="bib39">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schoenbaum</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Setlow</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Saddoris</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Gallagher</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Encoding predicted outcome and acquired value in orbitofrontal cortex during cue sampling depends upon input from basolateral amygdala</article-title>
          <source>Neuron</source>
          <volume>39</volume>
          <year>2003</year>
          <fpage>855</fpage>
          <lpage>867</lpage>
          <pub-id pub-id-type="pmid">12948451</pub-id>
        </element-citation>
      </ref>
      <ref id="bib40">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schonberg</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Joel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Inzelberg</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Segev</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Daw</surname>
              <given-names>N.D.</given-names>
            </name>
          </person-group>
          <article-title>Selective impairment of prediction error signaling in human dorsolateral but not ventral striatum in Parkinson's disease patients: evidence from a model-based fMRI study</article-title>
          <source>Neuroimage</source>
          <volume>49</volume>
          <year>2009</year>
          <fpage>772</fpage>
          <lpage>781</lpage>
          <pub-id pub-id-type="pmid">19682583</pub-id>
        </element-citation>
      </ref>
      <ref id="bib41">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schultz</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Getting formal with dopamine and reward</article-title>
          <source>Neuron</source>
          <volume>36</volume>
          <year>2002</year>
          <fpage>241</fpage>
          <lpage>263</lpage>
          <pub-id pub-id-type="pmid">12383780</pub-id>
        </element-citation>
      </ref>
      <ref id="bib42">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Singer</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>The neurobiology of punishment</article-title>
          <source>Nat. Rev. Neurosci.</source>
          <volume>8</volume>
          <year>2007</year>
          <fpage>300</fpage>
          <lpage>311</lpage>
          <pub-id pub-id-type="pmid">17375042</pub-id>
        </element-citation>
      </ref>
      <ref id="bib43">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Daw</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Singer</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Differential encoding of losses and gains in the human striatum</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>4826</fpage>
          <lpage>4831</lpage>
          <pub-id pub-id-type="pmid">17475790</pub-id>
        </element-citation>
      </ref>
      <ref id="bib44">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Koltzenburg</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wiech</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Opponent appetitive-aversive neural processes underlie predictive learning of pain relief</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <year>2005</year>
          <fpage>1234</fpage>
          <lpage>1240</lpage>
          <pub-id pub-id-type="pmid">16116445</pub-id>
        </element-citation>
      </ref>
      <ref id="bib45">
        <mixed-citation publication-type="other">Shen W, Flajolet M, Greengard P, Surmeier DJ (2008) Dichotomous dopaminergic control of striatal synaptic plasticity. Science 321 (5890), 848–851.</mixed-citation>
      </ref>
      <ref id="bib46">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stern</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Passingham</surname>
              <given-names>R.E.</given-names>
            </name>
          </person-group>
          <article-title>The nucleus accumbens in monkeys (Macaca fascicularis): II. Emotion and motivation</article-title>
          <source>Behav. Brain Res.</source>
          <volume>75</volume>
          <year>1996</year>
          <fpage>179</fpage>
          <lpage>193</lpage>
          <pub-id pub-id-type="pmid">8800655</pub-id>
        </element-citation>
      </ref>
      <ref id="bib47">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Taghzouti</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Louilot</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Herman</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Le Moal</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Alternation behavior, spatial discrimination, and reversal disturbances following 6-hydroxydopamine lesions in the nucleus accumbens of the rat</article-title>
          <source>Behav. Neural. Biol.</source>
          <volume>44</volume>
          <year>1985</year>
          <fpage>354</fpage>
          <lpage>363</lpage>
          <pub-id pub-id-type="pmid">3936470</pub-id>
        </element-citation>
      </ref>
      <ref id="bib48">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tom</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>C.R.</given-names>
            </name>
            <name>
              <surname>Trepel</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Poldrack</surname>
              <given-names>R.A.</given-names>
            </name>
          </person-group>
          <article-title>The neural basis of loss aversion in decision-making under risk</article-title>
          <source>Science</source>
          <volume>315</volume>
          <year>2007</year>
          <fpage>515</fpage>
          <lpage>518</lpage>
          <pub-id pub-id-type="pmid">17255512</pub-id>
        </element-citation>
      </ref>
      <ref id="bib50">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ungless</surname>
              <given-names>M.A.</given-names>
            </name>
          </person-group>
          <article-title>Dopamine: the salient issue</article-title>
          <source>Trends Neurosci.</source>
          <volume>27</volume>
          <year>2004</year>
          <fpage>702</fpage>
          <lpage>706</lpage>
          <pub-id pub-id-type="pmid">15541509</pub-id>
        </element-citation>
      </ref>
      <ref id="bib51">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Voorn</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Vanderschuren</surname>
              <given-names>L.J.M.J.</given-names>
            </name>
            <name>
              <surname>Groenewegen</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T.W.</given-names>
            </name>
            <name>
              <surname>Pennartz</surname>
              <given-names>C.M.A.</given-names>
            </name>
          </person-group>
          <article-title>Putting a spin on the dorsal–ventral divide of the striatum</article-title>
          <source>Trends Neurosci.</source>
          <volume>27</volume>
          <year>2004</year>
          <fpage>468</fpage>
          <lpage>474</lpage>
          <pub-id pub-id-type="pmid">15271494</pub-id>
        </element-citation>
      </ref>
      <ref id="bib52">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yacubian</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Glascher</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Schroeder</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Sommer</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Braus</surname>
              <given-names>D.F.</given-names>
            </name>
            <name>
              <surname>Buchel</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable systems for gain- and loss-related value predictions and errors of prediction in the human brain</article-title>
          <source>J. Neurosci.</source>
          <volume>26</volume>
          <year>2006</year>
          <fpage>9530</fpage>
          <lpage>9537</lpage>
          <pub-id pub-id-type="pmid">16971537</pub-id>
        </element-citation>
      </ref>
      <ref id="bib53">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yin</surname>
              <given-names>H.H.</given-names>
            </name>
            <name>
              <surname>Knowlton</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Balleine</surname>
              <given-names>B.W.</given-names>
            </name>
          </person-group>
          <article-title>Inactivation of dorsolateral striatum enhances sensitivity to changes in the action-outcome contingency in instrumental conditioning</article-title>
          <source>Behav. Brain Res.</source>
          <volume>166</volume>
          <year>2006</year>
          <fpage>189</fpage>
          <lpage>196</lpage>
          <pub-id pub-id-type="pmid">16153716</pub-id>
        </element-citation>
      </ref>
      <ref id="bib56">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zink</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Pagnoni</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Dhamala</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Berns</surname>
              <given-names>G.S.</given-names>
            </name>
          </person-group>
          <article-title>Human Striatal Response to Salient Nonrewarding Stimuli</article-title>
          <source>J. Neurosci.</source>
          <volume>23</volume>
          <year>2003</year>
          <fpage>8092</fpage>
          <lpage>8097</lpage>
          <pub-id pub-id-type="pmid">12954871</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p>
        <supplementary-material content-type="local-data" id="d30e1934">
          <caption>
            <title>Fig. S1</title>
            <p>Data from peak striatal voxels estimated using a finite impulse response model. Values represent percentage signal change. This figure can be compared to <xref rid="fig4" ref-type="fig">Fig. 4</xref> in the main manuscript.</p>
          </caption>
          <media xlink:href="mmc1.doc" mimetype="application" mime-subtype="msword"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was completed within the University of Cambridge Behavioural and Clinical Neuroscience Institute, funded by a joint award from the Medical Research Council and the Wellcome Trust. Additional funding for this study came from Wellcome Trust Programme Grant 076274/Z/04/Z awarded to T.W.R., B. J. Everitt, A. C. Roberts, and B. J. Sahakian. M.J.C. is supported by the Gates Cambridge Trust. We thank the nurses and administrative staff at the Wellcome Trust Clinical Research Facility (Addenbrooke's Hospital, Cambridge, UK) and all participants.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>Example task-sequence of two trials. Abbreviation: R.T. = reaction time. Subjects see two stimuli, one of which is highlighted with a black box (top left). They then have to predict whether the highlighted stimulus will be followed by reward or punishment (pressing a green or red button respectively). This is then followed by the actual outcome associated with the particular stimulus. Reversals are signaled by unexpected outcomes.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>Behavioral data. Perseverative error rates (percentage) following a reversal stratified by the <italic>to be predicted</italic> outcome. *<italic>P</italic> &lt; 0.05. Error bars represent SEM.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p>significant whole brain BOLD signals during (a) punishment-based reversals, (b) reward based-reversals and (c) reward-based reversals minus punishment-based reversals.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>(a) Parameter estimates (betas) extracted for the four trial-types (unexpected punishment, unexpected reward, expected punishment and expected reward) from striatal peak voxels revealed by the contrast map reflecting the valence by expectedness interaction (unexpected reward relative to expected reward minus unexpected punishment relative to expected punishment). (b) Parameter estimates (betas) extracted for the four trial-types from striatal peak voxels revealed by the contrast map reflecting the main effect of expectedness (both unexpected outcomes minus both expected outcomes). More posterior and dorsal regions of striatum activate solely for reward, while anterior and ventral regions are activated by both reward and punishment. (c) Parameter estimates extracted for the four trial-types from amygdala peak voxels from the interaction map<bold>.</bold> Numbers represent the Talairach voxel coordinates of the extracted peaks. Note that the selection of these data was not independent from the whole-brain analyses; data are plotted for illustration purposes only. Furthermore although we plot each trial type separately, only the differences between trial types should be interpreted.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <table-wrap id="tbl1" position="float">
      <label>Table 1</label>
      <caption>
        <p>Behavioral data. Error rates (percentage) and reaction times (ms) (standard error of the mean) for both switch and non-switch trials. Switch trials are stratified by the valence of the unexpected feedback that signaled the switch (<italic>preceding</italic> outcome), and by the valence of the feedback that should have been predicted (<italic>to be predicted</italic> outcome). The switch trial is the trial immediately after the unexpected feedback, perseverative errors are all consecutive errors after this switch trial.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th>
              <italic>A: Non-switch trials</italic>
              <hr/>
            </th>
            <th>
              <hr/>
            </th>
            <th>
              <hr/>
            </th>
          </tr>
          <tr>
            <th/>
            <th align="left">Reward</th>
            <th align="left">Punishment</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">RT</td>
            <td align="char">765 (19)</td>
            <td align="char">788 (19)</td>
          </tr>
          <tr>
            <td align="left">Errors</td>
            <td align="char">0.08 (0.86)</td>
            <td align="char">0.08 (0.61)</td>
          </tr>
        </tbody>
      </table>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th colspan="5">
              <italic>B: Switch trials</italic>
              <hr/>
            </th>
          </tr>
          <tr>
            <th/>
            <th colspan="2" align="left">Unexpected reward<hr/></th>
            <th colspan="2" align="left">Unexpected punishment<hr/></th>
          </tr>
          <tr>
            <th/>
            <th align="left">Reward</th>
            <th align="left">Punishment</th>
            <th align="left">Reward</th>
            <th align="left">Punishment</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="5" align="left">
              <italic>Reaction times</italic>
            </td>
          </tr>
          <tr>
            <td align="left">Switch</td>
            <td align="char">690 (27)</td>
            <td align="char">772 (36)</td>
            <td align="char">807 (32)</td>
            <td align="char">759 (31)</td>
          </tr>
          <tr>
            <td align="left">Perseveration</td>
            <td align="char">993 (110)</td>
            <td align="char">1071 (64)</td>
            <td align="char">886 (61)</td>
            <td align="char">937 (48)</td>
          </tr>
          <tr>
            <td colspan="5">  </td>
          </tr>
          <tr>
            <td colspan="5" align="left">
              <italic>Error rates</italic>
            </td>
          </tr>
          <tr>
            <td align="left">Switch</td>
            <td align="char">11.15 (1.01)</td>
            <td align="char">12.37 (1.11)</td>
            <td align="char">12.44 (0.91)</td>
            <td align="char">11.87 (0.90)</td>
          </tr>
          <tr>
            <td align="left">Perseveration</td>
            <td align="char">2.01 (0.61)</td>
            <td align="char">3.54 (0.76)</td>
            <td align="char">2.65 (0.49)</td>
            <td align="char">3.44 (0.72)</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="tbl2" position="float">
      <label>Table 2</label>
      <caption>
        <p>Unexpected punishment minus expected punishment.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Label</th>
            <th align="left">Talairach coordinates (<italic>x</italic>, <italic>y</italic>, <italic>z</italic>) of peak locus</th>
            <th>
              <italic>T</italic>
            </th>
            <th align="left">Cluster size (<italic>K</italic>)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Left posterior parietal cortex</td>
            <td align="left">−42 −48 −49</td>
            <td align="char">10.7</td>
            <td align="char">541</td>
          </tr>
          <tr>
            <td align="left">Right posterior parietal cortex</td>
            <td align="left">39 −54 45</td>
            <td align="char">9.4</td>
            <td align="char">432</td>
          </tr>
          <tr>
            <td align="left">Dorsomedial prefrontal cortex</td>
            <td align="left">0 21 49</td>
            <td align="char">8.8</td>
            <td align="char">217</td>
          </tr>
          <tr>
            <td align="left">Left frontal eye fields, extending into left dorsolateral prefrontal cortex</td>
            <td align="left">−45 9 38</td>
            <td align="char">9.5</td>
            <td align="char">498</td>
          </tr>
          <tr>
            <td align="left">Right dorsolateral prefrontal cortex</td>
            <td align="left">45 30 34</td>
            <td align="char">8.6</td>
            <td align="char">433</td>
          </tr>
          <tr>
            <td align="left">Left ventrolateral prefrontal cortex/insula</td>
            <td align="left">−30 21 −4</td>
            <td align="char">6.8</td>
            <td align="char">74</td>
          </tr>
          <tr>
            <td align="left">Right ventrolateral prefrontal cortex/insula</td>
            <td align="left">36 24 −4</td>
            <td align="char">7.7</td>
            <td align="char">148</td>
          </tr>
          <tr>
            <td align="left">Left lateral anterior prefrontal cortex</td>
            <td align="left">−39 54 11</td>
            <td align="char">6.2</td>
            <td align="char">22</td>
          </tr>
          <tr>
            <td align="left">Right lateral anterior prefrontal cortex</td>
            <td align="left">33 51 4</td>
            <td align="char">5.5</td>
            <td align="char">6</td>
          </tr>
          <tr>
            <td align="left">Right lateral orbitofrontal cortex</td>
            <td align="left">33 54 −8</td>
            <td align="char">5.4</td>
            <td align="char">7</td>
          </tr>
          <tr>
            <td align="left">Left anterior striatum</td>
            <td align="left">−12 6 4</td>
            <td align="char">6.3</td>
            <td align="char">20</td>
          </tr>
          <tr>
            <td align="left">Right anterior striatum</td>
            <td align="left">12 9 4</td>
            <td align="char">5.8</td>
            <td align="char">17</td>
          </tr>
          <tr>
            <td align="left">Left lateral cerebellum</td>
            <td align="left">−33 −63 −30</td>
            <td align="left">7.07.0</td>
            <td align="char">55</td>
          </tr>
          <tr>
            <td align="left">Right lateral cerebellum</td>
            <td align="left">30 −63 −30</td>
            <td align="char">8.6</td>
            <td align="char">57</td>
          </tr>
          <tr>
            <td align="left">Left medial cerebellum</td>
            <td align="left">−9 −78 −30</td>
            <td align="char">6.2</td>
            <td align="char">19</td>
          </tr>
          <tr>
            <td align="left">Right medial cerebellum</td>
            <td align="left">9 −75 −76</td>
            <td align="char">5.6</td>
            <td align="char">11</td>
          </tr>
          <tr>
            <td align="left">Right posterior temporal cortex</td>
            <td align="left">48 −27 −8</td>
            <td align="char">6.9</td>
            <td align="char">57</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Local maxima of suprathreshold clusters at <italic>P</italic><sub>WB_FWE</sub> &lt; 0.05.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap id="tbl3" position="float">
      <label>Table 3</label>
      <caption>
        <p>Unexpected reward minus expected reward.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Label</th>
            <th align="left">Talairach coordinates (<italic>x</italic>, <italic>y</italic>, <italic>z</italic>) of peak locus</th>
            <th>
              <italic>T</italic>
            </th>
            <th align="left">Cluster size (<italic>K</italic>)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Left posterior parietal cortex, extending into right posterior parietal cortex</td>
            <td align="left">−42 −48 −49</td>
            <td align="char">13.7</td>
            <td align="char">741</td>
          </tr>
          <tr>
            <td align="left">Right ventrolateral prefrontal cortex/insula, extending into left ventrolateral prefrontal cortex/insula, bilateral dorsolateral prefrontal cortex, lateral anterior and orbital frontal cortex, dorsomedial prefrontal cortex, striatum, and thalamus</td>
            <td align="left">36 21 −4</td>
            <td align="char">11.3</td>
            <td align="char">5041</td>
          </tr>
          <tr>
            <td align="left">Left cerebellum, extending into right cerebellum</td>
            <td align="left">−30 −13 −30</td>
            <td align="char">10.9</td>
            <td align="char">702</td>
          </tr>
          <tr>
            <td align="left">Posterior cingulate cortex</td>
            <td align="left">3 −30 26</td>
            <td align="char">5.9</td>
            <td align="char">28</td>
          </tr>
          <tr>
            <td align="left">Right posterior temporal cortex</td>
            <td align="left">60 −36 −8</td>
            <td align="char">8.2</td>
            <td align="char">167</td>
          </tr>
          <tr>
            <td align="left">Left posterior temporal cortex</td>
            <td align="left">−60 −36 −8</td>
            <td align="char">5.5</td>
            <td align="char">28</td>
          </tr>
          <tr>
            <td align="left">Midbrain</td>
            <td align="left">3 −27 −22</td>
            <td align="char">4.9</td>
            <td align="char">7</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Local maxima of suprathreshold clusters at <italic>P</italic><sub>WB_FWE</sub> &lt; 0.05.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </floats-group>
</article>