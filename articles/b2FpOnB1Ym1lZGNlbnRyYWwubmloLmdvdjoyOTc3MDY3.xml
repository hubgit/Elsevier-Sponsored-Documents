<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="brief-report">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Curr Biol</journal-id>
      <journal-title-group>
        <journal-title>Current Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0960-9822</issn>
      <issn pub-type="epub">1879-0445</issn>
      <publisher>
        <publisher-name>Cell Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2977067</article-id>
      <article-id pub-id-type="pmid">20888231</article-id>
      <article-id pub-id-type="publisher-id">CURBIO8343</article-id>
      <article-id pub-id-type="doi">10.1016/j.cub.2010.08.048</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Report</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Differentiable Neural Substrates for Learned and Described Value and Risk</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>FitzGerald</surname>
            <given-names>Thomas H.B.</given-names>
          </name>
          <email>thomas.fitzgerald@iop.kcl.ac.uk</email>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="aff2" ref-type="aff">2</xref>
          <xref rid="cor1" ref-type="corresp">∗</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Seymour</surname>
            <given-names>Ben</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="aff3" ref-type="aff">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Bach</surname>
            <given-names>Dominik R.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Dolan</surname>
            <given-names>Raymond J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>1</label>Wellcome Trust Centre for Neuroimaging, 12 Queen Square, London WC1N 3BG, UK</aff>
      <aff id="aff2"><label>2</label>Department of Clinical Neurosciences, Institute of Psychiatry, Camberwell, London SE5 8AF, UK</aff>
      <aff id="aff3"><label>3</label>Economic and Social Research Council Centre for Economic Learning and Social Evolution, Gower Street, London WC1E 6BT, UK</aff>
      <author-notes>
        <corresp id="cor1"><label>∗</label>Corresponding author <email>thomas.fitzgerald@iop.kcl.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>26</day>
        <month>10</month>
        <year>2010</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>26</day>
        <month>10</month>
        <year>2010</year>
      </pub-date>
      <volume>20</volume>
      <issue>20</issue>
      <fpage>1823</fpage>
      <lpage>1829</lpage>
      <history>
        <date date-type="received">
          <day>25</day>
          <month>3</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>3</day>
          <month>8</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>24</day>
          <month>8</month>
          <year>2010</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2010 ELL &amp; Excerpta Medica.</copyright-statement>
        <copyright-year>2010</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <title>Summary</title>
        <p>Studies of human decision making emerge from two dominant traditions: learning theorists [<xref rid="bib1 bib2 bib3" ref-type="bibr">1–3</xref>] study choices in which options are evaluated on the basis of experience, whereas behavioral economists and financial decision theorists study choices in which the key decision variables are explicitly stated. Growing behavioral evidence suggests that valuation based on these different classes of information involves separable mechanisms [<xref rid="bib4 bib5 bib6 bib7 bib8" ref-type="bibr">4–8</xref>], but the relevant neuronal substrates are unknown. This is important for understanding the all-too-common situation in which choices must be made between alternatives that involve one or another kind of information. We studied behavior and brain activity while subjects made decisions between risky financial options, in which the associated utilities were either learned or explicitly described. We show a characteristic effect in subjects' behavior when comparing information acquired from experience with that acquired from description, suggesting that these kinds of information are treated differently. This behavioral effect was reflected neurally, and we show differential sensitivity to learned and described value and risk in brain regions commonly associated with reward processing. Our data indicate that, during decision making under risk, both behavior and the neural encoding of key decision variables are strongly influenced by the manner in which value information is presented.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Highlights</title>
        <p>► Learned and explicitly described value and risk have different effects on behavior ► Learned and described value and risk have separable neural correlates ► Learned and described value are traded off in several brain regions ► Activity in the orbitofrontal cortex predicts bias toward learned options</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <title>Results and Discussion</title>
      <sec id="sec1.1">
        <title>Experimental Paradigm</title>
        <p>We used an event-related fMRI paradigm in which subjects (n = 17) made choices between three cues whose win probability they had previously learned (p = 0.1, 0.5, 0.9) and cues whose values were described in terms of an explicit win probability (nine cues, p = 0.05, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9, 0.95) (<xref rid="fig1" ref-type="fig">Figure 1</xref>). Probabilities were described both numerically and with the aid of a pie chart (note that because we only manipulate probability, and not magnitude, probability and value are effectively equivalent in our study). We then applied a logit analysis to subjects' choice patterns to derive estimates of the subjective value of the learned cues in terms of explicit probabilities [<xref rid="bib9 bib10" ref-type="bibr">9, 10</xref>]. We hypothesized that brain activity in regions associated with reward processing, specifically ventromedial prefrontal/medial orbitofrontal cortices (vmPFC/OFC), posterior cingulate cortex (PCC), and ventral striatum (VS), would show differential patterns of activity when subjects processed experienced and described values, respectively [<xref rid="bib11 bib12 bib13 bib14 bib15" ref-type="bibr">11–15</xref>].</p>
      </sec>
      <sec id="sec1.2">
        <title>Behavioral Findings</title>
        <p>Our behavioral results, evident in both subjective valuation and reaction time (RT) data, were consistent with learned and described values being processed differently during choice. Subjects significantly overvalued low (but not medium or high) learned-probability relative to described-probability cues (p &lt; 0.005 two-tailed t test; <xref rid="fig2" ref-type="fig">Figures 2</xref>A–2C; see also <xref rid="app2" ref-type="sec">Table S1</xref>A available online). This suggests that, for low win probabilities, the effect of learned value (LV) on choice was stronger than that of described value (DV), congruent with previous findings about explicit estimation of learned outcome probabilities [<xref rid="bib16" ref-type="bibr">16</xref>] (<xref rid="app2" ref-type="sec">Supplemental Data</xref>).</p>
        <p>Superficially, our behavioral findings seem to contradict evidence suggesting that low described probabilities tend to be overweighted and low learned probabilities underweighted [<xref rid="bib7" ref-type="bibr">7</xref>]. In fact, we believe there is no such contradiction, because major procedural differences, most notably the focus of previous studies on testing probability weighting within domain, with subjects choosing between pairs of learned-probability options or pairs of described-probability ones, are likely to account for any apparent difference. In our task, subjects were required to compare valuations across domains—in other words, to make a choice between a learned-probability option and a described-probability option. Because all subjects received the same amount of feedback about each learned cue, our data also suggest that behavioral differences in handling learned and described probabilities are unlikely to be due solely to sampling bias [<xref rid="bib7" ref-type="bibr">7</xref>].</p>
        <p>A multiple regression analysis of RT data showed no significant effect of either choice condition (whether subjects chose the learned- or described-value cue) or the subjective value of the chosen option. Importantly, there was a significant RT choice-condition-by-value interaction (p &lt; 0.01), indicating that learned value facilitated behavioral responding, whereas described value did not (<xref rid="fig2" ref-type="fig">Figure 2</xref>D; <xref rid="app2" ref-type="sec">Table S1</xref>B). This effect of learned value is entirely consistent with a well-established facilitative effect of appetitive conditioning on reaction times [<xref rid="bib15 bib17" ref-type="bibr">15, 17</xref>].</p>
      </sec>
      <sec id="sec1.3">
        <title>Brain Responses to Value</title>
        <p>Our use of a sequential presentation paradigm allowed us to examine value-correlated activity at separate times during the trial. Here our primary focus is on value signals present at choice-screen onset (reflecting the value signals present during actual choice), but we also consider neural activity at the presentation of the first offer to the subject (representing initial encoding and evaluation of stimuli; <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>; <xref rid="app2" ref-type="sec">Supplemental Data</xref>). In addition, cognizant of the fact that neuronal processes involved in valuation might change as a function of time, we tested for temporally decaying value signals at both time points (<xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>; <xref rid="app2" ref-type="sec">Supplemental Data</xref>).</p>
        <p>At choice time, we observed activity correlating with learned value in the vmPFC/OFC (p &lt; 0.002 whole-brain cluster corrected) and PCC (p &lt; 0.05 region of interest [ROI] cluster corrected; <xref rid="fig3" ref-type="fig">Figure 3</xref>A; <xref rid="app2" ref-type="sec">Table S2</xref>). By contrast, described value was correlated with activity in bilateral ventral putamen (VP) and cerebellum (all p &lt; 0.002 whole-brain cluster corrected; <xref rid="fig3" ref-type="fig">Figure 3</xref>B; <xref rid="app2" ref-type="sec">Table S2</xref>). Critically, a direct contrast showed that these activation patterns differed significantly. The (LV − DV) contrast showed differential activity in vmPFC/OFC (p &lt; 0.03 ROI cluster corrected) and PCC (p &lt; 0.02 whole-brain cluster corrected; <xref rid="fig3" ref-type="fig">Figures 3</xref>Ci and 3D; <xref rid="app2" ref-type="sec">Table S2</xref>). Conversely, the opposite (DV − LV) contrast was associated with differential activity in the left VP (p &lt; 0.03 whole-brain cluster corrected) and the thalamus (p &lt; 0.002 whole-brain cluster corrected), with activity also evident in the right VP, albeit not reaching our criterion level of significance (<xref rid="fig3" ref-type="fig">Figures 3</xref>Cii and 3D; <xref rid="app2" ref-type="sec">Table S2</xref>). Of note, both LV-correlated activity in the vmPFC/OFC and DV-correlated activity in the VP survived in a check model in which learned and described value regressors were orthogonalized to a simple binary choice parameter. These activation patterns, in regions repeatedly implicated in studies of value (e.g., [<xref rid="bib11 bib12 bib13 bib14 bib15" ref-type="bibr">11–15</xref>]), thus reflect option values rather than just selected option type. We emphasize that our findings do not conflict with an established relationship between activity in VS and reward learning [<xref rid="bib15 bib16 bib18 bib19" ref-type="bibr">15, 16, 18, 19</xref>]. In our paradigm, learning about reward contingencies was asymptotic: subjects merely retrieved previously learned information. LV- and DV-correlated activity at offer time also differed from one another markedly, although the regions involved were different to those involved at choice time (<xref rid="app2" ref-type="sec">Supplemental Data</xref>).</p>
        <p>At both choice and offer time, we found regions where activity significantly correlated with both LV and (LV − DV) on the one hand and both DV and (DV − LV) on the other. This raises the possibility that, rather than separately encoding LV and DV, these regions actually process relative value signals (LV − DV) and (DV − LV). Thus, rather than anatomically dissociated networks processing different kinds of reward information, the activity patterns we observe might reflect differential processing of reward information within a distributed value-sensitive network.</p>
        <p>In an exploratory post hoc ROI analysis, we addressed this issue by assessing whether activity in regions showing significant responses to the (LV − DV) contrast showed significant negative responses to DV in addition to positive LV responses. We then performed a similar analysis for the (DV − LV) contrast. Note that because we do not make use of unbiased ROIs, any results should be seen as suggestive rather than conclusive. At choice time, a significant negative correlation with DV was found in the PCC (p = 0.009) and with LV in the VP and thalamus (VP: p = 0.046, thalamus: p = 0.007; <xref rid="app2" ref-type="sec">Figure S3</xref>B). A negative correlation with LV was found in vmPFC/OFC, but this was not significant (vmPFC/OFC: p = 0.291; <xref rid="app2" ref-type="sec">Figure S3</xref>B). These findings provide suggestive evidence that activity in PCC and thalamus is sensitive to both LV and DV, though in distinct ways, together with weaker evidence that the same considerations apply to activity in VP and vmPFC/OFC. Based on these findings, we suggest that our results are best seen as reflecting differential sensitivities to different kinds of reward information within a valuation network [<xref rid="bib11 bib12 bib13 bib14 bib15" ref-type="bibr">11–15</xref>], with the establishment of the precise nature of these differences remaining an issue for future work. We note also evidence of relative value coding in a number of regions at offer time (<xref rid="app2" ref-type="sec">Supplemental Data</xref>).</p>
        <p>Additionally, we hypothesized that between-subject variability in responses to learned and described value would predict the degree to which individuals displayed choice behavior biased toward selecting learned-value options. This is precisely what we found (<xref rid="fig3" ref-type="fig">Figure 3</xref>E; <xref rid="app2" ref-type="sec">Supplemental Data</xref>). Individual subjects' parameter estimates in the vmPFC/OFC for the (LV − DV) contrast showed a significant positive correlation with the extent to which they overvalued the low-probability learned cue (<italic>R</italic> = 0.644, p = 0.012, permutation test). Post hoc testing showed both a strong positive correlation between overvaluing and LV parameter estimates (<italic>R</italic> = 0.482, p = 0.021, permutation test) and a strong negative correlation between overvaluing and DV parameter estimates (<italic>R</italic> = −0.419, p = 0.040, permutation test). This suggests that subjects who showed greater (though opposite) responses to LV and DV in the vmPFC/OFC showed an increased bias toward selecting learned-value options.</p>
      </sec>
      <sec id="sec1.4">
        <title>Risk Processing</title>
        <p>If learned- and described-value estimates generated during risky decision making have distinct neuronal substrates, then we might expect this to be reflected in distinct influences of learned and described risk (here defined as outcome variance [<xref rid="bib20 bib21" ref-type="bibr">20, 21</xref>]; <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>). Indeed, this prediction is supported by our RT data, which show a significant choice-condition-by-risk interaction, with learned risk having a greater impact on hastening subjects' responses (p &lt; 0.001; <xref rid="fig2" ref-type="fig">Figure 2</xref>E; <xref rid="app2" ref-type="sec">Table S1</xref>B). By examining ROIs previously associated with outcome risk and uncertainty [<xref rid="bib20 bib21 bib22 bib23 bib24 bib25 bib26" ref-type="bibr">20–26</xref>], we again show differential patterns of activity. Risk-related activity reflecting choice of learned options (LR) was seen in the anterior cingulate cortex (ACC) in precisely the same region as that observed in previous studies involving learned uncertainty about the decision environment [<xref rid="bib22 bib24 bib25" ref-type="bibr">22, 24, 25</xref>] (p &lt; 0.05, family-wise error, small-volume corrected [FWE-SVC]; <xref rid="fig4" ref-type="fig">Figure 4</xref>A; <xref rid="app2" ref-type="sec">Table S3</xref>). In contrast, the risk of selected described-value cues (DR) was correlated with activity in bilateral anterior insula cortices (AI) in regions previously reported as expressing risk in a task involving explicit assessment [<xref rid="bib21" ref-type="bibr">21</xref>] (both p &lt; 0.05, FWE-SVC; <xref rid="fig4" ref-type="fig">Figure 4</xref>B; <xref rid="app2" ref-type="sec">Table S3</xref>). Analyzing the (LR-DR) and (DR-LR) contrasts indicated that these activation patterns differed significantly from one another in ACC and the left AI (both p &lt; 0.05, FWE-SVC; <xref rid="fig4" ref-type="fig">Figures 4</xref>C and 4D; <xref rid="app2" ref-type="sec">Table S3</xref>). At offer time, only temporally decaying risk-correlated activity was found (see <xref rid="app2" ref-type="sec">Supplemental Data</xref>).</p>
        <p>By testing for relative risk encoding using a post hoc ROI analysis similar to that described above, we found that activity in ACC showed a negative correlation with DR but was not statistically significant (p = 0.090 Bonferroni), whereas activity in the AI did not show a negative correlation with LR (<xref rid="app2" ref-type="sec">Figure S3</xref>C). Our data are thus consistent with relative risk encoding in the ACC, but at the same time they do not provide strong support for this suggestion.</p>
        <p>Both RT and imaging correlates of risk could, in principle, be explained by nonlinear value encoding rather than risk encoding per se. This is highly unlikely in the case of our imaging findings, because there is no overlap between brain regions correlated with value and risk; given the fit between our RT data and imaging, we suggest that this is not the most probable explanation here, either.</p>
      </sec>
    </sec>
    <sec id="sec2">
      <title>Discussion</title>
      <p>Neuroscientific studies of human decision making tend to situate themselves conceptually within one of two frameworks: learning theory (most commonly reinforcement learning [<xref rid="bib1 bib19" ref-type="bibr">1, 19</xref>]) and behavioral economics (most often in the shape of prospect theory [<xref rid="bib12 bib27 bib28 bib29" ref-type="bibr">12, 27–29</xref>]). Although it is conceivable that value estimates, based on different kinds of information, are treated equivalently at the neural level, here we show this is not the case. Instead, our data show that during decision making under risk, value estimates based on learned and described information evoke differential patterns of activity within value-sensitive regions. These results speak against the application of a single unifying theoretical framework to relate empirical findings concerning learning to those based on microeconomics.</p>
      <p>The finding that activity in the vmPFC/OFC shows a strong positive response to learned value fits neatly with a large body of evidence linking this region with subjective valuation [<xref rid="bib11 bib30 bib31 bib32 bib33 bib34 bib35" ref-type="bibr">11, 30–35</xref>], in particular the finding that the vmPFC/OFC encodes the value of a variety of different goods [<xref rid="bib30 bib32 bib35 bib36" ref-type="bibr">30, 32, 35, 36</xref>], which is likely to depend upon prior experience of identical or similar goods. It also tallies with a more specific proposal derived from reinforcer devaluation studies, which indicate that the OFC is essential for using and updating outcome value [<xref rid="bib37 bib38 bib39 bib40" ref-type="bibr">37–40</xref>].</p>
      <p>It is less clear, by contrast, how precisely to interpret positive striatal responses to described value, because little prior work speaks directly to the issue of valuation by description. One possibility is that explicitly presented information has access to dopaminergic circuits akin to those involved in generating reward prediction errors [<xref rid="bib15 bib41" ref-type="bibr">15, 41</xref>]. This is somewhat in tension with the finding that RT was related to LV but not DV, but there remains uncertainty about exactly what aspect of performance is mechanistically related to reaction time, which can be taken as a measure of both Pavlovian and instrumental responding.</p>
      <p>In PCC, VP, and thalamus at choice time and in various regions at offer time, we find evidence of relative value encoding. Our data are consistent with this being the case also for vmPFC/OFC. This suggests that, rather than a strict anatomical dissociation, LV and DV processing may be reflected in differential sensitivities to these types of information in valuation regions. This can explain why prior studies, none of which force an explicit dissociation between LV and DV, report value-correlated activity across these regions (e.g., [<xref rid="bib12 bib13" ref-type="bibr">12, 13</xref>]), because in these instances activity need reflect only a single value, irrespective of what type of information is used to generate it.</p>
      <p>A similar point can be made in relation to our finding of differential sensitivity to learned and described risk in two areas previously implicated in encoding risk [<xref rid="bib20 bib21 bib22 bib23 bib24 bib25 bib26" ref-type="bibr">20–26</xref>]. Existing literature indicates ACC risk-correlated activity in the context of learning [<xref rid="bib22 bib24 bib25" ref-type="bibr">22, 24, 25</xref>] and insula activity where there is an explicit assessment of probabilities [<xref rid="bib20 bib21 bib23" ref-type="bibr">20, 21, 23</xref>] (though feedback is often present in these latter experimental paradigms). However, at least one study has reported risk-related activity in both areas [<xref rid="bib26" ref-type="bibr">26</xref>]. The activity patterns we observe here could again point to differential sensitivity to different kinds of risk information in a network of risk-sensitive areas rather than to an absolute anatomical dissociation.</p>
      <p>A potential concern in our study is the fact that learned and described cues are not exactly matched, because there were more described than learned cues (nine compared with three) and because described cues were more novel than learned ones. We do not think either difference explains our results. On the one hand, it is unlikely that a jump from three to nine types of cue would radically alter valuation mechanisms, and in any case subjects effectively had to order a combined set of 12 cues rather than simply generate preferences within separate sets of three (learned) and nine (described) options. On the other hand, novelty responses also seem unlikely to explain our data, because there is no reason to suppose that they would covary parametrically with value. Additionally, we do not find any resemblances between temporally decaying and stable activity across the conditions, which would be expected if simple prior experience (as opposed to value learning) could explain our data.</p>
      <p>Studying how evaluations are processed based on different kinds of information is of direct practical importance for understanding choice behavior in a range of real-life scenarios (e.g., medical decision making, financial trading). On this basis, we suggest that our results represent a modest first step toward understanding decision making in such complex but quotidian situations.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <label>1</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Sutton</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Barto</surname>
              <given-names>A.G.</given-names>
            </name>
          </person-group>
          <chapter-title>Reinforcement Learning: An Introduction</chapter-title>
          <year>1998</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib2">
        <label>2</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Stephens</surname>
              <given-names>D.W.</given-names>
            </name>
            <name>
              <surname>Krebs</surname>
              <given-names>J.R.</given-names>
            </name>
          </person-group>
          <chapter-title>Foraging Theory</chapter-title>
          <year>1986</year>
          <publisher-name>Princeton University Press</publisher-name>
          <publisher-loc>Princeton, NJ</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib3">
        <label>3</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Mackintosh</surname>
              <given-names>N.J.</given-names>
            </name>
            <name>
              <surname>Dickinson</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Instrumental (type II) conditioning</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Dickinson</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Boakes</surname>
              <given-names>R.A.</given-names>
            </name>
          </person-group>
          <source>Mechanisms of Learning and Motivation: A Memorial Volume to Jerzy Konorski</source>
          <year>1979</year>
          <publisher-name>Lawrence Erlbaum Associates</publisher-name>
          <publisher-loc>Hillsdale, NJ</publisher-loc>
          <fpage>143</fpage>
          <lpage>169</lpage>
        </element-citation>
      </ref>
      <ref id="bib4">
        <label>4</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hertwig</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Barron</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Weber</surname>
              <given-names>E.U.</given-names>
            </name>
            <name>
              <surname>Erev</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Decisions from experience and the effect of rare events in risky choice</article-title>
          <source>Psychol. Sci.</source>
          <volume>15</volume>
          <year>2004</year>
          <fpage>534</fpage>
          <lpage>539</lpage>
          <pub-id pub-id-type="pmid">15270998</pub-id>
        </element-citation>
      </ref>
      <ref id="bib5">
        <label>5</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jessup</surname>
              <given-names>R.K.</given-names>
            </name>
            <name>
              <surname>Bishara</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Busemeyer</surname>
              <given-names>J.R.</given-names>
            </name>
          </person-group>
          <article-title>Feedback produces divergence from prospect theory in descriptive choice</article-title>
          <source>Psychol. Sci.</source>
          <volume>19</volume>
          <year>2008</year>
          <fpage>1015</fpage>
          <lpage>1022</lpage>
          <pub-id pub-id-type="pmid">19000212</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <label>6</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ungemach</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Chater</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Stewart</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Are probabilities overweighted or underweighted when rare outcomes are experienced (rarely)?</article-title>
          <source>Psychol. Sci.</source>
          <volume>20</volume>
          <year>2009</year>
          <fpage>473</fpage>
          <lpage>479</lpage>
          <pub-id pub-id-type="pmid">19399978</pub-id>
        </element-citation>
      </ref>
      <ref id="bib7">
        <label>7</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hertwig</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Erev</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>The description-experience gap in risky choice</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>13</volume>
          <year>2009</year>
          <fpage>517</fpage>
          <lpage>523</lpage>
          <pub-id pub-id-type="pmid">19836292</pub-id>
        </element-citation>
      </ref>
      <ref id="bib8">
        <label>8</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wu</surname>
              <given-names>S.W.</given-names>
            </name>
            <name>
              <surname>Delgado</surname>
              <given-names>M.R.</given-names>
            </name>
            <name>
              <surname>Maloney</surname>
              <given-names>L.T.</given-names>
            </name>
          </person-group>
          <article-title>Economic decision-making compared with an equivalent motor task</article-title>
          <source>Proc. Natl. Acad. Sci. USA</source>
          <volume>106</volume>
          <year>2009</year>
          <fpage>6088</fpage>
          <lpage>6093</lpage>
          <pub-id pub-id-type="pmid">19332799</pub-id>
        </element-citation>
      </ref>
      <ref id="bib9">
        <label>9</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Camerer</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Ho</surname>
              <given-names>T.H.</given-names>
            </name>
          </person-group>
          <article-title>Experience-weighted attraction learning in normal form games</article-title>
          <source>Econometrica</source>
          <volume>67</volume>
          <year>1999</year>
          <fpage>827</fpage>
          <lpage>874</lpage>
        </element-citation>
      </ref>
      <ref id="bib10">
        <label>10</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lau</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic response-by-response models of matching behavior in rhesus monkeys</article-title>
          <source>J. Exp. Anal. Behav.</source>
          <volume>84</volume>
          <year>2005</year>
          <fpage>555</fpage>
          <lpage>579</lpage>
          <pub-id pub-id-type="pmid">16596980</pub-id>
        </element-citation>
      </ref>
      <ref id="bib11">
        <label>11</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Daw</surname>
              <given-names>N.D.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Cortical substrates for exploratory decisions in humans</article-title>
          <source>Nature</source>
          <volume>441</volume>
          <year>2006</year>
          <fpage>876</fpage>
          <lpage>879</lpage>
          <pub-id pub-id-type="pmid">16778890</pub-id>
        </element-citation>
      </ref>
      <ref id="bib12">
        <label>12</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kable</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>The neural correlates of subjective value during intertemporal choice</article-title>
          <source>Nat. Neurosci.</source>
          <volume>10</volume>
          <year>2007</year>
          <fpage>1625</fpage>
          <lpage>1633</lpage>
          <pub-id pub-id-type="pmid">17982449</pub-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <label>13</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knutson</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kaufman</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Peterson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Glover</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Distributed neural representation of expected value</article-title>
          <source>J. Neurosci.</source>
          <volume>25</volume>
          <year>2005</year>
          <fpage>4806</fpage>
          <lpage>4812</lpage>
          <pub-id pub-id-type="pmid">15888656</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <label>14</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McClure</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Laibson</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Loewenstein</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Cohen</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Separate neural systems value immediate and delayed monetary rewards</article-title>
          <source>Science</source>
          <volume>306</volume>
          <year>2004</year>
          <fpage>503</fpage>
          <lpage>507</lpage>
          <pub-id pub-id-type="pmid">15486304</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <label>15</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Deichmann</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>
          <source>Science</source>
          <volume>304</volume>
          <year>2004</year>
          <fpage>452</fpage>
          <lpage>454</lpage>
          <pub-id pub-id-type="pmid">15087550</pub-id>
        </element-citation>
      </ref>
      <ref id="bib16">
        <label>16</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schönberg</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Daw</surname>
              <given-names>N.D.</given-names>
            </name>
            <name>
              <surname>Joel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
          </person-group>
          <article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>12860</fpage>
          <lpage>12867</lpage>
          <pub-id pub-id-type="pmid">18032658</pub-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <label>17</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Niv</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Daw</surname>
              <given-names>N.D.</given-names>
            </name>
            <name>
              <surname>Joel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Tonic dopamine: Opportunity costs and the control of response vigor</article-title>
          <source>Psychopharmacology (Berl.)</source>
          <volume>191</volume>
          <year>2007</year>
          <fpage>507</fpage>
          <lpage>520</lpage>
          <pub-id pub-id-type="pmid">17031711</pub-id>
        </element-citation>
      </ref>
      <ref id="bib18">
        <label>18</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Montague</surname>
              <given-names>P.R.</given-names>
            </name>
            <name>
              <surname>Berns</surname>
              <given-names>G.S.</given-names>
            </name>
          </person-group>
          <article-title>Neural economics and the biological substrates of valuation</article-title>
          <source>Neuron</source>
          <volume>36</volume>
          <year>2002</year>
          <fpage>265</fpage>
          <lpage>284</lpage>
          <pub-id pub-id-type="pmid">12383781</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <label>19</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Koltzenburg</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>A.K.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
          </person-group>
          <article-title>Temporal difference models describe higher-order learning in humans</article-title>
          <source>Nature</source>
          <volume>429</volume>
          <year>2004</year>
          <fpage>664</fpage>
          <lpage>667</lpage>
          <pub-id pub-id-type="pmid">15190354</pub-id>
        </element-citation>
      </ref>
      <ref id="bib20">
        <label>20</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Huettel</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Decisions under uncertainty: Probabilistic context influences activation of prefrontal and parietal cortices</article-title>
          <source>J. Neurosci.</source>
          <volume>25</volume>
          <year>2005</year>
          <fpage>3304</fpage>
          <lpage>3311</lpage>
          <pub-id pub-id-type="pmid">15800185</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <label>21</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Preuschoff</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Quartz</surname>
              <given-names>S.R.</given-names>
            </name>
            <name>
              <surname>Bossaerts</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Human insula activation reflects risk prediction errors as well as risk</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>2745</fpage>
          <lpage>2752</lpage>
          <pub-id pub-id-type="pmid">18337404</pub-id>
        </element-citation>
      </ref>
      <ref id="bib22">
        <label>22</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Walton</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Rushworth</surname>
              <given-names>M.F.S.</given-names>
            </name>
          </person-group>
          <article-title>Learning the value of information in an uncertain world</article-title>
          <source>Nat. Neurosci.</source>
          <volume>10</volume>
          <year>2007</year>
          <fpage>1214</fpage>
          <lpage>1221</lpage>
          <pub-id pub-id-type="pmid">17676057</pub-id>
        </element-citation>
      </ref>
      <ref id="bib23">
        <label>23</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Critchley</surname>
              <given-names>H.D.</given-names>
            </name>
            <name>
              <surname>Mathias</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Neural activity in the human brain relating to uncertainty and arousal during anticipation</article-title>
          <source>Neuron</source>
          <volume>29</volume>
          <year>2001</year>
          <fpage>537</fpage>
          <lpage>545</lpage>
          <pub-id pub-id-type="pmid">11239442</pub-id>
        </element-citation>
      </ref>
      <ref id="bib24">
        <label>24</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brown</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Braver</surname>
              <given-names>T.S.</given-names>
            </name>
          </person-group>
          <article-title>Learned predictions of error likelihood in the anterior cingulate cortex</article-title>
          <source>Science</source>
          <volume>307</volume>
          <year>2005</year>
          <fpage>1118</fpage>
          <lpage>1121</lpage>
          <pub-id pub-id-type="pmid">15718473</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <label>25</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brown</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Braver</surname>
              <given-names>T.S.</given-names>
            </name>
          </person-group>
          <article-title>Risk prediction and aversion by anterior cingulate cortex</article-title>
          <source>Cogn. Affect. Behav. Neurosci.</source>
          <volume>7</volume>
          <year>2007</year>
          <fpage>266</fpage>
          <lpage>277</lpage>
          <pub-id pub-id-type="pmid">18189000</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <label>26</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>d'Acremont</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>Z.L.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Van der Linden</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bechara</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of risk prediction error during reinforcement learning in humans</article-title>
          <source>Neuroimage</source>
          <volume>47</volume>
          <year>2009</year>
          <fpage>1929</fpage>
          <lpage>1939</lpage>
          <pub-id pub-id-type="pmid">19442744</pub-id>
        </element-citation>
      </ref>
      <ref id="bib27">
        <label>27</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kahneman</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Tversky</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Prospect theory: An analysis of decision under risk</article-title>
          <source>Econometrica</source>
          <volume>47</volume>
          <year>1979</year>
          <fpage>263</fpage>
          <lpage>292</lpage>
        </element-citation>
      </ref>
      <ref id="bib28">
        <label>28</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>De Martino</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Kumaran</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Frames, biases, and rational decision-making in the human brain</article-title>
          <source>Science</source>
          <volume>313</volume>
          <year>2006</year>
          <fpage>684</fpage>
          <lpage>687</lpage>
          <pub-id pub-id-type="pmid">16888142</pub-id>
        </element-citation>
      </ref>
      <ref id="bib29">
        <label>29</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tom</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>C.R.</given-names>
            </name>
            <name>
              <surname>Trepel</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Poldrack</surname>
              <given-names>R.A.</given-names>
            </name>
          </person-group>
          <article-title>The neural basis of loss aversion in decision-making under risk</article-title>
          <source>Science</source>
          <volume>315</volume>
          <year>2007</year>
          <fpage>515</fpage>
          <lpage>518</lpage>
          <pub-id pub-id-type="pmid">17255512</pub-id>
        </element-citation>
      </ref>
      <ref id="bib30">
        <label>30</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hare</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Camerer</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Rangel</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>5623</fpage>
          <lpage>5630</lpage>
          <pub-id pub-id-type="pmid">18509023</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <label>31</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Padoa-Schioppa</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Assad</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Neurons in the orbitofrontal cortex encode economic value</article-title>
          <source>Nature</source>
          <volume>441</volume>
          <year>2006</year>
          <fpage>223</fpage>
          <lpage>226</lpage>
          <pub-id pub-id-type="pmid">16633341</pub-id>
        </element-citation>
      </ref>
      <ref id="bib32">
        <label>32</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Plassmann</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rangel</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Orbitofrontal cortex encodes willingness to pay in everyday economic transactions</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>9984</fpage>
          <lpage>9988</lpage>
          <pub-id pub-id-type="pmid">17855612</pub-id>
        </element-citation>
      </ref>
      <ref id="bib33">
        <label>33</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schoenbaum</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Roesch</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Orbitofrontal cortex, associative learning, and expectancies</article-title>
          <source>Neuron</source>
          <volume>47</volume>
          <year>2005</year>
          <fpage>633</fpage>
          <lpage>636</lpage>
          <pub-id pub-id-type="pmid">16129393</pub-id>
        </element-citation>
      </ref>
      <ref id="bib34">
        <label>34</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tremblay</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Relative reward preference in primate orbitofrontal cortex</article-title>
          <source>Nature</source>
          <volume>398</volume>
          <year>1999</year>
          <fpage>704</fpage>
          <lpage>708</lpage>
          <pub-id pub-id-type="pmid">10227292</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <label>35</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chib</surname>
              <given-names>V.S.</given-names>
            </name>
            <name>
              <surname>Rangel</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shimojo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
          </person-group>
          <article-title>Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>29</volume>
          <year>2009</year>
          <fpage>12315</fpage>
          <lpage>12320</lpage>
          <pub-id pub-id-type="pmid">19793990</pub-id>
        </element-citation>
      </ref>
      <ref id="bib36">
        <label>36</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>FitzGerald</surname>
              <given-names>T.H.B.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>The role of human orbitofrontal cortex in value comparison for incommensurable objects</article-title>
          <source>J. Neurosci.</source>
          <volume>29</volume>
          <year>2009</year>
          <fpage>8388</fpage>
          <lpage>8395</lpage>
          <pub-id pub-id-type="pmid">19571129</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <label>37</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gallagher</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>McMahan</surname>
              <given-names>R.W.</given-names>
            </name>
            <name>
              <surname>Schoenbaum</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Orbitofrontal cortex and representation of incentive value in associative learning</article-title>
          <source>J. Neurosci.</source>
          <volume>19</volume>
          <year>1999</year>
          <fpage>6610</fpage>
          <lpage>6614</lpage>
          <pub-id pub-id-type="pmid">10414988</pub-id>
        </element-citation>
      </ref>
      <ref id="bib38">
        <label>38</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Izquierdo</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Suda</surname>
              <given-names>R.K.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>E.A.</given-names>
            </name>
          </person-group>
          <article-title>Bilateral orbital prefrontal cortex lesions in rhesus monkeys disrupt choices guided by both reward value and reward contingency</article-title>
          <source>J. Neurosci.</source>
          <volume>24</volume>
          <year>2004</year>
          <fpage>7540</fpage>
          <lpage>7548</lpage>
          <pub-id pub-id-type="pmid">15329401</pub-id>
        </element-citation>
      </ref>
      <ref id="bib39">
        <label>39</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gottfried</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Encoding predictive reward value in human amygdala and orbitofrontal cortex</article-title>
          <source>Science</source>
          <volume>301</volume>
          <year>2003</year>
          <fpage>1104</fpage>
          <lpage>1107</lpage>
          <pub-id pub-id-type="pmid">12934011</pub-id>
        </element-citation>
      </ref>
      <ref id="bib40">
        <label>40</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Valentin</surname>
              <given-names>V.V.</given-names>
            </name>
            <name>
              <surname>Dickinson</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.P.</given-names>
            </name>
          </person-group>
          <article-title>Determining the neural substrates of goal-directed learning in the human brain</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>4019</fpage>
          <lpage>4026</lpage>
          <pub-id pub-id-type="pmid">17428979</pub-id>
        </element-citation>
      </ref>
      <ref id="bib41">
        <label>41</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schultz</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Dayan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Montague</surname>
              <given-names>P.R.</given-names>
            </name>
          </person-group>
          <article-title>A neural substrate of prediction and reward</article-title>
          <source>Science</source>
          <volume>275</volume>
          <year>1997</year>
          <fpage>1593</fpage>
          <lpage>1599</lpage>
          <pub-id pub-id-type="pmid">9054347</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="app2" sec-type="supplementary-material">
      <title>Supplemental Information</title>
      <p>
        <supplementary-material content-type="local-data" id="mmc1">
          <caption>
            <title>Document S1. Supplemental Experimental Procedures, Supplemental Data, Three Tables, and Four Figures</title>
          </caption>
          <media xlink:href="mmc1.pdf" mimetype="application" mime-subtype="pdf"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>We thank the radiographers at the Wellcome Department of Imaging Neuroscience for their assistance with scanning and members of the Emotion and Cognition group for valuable discussions. T.H.B.F. was supported by a studentship from King's College London. This work was funded by a Wellcome Trust Programme Grant to R.J.D.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="fig1">
      <label>Figure 1</label>
      <caption>
        <p>Illustration of a Single Trial of the Task Paradigm</p>
        <p>Subjects fixate for 1000 ms. They are then presented with the first offer (which can be either a described-value cue or a learned-value cue, fully counterbalanced and in pseudorandomized order) for 2000 ms, and, after a 500 ms delay, the second offer for 2000 ms. After another 500 ms delay, they are then asked to make their choice within 2000 ms. Successful choices were indicated by the appearance of a circle around the selected option. The intertrial interval was jittered between 0 and 3000 ms. In the example shown, the subject is being asked to decide between the option indicated by the square (the value of which they have previously learned) and a described-value option with a win probability of 0.2. (In this paradigm, outcome magnitudes are held constant, and so probability and value are equivalent.) For the fMRI analysis, events were modeled at both the first offer and choice-screen onset time.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Figure 2</label>
      <caption>
        <p>Behavioral Analysis</p>
        <p>(A–C) Logit analysis of subjects' pooled choice data for the lowest learned-value cue (p = 0.1) (A), the middle learned-value cue (p = 0.5) (B), and the highest learned-value cue (p = 0.9) (C). The probability of subjects choosing the learned-value option, when it was offered against each separate described-value option, was calculated (indicated by open blue circles), and this resulting probability distribution was fitted with a logistic sigmoid (green line). The indifference point (red filled circle) calculated from this was used as an estimate of relative subjective value (in other words, an estimate of each learned-value cue in terms of described probabilities). Indifference points were p = 0.23, 0.54, and 0.91, respectively, suggesting that subjects considerably overvalued the lowest learned-value cue. This can be seen by comparing the actual estimated subjective values (red filled circles) with the normative ones (indicated by dotted vertical lines) and suggests that subjects exhibited a bias toward learned options when considering low value alternatives. (Note that for the imaging analysis described here, individual subjects' choice patterns were analyzed separately.)</p>
        <p>(D) Normalized log reaction times (RTs) pooled across all subjects from which the effects of experimental session, difference in subjective value, and selected option type have been regressed out (<xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>). These have been binned into low, medium, and high chosen subjective value. Blue lines indicate mean log RTs from trials in which subjects chose the described-value cue, red lines indicate those in which they chose the learned-value cue, and vertical bars indicate 90% confidence intervals. The figure illustrates that RTs were negatively correlated with increasing chosen value only if subjects chose a learned-value cue, showing no equivalent effect of described value.</p>
        <p>(E) Normalized log RTs pooled across all subjects from which the effects of experimental session, difference in subjective value, selected option type, and chosen value have been regressed out (<xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>). These have been binned into low and high chosen subjective risk. Blue lines indicate mean log RTs from trials in which subjects chose the described-value cue, red lines indicate those in which they chose the learned-value cue, and vertical bars indicate 90% confidence intervals. The figure illustrates that RTs were negatively correlated with increasing chosen risk only if subjects chose a learned-value cue, showing no equivalent significant effect of described risk.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Figure 3</label>
      <caption>
        <p>Neural Correlates of Learned and Described Value at Choice Time</p>
        <p>(A) This shows that learned value correlated with activity in the ventromedial prefrontal/medial orbitofrontal cortices (vmPFC/OFC) and posterior cingulate cortex (PCC). vmPFC/OFC: peak cluster voxel ([−15, 57, −3], z = 4.20), p &lt; 0.002 whole-brain cluster corrected. PCC: peak voxel ([−3, −48, 33], z = 2.62), p &lt; 0.05 cluster corrected for the PCC region of interest (ROI). Image is at x = 0.</p>
        <p>(B) Described value correlated with activity in the bilateral ventral putamen (VP). Peak voxels: ([−30, 12, −6], z = 4.29) and ([27, 0, 6], z = 3.60). Both p &lt; 0.002 whole-brain cluster corrected. Image is at y = 10.</p>
        <p>(Ci) A direct comparison between responses to learned and described value (the (LV – DV) contrast) shows that activity in the vmPFC/OFC and PCC was greater for learned than described value. vmPFC/OFC: peak cluster voxel ([−15, 57, −3], z = 3.66), peak voxel within ROI ([−3, 45, −21], z = 2.73), p &lt; 0.03 cluster corrected for the vmPFC/OFC ROI. PCC: peak voxel ([−9, −48, 30], z = 3.22), p &lt; 0.02 whole-brain cluster corrected. This shows that value-sensitive activity in these regions was selective for learned-value options. Image is at x = −5.</p>
        <p>(Cii) The opposite (DV – LV) contrast shows that activity in left VP was better correlated with described relative to learned value. Peak voxel: ([−27, 9, 0], z = 3.17), p &lt; 0.03 whole-brain cluster corrected. This shows that value-sensitive activity in these regions was selective for described-value options. Image is at y = 10.</p>
        <p>(D) Mean parameter estimates for activation in the vmPFC/mOFC (red) and left VP (blue) for the (LV – DV) contrast. This illustrates that activity in the vmPFC/OFC was correlated more strongly with the value of learned cues than described ones, whereas the left VP showed the opposite pattern (this presentation is for illustrative purposes only; black bars indicate 90% confidence intervals).</p>
        <p>(E) Plot of individual subjects' parameter estimates for the (LV – DV) contrast in the vmPFC/OFC (y axis) against their estimated subjective value for the lowest learned-value cue (objective win probability = 0.1; x axis). These show a strong positive correlation (R = 0.644, p &lt; 0.01, permutation test), indicating that subjects that showed a greater degree of sensitivity to learned value relative to described value in the vmPFC/OFC also showed a bias toward selecting learned-value options. (Red line indicates the line of best fit generated by linear regression.)</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Figure 4</label>
      <caption>
        <p>Neural Correlates of Learned and Described Risk at Choice Time</p>
        <p>(A) The risk of chosen learned options was correlated with activity in the anterior cingulate cortex (ACC). Peak voxel: ([12, 30, 27], z = 3.52), p &lt; 0.05, family-wise error, small-volume corrected (FWE-SVC). Image is at x = 11; red p &lt; 0.005, orange p &lt; 0.001.</p>
        <p>(B) The risk of chosen described options was correlated with activity in the bilateral anterior insula cortices (AI). Peak voxel: ([27, 24, 0], z = 3.49, [−24, 27, 6], z = 3.66), p &lt; 0.05, FWE-SVC. Image is at y = 25; dark blue p &lt; 0.005, light blue p &lt; 0.001.</p>
        <p>(Ci) Activity in the ACC was correlated more strongly with the chosen learned risk than chosen described risk (showed a positive correlation with the (chosen learned risk – chosen described risk) contrast). Peak voxel: ([12, 33, 30], z = 3.49), p &lt; 0.05, FWE-SVC. This shows that risk-sensitive activity in these regions was selective for learned-value options. Image is at x = 13; red p &lt; 0.005, orange p &lt; 0.001.</p>
        <p>(Cii) Activity in the left AI correlated more strongly with chosen described risk than chosen learned risk (showed a negative correlation with the (chosen learned risk – chosen described risk) contrast). Peak voxel: ([−30, 33, 6], z = 3.59), p &lt; 0.05, FWE-SVC. This shows that risk-sensitive activity in these regions was selective for described-value options. Image is at y = 25; dark blue p &lt; 0.005, light blue p &lt; 0.001.</p>
        <p>(D) Mean parameter estimates for activation in the ACC (red) and left AI (blue) for the (chosen learned risk – chosen described risk) contrast. This illustrates that activity in ACC was correlated more strongly with the value of learned cues than described ones, whereas the left AI showed the opposite pattern. (This presentation is for illustrative purposes only; black bars indicate 90% confidence intervals.)</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
  </floats-group>
</article>