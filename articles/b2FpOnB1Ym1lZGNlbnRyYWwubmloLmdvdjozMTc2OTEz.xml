<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3176913</article-id>
      <article-id pub-id-type="pmid">21554967</article-id>
      <article-id pub-id-type="publisher-id">YNIMG8256</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2011.04.035</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Object representations in ventral and dorsal visual streams: fMRI repetition effects depend on attention and part–whole configuration</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Thoma</surname>
            <given-names>Volker</given-names>
          </name>
          <email>v.thoma@uel.ac.uk</email>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="cr0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Henson</surname>
            <given-names>Richard N.</given-names>
          </name>
          <xref rid="af0010" ref-type="aff">b</xref>
        </contrib>
      </contrib-group>
      <aff id="af0005"><label>a</label>School of Psychology, University of East London, UK</aff>
      <aff id="af0010"><label>b</label>MRC Cognition and Sciences Unit, Cambridge, UK</aff>
      <author-notes>
        <corresp id="cr0005"><label>⁎</label>Corresponding author at: School of Psychology, UEL, Water Lane, E15 4LZ, London, UK. Fax: + 44 20 8223 4937. <email>v.thoma@uel.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>15</day>
        <month>7</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>15</day>
        <month>7</month>
        <year>2011</year>
      </pub-date>
      <volume>57</volume>
      <issue>2</issue>
      <fpage>513</fpage>
      <lpage>525</lpage>
      <history>
        <date date-type="received">
          <day>5</day>
          <month>1</month>
          <year>2011</year>
        </date>
        <date date-type="rev-recd">
          <day>12</day>
          <month>4</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>18</day>
          <month>4</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 Elsevier Inc.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>The effects of attention and object configuration on the neural responses to short-lag visual image repetition were investigated with fMRI. Attention to one of two object images in a prime display was cued spatially. The images were either intact or split vertically; a manipulation that negates the influence of view-based representations. A subsequent single intact probe image was named covertly. Behavioural priming observed as faster button presses was found for attended primes in both intact and split configurations, but only for uncued primes in the intact configuration. In a voxel-wise analysis, fMRI repetition suppression (RS) was observed in a left mid-fusiform region for attended primes, both intact and split, whilst a right intraparietal region showed repetition enhancement (RE) for intact primes, regardless of attention. In a factorial analysis across regions of interest (ROIs) defined from independent localiser contrasts, RS for attended objects in the ventral stream was significantly left-lateralised, whilst repetition effects in ventral and dorsal ROIs correlated with the amount of priming in specific conditions. These fMRI results extend hybrid theories of object recognition, implicating left ventral stream regions in analytic processing (requiring attention), consistent with prior hypotheses about hemispheric specialisation, and implicating dorsal stream regions in holistic processing (independent of attention).</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Research highlights</title>
        <p>► FMRI repetition effects for visual objects were studied by varying view and attention. ► Attended objects in intact and split views showed fMRI suppression in ventral areas. ► View-specific fMRI enhancement was found in dorsal areas regardless of attention. ► Left ventral effects correlated with attended, dorsal effects with unattended priming. ► Left ventral areas are implicated in analytic, dorsal areas in holistic processing.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Attention</kwd>
        <kwd>fMRI</kwd>
        <kwd>Object recognition</kwd>
        <kwd>Repetition suppression</kwd>
        <kwd>Repetition enhancement</kwd>
        <kwd>View-dependence</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="s0005">
      <title>Introduction</title>
      <p>How do we recognise familiar objects when they are shown from an unfamiliar viewpoint, or with some of their parts obscured? In order to infer the nature of representations that mediate such object constancy, many behavioural studies have measured ‘priming’: the improved recognition performance associated with repetition of an object, as a function of various changes in the manner in which that object is depicted (<xref rid="bb0010" ref-type="bibr">Bartram, 1976</xref>). A general finding is that priming is greatest if an object is repeated in the same view, and decreases when shown in a different view, such as when rotated in the picture plane (<xref rid="bb0260 bb0385" ref-type="bibr">Lawson, 1999; Thoma and Davidoff, 2007</xref>). Studies using functional magnetic resonance imaging (fMRI) also show repetition effects: Blood oxygen level-dependent (BOLD) signals in various ventral visual stream regions, such as in lateral occipital and inferior temporal cortices, tend to decrease when a visual object is repeated (<xref rid="bb0175 bb0245 bb0250 bb0240 bb0420" ref-type="bibr">Grill-Spector et al., 1999; Kourtzi and Kanwisher, 2000; Koutstaal, 2001; James et al., 2002; Vuilleumier et al., 2002</xref>). A number of fMRI experiments have shown that this “repetition suppression” (RS; <xref rid="bb0180" ref-type="bibr">Grill-Spector et al., 2006</xref>) is maximal when the initial and repeated views of an object are identical, and decreases with the amount of change in view, e.g. following rotation (<xref rid="bb0160 bb0125 bb0005" ref-type="bibr">Gauthier et al., 2002; Ewbank et al., 2005; Andresen et al., 2009</xref>). This finding has been used to support theories that objects are stored in “view-specific” representations, e.g., via several 2D views of an object (<xref rid="bb0405 bb0410 bb0325 bb0050 bb0015 bb0370 bb0375" ref-type="bibr">Ullman, 1989, 1998; Poggio and Edelman, 1990; Bulthoff and Edelman, 1992; Basri and Ullman, 1993; Tarr, 1995; Tarr and Gauthier, 1998</xref>). Object invariance is then accomplished by interpolation across these views (<xref rid="bb0405 bb0325 bb0275" ref-type="bibr">Ullman 1989; Poggio and Edelman, 1990; Logothetis, 1994</xref>), or by a distributed neural representation across view-tuned neurons (<xref rid="bb0320" ref-type="bibr">Perrett et al., 1998</xref>; for review, see <xref rid="bb0315" ref-type="bibr">Peissig and Tarr, 2007</xref>).</p>
      <p>However, the simple rotation of object images in-plane or even in-depth tends to maintain some low-level similarity between initial and repeated images (e.g., even at the level of pixel overlap; <xref rid="bb0065" ref-type="bibr">Chouinard et al., 2008</xref>). A recent study by <xref rid="bb0190" ref-type="bibr">Hayworth and Biederman (2006)</xref> controlled for this by using part-based line-drawings of objects, the contours of which did not overlap with previously shown contours of each part. According to this study, more anterior parts of the ventral visual stream (specifically the posterior fusiform gyrus) are involved in an intermediate representation of shape that is largely “part-based”, and abstracted from view-specific, retinotopically-based representations. Part-based representations are often conceptualised as structural descriptions (<xref rid="bb0365 bb0285 bb0020" ref-type="bibr">Sutherland, 1968; Marr and Nishihara, 1978; Biederman, 1987</xref>), in which an object is stored as a combination of generalised parts and their spatial relations. Structural descriptions are largely viewpoint-independent as long as crucial parts are visible (<xref rid="bb0220" ref-type="bibr">Hummel and Biederman, 1992</xref>). There is considerable evidence for structural descriptions from behavioural and animal studies (<xref rid="bb0020 bb0040 bb0030 bb0270" ref-type="bibr">Biederman, 1987; Biederman and Gerhardstein, 1993; Biederman and Bar, 1999; Lazareva et al., 2008</xref>). Importantly, structural descriptions also allow for effects of changed viewpoints on recognition of repeated objects, such as when in-plane rotations perturb the spatial relations between parts (<xref rid="bb0220" ref-type="bibr">Hummel and Biederman, 1992</xref>) or when in-depth rotations occlude or reveal parts across rotations (<xref rid="bb0040" ref-type="bibr">Biederman and Gerhardstein, 1993</xref>).</p>
      <p>A recent model of object recognition, termed the “hybrid model” (<xref rid="bb0225 bb0215" ref-type="bibr">Hummel and Stankiewicz, 1996; Hummel, 2001</xref>), proposes that objects are processed in two parallel routes: an “analytic” route, which uses view-independent structural representations in terms of an object's parts and their spatial relations, and a “holistic” route, which uses exclusively view-dependent representations with fast access to stored views. In the hybrid model, visual attention is necessary to bind parts and spatial relations within the analytic route, but is not required for processing in the holistic route (see <xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>, for details). Contrary to view-based theories, this model predicts that priming should occur from attended primes regardless of whether they are familiar or unfamiliar views of objects, but should only occur from unattended primes that are familiar views; a pattern that has been confirmed behaviourally (<xref rid="bb0360 bb0390" ref-type="bibr">Stankiewicz et al., 1998; Thoma et al., 2004</xref>).</p>
      <p>The current study therefore investigated the brain regions that support visual object constancy by using fMRI to examine how neural repetition effects relate to this hybrid model. More specifically, we employed an alternative to view transformation by vertically splitting line-drawings of objects. This manipulation has been argued to be a simple means with which to distinguish between part-based and view-based representations (<xref rid="bb0390 bb0185" ref-type="bibr">Thoma et al., 2004; Hayward et al., 2010</xref>). Intact and split images of an object (e.g. a horse; see <xref rid="f0005" ref-type="fig">Fig. 1</xref>A) are completely different holistic representations (different features are bound to different locations in the image, see <xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>), but retain an almost equivalent structural representation (the same parts are depicted in many of the same spatial relations). Thus splitting object images disrupts view-specific matching but not recognition based on parts (<xref rid="bb0390 bb0385" ref-type="bibr">Thoma et al., 2004; Thoma and Davidoff, 2007</xref>). There is accumulating evidence for hybrid representations of objects from behavioural studies in healthy individuals (<xref rid="bb0360 bb0355 bb0390 bb0380 bb0395" ref-type="bibr">Stankiewicz, et al., 1998; Stankiewicz and Hummel, 2002; Thoma et al., 2004; Thoma and Davidoff 2006; Thoma et al., 2007</xref>) and patients with object agnosia (<xref rid="bb0075" ref-type="bibr">Davidoff and Warrington, 1999</xref>). However, it is not yet clear whether these different types of object representations are supported by different brain regions. One proposal by <xref rid="bb0290" ref-type="bibr">Marsolek (1999)</xref> suggests that analytic vs holistic representations are favoured by left and right hemispheres respectively (see also <xref rid="bb0055" ref-type="bibr">Burgund and Marsolek, 2000</xref>).</p>
      <p>The second important manipulation of the present experiment was whether or not the object primes were spatially cued in order to manipulate visual attention. According to the hybrid model it is predicted that repetition effects occur for attended intact and split objects, whereas uncued objects show repetition effects only in familiar intact views. A few previous imaging studies have examined the role of attention in visual object repetition effects, but their implications for hybrid models are unclear. For example, two studies found RS in ventral stream regions across mirror-reflected images of objects: one only when those images were spatially cued (<xref rid="bb0105" ref-type="bibr">Eger et al., 2004</xref>), the other even when those images were uncued (<xref rid="bb0425" ref-type="bibr">Vuilleumier et al., 2005</xref>). However, mirror-reflection is arguably suboptimal for dissociating different types of representations, because in many cases it does not prevent overlap of low-level (2D) features (unless the object is highly asymmetrical) and because a mirror view of an object is also likely to be a familiar (learned) view. Such findings therefore do not allow strong conclusions about view constancy or holistic vs part-based representations. Furthermore, in the study that did find RS for uncued objects, cued and uncued objects occupied the same location but in different colours (e.g., <xref rid="bb0425" ref-type="bibr">Vuilleumier et al., 2005</xref>). This feature-based manipulation of attention may not be as effective as spatial cueing in minimising attentional slippage to the uncued stimulus (<xref rid="bb0120 bb0255 bb0200" ref-type="bibr">Eriksen and St James, 1986; Lachter et al., 2004; Henson and Mouchlianitis, 2007</xref>).</p>
      <p>The present study addressed these issues by examining the BOLD response to an intact object image (the “probe” stimulus) as a function of immediately-preceding presentation of either the same or a different object (the “prime” stimulus), where the prime was manipulated by factorially crossing its configuration (intact vs split) with its cued location (attended vs uncued). The study was also designed to address other methodological details that might have affected previous fMRI studies of visual object priming. First, some previous fMRI studies (<xref rid="bb0105" ref-type="bibr">Eger et al., 2004</xref>) re-used the same objects across trials. “Long-lag” repetition effects across trials (<xref rid="bb0205" ref-type="bibr">Henson et al., 2004</xref>) may have reduced sensitivity to the short-lag, within-trial repetition effects of interest (e.g., by “saturating” effects of repetition). Therefore, every object in the current study was only shown in one trial. Second, many fMRI studies of object priming (<xref rid="bb0420 bb0105" ref-type="bibr">Vuilleumier et al., 2002; Eger et al., 2004</xref>) employed semantic decision tasks, which may be suboptimal in disentangling perceptual from semantic contributions to repetition effects. For example, post-perceptual, semantic contributions to the BOLD signal may have reduced the differences in RS across their visual transformations (see, e.g., <xref rid="bb0450" ref-type="bibr">Horner and Henson, in press</xref>). In contrast, behavioural priming studies have favoured naming tasks, because the demands on naming are additive with the amount of perceptual change (<xref rid="bb0035 bb0045" ref-type="bibr">Biederman and Cooper, 1991; Bruce et al., 2000</xref>). Participants in the current study therefore performed a covert naming task; covert in order to minimise fMRI artefacts induced by speech-related movement, but accompanied by a key press to provide an RT measure of priming. Finally, selective attention was manipulated by spatial cueing of briefly-displayed objects, which is likely to minimise the influence of top–down processing (e.g., as compared to colour-based cueing of overlapping figures, <xref rid="bb0425" ref-type="bibr">Vuilleumier et al., 2005</xref>).</p>
      <p>Our main focus was on regions within the ventral and dorsal visual-processing streams (<xref rid="bb0295" ref-type="bibr">Milner and Goodale, 1995</xref>). Most previous fMRI studies of visual object recognition have focussed on the ventral stream, with the more anterior regions (e.g., fusiform gyrus) tending to show greater generalisation of RS across low-level visual transformations than more posterior (e.g., occipital) regions (<xref rid="bb0175 bb0420" ref-type="bibr">Grill-Spector et al., 1999; Vuilleumier et al., 2002</xref>). However, there are also regions within the dorsal stream that respond to visual objects, particularly in parietal cortex, and which can show response increases (repetition enhancement, RE) to primed objects (<xref rid="bb0090 bb0110" ref-type="bibr">Dolan et al., 1997; Eger et al., 2007</xref>). Regions in the dorsal stream are generally thought to mediate the visuomotor transformations required for control of actions (<xref rid="bb0165" ref-type="bibr">Goodale and Milner, 2004</xref>). Parietal lesions can lead to problems processing objects in “unusual views” (<xref rid="bb0435 bb0265 bb0430" ref-type="bibr">Warrington and Taylor, 1978; Layman and Greene, 1988; Warrington and James, 1988</xref>), or with integration of multiple items/objects into a coherent whole (<xref rid="bb0230" ref-type="bibr">Humphreys et al., 1992</xref>). In this case, parietal regions should show greater BOLD signal for split than intact objects (e.g., in our localiser session), and repetition effects in parietal regions should be sensitive to prime configuration.</p>
      <p>In summary, the aim of our study was to test the hybrid model of <xref rid="bb0215" ref-type="bibr">Hummel (2001)</xref> that allows for both analytic (part-based) and holistic (view-based) processing. According to this model, brain regions supporting analytic processing should show repetition effects from both intact and split prime objects, but only when attended, whereas brain regions supporting holistic processing should show repetition effects only from intact prime objects, whether attended or not (see <xref rid="f0005" ref-type="fig">Fig. 1</xref>A). We expected that analytic processing would involve anterior ventral stream regions (most likely fusiform, <xref rid="bb0175" ref-type="bibr">Grill-Spector et al., 1999</xref>), particularly in the left hemisphere (<xref rid="bb0290 bb0420" ref-type="bibr">Marsolek, 1999; Vuilleumier et al., 2002</xref>). Holistic processing, on the other hand, was expected to involve more posterior ventral stream regions, and also possibly parietal regions in the dorsal stream, which have been previously been implicated in priming paradigms (<xref rid="bb0090 bb0110" ref-type="bibr">Dolan et al., 1997; Eger et al., 2007</xref>). A finding that the effects of attention and of configuration on fMRI responses to object repetition occur in different brain regions would provide further, neural support for the hybrid model.</p>
    </sec>
    <sec sec-type="materials|methods" id="s0010">
      <title>Materials and methods</title>
      <sec id="s0015">
        <title>Participants</title>
        <p>Twenty-one, neurologically-healthy participants were recruited for this study. Of these, four participants were dropped because they could not covertly name (as indicated by a button press) either the prime or probe on more than one half of the trials (leaving seventeen participants). They were healthy right-handed volunteers (9 males), with a mean age of 26 years (range 19–41) and with normal or corrected vision. The study was approved by a local research ethics committee (LREC reference 05/Q0108/401). The participants were informed they could withdraw from the study at any point and they gave their written consent before participation.</p>
      </sec>
      <sec id="s0020">
        <title>Stimuli</title>
        <p>As in <xref rid="bb0390" ref-type="bibr">Thoma et al. (2004)</xref>, we used the manipulation of splitting an image to investigate the nature of visual representations. The rationale is that intact and split images of an object (e.g. a horse) are completely different holistic representations (different features are statically bound to different locations in the image, see <xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>) whilst they remain highly structurally similar to observers because they depict the same parts in roughly equivalent spatial relations. Splitting an image is unproblematic for the integrity of a structural description as long as the shapes of the object's parts (such as the halves of the horse's torso in <xref rid="f0005" ref-type="fig">Fig. 1</xref>A) are recoverable from the information presented in each half of the image (<xref rid="bb0020 bb0220" ref-type="bibr">Biederman, 1987; Hummel and Biederman, 1992</xref>). The recovery is feasible because for shape recognition the relations between connected parts (e.g., the split half depicting the front of the horse) are more important than relations between separated parts (<xref rid="bb0330" ref-type="bibr">Saiki and Hummel, 1996</xref>). Indeed, <xref rid="bb0060" ref-type="bibr">Cave and Kosslyn (1993)</xref> showed that split stimuli are substantially easier to recognise than scrambled objects that disturb the spatial relationships between parts (for a further account on the rationale for split images, see <xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>).</p>
        <p>We used 748 digitised black and white line drawings of familiar objects derived from different sources (<xref rid="bb0350 bb0070" ref-type="bibr">Snodgrass and Vanderwart, 1980; Cycowicz et al., 1997</xref>). For each object, a “split” version was created by using a 50–60% “offset” filter in Adobe Photoshop 5.5, resulting in images that appeared to be cut vertically in two halves that were relocated to the opposite side of the canvas (see <xref rid="f0005" ref-type="fig">Fig. 1</xref>A). The images were standardised in size such that they subtended 4° of visual angle along their main axis of elongation (i.e. horizontal or vertical) when viewed in the MRI scanner. A random-line pattern mask that covered the whole screen (15.6° of visual angle) was presented following prime displays and a smaller random-line pattern mask (4.6° × 3.45°) was presented at the screen centre following probe displays. An outline circle (0.25°) and a fixation cross (0.25°) were presented before each trial.</p>
        <p>A prime display consisted of a target object that appeared either 4° left or right of fixation in a cueing square, and an uncued object that appeared at the other side of fixation. The probe display consisted of a single object shown at the centre of the screen. The probe object was equally likely to be the same as the uncued prime, the same as the task-irrelevant prime, or a new image. The left or right location and the configuration of the probed and unprobed object (intact or split) were counterbalanced for each of the 3 repetition conditions (attended repeated, uncued repeated, or no object repeated). These 24 (2 hemifield × 2 configuration probed × 2 configuration unprobed × 3 repetition) variations of prime–probe trial pairs were repeated 11 times constituting 264 trial pairs in total. Each object appeared only in one prime–probe pair throughout the experiment.</p>
        <p>The assignment of objects to experimental conditions was controlled across participants by placing each image into one of 8 subsets: 6 subsets with 44 objects that appeared as both prime and probe objects; and 2 subsets containing 176 images that were used as “fillers” for prime objects that never appeared as a probe. The first 6 subsets were counterbalanced across participants so that each object appeared in a particular condition (attended-intact, attended-split, uncued-intact, uncued-split, unprimed-intact, unprimed-split) equally often as a probe. The 2 subsets of “filler objects” in the prime display were randomly assigned as attended (not probed) and uncued (not probed) in both intact and split configurations. The instructions and stimuli were shown on a screen located ~ 90 cm above the participants' head and viewed via a mirror on the head coil.</p>
        <p>A separate ‘localiser’ session was run after the main experiment to determine brain regions generally responsive to the object images used. A set of objects different from those in the priming study was presented in addition to ‘scrambled’ versions of 120 objects drawn from the “fillers” in the main experiment. The scrambling was done by first rotating an object and then using a filter in Adobe Photoshop 6.0 which divided the image into 20 quadrants and randomly moved them within the original frame. The reason for using a separate localiser session, rather than using an orthogonal localising contrast within the main experiment, reflected the concern that the inclusion of additional trials with fully-scrambled objects would disrupt the main experimental task, and this would deviate from replicating our prior behavioural studies (see <xref rid="bb0150" ref-type="bibr">Friston et al., 2006</xref>).</p>
      </sec>
      <sec id="s0025">
        <title>Procedure</title>
        <p>The main experiment consisted of two short practise sessions (one outside and one inside the scanner), three experimental sessions (two 12 minute sessions and one 8 min session), with a 1-minute break in between, plus a localiser session (6 min) at the end. Structural scans were taken between experimental and localiser sessions. The whole experiment lasted about 55 min.</p>
        <p>Participants were instructed to watch a sequence of trial-pairs consisting of prime and probe displays. They were told to attend to the object in the cued location and name it covertly and press a button with their right index finger as soon as they had named the object. Participants were instructed to ignore the object presented on the uncued side.</p>
        <p>The participants read instructions, which they then paraphrased back to the experimenter. The experimental session began with 12 practise trials using a set of images different from the experimental set. After the practise trials, the participants were asked whether they had any questions. Another practise session (with the same images as before) was run inside the scanner. The ordering of the 264 experimental trials and the pairing of attended and uncued objects on prime trials were randomised for each participant.</p>
        <p>The basic sequence of events within one trial is depicted in <xref rid="f0005" ref-type="fig">Fig. 1</xref>B. An unfilled circle in the centre of the screen remained for 495 ms. The circle was then replaced with a fixation cross, which remained on the screen for another 495 ms, followed by a blank white screen for 30 ms. An attentional cueing square subtending 4.5° of visual angle was then presented either to the left or right of the fixation cross, centred 4.0° from fixation. After 60 ms, two object images were displayed simultaneously for 135 ms, with the attended image inside the square, and the unattended image centred 4.0° from fixation on the other side of the screen. The prime images could be both intact, both split or one of each. After the images disappeared a random-line pattern mask that covered the entire screen (15.6° of visual angle) was shown for 495 ms. The entire prime display lasted less than 200 ms, a duration too short to permit a saccade to the cueing square or either object.</p>
        <p>Following the prime display, a blank screen was displayed for 1495 ms, followed by a fixation cross (495 ms). After a 30 ms blank screen, the probe image was displayed in the centre of the screen for 150 ms. The probe object was either the previously attended object (attended conditions), the uncued object (uncued conditions), or an object the participant had not seen previously in the experiment (unprimed baseline condition). The probe image was always intact. The probe display was followed by a single pattern mask (4.6°) shown for 495 ms, which in turn was followed by a blank screen lasting 2670 ms. Again, the participant's task was to name the probe object as quickly and as accurately as possible and press a button. A trial lasted about 7 s and started automatically after the previous trial had ended.</p>
        <p>For the localiser session, stimuli were presented in blocks of 3 types: 5 blocks of intact objects, 5 blocks of split objects and 10 blocks of scrambled objects, presented in alternated sequence (intact, scrambled, split, scrambled, etc.). Each block contained 13 trials, presented with a SOA and ISI of 1500 ms and 1000 ms, on which participants made a 1-back judgment (i.e. press the button whether the previous image was the same as the current one, which happened in 1 out of 13 trials on average across the session). There was a 500 ms pause between blocks.</p>
      </sec>
      <sec id="s0030">
        <title>fMRI acquisition</title>
        <p>Thirty-two T2*-weighted transverse slices (64 × 64 3mm × 3mm pixels, TE = 30 ms, flip-angle = 78°) per volume were taken using Echo-Planar Imaging (EPI) on a 3T TIM Trio system (Siemens, Erlangen, Germany), with a repetition time (TR) of 2000 ms per volume. Slices were 3-mm thick with a 0.75 mm gap, tilted approximately 30° at the front to minimise eye-ghosting, and acquired in descending order. The main experiment was split into three sessions, producing 935 functional volumes in total; the localiser session contained 203 scans (excluding the first 10 volumes per session in both cases, to allow for spin equilibration). A T1-weighted structural volume was also acquired for each participant with 1mm × 1mm × 1mm voxels using MPRAGE and GRAPPA parallel imaging (flip-angle = 9o; TE = 2.00 s; acceleration factor = 2).</p>
        <p>Data were analysed using Statistical Parametric Mapping (SPM5, <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm5.html">http://www.fil.ion.ucl.ac.uk/spm5.html</ext-link>). Preprocessing of image volumes included spatial realignment to correct for movement, followed by spatial normalisation to Talairach space, using the linear and nonlinear normalisation parameters estimated from warping each participant's structural image to a T1-weighted average template image from the Montreal Neurological Institute (MNI). These re-sampled images (voxel size 3 × 3 × 3 mm) were smoothed spatially by a 10 mm FWHM Gaussian kernel (final smoothness approximately 14 × 14 × 14 mm). Note that this smoothing may attenuate signals at a finer spatial scale (e.g., regions with different retinotopy), but will also increase sensitivity to signals at a comparable spatial scale, and is common in group analyses to allow for residual individual differences in anatomy after spatial normalisation, and to fulfil the assumptions behind random field theory, particularly with low degrees of freedom (<xref rid="bb0310" ref-type="bibr">Nichols and Hayasaka, 2003</xref>).</p>
        <p>Statistical analysis was performed in a two-level approximation to a Mixed Effects model. In the first level, neural activity to each prime and probe event within a trial was modelled by a delta function at stimulus onset. The BOLD response was modelled by a convolution of these delta functions by a canonical Haemodynamic Response Function (HRF). The resulting time-courses were down-sampled at the midpoint of each scan to form regressors in a General Linear Model (GLM).</p>
        <p>For each main experimental session in the GLM, 11 separate regressors were modelled: 7 locked to probe onset and 4 locked to prime onset. The probe-locked events consisted of 6 trial-types of interest, plus a 7th trial-type to model error trials of no interest (errors were trials in which participants did not press a key for either the prime or probe; see <xref rid="s0045" ref-type="sec">Behavioural results</xref>). The 6 trial-types of interest were attended-intact, attended-split, uncued-intact, uncued-split, unprimed-intact and unprimed-split. The 4 prime-locked events were differentiated according to whether the attended prime was intact or split, and on the left or right of fixation. Note that these regressors were not of interest, but included in the GLM so as to remove effects on the BOLD response locked to the probe (which followed shortly after) that were caused by the nature of the prime. Because these prime events were not split according to the primed vs unprimed nature of the probe, their inclusion did not affect differences between primed and unprimed probe-locked responses. To account for (linear) residual artefacts after realignment, each session also included six further regressors representing the movement parameters estimated during realignment. Voxel-wise parameter estimates for these regressors were obtained by Restricted Maximum-Likelihood (ReML) estimation, using a temporal high-pass filter (cut-off 128 s) to remove low-frequency drifts, and modelling temporal autocorrelation across scans with an AR(1) process.</p>
        <p>The localiser data were fit using the same type of linear-convolution GLM, which contained two regressor modelling epochs of 20 s duration: one for intact object blocks and one for split object blocks (scrambled object blocks thus comprising the implicit baseline).</p>
        <p>Four “repetition” contrasts were evaluated on the parameter estimates estimated in the main experiment GLM, in which the unprimed-intact and unprimed-split conditions were subtracted from the corresponding attended and uncued primed conditions (averaging across sessions).</p>
        <p>We performed two types of analysis on these repetition contrasts: 1) a voxel-wise analysis on normalised images, and 2) a functionally-defined region-of-interest (fROI) analysis on a handful of regions defined from the independent localiser data. The first analysis offers an exhaustive search for effects across the brain (in case effects are found beyond a priori regions of interest); the second analysis allows for factorial analyses across brain regions (e.g., by adding factors of left/right, anterior/posterior), where those regions are defined independently of the condition effects of interest (see <xref rid="s0040" ref-type="sec">Results</xref>).</p>
      </sec>
      <sec id="s0035">
        <title>Voxel-wise analyses</title>
        <p>Images of the four repetition contrasts comprised the data for a second-level model, which treated participants as a random effect, corresponding to a 2 × 2 (Attention × Configuration) repeated-measures ANOVA on repetition effects (analogous to the ANOVA performed on the behavioural data). Within the second-level model, Statistical Parametric Maps (SPMs) were created of the T or F-statistic for the various ANOVA effects of interest, using a single pooled error estimate for all contrasts, whose nonsphericity was estimated using ReML as described in <xref rid="bb0145" ref-type="bibr">Friston et al. (2002)</xref>. For the localiser fMRI data, separate second-level models (conforming to one-sample T-tests) were performed for first-level contrasts of 1) the average of intact and split objects vs Scrambled objects and 2) intact vs split objects. Unless otherwise stated, the SPMs for repetition effects were height-thresholded at the voxel-level at p &lt; .05, corrected for multiple comparisons using Random Field Theory for mask images containing voxels that showed greater activity for intact than Scrambled images, or for split than intact images, in the corresponding second-level models of the localiser data. Stereotactic coordinates of the maxima within the thresholded SPMs correspond to the MNI template.</p>
      </sec>
      <sec id="s0040">
        <title>Group-fROI analyses</title>
        <p>In this analysis, the contrast values for the same repetition contrasts described in the first-level analyses above were extracted from spherical volumes of 8 mm radius that were centred on selected maxima defined independently by the localiser contrasts of intact, split and scrambled objects (as has been common in neuroimaging studies of visual object recognition; e.g., <xref rid="bb0335" ref-type="bibr">Saxe et al., 2006</xref>). These fROI repetition effects were subjected to the same repeated-measures ANOVA as the behavioural data, but with additional factors of Laterality (left vs right) and, for the ventral stream, Rostrality (anterior vs posterior), in order to address hypotheses raised in the <xref rid="s0005" ref-type="sec">Introduction</xref>.</p>
      </sec>
    </sec>
    <sec id="s0045">
      <title>Results</title>
      <sec id="s0050">
        <title>Behavioural results</title>
        <sec id="s0055">
          <title>Prime responses</title>
          <p>Trials in which participants did not press a button to primes, or in which button presses to primes were faster than 300 ms, were counted as errors. One-way within-participant analyses of variance (ANOVAs) were conducted on the correct RTs and error rates for the attended prime object, with the factor of configuration (split, intact). These ANOVAs showed a main effect on the RTs, F(1, 16) = 10.3, p &lt; .01, MSE = 2485, and on the error rates, F(1, 16) = 19.2, p &lt; .001, MSE = 2.64 . Mean RTs were 847 ms for intact images (M error rate = 13%) and 899 ms (M error rate = 24%) for split images. Thus, configuration was effectively manipulated in the processing of the prime display, with poorer performance for split objects, as previously observed by <xref rid="bb0390" ref-type="bibr">Thoma et al. (2004)</xref>. This indicates that participants complied with instructions and named objects subvocally.</p>
        </sec>
        <sec id="s0060">
          <title>Probe responses</title>
          <p>Trials with latencies longer than 3000 ms or shorter than 300 ms were counted as an error (M = 8%). In all conditions, priming was calculated as the participant's mean RT at probe in the unprimed (baseline) condition minus their mean RT in the corresponding experimental condition. Trials on which either the prime or probe responses were errors (M = 20%) were excluded from the statistical analysis.</p>
          <p>A 2 (Attention: attended vs. uncued) × 2 (Prime Configuration: intact vs. split) within-participants analysis of variance (ANOVA) revealed a reliable main effect of Attention, F(1, 16) = 22.0, p &lt; .001, and a marginal effect of Prime Configuration, F(1, 16) = 3.79, p = .07. The interaction between Attention and Prime Configuration did not approach significance, F(1, 16) &lt; 1 (see <xref rid="t0005" ref-type="table">Table 1</xref>). There were no indications of a speed-accuracy trade-off in any condition.</p>
          <p>Analysis of each priming condition was performed to determine which type of prime display caused savings in response time for the probe display (i.e., faster naming responses relative to unprimed probes) using one-tailed t-tests. Priming was reliably greater than zero in the attended-intact, t (16) = 5.51, p &lt; .001; attended-split, t (16) = 4.19, p &lt; .001; and uncued-intact, t (16) = 2.20, p &lt; .05, conditions, but not in the uncued-split condition, t (16) &lt; 1 (see <xref rid="f0010" ref-type="fig">Fig. 2</xref>). This replicates earlier behavioural results obtained with overt naming tasks (<xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>), and shows that split images prime an intact probe image only when attended, but not when uncued, whilst intact images prime themselves when attended as well as uncued. Indeed, it is noteworthy that the RTs for a button press associated with covert naming in the scanner are sensitive enough to replicate the pattern of behavioural priming effects.</p>
        </sec>
        <sec id="s0065">
          <title>Localiser responses</title>
          <p>The only dependent variable of interest here was accuracy, which was 93%, indicating that participants adhered to instructions and performed well.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s0070">
      <title>Imaging results</title>
      <sec id="s0075">
        <title>Voxel-wise analysis — Localiser results</title>
        <p>Our interest was in BOLD repetition effects in brain regions showing significant responses to objects. To define these brain areas sensitive to line-drawings of familiar objects, we used a localiser block for each participant in which objects were shown in an intact configuration, split into two halves, or fully scrambled (see <xref rid="s0010" ref-type="sec">Materials and methods</xref>).</p>
        <p>Contrasting the BOLD response to objects (averaging across intact and split) vs scrambled objects, we obtained greater responses to objects in expected bilateral ventral visual stream regions, from lateral occipital to anterior ventral temporal cortex (see <xref rid="f0015" ref-type="fig">Fig. 3</xref>A and Supplementary Table 1).</p>
        <p>We also contrasted BOLD responses for intact vs split objects. No voxels showed greater responses to intact objects at the corrected threshold, but two reliable bilateral clusters of voxels were found to show greater responses for split images, which extended along the dorsal visual stream, from dorsal occipital lobes to bilateral superior parietal gyri and the intraparietal sulcus (see <xref rid="f0015" ref-type="fig">Fig. 3</xref>B and Supplementary Table 2). These response increases may correspond to visuospatial, mental imagery processes by which participants “fused” the two halves of split objects.</p>
        <p>In summary, the two orthogonal localiser contrasts of objects vs scrambled objects, and of split objects vs intact objects, elegantly revealed ventral and dorsal visual processing streams respectively (cf. left and right panels of <xref rid="f0015" ref-type="fig">Fig. 3</xref>).</p>
      </sec>
      <sec id="s0080">
        <title>Voxel-wise analysis — Repetition effects</title>
        <p>Our primary interest was in BOLD repetition-suppression (RS) and repetition enhancement (RE) effects in brain regions that respond to visual objects (split or intact). Thus we report effects of repetition that survived p &lt; .05, two-tailed, corrected for the whole brain, or for search volumes defined by either the above two localiser contrasts. (For additional voxels that survived a similar threshold but outside the localiser masks, see Supplementary Table 3.)</p>
        <p>As with the behavioural ANOVA, we tested three effects of Attention and Configuration on repetition effects: the main effect of Attention, main effect of Configuration and their interaction. These are reported in <xref rid="t0010" ref-type="table">Table 2</xref>. According to hybrid theories of object recognition, analytic representations should be revealed by the main effect of attention (more specifically, RS is expected for attended-intact and attended-split conditions, but not for uncued-intact or uncued-split conditions), whereas holistic representations should be revealed by the main effect of configuration (more specifically, RS is expected for attended-intact and uncued-intact conditions, but not attended-split or uncued-split conditions). The interaction is not necessarily predicted by hybrid models, but could be explained if the effects of holistic and analytical representations are super-additive (or by other theories, e.g., that RS only occurs for repetition of identical or visually-similar images that are attended) and is therefore also of interest.</p>
        <sec id="s0085">
          <title>The main effect of attention on repetition effects</title>
          <p>An F-contrast for the main effect of attended vs uncued conditions on RS (averaged across intact and split primes) revealed only one maximum in left anterior fusiform (<xref rid="f0020" ref-type="fig">Fig. 4</xref>A) that survived correction for the search region defined by object-responsive voxels in the localiser contrast of objects vs scrambled objects (no maxima survived correction for the localiser contrast of split vs intact objects). This fusiform maximum showed RS from both attended conditions (<xref rid="f0020" ref-type="fig">Fig. 4</xref>A), though larger RS from attended-intact than attended-split conditions (post hoc T(16) = 2.16, p &lt; .05, two-tailed).</p>
        </sec>
        <sec id="s0090">
          <title>The main effect of configuration on repetition effects</title>
          <p>An F-contrast for the main effect of intact vs split configuration on repetition effects (averaged across attended and uncued primes) did not reveal any maxima that survived p &lt; .05, two-tailed corrected for either of the localiser contrasts. However, there was a maximum in right intraparietal sulcus (<xref rid="f0020" ref-type="fig">Fig. 4</xref>B) that survived p &lt; .10 corrected for the localiser contrast of split vs intact objects. This maximum showed RE (larger responses from primed than unprimed) for intact (but not split) conditions (<xref rid="f0020" ref-type="fig">Fig. 4</xref>B). Given prior evidence that parietal cortex shows RE during similar paradigms, such that one could make a one-tailed prediction for this region, plus further evidence for RE in the fROI analyses below, we considered this voxel-wise effect worth reporting.</p>
        </sec>
        <sec id="s0095">
          <title>Interaction of attention and configuration on repetition effects</title>
          <p>Finally, an F-contrast for the interaction between attention and configuration on repetition effects revealed only one maximum in left lateral occipital cortex (<xref rid="f0020" ref-type="fig">Fig. 4</xref>C) that survived correction for the object-responsive voxels in the objects vs scrambled objects localiser contrast (no maxima survived correction for the localiser contrast of split vs intact objects). (For voxels showing reliable simple effects of repetition within each condition, see Supplementary Table 4.)</p>
          <p>Note that none of the above effects of attention and/or configuration occurred within voxels that showed a reliable difference between whether cued primes were left or right of fixation (see Supplementary Fig. 1), suggesting that they do not show strong retinotopy (at least at the level of attended visual field).</p>
        </sec>
        <sec id="s0100">
          <title>Group-fROI analysis — Ventral visual stream</title>
          <p>Given the hypotheses outlined in the <xref rid="s0005" ref-type="sec">Introduction</xref> about functional specialisation along the posterior–anterior and left–right axes of the ventral stream, we investigated BOLD repetition effects across four fROIs in the ventral stream. To define these fROIs independently of the above voxel-wise repetition effects, the data for the main experiment were extracted from volumes centred on the maximum of the contrast of objects vs scrambled objects in the independent localiser data in Supplementary Table 1 – specifically the left and right inferior temporal gyrus maxima ([− 51 − 75 − 6] and [+ 48 − 72 − 5]) – henceforth, “posterior” ventral stream fROIs – and left and right mid fusiform gyrus maxima ([− 42 − 48 − 18] and [45 − 51 − 18]) – henceforth, “anterior” ventral stream fROIs. Analogous results when the coordinates of these fROIs were defined individually from the SPM for each participant's localiser data, rather than the present group-based SPM, are shown in the Supplementary Materials.</p>
          <p>A 2 × 2 × 2 × 2 ANOVA on BOLD repetition effects, formed by adding the factors of “Laterality” and “Rostrality”, revealed a highly reliable interaction between Attention and Laterality, F(1, 16) = 22.4, p &lt; .001 (in addition to a main effect of Laterality, F(1, 16) = 11.2, p &lt; .005, and the expected main effect of Attention, F(1, 16) = 5.00, p &lt; .05). A plot of the mean repetition effects corresponding to this interaction (i.e., averaging across the factors of Configuration and Rostrality) showed reliable RS in attended conditions in the left hemisphere, but not in the right (<xref rid="f0025" ref-type="fig">Fig. 5</xref>A). This was confirmed by separate ANOVAs on left and right hemisphere fROIs, which showed a reliable main effect of Attention in the left, F(1, 16) = 10.5, p &lt; .005, but not in the right, F(1, 16) = 1.10, p = .31, hemisphere. Furthermore, the amount of priming showed a positive correlation across participants with the amount of RS for attended objects averaged across the left hemisphere fROIs (and across Rostrality and Configuration), Pearson's R = 0.64, p &lt; .01 (<xref rid="f0025" ref-type="fig">Fig. 5</xref>A, right panel). There was no such correlation for right hemisphere fROIs, or for uncued conditions in either left or right fROIs, Rs &lt; .29, ps &gt; .27.</p>
          <p>No other interactions reached significance in the 2 × 2 × 2 × 2 ANOVA, except the three-way interaction between Rostrality, Laterality and Configuration, F(1, 16) = 10.1, p &lt; .01. However, in separate ANOVAs on left and right fROIs (averaged across Attention), no effects of Rostrality or Configuration reached significance in either hemisphere, Fs &lt; 3.15, p &gt; .09, so this three-way interaction was not explored further.</p>
        </sec>
        <sec id="s0105">
          <title>Group-fROI analysis — Dorsal visual stream</title>
          <p>Given the hypotheses outlined in the <xref rid="s0005" ref-type="sec">Introduction</xref> about the role of the dorsal visual stream in visual object recognition, and the effect of configuration on repetition effects in the right intraparietal sulcus (IPS) in the above voxel-wise analysis, we further investigated BOLD repetition effects in fROIs defined by the contrast of split vs intact objects in the independent localiser data — specifically the left and right IPS maxima in Supplementary Table 2. Analogous results for individually-defined fROI coordinates are shown in the Supplementary Materials. A 2 × 2 × 2 ANOVA with factors Laterality, Attention and Configuration revealed only a main effect of Configuration, F(1, 16) = 4.48, p &lt; .05, and a main effect of Laterality, F(1, 16) = 9.13, p &lt; .01. A plot of the mean repetition effects (averaging across Attention) showed reliable repetition enhancement in the intact conditions (<xref rid="f0025" ref-type="fig">Fig. 5</xref>B), at least in the right intraparietal sulcus (consistent with <xref rid="f0020" ref-type="fig">Fig. 4</xref>B). There was no reliable correlation between the amount of priming and the size of the BOLD repetition effect from intact, R = .17, p = .50, or split, R = .15, p = .58, objects when averaging across Attention (and Laterality). The absence of such a relationship would nonetheless be expected if priming in the attended conditions was determined primarily by RS in the ventral stream, as suggested by <xref rid="f0025" ref-type="fig">Fig. 5</xref>A.<xref rid="fn0005" ref-type="fn">1</xref> Thus when analysing uncued conditions only, there was now a reliable positive correlation between priming and the amount of RE from intact objects, R = .52, p &lt; .05 (<xref rid="f0025" ref-type="fig">Fig. 5</xref>B, right panel), as expected, but not from split objects, R = −.23, p = .37 (where there was no net priming).</p>
        </sec>
      </sec>
    </sec>
    <sec id="s0110">
      <title>Discussion</title>
      <p>The present study is the first to provide neural evidence for the hybrid model of visual object recognition (<xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>). As predicted by this model, attended objects showed fMRI repetition effects for both intact and split views when attended, but repetition effects were strictly view-based for unattended objects. Behavioural priming effects in the form of faster covert naming were also observed from attended primes in both intact and split configurations, but only from uncued primes in an intact configuration, replicating previous findings (e.g., <xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>). This pattern was evident in two main effects (more priming from attended than uncued primes, and more priming from intact than split primes), with no interaction, which is consistent with the operation of two parallel routes: an analytic route in which part-based representations can generalise across split images, but which requires attention, and a holistic route in which view-based representations can be accessed without attention (<xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>). Our fMRI data suggest that these two routes map broadly onto ventral and dorsal visual streams respectively.</p>
      <p>Importantly, the fMRI and behavioural repetition effects were inter-related: Firstly, the amount of repetition suppression (RS) in the left ventral stream (averaged across “posterior” and “anterior” functionally-defined regions of interest, fROIs) correlated positively with the amount of behavioural priming, but only for attended primes, as would be expected from contributions from an analytical pathway.<xref rid="fn0010" ref-type="fn">2</xref> Secondly, the amount of repetition enhancement (RE) in the dorsal stream (averaged across left and right fROIs) correlated positively with the amount of behavioural priming, but only from uncued, intact primes, as would be expected from contributions from a holistic pathway. Below, we review these aspects of the present fMRI findings in relation to previous studies, before discussing the implications of the present findings for theories of visual object recognition.</p>
      <sec id="s0115">
        <title>Comparison with previous fMRI studies of object repetition effects in ventral stream</title>
        <p>One reason for the current investigation was that the manipulation of viewpoint in most previous fMRI studies does not always allow strong conclusions about the types of representations involved in object recognition, because most object recognition theories include some form of view-specific representation (<xref rid="bb0025" ref-type="bibr">Biederman, 2000</xref>), or predict some viewpoint-dependent effects even for part-based representations, (<xref rid="bb0220 bb0380" ref-type="bibr">Hummel and Biederman, 1992; Thoma and Davidoff, 2006</xref>). Thus so-called “view-dependent” effects based on manipulations of object orientation may not reliably indicate whether the neural populations involved in RS are truly view-based rather than part-based. In contrast, the RS observed here using split images cannot be explained by view-interpolation, because a split image is by definition not a familiar view.</p>
        <p>A number of previous fMRI studies have suggested a greater degree of abstraction from posterior to anterior regions along the ventral visual stream, for example between posterior and anterior parts of the ventral visual stream (e.g., <xref rid="bb0175 bb0240" ref-type="bibr">Grill-Spector et al., 1999; James et al., 2002</xref>). Our fROI analysis, based on regions defined by our localiser contrast of objects vs scrambled objects, did not reveal any difference between posterior (inferior temporal) and anterior (mid-fusiform) fROIs in the effects of intact vs split configurations on the size of RS (it only revealed a main effect of attention on RS, averaging across these two regions). Nonetheless, it is interesting to note that the maxima identified in our voxel-wise analysis showed reliable RS from both intact and split attended primes in an anterior fusiform region (<xref rid="f0020" ref-type="fig">Fig. 4</xref>A), but RS only from intact, attended primes in a lateral occipital region (<xref rid="f0020" ref-type="fig">Fig. 4</xref>C), which is consistent with prior evidence for some degree of view-independence in fusiform cortex (e.g., <xref rid="bb0250 bb0420 bb0345 bb0105" ref-type="bibr">Koutstaal et al., 2001; Vuilleumier et al., 2002; Simons et al., 2003; Eger et al., 2004</xref>). Further experiments are needed to provide more definitive data on this question of abstraction along the posterior–anterior axis of the ventral stream.</p>
        <p>Furthermore, both anterior fusiform and lateral occipital maxima identified by the voxel-wise analysis showed greater RS from intact than split images, when attended (which appeared to drive the interaction between configuration and attention on RS for the lateral occipital region, and which was reliable in an unbiased, post hoc <italic>t</italic>-test for the anterior fusiform region). This is consistent with the general pattern in previous studies, that RS is greatest when both prime and probe stimuli are shown in the same rather than a changed view (<xref rid="bb0175 bb0160 bb0125 bb0135 bb0005" ref-type="bibr">Grill-Spector et al., 1999; Gauthier et al., 2002; Ewbank et al., 2005; Fang et al., 2006; Andresen et al., 2009</xref>). Thus, when these voxel-wise results are considered in conjunction with the fROI results, it seems likely that the left ventral stream actually contains a combination of view-specific as well as part-based representations of object shape. This interpretation is to some degree at odds with claims from a recent study by <xref rid="bb0190" ref-type="bibr">Hayworth and Biederman (2006)</xref> in which RS in lateral occipital cortex was attributed almost exclusively to the repetition of part-critical vertices, and only to a lesser degree to the repetition of local contours (see <xref rid="bb0035" ref-type="bibr">Biederman and Cooper, 1991</xref>). However, stimulus pairs in these experiments were apparently repeated a number of times, making it difficult to assess the part-based contribution from one-shot recognition. Furthermore, RS was measured using a long-lag priming paradigm with several minutes between prime and probe stimulus, which is known to produce view-invariant effects that disappear or are attenuated when a short-lag paradigm is used (<xref rid="bb0115 bb0005" ref-type="bibr">Epstein et al., 2008; Andresen et al., 2009</xref>). Overall, our results suggest that the neural correlates of object repetition in the ventral stream are more dependent on the holistic shape of an object than implied by Hayworth and Biederman's findings.<xref rid="fn0015" ref-type="fn">3</xref></p>
        <p>We did not find any repetition effects in the ventral stream for uncued objects. This is contrary to some previous studies (e.g., <xref rid="bb0300 bb0425" ref-type="bibr">Murray and Wojciulik, 2003; Vuilleumier et al., 2005</xref>), but consistent with others (e.g., <xref rid="bb0105 bb0200" ref-type="bibr">Eger et al., 2004; Henson and Mouchlianitis, 2007</xref>). One reason for this difference may be that we used a spatial manipulation of attention, rather than a feature- or object-based manipulation of attention to spatially-coincident stimuli (<xref rid="bb0300 bb0425" ref-type="bibr">Murray and Wojciulik, 2003; Vuilleumier et al., 2005</xref>) which may not have fully prevented participants from attending uncued stimuli (<xref rid="bb0120 bb0255" ref-type="bibr">Eriksen and St James, 1986; Lachter et al., 2004</xref>). In this case, it would appear that repetition effects in the ventral stream depend strongly on attention (see <xref rid="bb0200" ref-type="bibr">Henson and Mouchlianitis, 2007</xref>, for further discussion). Nonetheless, the present study did find reliable repetition effects in the dorsal stream from uncued intact primes, which is discussed next.</p>
      </sec>
      <sec id="s0120">
        <title>Object-related activity in the dorsal stream</title>
        <p>The voxel-wise analyses showed bilateral regions within the dorsal stream that were more active for split than intact objects in the localiser session (<xref rid="f0015" ref-type="fig">Fig. 3</xref>B), within which a maximum in the right intraparietal sulcus (IPS) showed RE from intact primes in the main experiment, regardless of attention (<xref rid="f0020" ref-type="fig">Fig. 4</xref>B). The fROI analysis confirmed reliable RE in the right IPS from intact primes, which correlated with the amount of behavioural priming in the intact, uncued condition. These findings are generally consistent for a role of the dorsal stream in visual object processing (see <xref rid="s0005" ref-type="sec">Introduction</xref>), though the nature of this processing deserves further consideration.</p>
        <p>One explanation for the increased BOLD response to split than intact images in the localiser is that IPS supports visual transformations that are needed to identify split stimuli (see <xref rid="s0005" ref-type="sec">Introduction</xref>). In this case, one might expect RS in this region when a split probe is primed by a split (or intact) prime, owing to prior facilitation of these transformations. Note, however, that the split condition in the present paradigm refers to the prime, and that the probe was always an intact image. Thus whilst this explanation might account for the IPS BOLD increases in the localiser session, it is not clear that it accounts for the RE from intact but not split primes in the main experiment.</p>
        <p>An alternative explanation of the RE in IPS is that it reflected a “match” with the contents of visual short term memory (VSTM) (<xref rid="bb0400" ref-type="bibr">Todd and Marois, 2004</xref>; <xref rid="bb0460" ref-type="bibr">Xu and Chun, 2006</xref>). Assuming these contents were image-based representations, then a match would only occur for intact stimuli.<xref rid="fn0020" ref-type="fn">4</xref> Nonetheless, there are reasons why the present parietal RE effects are likely to reflect more than simple matching in VSTM. Firstly, the amount of RE in IPS correlated with the amount of behavioural priming in the uncued-intact condition. If this RE in IPS is causally related to behavioural priming, then a pure VSTM matching explanation cannot explain other behavioural priming effects, such as the finding that intact uncued objects do not prime themselves when they are shown upside down in both prime and probe displays (<xref rid="bb0395" ref-type="bibr">Thoma et al., 2007</xref>). Secondly, a previous fMRI study showed that the dorsal stream distinguished between object classes, without any obvious differences in VSTM, suggesting a capacity for object recognition in parietal cortex (<xref rid="bb0130" ref-type="bibr">Fang and He, 2005</xref>).</p>
        <p>RE in parietal cortex has been found in at least two other fMRI studies of visual object priming (<xref rid="bb0090 bb0110" ref-type="bibr">Dolan et al., 1997; Eger et al., 2007</xref>). Although both studies differed methodologically from the present paradigm, their results overall reinforce an important role of parietal cortex in visual object priming. The findings most directly related to the present view-specific repetition effects in IPS come from a study by <xref rid="bb0240" ref-type="bibr">James et al. (2002)</xref>. These authors found fMRI response reductions in both lateral occipital cortex and caudal IPS during blocks in which objects were repeated multiple times, but these reductions only generalised over depth rotations in lateral occipital cortex. Thus, IPS responded to repeated (intact) objects only when shown in the same view, as in our study, though this response was RS rather than the RE, unlike in our study. This discrepancy between RS and RE may relate to the differences between two paradigms: The James et al. paradigm involved only passive viewing, and objects were repeated many times within a block (more typical of an “fMR adaptation” paradigm; e.g., <xref rid="bb0175" ref-type="bibr">Grill-Spector et al., 1999</xref>), such that their RS reflected a reduction in the mean response throughout a block. This reduced average response may be caused by reduced attentional demands across the block, as participants begin to expect the same visual image on every trial. Nonetheless, despite the different direction of repetition effects, James et al's conclusion that the dorsal stream codes for object identity in a strict view-based fashion is consistent with our proposal here that the IPS maintains holistic object representations. Indeed, a metrically-veridical representation (rather than an abstract part-based one) would make sense for guiding actions via the dorsal stream (see <xref rid="s0005" ref-type="sec">Introduction</xref>; <xref rid="bb0295" ref-type="bibr">Milner and Goodale, 1995</xref>). Thus, although the exact nature of RS vs RE in parietal cortex is difficult to establish, it is clear that they are view-specific and correlate with behavioural priming, suggesting a role in visual object recognition.</p>
      </sec>
      <sec id="s0125">
        <title>Laterality effects within ventral and dorsal streams</title>
        <p>The fROI analysis revealed a clear effect of laterality on RS within the ventral visual stream, whereby only regions on the left showed RS for attended primes. This is consistent with the hypothesis of dissociable neural subsystems (DNS) within left and right hemispheres (<xref rid="bb0290" ref-type="bibr">Marsolek, 1999</xref>): An abstract-category recognition system is assumed to be dominant in the left hemisphere, with the ability to represent features of objects independently, such as non-accidental properties (<xref rid="bb0280 bb0020" ref-type="bibr">Lowe, 1985; Biederman, 1987</xref>). This subsystem permits the visual system to generalise across different members of a category, given that they usually share a common subset of features. In contrast, the specific-exemplar subsystem (dominant in the right hemisphere) processes object shape as a whole; i.e., features are not represented independently of each other. It is thus sensitive to object shape, and maps different shape exemplars to different output representations. The present data therefore support this general proposal (see also <xref rid="bb0080" ref-type="bibr">Dien, 2009</xref>, for a review on hemispheric differences in object recognition).</p>
        <p>A different – though not incompatible – explanation of our laterality effects is that our task involved object naming, which is usually associated with left hemispheric activation. Indeed, the present RS effects, particularly from split objects, could result from simple (covert) name repetition. This would seem unlikely though, given that <xref rid="bb0065" ref-type="bibr">Chouinard et al. (2008)</xref> found that repeating a different exemplar of the same name produced no detectable RS in ventral stream regions (see also <xref rid="bb0450" ref-type="bibr">Horner and Henson, in press</xref>). Nonetheless, the pattern of RS in visual responsive areas is likely to depend not merely on stimulus repetition, but also the task performed on each presentation (<xref rid="bb0195" ref-type="bibr">Henson 2003</xref>). As noted earlier, previous imaging studies have tended to use semantic decision tasks, or at least highly nameable objects, such that their greater RS in the left than right hemisphere (<xref rid="bb0250 bb0420 bb0345 bb0105 bb0445 bb0155" ref-type="bibr">Koutstaal et al., 2001; Vuilleumier et al., 2002; Simons et al., 2003; Eger et al., 2004; Zago et al., 2005; Ganel et al., 2006</xref>) could also reflect covert naming. Evidence for the role of task demands comes from a review of laterality studies (<xref rid="bb0170" ref-type="bibr">Grabowska and Nowicka, 1996</xref>): For tasks that involve active recognition - in particular of high spatial frequency stimuli like our line drawings - the LH shows an advantage, whereas less demanding perceptual tasks typically show no lateralisation or a RH advantage. Furthermore, whilst other studies have found repetition effects in the right hemisphere (albeit still smaller than in LH) our results may reflect a smaller effect size than is typical, due to the shorter presentation time of prime and probe objects (&lt;=150 ms) than in previous studies (see <xref rid="bb0445" ref-type="bibr">Zago et al., 2005</xref>).</p>
        <p>There was also a laterality effect on RE in the dorsal stream, with greater RE in right than left IPS. However, this main effect of laterality did not interact with intact vs split primes, so is difficult to relate, for example, to a possible right hemisphere advantage in coding holistic representations. We therefore leave this finding for future exploration.</p>
        <p>To summarise the current fMRI effects in conjunction with behavioural priming – and their dependence on experimental parameters to allow comparisons with other studies – we propose the following: In short-lag repetition paradigms – in which objects are not repeated across trials and a naming task is used for both prime and probe objects – reliable RS effects for same and different (non-overlapping) views of spatially-cued objects are observed in left ventral stream regions, with view-specific effects still dominant, in particular in posterior ventral regions. At the same time, view-specific repetition enhancement effects in dorsal stream regions such as intraparietal cortex appear independent of spatial cueing, and mirror behavioural priming.</p>
      </sec>
      <sec id="s0130">
        <title>Implications for object recognition</title>
        <p>The observation that RS effects in the ventral stream are sensitive to the precise view (configuration) seems at first to concur with theories of object recognition that explain object constancy with transformations or interpolations across 2D views of an object (<xref rid="bb0405 bb0410 bb0325 bb0050 bb0275 bb0370 bb0375" ref-type="bibr">Ullman, 1989, 1998; Poggio and Edelman, 1990; Bulthoff and Edelman, 1992; Logothetis et al., 1994; Tarr, 1995; Tarr and Gauthier, 1998</xref>) or by a distributed neural representation across view-tuned neuronal ensembles (<xref rid="bb0320" ref-type="bibr">Perrett et al., 1998</xref>; see <xref rid="bb0315" ref-type="bibr">Peissig and Tarr, 2007</xref>, for a review). However, the concept of view-dependency is not unique to these models and structural description theories also predict certain view-specific effects (<xref rid="bb0040 bb0025" ref-type="bibr">Biederman and Gerhardstein, 1993; Biederman, 2000</xref>). More importantly, the present evidence for RS from split images cannot easily be accounted for by view-interpolation or view-transformation accounts. A split image of a horse is by definition not a view (in the sense of a holistic representation, see <xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>), in particular if it has never been seen (and encoded) in such a configuration. This has also been established in behavioural work: <xref rid="bb0390" ref-type="bibr">Thoma et al. (2004)</xref> found priming for uncued objects in familiar views, but not for split images, even if both prime and probe images of the same object were split. Other recent work also casts doubt on the idea of view-transformation processes: Even the robust rotation-dependent RS effects obtained by <xref rid="bb0005" ref-type="bibr">Andresen et al. (2009)</xref> showed that visual angle alone was not a sufficient explanatory factor for lateral occipital responses, as would have been predicted by many view-based theories of object constancy.</p>
        <p>To account for these and related properties of object recognition without postulating part-based object processing, some recent view-based models (e.g., <xref rid="bb0095 bb0100 bb0415" ref-type="bibr">Edelman and Intrator, 2000, 2003; Ullman, 2007</xref>) have proposed templates for object “fragments” instead of templates for whole objects. The fragments are pictorial features that represent the image appearance of object components, unlike genuine 3D volumes postulated by structural description theories. Although the “fragment” approach seems to provide an alternative solution to account for object constancy, experimental evidence for it is inconclusive (<xref rid="bb0305" ref-type="bibr">Newell et al., 2005</xref>). Importantly, fragments derived from learned views (e.g., <xref rid="bb0095" ref-type="bibr">Edelman and Intrator, 2000,</xref> <xref rid="bb0100" ref-type="bibr">2003</xref>) arguably do not predict visual priming from split images to their intact counterparts because the proposed sets of fragments are tied to specific locations in the visual field (a mechanism called “what + where” coding; see <xref rid="bb0095 bb0100" ref-type="bibr">Edelman and Intrator, 2000, 2003</xref>). Since the two sets of fragments in the present split and intact images are completely non-overlapping, and prime and probe objects appear in different locations, the fragment model would hardly predict priming from one image to the other (see <xref rid="bb0455" ref-type="bibr">Hummel, 2003</xref>; <xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>). Furthermore, <xref rid="bb0100" ref-type="bibr">Edelman and Intrator (2003)</xref> postulate that multiple fixations are needed during initial encoding in order to establish the various location-dependent object fragments. In the current study, split images primed subsequent intact probe images even though their presentation was too short to permit saccades. Finally, feature-based models such as <xref rid="bb0415" ref-type="bibr">Ullman's (2007)</xref> postulate that repetition effects should be more similar the more two objects (or their images) share informative features. Since both split and intact images share essentially the same informative features, a feature approach alone cannot explain why there is such dominance for intact objects (see <xref rid="bb0455" ref-type="bibr">Hummel, 2003</xref>, for a discussion of fragment and feature accounts).</p>
        <p>The present evidence for RS from split objects in left ventral stream (when attended) provides limited support for part-based representations, such as structural descriptions (e.g. <xref rid="bb0220" ref-type="bibr">Hummel and Biederman, 1992</xref>). At the same time, the greater RS in fusiform/inferior temporal areas from intact than split configurations indicates a further, view-specific component. This conclusion could be challenged from a structural description perspective with the argument that splitting an object image may disrupt spatial relations between some parts, resulting in less RS for the subsequent intact version. However, there is evidence that such disruptions are unlikely or minimal (<xref rid="bb0390" ref-type="bibr">Thoma et al., 2004</xref>) and that view-change or splitting reduces priming to the same degree (<xref rid="bb0385" ref-type="bibr">Thoma and Davidoff, 2007</xref>). A further possible objection related to the splitting manipulation is that split images simply require additional processing resources, which reduce any subsequent priming. However, <xref rid="bb0390" ref-type="bibr">Thoma et al. (2004, Experiment 3)</xref> showed that a split (attended) object primed its identical split self just as much as intact images prime each other. Thus, our conclusion is that strictly part-based (structural) accounts of object recognition alone cannot explain the view-specific RS effects.</p>
        <p>Rather, we propose that the current results constitute some of the first neural support for a hybrid account of object recognition, which predicts the involvement of both holistic (automatic and view-specific) and analytic (part-based) representations in object recognition (e.g., <xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>). As would be predicted by a hybrid analytic/holistic account, RS generalised over configurational changes in (left) fusiform areas for attended objects only. The finding that behavioural priming from intact objects was greater than from split objects is also consistent with Hummel's account, in that priming for previously attended objects in the identical (intact) view receives contributions from both analytic representations and holistic (view-based) representations, whereas priming for attended objects in novel (here: split) views relies on analytic representations only. Indeed, in its computational instantiation ("JIM.3", <xref rid="bb0215" ref-type="bibr">Hummel, 2001</xref>), analytic (attention-dependent) and holistic (view-specific) priming components are additive, a prediction that has been confirmed in behavioural work (<xref rid="bb0360 bb0390 bb0395 bb0380" ref-type="bibr">Stankiewicz et al., 1998; Thoma et al., 2004, 2007; Thoma and Davidoff, 2006</xref>) and in the present behavioural data. The finding that RS in the left ventral stream regions was also greater from intact than from split primes, however, suggests that there may be additional view-dependent representations in the ventral stream (or that its activity reflects interactions with activation of holistic representations in the dorsal stream<xref rid="fn0025" ref-type="fn">5</xref>).</p>
      </sec>
    </sec>
    <sec id="s0135">
      <title>Conclusions</title>
      <p>The current findings support hybrid models of visual object recognition that include both analytic and holistic pathways, with the analytic pathway dependent on visual attention. Regions in the left ventral visual stream only showed repetition suppression (RS) from spatially-cued primes, which occurred even for split primes in more anterior fusiform regions, and the amount of this RS correlated with the amount of behavioural priming, consistent with an analytic pathway. Regions in the dorsal stream on the other hand, specifically the intraparietal sulcus, showed repetition enhancement (RE) only for intact primes, regardless of attention, and the amount of RE correlated with the amount of behavioural priming from uncued, intact primes, consistent with a holistic pathway. Nonetheless, the ventral stream regions also showed greater RS from intact than split primes, which would not be expected if these regions utilised purely structural representations, and which deserves further exploration in future neuroimaging studies of visual object recognition.</p>
    </sec>
    <sec id="s0140">
      <title>Commercial relationships</title>
      <p>None.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bb0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Andresen</surname>
              <given-names>D.R.</given-names>
            </name>
            <name>
              <surname>Vinberg</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>The representation of object viewpoint in human visual cortex</article-title>
          <source>Neuroimage</source>
          <volume>45</volume>
          <year>2009</year>
          <fpage>522</fpage>
          <lpage>536</lpage>
          <pub-id pub-id-type="pmid">19100844</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0010">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bartram</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Levels of coding in picture–picture comparison tasks</article-title>
          <source>Mem. Cognit.</source>
          <year>1976</year>
          <fpage>593</fpage>
          <lpage>602</lpage>
        </element-citation>
      </ref>
      <ref id="bb0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Basri</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ullman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The alignment of objects with smooth surfaces</article-title>
          <source>CVGIP Image Underst.</source>
          <volume>57</volume>
          <year>1993</year>
          <fpage>331</fpage>
          <lpage>345</lpage>
        </element-citation>
      </ref>
      <ref id="bb0020">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Recognition-by-components: a theory of human image understanding</article-title>
          <source>Psychol. Rev.</source>
          <volume>94</volume>
          <year>1987</year>
          <fpage>115</fpage>
          <lpage>147</lpage>
          <pub-id pub-id-type="pmid">3575582</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Recognizing depth-rotated objects: a review of recent research and theory</article-title>
          <source>Spat. Vis.</source>
          <volume>13</volume>
          <year>2000</year>
          <fpage>241</fpage>
          <lpage>253</lpage>
          <pub-id pub-id-type="pmid">11198235</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Bar</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>One-shot viewpoint invariance in matching novel objects</article-title>
          <source>Vision Res.</source>
          <volume>39</volume>
          <year>1999</year>
          <fpage>2885</fpage>
          <lpage>2899</lpage>
          <pub-id pub-id-type="pmid">10492817</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Cooper</surname>
              <given-names>E.E.</given-names>
            </name>
          </person-group>
          <article-title>Priming contour-deleted images: evidence for intermediate representations in visual object recognition</article-title>
          <source>Cogn. Psychol.</source>
          <volume>23</volume>
          <year>1991</year>
          <fpage>393</fpage>
          <lpage>419</lpage>
          <pub-id pub-id-type="pmid">1884597</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Gerhardstein</surname>
              <given-names>P.C.</given-names>
            </name>
          </person-group>
          <article-title>Recognizing depth-rotated objects: evidence and conditions for three-dimensional viewpoint invariance</article-title>
          <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
          <volume>19</volume>
          <year>1993</year>
          <fpage>1162</fpage>
          <lpage>1182</lpage>
          <pub-id pub-id-type="pmid">8294886</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Carson</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Burton</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Ellis</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual priming is not a necessary consequence of semantic classification of pictures</article-title>
          <source>Q. J. Exp. Psychol. A</source>
          <volume>53</volume>
          <year>2000</year>
          <fpage>289</fpage>
          <lpage>323</lpage>
          <pub-id pub-id-type="pmid">10881608</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bulthoff</surname>
              <given-names>H.H.</given-names>
            </name>
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Psychophysical support for a two-dimensional view interpolation theory of objectrecognition</article-title>
          <source>Proc. Natl. Acad. Sci. U. S. A.</source>
          <volume>89</volume>
          <year>1992</year>
          <fpage>60</fpage>
          <lpage>64</lpage>
          <pub-id pub-id-type="pmid">1729718</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0055">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burgund</surname>
              <given-names>E.D.</given-names>
            </name>
            <name>
              <surname>Marsolek</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Viewpoint-invariant and viewpoint-dependent object recognition in dissociable neural subsystems</article-title>
          <source>Psychon. Bull. Rev.</source>
          <volume>7</volume>
          <year>2000</year>
          <fpage>480</fpage>
          <lpage>489</lpage>
          <pub-id pub-id-type="pmid">11082854</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cave</surname>
              <given-names>C.B.</given-names>
            </name>
            <name>
              <surname>Kosslyn</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>The role of parts and spatial relations in object identification</article-title>
          <source>Perception</source>
          <volume>22</volume>
          <year>1993</year>
          <fpage>229</fpage>
          <lpage>248</lpage>
          <pub-id pub-id-type="pmid">8474847</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chouinard</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Morrissey</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Kohler</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Repetition suppression in occipital–temporal visual areas is modulated by physical rather than semantic features of objects</article-title>
          <source>Neuroimage</source>
          <volume>41</volume>
          <year>2008</year>
          <fpage>130</fpage>
          <lpage>144</lpage>
          <pub-id pub-id-type="pmid">18375148</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cycowicz</surname>
              <given-names>Y.M.</given-names>
            </name>
            <name>
              <surname>Friedman</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Rothstein</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Snodgrass</surname>
              <given-names>J.G.</given-names>
            </name>
          </person-group>
          <article-title>Picture naming by young children: norms for name agreement, familiarity, and visual complexity</article-title>
          <source>J. Exp. Child Psychol.</source>
          <volume>65</volume>
          <year>1997</year>
          <fpage>171</fpage>
          <lpage>237</lpage>
          <pub-id pub-id-type="pmid">9169209</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0075">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Davidoff</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Warrington</surname>
              <given-names>E.K.</given-names>
            </name>
          </person-group>
          <article-title>The bare bones of object recognition: implications from a case of object recognition impairment</article-title>
          <source>Neuropsychologia</source>
          <volume>37</volume>
          <year>1999</year>
          <fpage>279</fpage>
          <lpage>292</lpage>
          <pub-id pub-id-type="pmid">10199642</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dien</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>A tale of two recognition systems: implications of the fusiform face area and the visual word form area for lateralized object recognition models</article-title>
          <source>Neuropsychologia</source>
          <volume>47</volume>
          <year>2009</year>
          <fpage>1</fpage>
          <lpage>16</lpage>
          <pub-id pub-id-type="pmid">18805434</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0085">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dobbins</surname>
              <given-names>I.G.</given-names>
            </name>
            <name>
              <surname>Schnyer</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Verfaellie</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Schacter</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Cortical activity reductions during repetition priming can result from rapid response learning</article-title>
          <source>Nature</source>
          <volume>428</volume>
          <year>2004</year>
          <fpage>316</fpage>
          <lpage>319</lpage>
          <pub-id pub-id-type="pmid">14990968</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Fink</surname>
              <given-names>G.R.</given-names>
            </name>
            <name>
              <surname>Rolls</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Booth</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>How the brain learns to see objects and faces in an impoverished context</article-title>
          <source>Nature</source>
          <volume>389</volume>
          <year>1997</year>
          <fpage>596</fpage>
          <lpage>599</lpage>
          <pub-id pub-id-type="pmid">9335498</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Intrator</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>(Coarse coding of shape fragments) + (retinotopy) ≈ representation of structure</article-title>
          <source>Spat. Vis.</source>
          <volume>13</volume>
          <year>2000</year>
          <fpage>255</fpage>
          <lpage>264</lpage>
          <pub-id pub-id-type="pmid">11198236</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Intrator</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Towards structural systematicity in distributed, statically bound visual representations</article-title>
          <source>Cogn. Sci.</source>
          <volume>27</volume>
          <year>2003</year>
          <fpage>73</fpage>
          <lpage>109</lpage>
        </element-citation>
      </ref>
      <ref id="bb0105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eger</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.N.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>BOLD repetition decreases in object-responsive ventral visual areas depend on spatial attention</article-title>
          <source>J. Neurophysiol.</source>
          <volume>92</volume>
          <year>2004</year>
          <fpage>1241</fpage>
          <lpage>1247</lpage>
          <pub-id pub-id-type="pmid">15056686</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eger</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Mechanisms of top–down facilitation in perception of visual objects studied by fMRI</article-title>
          <source>Cereb. Cortex</source>
          <volume>17</volume>
          <year>2007</year>
          <fpage>2123</fpage>
          <lpage>2133</lpage>
          <pub-id pub-id-type="pmid">17101690</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0115">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Epstein</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Parker</surname>
              <given-names>W.E.</given-names>
            </name>
            <name>
              <surname>Feiler</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Two kinds of fMRI repetition suppression? Evidence for dissociable neural mechanisms</article-title>
          <source>J. Neurophysiol.</source>
          <volume>99</volume>
          <year>2008</year>
          <fpage>2877</fpage>
          <lpage>2886</lpage>
          <pub-id pub-id-type="pmid">18400954</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0120">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eriksen</surname>
              <given-names>C.W.</given-names>
            </name>
            <name>
              <surname>St James</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Visual attention within and around the field of focal attention: a zoom lens model</article-title>
          <source>Percept. Psychophys.</source>
          <volume>40</volume>
          <year>1986</year>
          <fpage>225</fpage>
          <lpage>240</lpage>
          <pub-id pub-id-type="pmid">3786090</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0125">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ewbank</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Schluppeck</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Andrews</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>fMR-adaptation reveals a distributed representation of inanimate objects and places in human visual cortex</article-title>
          <source>Neuroimage</source>
          <volume>28</volume>
          <year>2005</year>
          <fpage>268</fpage>
          <lpage>279</lpage>
          <pub-id pub-id-type="pmid">16054842</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0130">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Cortical responses to invisible objects in the human dorsal and ventral pathways</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <year>2005</year>
          <fpage>1380</fpage>
          <lpage>1385</lpage>
          <pub-id pub-id-type="pmid">16136038</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0135">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fang</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Duration-dependent fMRI adaptation and distributed viewer-centered face representation in human visual cortex</article-title>
          <source>Cereb. Cortex</source>
          <volume>17</volume>
          <year>2006</year>
          <fpage>1402</fpage>
          <lpage>1411</lpage>
          <pub-id pub-id-type="pmid">16905593</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Glaser</surname>
              <given-names>D.E.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.N.A.</given-names>
            </name>
            <name>
              <surname>Kiebel</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Phillips</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Classical and Bayesian inference in neuroimaging: applications</article-title>
          <source>Neuroimage</source>
          <volume>16</volume>
          <year>2002</year>
          <fpage>484</fpage>
          <lpage>512</lpage>
          <pub-id pub-id-type="pmid">12030833</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0150">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Rotshtein</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Geng</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Sterzer</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>A critique of functional localisers</article-title>
          <source>Neuroimage</source>
          <volume>30</volume>
          <year>2006</year>
          <fpage>1077</fpage>
          <lpage>1087</lpage>
          <pub-id pub-id-type="pmid">16635579</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0155">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ganel</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Gonzalez</surname>
              <given-names>C.L.</given-names>
            </name>
            <name>
              <surname>Valyear</surname>
              <given-names>K.F.</given-names>
            </name>
            <name>
              <surname>Culham</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Köhler</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The relationship between fMRI adaptation and repetition priming</article-title>
          <source>Neuroimage</source>
          <volume>32</volume>
          <year>2006</year>
          <fpage>1432</fpage>
          <lpage>1440</lpage>
          <pub-id pub-id-type="pmid">16854597</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0160">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gauthier</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Hayward</surname>
              <given-names>W.G.</given-names>
            </name>
            <name>
              <surname>Tarr</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Anderson</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Skudlarski</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Gore</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>BOLD activity during mental rotation and viewpoint-dependent object recognition</article-title>
          <source>Neuron</source>
          <volume>34</volume>
          <year>2002</year>
          <fpage>161</fpage>
          <lpage>171</lpage>
          <pub-id pub-id-type="pmid">11931750</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0165">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Milner</surname>
              <given-names>A.D.</given-names>
            </name>
          </person-group>
          <article-title>Plans for action</article-title>
          <source>Behav. Brain Sci.</source>
          <volume>27</volume>
          <year>2004</year>
        </element-citation>
      </ref>
      <ref id="bb0170">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grabowska</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nowicka</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Visual spatial frequency model of cerebral asymmetry: a critical surwey of behavioural and elecrophysiological studies</article-title>
          <source>Psychol. Bull.</source>
          <volume>120</volume>
          <year>1996</year>
          <fpage>434</fpage>
          <lpage>449</lpage>
          <pub-id pub-id-type="pmid">8900082</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0175">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kushnir</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Itzchak</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Differential processing of objects under various viewing conditions in the human lateral occipital complex</article-title>
          <source>Neuron</source>
          <volume>24</volume>
          <year>1999</year>
          <fpage>187</fpage>
          <lpage>203</lpage>
          <pub-id pub-id-type="pmid">10677037</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0180">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Repetition and the brain: neural models of stimulus-specific effects</article-title>
          <source>Trends Cogn. Sci. (Regul. Ed.)</source>
          <volume>10</volume>
          <year>2006</year>
          <fpage>14</fpage>
          <lpage>23</lpage>
          <pub-id pub-id-type="pmid">16321563</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hayward</surname>
              <given-names>W.G.</given-names>
            </name>
            <name>
              <surname>Zhou</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Man</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Harris</surname>
              <given-names>I.M.</given-names>
            </name>
          </person-group>
          <article-title>Repetition blindness for rotated objects</article-title>
          <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
          <volume>36</volume>
          <year>2010</year>
          <fpage>57</fpage>
          <lpage>73</lpage>
          <pub-id pub-id-type="pmid">20121295</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0190">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hayworth</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Neural evidence for intermediate representations in object recognition</article-title>
          <source>Vision Res.</source>
          <volume>46</volume>
          <year>2006</year>
          <fpage>4024</fpage>
          <lpage>4031</lpage>
          <pub-id pub-id-type="pmid">16979693</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0195">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Neuroimaging studies of priming</article-title>
          <source>Prog. Neurobiol.</source>
          <volume>70</volume>
          <year>2003</year>
          <fpage>53</fpage>
          <lpage>81</lpage>
          <pub-id pub-id-type="pmid">12927334</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0200">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Mouchlianitis</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Effect of spatial attention on stimulus-specific haemodynamic repetition effects</article-title>
          <source>Neuroimage</source>
          <volume>35</volume>
          <year>2007</year>
          <fpage>1317</fpage>
          <lpage>1329</lpage>
          <pub-id pub-id-type="pmid">17350862</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0205">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rylands</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ross</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Vuilleumeir</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Rugg</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The effect of repetition lag on electrophysiological and haemodynamic correlates of visual object priming</article-title>
          <source>Neuroimage</source>
          <volume>21</volume>
          <year>2004</year>
          <fpage>1674</fpage>
          <lpage>1689</lpage>
          <pub-id pub-id-type="pmid">15050590</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0450">
        <mixed-citation publication-type="other">Horner, A.J., Henson, R.N., in press. Repetition suppression in occipitotemporal cortex despite negligible visual similarity: evidence for post-perceptual processing? Hum Brain Mapp.</mixed-citation>
      </ref>
      <ref id="bb0210">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Horner</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Priming, response learning and repetition suppression</article-title>
          <source>Neuropsychologia</source>
          <volume>46</volume>
          <year>2008</year>
          <fpage>1979</fpage>
          <lpage>1991</lpage>
          <pub-id pub-id-type="pmid">18328508</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0215">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Complementary solutions to the binding problem in vision: implications for shape perception and object recognition</article-title>
          <source>Vis. Cogn.</source>
          <volume>8</volume>
          <year>2001</year>
          <fpage>489</fpage>
          <lpage>517</lpage>
        </element-citation>
      </ref>
      <ref id="bb0455">
        <mixed-citation publication-type="other">Hummel J.E., 2003. “Effective systematicity” in, “effective systematicity” out: a reply to Edelman and Intrator (2003). Cog. Sci. 27:327–329.</mixed-citation>
      </ref>
      <ref id="bb0220">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic binding in a neural network for shape recognition</article-title>
          <source>Psychol. Rev.</source>
          <volume>99</volume>
          <year>1992</year>
          <fpage>480</fpage>
          <lpage>517</lpage>
          <pub-id pub-id-type="pmid">1502274</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0225">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Stankiewicz</surname>
              <given-names>B.J.</given-names>
            </name>
          </person-group>
          <chapter-title>An architecture for rapid, hierarchical structural description</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Inui</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>McClelland</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <source>Attention and Performance XVI: Information Integration in Perception and Communication</source>
          <year>1996</year>
          <publisher-name>MIT Press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bb0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Humphreys</surname>
              <given-names>G.W.</given-names>
            </name>
            <name>
              <surname>Riddoch</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Quinlan</surname>
              <given-names>P.T.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Donnelly</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Parallel pattern processing and visual agnosia</article-title>
          <source>Can. J. Psychol. Rev. Can. Psychol.</source>
          <volume>46</volume>
          <year>1992</year>
          <fpage>377</fpage>
          <lpage>416</lpage>
        </element-citation>
      </ref>
      <ref id="bb0240">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>James</surname>
              <given-names>T.W.</given-names>
            </name>
            <name>
              <surname>Humphrey</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Gati</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
          </person-group>
          <article-title>Differential effects of viewpoint on object-driven activation in dorsal and ventral streams</article-title>
          <source>Neuron</source>
          <volume>35</volume>
          <year>2002</year>
          <fpage>793</fpage>
          <lpage>801</lpage>
          <pub-id pub-id-type="pmid">12194877</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0245">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kourtzi</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Kanwisher</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Cortical regions involved in perceiving object shape</article-title>
          <source>J. Neurosci.</source>
          <volume>20</volume>
          <year>2000</year>
          <fpage>3310</fpage>
          <lpage>3318</lpage>
          <pub-id pub-id-type="pmid">10777794</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0250">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Koutstaal</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Wagner</surname>
              <given-names>A.D.</given-names>
            </name>
            <name>
              <surname>Rotte</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Maril</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>Schacter</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual specificity in visual object priming: functional magnetic resonance imaging evidence for a laterality difference in fusiform cortex</article-title>
          <source>Neuropsychologia</source>
          <volume>39</volume>
          <year>2001</year>
          <fpage>184</fpage>
          <lpage>199</lpage>
          <pub-id pub-id-type="pmid">11163375</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0255">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lachter</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Forster</surname>
              <given-names>K.I.</given-names>
            </name>
            <name>
              <surname>Ruthruff</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Forty-five years after Broadbent (1958): still no identification without attention</article-title>
          <source>Psychol. Rev.</source>
          <volume>111</volume>
          <year>2004</year>
          <fpage>880</fpage>
          <lpage>913</lpage>
          <pub-id pub-id-type="pmid">15482066</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0260">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lawson</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Achieving visual object constancy across plane rotation and depth rotation</article-title>
          <source>Acta Psychol.</source>
          <volume>102</volume>
          <year>1999</year>
          <fpage>221</fpage>
          <lpage>245</lpage>
        </element-citation>
      </ref>
      <ref id="bb0265">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Layman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Greene</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>The effect of stroke on object recognition</article-title>
          <source>Brain Cogn.</source>
          <volume>7</volume>
          <year>1988</year>
          <fpage>87</fpage>
          <lpage>114</lpage>
          <pub-id pub-id-type="pmid">3345270</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0270">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lazareva</surname>
              <given-names>O.F.</given-names>
            </name>
            <name>
              <surname>Wasserman</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Pigeons and humans are more sensitive to nonaccidental than to metric changes in visual objects</article-title>
          <source>Behav. Processes</source>
          <volume>77</volume>
          <year>2008</year>
          <fpage>199</fpage>
          <lpage>209</lpage>
          <pub-id pub-id-type="pmid">18248918</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0275">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Logothetis</surname>
              <given-names>N.K.</given-names>
            </name>
            <name>
              <surname>Pauls</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bulthoff</surname>
              <given-names>H.H.</given-names>
            </name>
            <name>
              <surname>Poggio</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>View-dependent object recognition by monkeys</article-title>
          <source>Curr. Biol.</source>
          <volume>4</volume>
          <issue>5</issue>
          <year>1994</year>
          <fpage>401</fpage>
          <lpage>414</lpage>
          <pub-id pub-id-type="pmid">7922354</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0280">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Lowe</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Perceptual organization and visual recognition</chapter-title>
          <source>Distributors for North America Kluwer Academic Publishers, Boston</source>
          <year>1985</year>
          <publisher-name>Kluwer Academic Publishers</publisher-name>
          <publisher-loc>Hingham MA U.S.A</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0285">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Marr</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Nishihara</surname>
              <given-names>H.K.</given-names>
            </name>
          </person-group>
          <article-title>Representation and recognition of the spatial organization of three-dimensional shapes</article-title>
          <source>Proc. R. Soc. B Biol. Sci.</source>
          <volume>200</volume>
          <year>1978</year>
          <fpage>269</fpage>
          <lpage>294</lpage>
          <pub-id pub-id-type="pmid">24223</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0290">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Marsolek</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable neural subsystems underlie abstract and specific object recognition</article-title>
          <source>Psychol. Sci.</source>
          <volume>10</volume>
          <year>1999</year>
          <fpage>111</fpage>
          <lpage>118</lpage>
        </element-citation>
      </ref>
      <ref id="bb0295">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Milner</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
          </person-group>
          <source>The Visual Brain in Action</source>
          <year>1995</year>
          <publisher-name>Oxford University Press</publisher-name>
          <publisher-loc>Oxford, New York</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0300">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murray</surname>
              <given-names>S.O.</given-names>
            </name>
            <name>
              <surname>Wojciulik</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Attention increases neural selectivity in the human lateral occipital complex</article-title>
          <source>Nat. Neurosci.</source>
          <volume>7</volume>
          <year>2003</year>
          <fpage>70</fpage>
          <lpage>74</lpage>
          <pub-id pub-id-type="pmid">14647291</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0305">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Newell</surname>
              <given-names>F.N.</given-names>
            </name>
            <name>
              <surname>Sheppard</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Shapiro</surname>
              <given-names>K.L.</given-names>
            </name>
          </person-group>
          <article-title>The interaction of shape- and location-based priming in object categorisation: evidence for a hybrid “what + where” representation stage</article-title>
          <source>Vision Res.</source>
          <volume>45</volume>
          <year>2005</year>
          <fpage>2065</fpage>
          <lpage>2080</lpage>
          <pub-id pub-id-type="pmid">15845239</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0310">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nichols</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Hayasaka</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Controlling the familywise error rate in functional neuroimaging: a comparative review</article-title>
          <source>Stat. Methods Med. Res.</source>
          <volume>5</volume>
          <year>2003</year>
          <fpage>419</fpage>
          <lpage>446</lpage>
          <pub-id pub-id-type="pmid">14599004</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0315">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Peissig</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Tarr</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Visual object recognition: do we know more now than we did 20 years ago?</article-title>
          <source>Annu. Rev. Psychol.</source>
          <volume>58</volume>
          <year>2007</year>
          <fpage>75</fpage>
          <lpage>96</lpage>
          <pub-id pub-id-type="pmid">16903801</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0320">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Perrett</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Oram</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Ashbridge</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Evidence accumulation in cell populations responsive to faces: an account of generalisation of recognition without mental transformations</article-title>
          <source>Cognition</source>
          <volume>67</volume>
          <year>1998</year>
          <fpage>111</fpage>
          <lpage>145</lpage>
          <pub-id pub-id-type="pmid">9735538</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0325">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Poggio</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>A network that learns to recognize three-dimensional objects</article-title>
          <source>Nature</source>
          <volume>343</volume>
          <year>1990</year>
          <fpage>263</fpage>
          <lpage>266</lpage>
          <pub-id pub-id-type="pmid">2300170</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0330">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saiki</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Attribute conjunctions and the part configuration advantage in object category learning</article-title>
          <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
          <volume>22</volume>
          <year>1996</year>
          <fpage>1002</fpage>
          <lpage>1019</lpage>
          <pub-id pub-id-type="pmid">8708600</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0335">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saxe</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Brett</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kanwisher</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Divide and conquer: a defense offunctional localizers</article-title>
          <source>Neuroimage</source>
          <volume>30</volume>
          <year>2006</year>
          <fpage>1088</fpage>
          <lpage>1096</lpage>
          <pub-id pub-id-type="pmid">16635578</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0340">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sayres</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Object-selective cortex exhibits performance-independent repetition suppression</article-title>
          <source>J. Neurophysiol.</source>
          <volume>95</volume>
          <year>2006</year>
          <fpage>995</fpage>
          <lpage>1007</lpage>
          <pub-id pub-id-type="pmid">16236787</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0345">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Simons</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Koutstaal</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Prince</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Wagner</surname>
              <given-names>A.D.</given-names>
            </name>
            <name>
              <surname>Schacter</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Neural mechanisms of visual object priming: evidence for perceptual and semantic distinctions in fusiform cortex</article-title>
          <source>Neuroimage</source>
          <volume>19</volume>
          <year>2003</year>
          <fpage>613</fpage>
          <lpage>626</lpage>
          <pub-id pub-id-type="pmid">12880792</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0350">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Snodgrass</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Vanderwart</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A standardized set of 260 pictures: norms for name agreement, image agreement, familiarity, and visual complexity</article-title>
          <source>J. Exp. Psychol. Hum. Learn.</source>
          <volume>6</volume>
          <year>1980</year>
          <fpage>174</fpage>
          <lpage>215</lpage>
          <pub-id pub-id-type="pmid">7373248</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0355">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stankiewicz</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Automatic priming for translation- and scale-invariant representations of object shape</article-title>
          <source>Vis. Cogn.</source>
          <volume>9</volume>
          <year>2002</year>
          <fpage>719</fpage>
          <lpage>739</lpage>
        </element-citation>
      </ref>
      <ref id="bb0360">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stankiewicz</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Cooper</surname>
              <given-names>E.E.</given-names>
            </name>
          </person-group>
          <article-title>The role of attention in priming for left–right reflections of object images: evidence for a dual representation of object shape</article-title>
          <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
          <volume>24</volume>
          <year>1998</year>
          <fpage>732</fpage>
          <lpage>744</lpage>
          <pub-id pub-id-type="pmid">9627412</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0365">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sutherland</surname>
              <given-names>N.S.</given-names>
            </name>
          </person-group>
          <article-title>Outlines of a theory of visual pattern recognition in animals and man</article-title>
          <source>Proc. R. Soc. B Biol. Sci.</source>
          <volume>171</volume>
          <year>1968</year>
          <fpage>297</fpage>
          <lpage>317</lpage>
          <pub-id pub-id-type="pmid">4387406</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0370">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tarr</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Rotating objects to recognize them: a case study on the role of viewpoint dependency in the recognition of three-dimensional objects</article-title>
          <source>Psychon. Bull. Rev.</source>
          <volume>2</volume>
          <year>1995</year>
          <fpage>55</fpage>
          <lpage>82</lpage>
        </element-citation>
      </ref>
      <ref id="bb0375">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tarr</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Gauthier</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Do viewpoint-dependent mechanisms generalize across members of a class?</article-title>
          <source>Cognition</source>
          <volume>67</volume>
          <year>1998</year>
          <fpage>73</fpage>
          <lpage>110</lpage>
          <pub-id pub-id-type="pmid">9735537</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0380">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thoma</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Davidoff</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Priming of depth-rotated objects depends on attention and part changes</article-title>
          <source>Exp. Psychol.</source>
          <volume>53</volume>
          <year>2006</year>
          <fpage>31</fpage>
          <lpage>47</lpage>
          <pub-id pub-id-type="pmid">16610271</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0385">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Thoma</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Davidoff</surname>
              <given-names>J.B.</given-names>
            </name>
          </person-group>
          <chapter-title>Object recognition: attention and dual routes</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Osaka</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Rentschler</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Biederman</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <source>Object Recognition, Attention &amp; Action. Tokyo</source>
          <year>2007</year>
          <fpage>141</fpage>
          <lpage>157</lpage>
        </element-citation>
      </ref>
      <ref id="bb0390">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thoma</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Hummel</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Davidoff</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Evidence for holistic representations of ignored images and analytic representations of attended images</article-title>
          <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
          <volume>30</volume>
          <year>2004</year>
          <fpage>257</fpage>
          <lpage>267</lpage>
          <pub-id pub-id-type="pmid">15053687</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0395">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thoma</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Davidoff</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hummel</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Priming of plane-rotated objects depends on attention and view familiarity</article-title>
          <source>PVIS</source>
          <volume>15</volume>
          <year>2007</year>
          <fpage>179</fpage>
          <lpage>210</lpage>
        </element-citation>
      </ref>
      <ref id="bb0400">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Todd</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Marois</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Capacity limit of visual short-term memory in human posterior parietal cortex</article-title>
          <source>Nature</source>
          <volume>428</volume>
          <year>2004</year>
          <fpage>751</fpage>
          <lpage>754</lpage>
          <pub-id pub-id-type="pmid">15085133</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0405">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ullman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Aligning pictorial descriptions: an approach to object recognition</article-title>
          <source>Cognition</source>
          <volume>32</volume>
          <year>1989</year>
          <fpage>193</fpage>
          <lpage>254</lpage>
          <pub-id pub-id-type="pmid">2752709</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0410">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ullman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Three-dimensional object recognition based on the combination of views</article-title>
          <source>Cognition</source>
          <volume>67</volume>
          <year>1998</year>
          <fpage>21</fpage>
          <lpage>44</lpage>
          <pub-id pub-id-type="pmid">9735535</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0415">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ullman</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Object recognition and segmentation by a fragment-based hierarchy</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>11</volume>
          <year>2007</year>
          <fpage>58</fpage>
          <lpage>64</lpage>
          <pub-id pub-id-type="pmid">17188555</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0420">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.N.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Multiple levels of visual object constancy revealed by event-related fMRI of repetition priming</article-title>
          <source>Nat. Neurosci.</source>
          <volume>5</volume>
          <year>2002</year>
          <fpage>491</fpage>
          <lpage>499</lpage>
          <pub-id pub-id-type="pmid">11967545</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0425">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Duhoux</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Selective attention modulates neural substrates of repetition priming and “implicit” visual memory: suppressions and enhancements revealed by fMRI</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>17</volume>
          <year>2005</year>
          <fpage>1245</fpage>
          <lpage>1260</lpage>
          <pub-id pub-id-type="pmid">16197681</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0430">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Warrington</surname>
              <given-names>E.K.</given-names>
            </name>
            <name>
              <surname>James</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Visual apperceptive agnosia: a clinico-anatomical study of three cases</article-title>
          <source>Cortex</source>
          <volume>24</volume>
          <year>1988</year>
          <fpage>13</fpage>
          <lpage>32</lpage>
          <pub-id pub-id-type="pmid">3371008</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0435">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Warrington</surname>
              <given-names>E.K.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Two categorical stages of object recognition</article-title>
          <source>Perception</source>
          <volume>7</volume>
          <year>1978</year>
          <fpage>695</fpage>
          <lpage>705</lpage>
          <pub-id pub-id-type="pmid">740510</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0460">
        <mixed-citation publication-type="other">Xu, Y., Chun, M.M., 2006. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91–95.</mixed-citation>
      </ref>
      <ref id="bb0440">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Xu</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Turk-Browne</surname>
              <given-names>N.B.</given-names>
            </name>
            <name>
              <surname>Chun</surname>
              <given-names>M.M.</given-names>
            </name>
          </person-group>
          <article-title>Dissociating task performance from fMRI repetition attenuation in ventral visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>5981</fpage>
          <lpage>5985</lpage>
          <pub-id pub-id-type="pmid">17537969</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0445">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zago</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Fenske</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Aminoff</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Bar</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The rise and fall of visual priming: how visual exposure shapes cortical representations of objetcs</article-title>
          <source>Cereb. Cortex</source>
          <volume>15</volume>
          <year>2005</year>
          <fpage>1655</fpage>
          <lpage>1665</lpage>
          <pub-id pub-id-type="pmid">15716471</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="s0150" sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p>
        <supplementary-material content-type="local-data" id="ec0005">
          <caption>
            <p>Supplementary Materials.</p>
          </caption>
          <media xlink:href="mmc1.pdf" mimetype="application" mime-subtype="pdf"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was supported by a Higher Education Funding Council of England (HEFCE) grant to VT and by the Medical Research Council (MC_US_A060_0046). We thank Rhodri Cusack, Audrey Duarte, Elias Mouchlianitis, the MRC CBU radiographers and the participants for their assistance, and two anonymous reviewers for their helpful comments.</p>
    </ack>
    <fn-group>
      <fn id="fn0005">
        <label>1</label>
        <p>Indeed, there was no reliable correlation between amount of priming and BOLD repetition effects for the attended-intact condition, r = −.20, p = .43.</p>
      </fn>
      <fn id="fn0010">
        <label>2</label>
        <p>Correlations between visual object RS and behavioural priming have often not been found (<xref rid="bb0340 bb0440 bb0210 bb0005" ref-type="bibr">Sayres and Grill-Spector, 2006; Xu et al., 2007; Horner and Henson, 2008; Andresen et al., 2009</xref>; though see <xref rid="bb0155" ref-type="bibr">Ganel et al., 2006</xref>). However, these previous studies have tended to measure priming with a semantic classification task, for which a large part of the priming-related variance in RTs is likely to be explained by stimulus–response bindings, rather than by access to visual object representations (<xref rid="bb0085 bb0210" ref-type="bibr">Dobbins et al., 2004; Horner and Henson, 2008</xref>).</p>
      </fn>
      <fn id="fn0015">
        <label>3</label>
        <p>This is not to say that the representations mediating view-specific effects are based on contours. Similar to <xref rid="bb0190" ref-type="bibr">Hayworth and Biederman's (2006)</xref> results, <xref rid="bb0245" ref-type="bibr">Kourtzi and Kanwisher (2000)</xref> found adaptation in the lateral occipital cortex even when contours differed between equivalently perceived shapes of a repeated object, but not when contours were identical but perceived shape differed. These data indicate that the lateral occipital cortex represents not simple image features, but rather higher level shape information, which may explain why previous researchers observed scale independence in this region (<xref rid="bb0420" ref-type="bibr">Vuilleumier et al., 2002</xref>).</p>
      </fn>
      <fn id="fn0020">
        <label>4</label>
        <p>This match might even occur for intact primes that were not cued, as long as they were registered into VSTM in some way. Uncued primes might enter VSTM via leakage of attention to the uncued location, as might be encouraged by the present priming paradigm, given that uncued primes could potentially still help the naming of the probe on one third of trials. By using catch trials however, <xref rid="bb0380" ref-type="bibr">Thoma and Davidoff (2006)</xref> showed that none of their participants were able to remember uncued stimuli in a similar priming paradigm, rendering this attentional-slippage argument unlikely.</p>
      </fn>
      <fn id="fn0025">
        <label>5</label>
        <p>Such interactions between dorsal and ventral streams might occur too rapidly to be detectable with fMRI, but might be detected with the higher temporal resolution of EEG or MEG data.</p>
      </fn>
    </fn-group>
  </back>
  <floats-group>
    <fig id="f0005">
      <label>Fig. 1</label>
      <caption>
        <p>(A). Examples of intact and split images used in the current study and graphic representation of the experimental design. Both attended and uncued objects prime their corresponding probe when shown in an intact configuration (holistic priming, depicted by contrast-reversal), resulting in a main effect of configuration. Both intact as well as split objects prime an intact probe object when attended (analytic priming, depicted as cylinders), resulting in a main effect of attention.(B) Sequence of events within one trial of the main experiment.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="f0010">
      <label>Fig. 2</label>
      <caption>
        <p>Behavioural priming, i.e., unprimed–primed RTs, for each condition of interest (AttInt = attended, intact condition, AttSpl = attended, split condition, UncIn = uncued, intact condition, UncSpl = uncued, split condition). Error bars reflect one-tailed 95% confidence intervals.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="f0015">
      <label>Fig. 3</label>
      <caption>
        <p>Maximal intensity projections (MIP) of clusters that survived p &lt; .05 corrected for their spatial extent (using a height threshold of p &lt; .001 uncorrected) in the localiser session for the contrasts of: (A) objects (averaging over intact and split) vs scrambled objects, and (B) split vs intact objects.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="f0020">
      <label>Fig. 4</label>
      <caption>
        <p>Voxel-wise results. On the left, statistical parametric maps of regions implicated in object recognition shown on orthogonal sections through a normalised structural of one participant. (A) Voxels in cyan were more active for objects than scrambled objects in the localiser (<xref rid="f0015" ref-type="fig">Fig. 3</xref>), and formed the search space for the voxels in red that showed a main effect of attention on repetition effects in the main experiment, thresholded at p &lt; .001 uncorrected. Cross-hair centred on the left fusiform maximum that was the only maximum to survive correction for the search region. (B) Voxels in yellow were more active for split than intact objects in the localiser (<xref rid="f0015" ref-type="fig">Fig. 3</xref>), and formed the search space for the voxels in red that showed a main effect of configuration on repetition effects in the main experiment, thresholded at p &lt; .001 uncorrected. Cross-hair centred on the right intraparietal maximum that was the only maximum to survive correction for the search region. (C) Voxels in cyan were more active for objects than scrambled objects in the localiser (<xref rid="f0015" ref-type="fig">Fig. 3</xref>), and formed the search space for the voxels in red that showed an interaction between attention and configuration on repetition effects in the main experiment, thresholded at p &lt; .001 uncorrected. Cross-hair centred on the left lateral occipital maximum that was the only maximum to survive correction for the search region. On the right, percentage BOLD signal change between the peak of the fitted event-related response to the primed conditions subtracted from that of the corresponding unprimed conditions (i.e., where positive = repetition suppression (RS), and where percentage is relative to the mean BOLD signal over all voxels and volumes), for each of the four conditions of interest (AttIntact = attended, intact condition, AttSplit = attended, split condition, UncIntact = uncued, intact condition, UncSplit = uncued, split condition). Error bars are two-tailed 95% confidence intervals of repetition effects vs zero.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="f0025">
      <label>Fig. 5</label>
      <caption>
        <p>Group-fROI results (A) On the left, BOLD repetition effects for attended and uncued conditions (averaged across intact and split configurations) for left (L) and right (R) fROIs within the ventral visual stream (averaged across posterior and anterior fROIs; see text). See <xref rid="f0020" ref-type="fig">Fig. 4</xref> legend for further details. On the right, scatter plot of each participant's behavioural priming for attended primes (averaged across intact and split configurations) against RS in left fROI regions (averaged across posterior and anterior fROIs). (B) On the left, BOLD repetition effects for intact and split configuration conditions (averaged across attended and uncued) for left (L) and right (R) fROIs within the dorsal visual stream (see text). On the right, scatter plot of each participant's behavioural priming against RE for uncued, intact primes in intraparietal fROIs (averaged across left and right fROIs).</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <table-wrap id="t0005" position="float">
      <label>Table 1</label>
      <caption>
        <p>Mean response times (ms) and percentage errors for probe responses.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th align="left">Attendintact</th>
            <th align="left">Attendsplit</th>
            <th align="left">Uncuedintact</th>
            <th align="left">Uncuedsplit</th>
            <th align="left">Unprimedintact</th>
            <th align="left">Unprimedsplit</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">M</td>
            <td align="left">699</td>
            <td align="left">712</td>
            <td align="left">793</td>
            <td align="left">812</td>
            <td align="left">824</td>
            <td align="left">806</td>
          </tr>
          <tr>
            <td align="left">SE</td>
            <td align="left">79</td>
            <td align="left">88</td>
            <td align="left">87</td>
            <td align="left">89</td>
            <td align="left">93</td>
            <td align="left">94</td>
          </tr>
          <tr>
            <td align="left">% error</td>
            <td align="left">8 +/− 1</td>
            <td align="left">9 +/− 1</td>
            <td align="left">9 +/− 1</td>
            <td align="left">8 +/− 1</td>
            <td align="left">7 +/− 1</td>
            <td align="left">7 +/− 1</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="t0010" position="float">
      <label>Table 2</label>
      <caption>
        <p>Factorial effects of Attention and Configuration on BOLD repetition effects that survived p &lt; .05 corrected for the space defined by the object vs scrambled localiser contrast (indicated with *) or p &lt; .10 corrected for the space defined by the intact vs split localiser contrast (indicated with <sup>+</sup>).</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">
              <italic>Contrast</italic>
            </th>
            <th align="left">
              <italic>Region</italic>
            </th>
            <th colspan="3" align="left">
              <italic>MNI coordinates</italic>
            </th>
            <th align="left">
              <italic>Z</italic>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Main effect of Attention</td>
            <td align="left">Ant fusiform gyrus L</td>
            <td align="char">− 36</td>
            <td align="char">− 36</td>
            <td align="char">− 21</td>
            <td align="char">3.83*</td>
          </tr>
          <tr>
            <td align="left">Main effect of Configuration</td>
            <td align="left">Sup parietal R</td>
            <td align="char">+ 36</td>
            <td align="char">− 54</td>
            <td align="char">+ 57</td>
            <td align="char">3.48<sup>+</sup></td>
          </tr>
          <tr>
            <td align="left">Interaction Attention × Configuration</td>
            <td align="left">Middle occipital gyrus L</td>
            <td align="char">− 51</td>
            <td align="char">− 66</td>
            <td align="char">− 12</td>
            <td align="char">3.80*</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </floats-group>
</article>