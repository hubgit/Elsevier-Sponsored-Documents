<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuropsychologia</journal-id>
      <journal-title-group>
        <journal-title>Neuropsychologia</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0028-3932</issn>
      <issn pub-type="epub">1873-3514</issn>
      <publisher>
        <publisher-name>Pergamon Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3083513</article-id>
      <article-id pub-id-type="pmid">21237181</article-id>
      <article-id pub-id-type="publisher-id">NSY3962</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.01.009</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Normal form from biological motion despite impaired ventral stream function</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Gilaie-Dotan</surname>
            <given-names>S.</given-names>
          </name>
          <email>shagido@gmail.com</email>
          <xref rid="aff0005" ref-type="aff">a</xref>
          <xref rid="aff0010" ref-type="aff">b</xref>
          <xref rid="cor0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Bentin</surname>
            <given-names>S.</given-names>
          </name>
          <xref rid="aff0015" ref-type="aff">c</xref>
          <xref rid="aff0020" ref-type="aff">d</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Harel</surname>
            <given-names>M.</given-names>
          </name>
          <xref rid="aff0025" ref-type="aff">e</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Rees</surname>
            <given-names>G.</given-names>
          </name>
          <xref rid="aff0005" ref-type="aff">a</xref>
          <xref rid="aff0010" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Saygin</surname>
            <given-names>A.P.</given-names>
          </name>
          <email>saygin@cogsci.ucsd.edu</email>
          <xref rid="aff0030" ref-type="aff">f</xref>
          <xref rid="cor0010" ref-type="corresp">⁎⁎</xref>
        </contrib>
      </contrib-group>
      <aff id="aff0005"><label>a</label>Institute of Cognitive Neuroscience, University College London, London, UK</aff>
      <aff id="aff0010"><label>b</label>Wellcome Trust Centre for Neuroimaging, University College London, London, UK</aff>
      <aff id="aff0015"><label>c</label>Department of Psychology, Hebrew University of Jerusalem, Jerusalem, Israel</aff>
      <aff id="aff0020"><label>d</label>Interdisciplinary Center for Neural Computation, Hebrew University of Jerusalem, Jerusalem, Israel</aff>
      <aff id="aff0025"><label>e</label>Department of Neurobiology, Weizmann Institute of Science, Rehovot, Israel</aff>
      <aff id="aff0030"><label>f</label>Department of Cognitive Science and Neuroscience Program, University of California San Diego, 9500 Gilman Drive, San Diego, CA 92093-0515, USA</aff>
      <author-notes>
        <corresp id="cor0005"><label>⁎</label>Corresponding author at: Institute of Cognitive Neuroscience, University College London, Alexandra House, 17 Queen Square, London WC1N 3AR, UK. Tel.: +44 20 7679 1122; fax: +44 20 7813 2835. <email>shagido@gmail.com</email></corresp>
        <corresp id="cor0010"><label>⁎⁎</label>Corresponding author at: University of California, San Diego, 9500 Gilman Drive, CA 92093-0515, USA. Tel.: +1 858 822 4403; fax: +1 858 534 1128. <email>saygin@cogsci.ucsd.edu</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <month>4</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <month>4</month>
        <year>2011</year>
      </pub-date>
      <volume>49</volume>
      <issue>5</issue>
      <fpage>1033</fpage>
      <lpage>1043</lpage>
      <history>
        <date date-type="received">
          <day>30</day>
          <month>7</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>13</day>
          <month>12</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>6</day>
          <month>1</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 Elsevier Ltd.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract abstract-type="graphical">
        <title>Research highlights</title>
        <p>▶ Normal biological motion processing can exist independently from form processing. ▶ Intact ventral stream processing is not necessary for biological form-from-motion. ▶ Proper ventral stream processing is necessary for non-biological form-from-motion. ▶ Normal visual inputs from V5/MT+ can suffice to activate the action perception system. ▶ Biological motion can be processed successfully even with compromised ventral stream.</p>
      </abstract>
      <abstract>
        <p>We explored the extent to which biological motion perception depends on ventral stream integration by studying LG, an unusual case of developmental visual agnosia. LG has significant ventral stream processing deficits but no discernable structural cortical abnormality. LG's intermediate visual areas and object-sensitive regions exhibit abnormal activation during visual object perception, in contrast to area V5/MT+ which responds normally to visual motion (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan, Perry, Bonneh, Malach, &amp; Bentin, 2009</xref>). Here, in three studies we used point light displays, which require visual integration, in adaptive threshold experiments to examine LG's ability to detect form from biological and non-biological motion cues. LG's ability to detect and discriminate form from biological motion was similar to healthy controls. In contrast, he was significantly deficient in processing form from non-biological motion. Thus, LG can rely on biological motion cues to perceive human forms, but is considerably impaired in extracting form from non-biological motion. Finally, we found that while LG viewed biological motion, activity in a network of brain regions associated with processing biological motion was functionally correlated with his V5/MT+ activity, indicating that normal inputs from V5/MT+ might suffice to activate his action perception system. These results indicate that processing of biologically moving form can dissociate from other form processing in the ventral pathway. Furthermore, the present results indicate that integrative ventral stream processing is necessary for uncompromised processing of non-biological form from motion.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Biological motion</kwd>
        <kwd>Form agnosia</kwd>
        <kwd>Form from motion</kwd>
        <kwd>Point-light displays</kwd>
        <kwd>Ventral visual stream</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec0005">
      <label>1</label>
      <title>Introduction</title>
      <p>Visual perception of body movements of other animate entities is fundamental to our survival and well-being. Perception of biological motion is a crucial component of this ubiquitous and important process (<xref rid="bib0020" ref-type="bibr">Blake &amp; Shiffrar, 2007</xref>). One frequently exploited technique in the study of biological motion is point-light displays (<xref rid="bib0105" ref-type="bibr">Johansson, 1973</xref>). Animated point-light displays of human figures comprise about a dozen markers attached to the limbs of a person and when in motion, provide compelling demonstration of biological form from motion. Even though they comprise only a few point lights, these stimuli can depict a person's body movements vividly, conveying detailed information such as gender, identity, and emotions (e.g., <xref rid="bib0050 bib0155 bib0160 bib0215" ref-type="bibr">Dittrich, Troscianko, Lea, &amp; Morgan, 1996; Perry, Troje, &amp; Bentin, 2010; Pollick, Paterson, Bruderlin, &amp; Sanford, 2001; Troje, 2002</xref>). Biological motion perception is supported by a network of brain areas, including temporal, frontal and parietal cortical regions (<xref rid="bib0020 bib0085 bib0165 bib0170 bib0175 bib0190" ref-type="bibr">Blake &amp; Shiffrar, 2007; Grossman &amp; Blake, 2002; Puce &amp; Perrett, 2003; Rizzolatti &amp; Sinigaglia, 2010; Saygin, 2007; Saygin, Wilson, Hagler, Bates, &amp; Sereno, 2004</xref>), here referred to as the “Action Perception System” (APS).</p>
      <p>Even with point-light displays, biological motion involves form processing as well as motion processing <italic>per se</italic>. This raises the question of whether biological motion perception and form processing interact or are independent. The involvement of form processing in biological motion perception has indeed been supported by several psychophysical, neuroimaging and neurophysiological studies (<xref rid="bib0015 bib0030 bib0085 bib0115 bib0135 bib0230" ref-type="bibr">Beintema, Georg, &amp; Lappe, 2006; Bruce, Desimone, &amp; Gross, 1981; Grossman &amp; Blake, 2002; Lange &amp; Lappe, 2006; Neri, Morrone, &amp; Burr, 1998; Vangeneugden, Pollick, &amp; Vogels, 2009</xref>). Others have highlighted the importance of dynamic cues in biological motion perception (<xref rid="bib0035 bib0065 bib0210" ref-type="bibr">Cavanagh, Labianca, &amp; Thornton, 2001; Giese &amp; Poggio, 2003; Thurman &amp; Grossman, 2008</xref>).</p>
      <p>In the present study, we used point-light displays to investigate whether biological motion perception depended on form processing in LG, an individual known to have developmental form processing deficits but who reports normal motion perception. Behaviourally, LG has problems integrating visual stimuli into coherent forms. In contrast, based on his introspection, he recognizes people by the way they walk, suggesting that his biological motion perception is not deficient (<xref rid="tbl0005" ref-type="table">Table 1</xref>). In a recent fMRI study, we found that the activity in LG's visual cortex associated with visual stimulation was consistent with such a dissociation between motion and form processing (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan, Perry, Bonneh, Malach, &amp; Bentin, 2009</xref>). That earlier study found that abnormal activity in LG's intermediate visual regions leads to impaired sensitivity to objects in higher-level object sensitive areas (e.g., LO, see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>A, red dotted regions), while responses in motion sensitive area V5/MT+ to visual motion were normal (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>A, V5/MT+ denoted in green).</p>
      <p>In brief, LG displays apparently normal motion sensitivity, yet exhibits form processing impairments. We therefore reasoned that examining his biological form from motion perception using point-light displays might shed light on the dependence of biological motion processing on form integration. In addition, we also tested LG's non-biological form from motion (<xref rid="bib0095 bib0180" ref-type="bibr">Hiris, 2007; Saygin, Cook, &amp; Blakemore, 2010</xref>) allowing us to examine whether recognition of moving forms by different motion types displayed different dependencies on form integration and ventral stream processing.</p>
      <p>We tested LG and compared his performance with that of age-matched healthy controls in three experiments that measured perceptual thresholds for form from motion perception using biological motion (in Experiments 1 and 2) and non-biological motion (in Experiments 2 and 3). We have used the paradigms of Experiments 1 and 2 successfully in previous studies with stroke patients (<xref rid="bib0175" ref-type="bibr">Saygin, 2007</xref>) and autism spectrum conditions (<xref rid="bib0180" ref-type="bibr">Saygin et al., 2010</xref>). The paradigm of Experiment 3 was also based on a previously published technique (<xref rid="bib0195" ref-type="bibr">Singer &amp; Sheinberg, 2008</xref>).</p>
      <p>We also wanted to examine the functional integrity of the APS in LG's brain, given that there are sparse and abnormal visual inputs from LG's V2/V3 and ventral stream (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>). Since a primary source of input into the APS is the motion sensitive visual region V5/MT+, we assessed whether the activity in the APS regions was functionally correlated to LG's right V5/MT+ activity during natural viewing of biological and non-biological motion movie clips.</p>
    </sec>
    <sec id="sec0010">
      <label>2</label>
      <title>General methods</title>
      <sec id="sec0015">
        <label>2.1</label>
        <title>Participants</title>
        <p>LG was 23 years old when tested on Experiments 1 and 2; and 24 years old when tested on Experiment 3. Thirteen age-matched control participants were tested in Experiment 1 (mean age 20.42 ± 1.08 (S.D.)), 21 in Experiment 2 (mean age 23.29 ± 4.88), and 8 in Experiment 3 (mean age 22.62 ± 2.45). Approximately half of the control participants were women. All control participants had normal or corrected to normal vision and no history of neurological disorders. LG was tested in his home. Control participants were tested at the Institute for Cognitive Neuroscience, University College London. All participants gave written informed consent and the experiments were approved by local ethics committee (University College London).</p>
      </sec>
    </sec>
    <sec id="sec0020">
      <label>3</label>
      <title>Experiment 1</title>
      <p>In this experiment we assessed the ability of LG to process form from biological motion. On each trial, LG and control participants were presented with two point-light displays presented simultaneously and were instructed to decide which of the two displays contained an animation of an upright human figure performing one of seven actions (see Section <xref rid="sec0030" ref-type="sec">3.1.1</xref>, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>A, <xref rid="sec0185" ref-type="sec">Supplementary Figs. 1–3</xref>; <xref rid="bib0175" ref-type="bibr">Saygin, 2007</xref>).</p>
      <sec id="sec0025">
        <label>3.1</label>
        <title>Experiment 1: methods</title>
        <sec id="sec0030">
          <label>3.1.1</label>
          <title>Experiment 1: stimuli</title>
          <p>Biological motion animations were created by videotaping an actor performing various activities, and encoding only the joint positions in digitized videos (<xref rid="bib0005" ref-type="bibr">Ahlstrom, Blake, &amp; Ahlstrom, 1997</xref>). In the videos, the joints were represented by 12 small white points against a black background (<xref rid="fig0010" ref-type="fig">Fig. 2</xref>A; for an animated example, see <xref rid="sec0185" ref-type="sec">Supplementary Figs. 2 and 3</xref>). The biological motion animations depicted one of seven actions: walking, jogging, throwing, underarm throwing (bowling), stepping up, a high kick into the air, and a lower kick. Each animation consisted of 20 distinct frames and was displayed for 0.5 s (16.5 ms interframe interval, 60 Hz). The final frame then remained visible for 0.3 s, after which the animation looped from the beginning. Since a joint could become occluded by other body parts during an action, some points could at times become briefly invisible.</p>
          <p>For each of the seven biological motion animations, a matched spatially scrambled animation was created. This was done by scrambling the starting positions of the 12 points while keeping the moving trajectories of each point unchanged. Hence, the scrambled animations contained the same local motion information as the biological motion animations, but without the global form of the latter. The starting positions of the scrambled points were chosen randomly within a region such that the total area encompassed by the scrambled animation was similar to that of the biological animation.</p>
          <p>During each trial, the displays of both biological motion stimuli and their scrambled counterparts had additional moving noise points randomly superimposed on them. The moving trajectories of these noise points were generated in the same way as of the scrambled animations. The task became more difficult with increasing number of noise points. The number of noise points was manipulated in an adaptive procedure (see below).</p>
          <p>Each animation subtended approximately 4 × 6° (width × height) visual angle when viewed from 55 cm. The total area occupied by each point-light display (comprising the animation plus the noise points) was approximately 7° of visual angle in diameter. On each trial, the two point-light displays (one containing the biological motion animation, the other containing its scrambled counterpart) were displayed to the left and right of the centre of the screen respectively (centred at approximately 9° from the centre of the screen), their vertical centres horizontally aligned (see <xref rid="sec0185" ref-type="sec">Supplementary Fig. 1</xref>). Stimuli were presented and responses recorded using MATLAB (Mathworks, Natick, MA, USA) and the Psychophysics Toolbox V2.54 (<xref rid="bib0025 bib0150" ref-type="bibr">Brainard, 1997; Pelli, 1997</xref>).</p>
        </sec>
        <sec id="sec0035">
          <label>3.1.2</label>
          <title>Experiment 1: procedure</title>
          <p>Participants were familiarized with the seven types of biological motion animations before the experiment started. At this stage, each animation was displayed on the screen (without any noise points superimposed) and the participants described verbally what they perceived.</p>
          <p>Following the familiarization phase, sensitivity to biological motion was assessed using a 2-AFC experimental design. Two point-light displays were displayed in each trial (see details above), one containing a biological motion animation (one of the seven human actions, see above) and the other containing its scrambled counterpart. The side of the biological motion animation was randomly determined on each trial. Participants were instructed to press one of two keys on the keyboard indicating the side for which the animation represented ‘a person’. The animations were repeated continuously until a response was given. Participants were not required to fixate (e.g., at the centre of the screen); instead, they were allowed to look at the stimuli as they pleased.</p>
          <p>To yield a psychometric measure of performance, we varied the number of noise points in each trial using a Bayesian adaptive procedure that efficiently estimated the level of noise at which a participant performed at a desired level of accuracy (QUEST, <xref rid="bib0235" ref-type="bibr">Watson &amp; Pelli, 1983</xref>). After the familiarization phase, control participants performed total of 118 adaptive trials, and an accuracy threshold of 82% was estimated for each participant using the mean of the posterior probability density function. These trials were presented in two equal blocks separated by a 10-s rest period (in fact, since the task was not timed, subjects could take additional breaks at any time). Control participants completed one run of the experiment. LG completed two runs of the experiment, each with 73 adaptive trials, with a rest period of 10 s after 40 trials in each run.</p>
        </sec>
        <sec id="sec0040">
          <label>3.1.3</label>
          <title>Experiment 1: data analysis</title>
          <p>The perceptual threshold was defined as the estimated number of noise points that allowed each participant to perform at the pre-determined accuracy level, as described above. Thresholds from multiple runs were averaged. We considered LG's performance to be significantly different from controls if it differed by more than two standard deviations from the mean of the controls’ performance. These differences in thresholds between LG and controls were further confirmed by using established statistical procedures to compare between single cases and controls (<xref rid="bib0040 bib0045" ref-type="bibr">Corballis, 2009; Crawford, Garthwaite, &amp; Howell, 2009</xref>).</p>
        </sec>
      </sec>
      <sec id="sec0045">
        <label>3.2</label>
        <title>Experiment 1: results and interim discussion</title>
        <p>This experiment tested LG's sensitivity to point-light biological motion (<xref rid="bib0175" ref-type="bibr">Saygin, 2007</xref>). During familiarization, neither LG, nor any of the controls had trouble recognizing the movements depicted by the biological motion point-light displays (see <xref rid="fig0010" ref-type="fig">Fig. 2</xref>A; <xref rid="sec0185" ref-type="sec">Supplementary Figs. 2 and 3</xref>). LG was immediately able to report the correct movements presented during familiarization. The noise point thresholds for the main 2AFC part of the experiment are shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B. LG's performance was clearly within the range of the controls (LG: 23.66, 0.45 S.D. above controls’ mean (20.58 ± 6.80 (S.D.)), see <xref rid="fig0010" ref-type="fig">Fig. 2</xref>B). Statistical analysis confirmed this (<italic>t</italic>(12)<sub>Crawford</sub> = 0.436, <italic>p</italic> = 0.67; <italic>t</italic>(12)<sub>Corballis</sub> = 0.452, <italic>p</italic> = 0.659). This pattern was not influenced by learning as it held even when we examined performance on the first session separately (LG: 20.52, 0.16 S.D. above controls’ mean for first session 19.53 ± 6.26 (S.D), <italic>t</italic>(12)<sub>Crawford</sub> = 0.151, <italic>p</italic> = 0.88; <italic>t</italic>(12)<sub>Corballis</sub> = 0.157, <italic>p</italic> = 0.877).</p>
        <p>The results of this experiment indicate that LG was able to detect human figures normally based on their characteristic biological motion. Thus, the functional impairment in his ventral system did not appear to interfere with his ability to perceive form from biological motion, even when integration was essential for the task.</p>
      </sec>
    </sec>
    <sec id="sec0050">
      <label>4</label>
      <title>Experiment 2</title>
      <p>This experiment aimed to assess LG's ability to perceive form from biological or non-biological motion (<xref rid="bib0095 bib0180" ref-type="bibr">Hiris, 2007; Saygin et al., 2010</xref>). A single point-light animation was displayed on each trial, and participants were instructed to determine whether the target (defined either by biological motion or non-biological translational motion) was moving to the right or to the left. In the biological motion condition the target was an animation depicting a person walking, which featured a recognizable, familiar biological form. In the two non-biological motion conditions, the point-light animated target formed either a familiar form (a rectangle), or an unfamiliar form (see Section <xref rid="sec0060" ref-type="sec">4.1.1</xref> for details).</p>
      <sec id="sec0055">
        <label>4.1</label>
        <title>Experiment 2: methods</title>
        <sec id="sec0060">
          <label>4.1.1</label>
          <title>Experiment 2: stimuli</title>
          <p>This experiment comprised three conditions, each featuring a different type of point light display, all composed of white points presented on a black background. Still frames depicting the three types of stimuli for each of the three experimental conditions are shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref>A. The biological motion (BM) point-light animation was identical to the walking figure from Experiment 1 (for an animation demo see <xref rid="sec0185" ref-type="sec">Supplementary Fig. 3</xref>). The walking movement did not include translation (as if walking on a treadmill), like in most studies on biological motion. The direction that the walker faced (right or left) was determined randomly on each trial. The familiar non-biological motion object (nonBMO) was a rectangle made of equidistant points and translated at 0.5 pixels/frame (at 60 Hz) to the right or to the left (again determined randomly). The unfamiliar non-biological motion object (nonBMU) was an unstructured form translating as in the nonBMO condition. The nonBMU was obtained by taking a single frame from the biological motion animation and presenting it upside-down. Such inverted point light displays are typically perceived as a set of random points, and inversion greatly disrupts the percept of a biological figure (<xref rid="bib0145 bib0185 bib0205" ref-type="bibr">Pavlova &amp; Sokolov, 2003; Saygin, Driver, &amp; de Sa, 2008; Sumi, 1984</xref>).</p>
          <p>As in Experiment 1, a variable number of noise points with similar motion trajectories as the targets were also presented on each trial. The initial spatial location of the noise points was determined randomly. In the biological motion (BM) condition, each noise point had the motion trajectory of one of the points from the target biological motion animation. The noise points in the non-biological motion conditions (nonBMO and nonBMU) translated horizontally. A number of the noise points (equal to those of the target) always moved in the opposite direction to the target point light animation, so that it would not be possible to determine the direction of target movement simply by summation of the overall movement direction in the display. The rest of the noise points moved either to the left or to the right randomly.</p>
          <p>The target point-light displays subtended approximately 4 × 8° visual angle when viewed from 55 cm while the region populated by the target point-light display and the noise points together was approximately 8 × 12° visual angle. On each trial, the target point-light display was presented at a randomly jittered location within a 2.2° radius from the centre of the screen. Stimuli were presented and responses recorded using Matlab (Mathworks, Natick, MA, USA) and the Psychophysics Toolbox V2.54 (<xref rid="bib0025 bib0150" ref-type="bibr">Brainard, 1997; Pelli, 1997</xref>).</p>
        </sec>
        <sec id="sec0065">
          <label>4.1.2</label>
          <title>Experiment 2: procedure</title>
          <p>For each condition the experiment started with a practice block, which included up to 20 trials of that condition, with a range of predetermined number of noise points (ranging from 0 to 70). The practice was followed by the main experimental block for that condition, which included 60 adaptive trials, beginning with 20 noise points. To measure discrimination thresholds for the direction of motion in each condition, we used the same Bayesian adaptive paradigm as in Experiment 1 (QUEST). The number of noise points was varied from trial to trial, and we estimated the number of noise points at which each participant performed at 75% accuracy (<xref rid="bib0235" ref-type="bibr">Watson &amp; Pelli, 1983</xref>). A 10-s break followed trial 36 in each block, and additional rest was allowed between blocks. Each block lasted between 3 and 4 min. Participants completed three blocks of each condition.</p>
          <p>Each trial started with a white fixation cross displayed at the centre of the screen for 750 ms, after which the point-light displays were presented along with noise points (see more details above). Participants pressed one of two keys to indicate the perceived movement direction of the target point-light display (right or left). The task became more difficult with increasing number of noise points. If no response was given within 2000 ms from the end of the stimulus presentation, the trial was terminated and an incorrect response was used in the QUEST algorithm. After each response, a visual feedback cue appeared for 750 ms (green fixation cross for correct and red for incorrect).</p>
        </sec>
        <sec id="sec0070">
          <label>4.1.3</label>
          <title>Experiment 2: data analysis</title>
          <p>For each experimental condition thresholds were calculated for LG and for each of the control participants and data were analyzed as in Experiment 1.</p>
        </sec>
      </sec>
      <sec id="sec0075">
        <label>4.2</label>
        <title>Experiment 2: results and interim discussion</title>
        <p>As in Experiment 1, LG's biological motion (BM) detection was well within the controls’ range in Experiment 2 (LG: 23.43, 0.43 S.D. from the control mean, which was 26.53 ± 7.16 (S.D.); <italic>t</italic>(20)<sub>Crawford</sub> = −0.423, <italic>p</italic> = 0.676, <italic>t</italic>(20)<sub>Corballis</sub> = −0.432, <italic>p</italic> = 0.669; see <xref rid="fig0015" ref-type="fig">Fig. 3</xref>B). In contrast, LG performed significantly worse than controls in the non-biological structured object (nonBMO) condition (LG: 42.47, 2.26 S.D. below controls’ average of 91.06 ± 21.52; <italic>t</italic>(20)<sub>Crawford</sub> = −2.21, <italic>p</italic> = 0.035, <italic>t</italic>(20)<sub>Corballis</sub> = −2.26, <italic>p</italic> = 0.039). Finally, with the unstructured stimuli (nonBMU), both LG and controls performed equally poorly (LG at 19.33, 0.46 S.D. from controls mean 22.53 ± 7.02; <italic>t</italic>(20)<sub>Crawford</sub> = −0.45, <italic>p</italic> = 0.66, <italic>t</italic>(20)<sub>Corballis</sub> = −0.46, <italic>p</italic> = 0.653).</p>
        <p>The important comparisons related to our research question (whether LG's form from motion perception was normal) are found in the within-condition comparisons of LG to controls. Consistent with the findings of Experiment 1, comparing the performance of LG and controls indicated that LG was indeed able to process biological motion as well as controls, now confirmed with a second task (direction discrimination). However, his ability to discriminate the direction of a moving structured object defined by non-biological form from motion was significantly worse than that of controls. Between-condition comparisons revealed that thresholds differed significantly between conditions (all pairwise differences were significant, <italic>p</italic> &lt; 0.05), broadly consistent with findings by <xref rid="bib0095" ref-type="bibr">Hiris (2007)</xref>. However, the raw thresholds of the biological motion (BM) and the non-biological motion conditions (nonBMO and nonBMU) are not comparable since form from motion is conveyed very differently between the two types of motion. As for the non-biological motion conditions, even though the thresholds of non-biological motion conditions (nonBMO and nonBMU) were significantly different (<italic>p</italic> &lt; 10<sup>−12</sup>), there was a strong and significant correlation between them (<italic>r</italic> = 0.58; <italic>r</italic><sup>2</sup> = 0.32, <italic>t</italic>(19) = 3.14, <italic>p</italic> = 0.005), indicating that these are likely to be processed by some joint mechanisms. There was a weaker correlation between biological motion (BM) thresholds and the non-biological structured object (nonBMO, rectangle) thresholds (<italic>r</italic> = 0.414; <italic>r</italic><sup>2</sup> = 0.17, <italic>t</italic>(19) = 1.99, <italic>p</italic> = 0.062).</p>
        <p>LG appears to have limited ability to utilize form cues in form from non-biological motion perception. For control participants, thresholds (Experiment 2) were notably higher in the non-biological structured object condition (nonBMO) compared with the non-biological unstructured condition (nonBMU). In contrast, LG showed a more modest increase in noise point threshold for the structured object, compared with the unstructured object, likely because he could not rely on an intact ventral stream to fully take advantage of the form information that makes the non-biological structured object condition (nonBMO) much easier for controls. We hypothesize that controls, with normal visual integration mechanisms (<xref rid="bib0125" ref-type="bibr">Lerner, Hendler, &amp; Malach, 2002</xref>), can utilize integration mechanisms in the ventral stream to improve their performance when the moving object has a coherent form. The rectangle stimulus used in this condition (nonBMO condition) conveyed a strong Gestalt, which even LG was able to use. However when the rectangle was masked with noise points the integration process became more difficult. For the unstructured object condition (nonBMU), controls, as well as LG, were not able to use integration benefits since the form did not convey a strong Gestalt.</p>
        <p>The apparent dissociation between LG's normal performance on form from biological motion compared to his impaired performance on the form from non-biological motion might be due to the biological aspect of the motion, and that there may be unique pathways supporting biological motion processing. However, there are additional differences between these conditions. LG's ability to successfully recognize biological figures may stem from the fact that these stimuli have an induced object-typical motion, rather than from the biological nature of that induced motion <italic>per se</italic>. Humans have a typical, characteristic motion, whereas rectangles do not. It is possible that LG was more familiar with the object-typical biological motion in the biological motion (BM) condition than with the somewhat arbitrary pairing of rectangular form and linear motion we used in the non-biological structured object (nonBMO) condition (though presumably, so were control participants (<xref rid="bib0035" ref-type="bibr">Cavanagh et al., 2001</xref>)). Another possible distinction between these conditions could be related to the dimensionality of the induced percept. The rectangle in the non-biological structured object (nonBMO) condition was a 2D shape and the translating motion did not induce any additional depth cues. The biologically moving human figure on the other hand depicted a 3D person, and might have induced a more vivid 3D percept. Finally, the complexity of the motion itself may differentiate the conditions, as more complex motion defining the object might provide better binding cues. In this case, the rectangle had in some sense the simplest motion (same linear trajectory for all the object points), whereas the human figure had more complex motion trajectories in space. We took these factors into account and further assessed LG's non-biological form from motion in Experiment 3.</p>
      </sec>
    </sec>
    <sec id="sec0080">
      <label>5</label>
      <title>Experiment 3</title>
      <p>This experiment sought to further assess LG's ability to identify and detect non-biological objects defined by motion. In the present experiment, we used more naturalistic, three-dimensional non-biological objects (spheres and cylinders) defined by motion cues. The motion was both characteristic of these objects (rotation/spin) and conveyed surface and three dimensional structure (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>A and D). Furthermore the local motions in space were more complex than translation.</p>
      <p>The paradigm we used allowed the presentation of an object (sphere or cylinder) based only on the local motion vectors across the object (<xref rid="bib0195" ref-type="bibr">Singer &amp; Sheinberg, 2008</xref>). An animated three-dimensional scene composed of a rotating object and a static background was rendered in real-time as a pattern of points. A global percept of the moving object (or a whole moving scene) emerged from the integration of the local motion vectors into a coherent moving shape. Thus, the perception of an object was based only on the motion vectors across the object. Since each point followed the trajectory of the underlying motion in the scene, only points located on the rotating object surface actually had local motion, while the points located “on the background” did not. Each static frame of the animation appeared to be a uniform random field of points (see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>A and D). By varying different parameters of this paradigm (number of points in the display and the rotation speed of the object) we were able to modulate task difficulty (see below).</p>
      <sec id="sec0085">
        <label>5.1</label>
        <title>Experiment 3: methods</title>
        <sec id="sec0090">
          <label>5.1.1</label>
          <title>Experiment 3: stimuli</title>
          <p>Throughout each experimental session, the display was composed of flickering white points that randomly appeared on a black screen (“formless dot field” random dot motion). Each point had a short lifetime (1.33 s, 80 frames at 60 frames/s) and the appearances of the points on the screen were not synchronized. When a rotating object trial began, the motion of a rotating object was embedded into the flickering point display. Flickering points that appeared in the location of the rotating object surface followed the local motion of the object's surface for the full extent of their lifetime (1.33 s). When a trial ended, all the points in the display had no local motion (i.e., each point appeared and stayed at the same location on the screen for its whole lifetime). The rotating object was either a 3D sphere or cylinder (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>A and D). Half of the trials were of a rotating sphere and half of a cylinder, and the order was determined randomly. The spinning object rotated around its north–south axis which was tilted 27° away from the screen's <italic>y</italic> axis plane (north end farther away, south end closer), similar to the Earth's tilt. The object rotation direction was determined randomly (clockwise or anticlockwise, 50% trials to each direction). The size of the sphere when viewed from 55 cm distance was 12 × 9.9° visual angle (width × height), the size of the cylinder was 8.2 × 9.4° (width × height) visual angle, and the point diameter was 0.16° visual angle. Screen resolution was 1024 × 768, refresh rate 60 Hz. Stimuli were presented using Matlab (Mathworks, Natick, MA, USA) and Psychophysics Toolbox 3 (<xref rid="bib0025 bib0150" ref-type="bibr">Brainard, 1997; Pelli, 1997</xref>). The experimental stimuli were based on the FDFDemo and moglFDF functions provided with the Psychophysics Toolbox, which provides an OpenGL (Silicon Graphics Inc.) interface for Matlab.</p>
        </sec>
        <sec id="sec0095">
          <label>5.1.2</label>
          <title>Experiment 3: tasks</title>
          <sec id="sec0100">
            <label>5.1.2.1</label>
            <title>Object recognition</title>
            <p>In the object recognition task, a rotating object appeared in every trial (a sphere or a cylinder) and participants’ task was to press a key once the object was recognized and then verbally indicate to the experimenter what the object was. The object rotated until the response was given without time restriction.</p>
            <p>In four conditions, object rotation speed was parametrically set to 0.5 (FstRot), 0.0833 (MedRot), 0.0167 (SlwRot), or 0.0033 (vSlwRot) rotations/s, while the number of points composing the formless point field was constant (1600, see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>A–C). Four conditions (1600pnt, 500pnt, 100pnt, and 50pnt) included a parametric change to the number of points composing the formless point field (1600, 500, 100, or 50 respectively) while the rotation speed remained constant (0.5 rotations/s, see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>D–F). Note that the 1600pnt and FstRot conditions are identical (maximal rotation speed and maximal number of points).</p>
          </sec>
          <sec id="sec0105">
            <label>5.1.2.2</label>
            <title>Object detection</title>
            <p>The object detection sessions took place after the object recognition sessions. The stimuli in the object detection sessions were identical to those in the object recognition task in all aspects, except that the object was present in only half of the trials. In the other half of the trials, there was no local motion.</p>
            <p>The rotating object (sphere or cylinder) appeared in 10 of the 20 trials and the participant had to press a key to indicate whether or not the object was present. After the key press, they had to verbally indicate by “yes” or “no” whether or not there was an object present. There was no time restriction for providing responses, and in the case of a present (rotating) object the object rotated until the key press. Before each object detection session of 20 trials with specific fixed parameters, participants were notified verbally by the experimenter about the approximate rotation speed of the objects in the session so that they would know what to expect for a ‘present object’ trial (e.g., “in this session the objects will be rotating really slowly”).</p>
          </sec>
        </sec>
        <sec id="sec0110">
          <label>5.1.3</label>
          <title>Experiment 3: procedure</title>
          <p>Participants viewed an example set of a few trials with 1600 points and rotation speed of 0.5 rotations/s, parameters that provided easy recognition of the objects even for LG (see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>A, conditions FstRot and 1600pnt) and reported verbally what object they saw on the screen. After these practice trials, each condition included a session of 20 trials with fixed parameters throughout the session (number of points, rotating speed). Participants’ verbal responses were recorded on paper and later digitized for further analysis. After the verbal response and once the participant was ready, another button was pressed to start the next trial.</p>
        </sec>
        <sec id="sec0115">
          <label>5.1.4</label>
          <title>Experiment 3: data analysis</title>
          <p>In this experiment for each experimental condition we compared LG's accuracy to those of the control participants and then determined whether LG's performance was significantly different from that of the controls’ as was done in Experiments 1 and 2.</p>
        </sec>
      </sec>
      <sec id="sec0120">
        <label>5.2</label>
        <title>Experiment 3: results and interim discussion</title>
        <p><xref rid="fig0020" ref-type="fig">Fig. 4</xref>B and E depicts the object recognition results (see <xref rid="tbl0010" ref-type="table">Table 2</xref> for full performance details and statistical results). Object recognition was at ceiling for both LG and controls for the FstRot, MedRot, 1600pnt, and 500pnt conditions. However, when less object information was available in the display (slower rotation speed, 0.0167 (SlwRot) or 0.0033 (vSlwRot) rotations/s, or 100 points defining the object (100pnt)), LG's object recognition impairment became apparent. He reported not being able to do the task, and even without a time constraint, he claimed to be guessing. Even though in the 100pnt condition, his performance was better than chance (65%), this was significantly worse than controls’ recognition accuracy (98.13% ± 2.59 (S.D)).</p>
        <p>In contrast to object recognition, LG's performance in the object detection task was perfect, indistinguishable from controls even when the displays contained sparse object information (vSlwRot and 100pnt conditions). He indicated verbally that he could see that “there is something” when an object was present (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>C and F, and <xref rid="tbl0010" ref-type="table">Table 2</xref> for full details), though he was unable to report which object it was. His normal detection ability might be accounted for by the local motion cues that the object induced. This motion could be easily detected without the need to integrate them into a coherent shape (<xref rid="bib0195" ref-type="bibr">Singer &amp; Sheinberg, 2008</xref>).</p>
        <p>In sum, consistent with the results observed in Experiment 2, LG displayed impaired recognition of form from non-biological motion. We thus verified that LG shows a dissociation between form from biological motion and from non-biological motion, possibly indicating there are distinct processes underlying biological motion perception.</p>
      </sec>
    </sec>
    <sec id="sec0125">
      <label>6</label>
      <title>fMRI connectivity analyses</title>
      <p>Finally, we sought to examine whether LG's normal biological motion perception would be reflected in the functional integrity of the entire APS when viewing biological motion stimuli, despite the sparse and abnormal visual inputs from V2/V3 and ventral stream (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>).</p>
      <p>In a recent neuroimaging study we localized LG's motion sensitive area V5/MT+ and found its activity to motion stimuli normal (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>). Here, we examined the functional connectivity of LG's right V5/MT+ to the rest of the brain using new analyses performed on the previously collected fMRI data.</p>
      <sec id="sec0130">
        <label>6.1</label>
        <title>fMRI connectivity: methods</title>
        <p>LG was 21 years old when he participated in the fMRI experiments described below. Written informed consent to participate in these experiments was obtained prior to participation, according to the Tel-Aviv Sourasky Medical Center ethics committee that approved the experimental protocol.</p>
        <sec id="sec0135">
          <label>6.1.1</label>
          <title>fMRI connectivity: procedure</title>
          <p>The fMRI experiments are described below, and further details can be found in <xref rid="sec0185" ref-type="sec">Supplementary Methods</xref> as well as in previous publications (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>; and see <xref rid="bib0010" ref-type="bibr">Avidan, Hasson, Malach, &amp; Behrmann, 2005</xref>).</p>
          <sec id="sec0140">
            <label>6.1.1.1</label>
            <title>V5/MT+ localizer</title>
            <p>This experiment (as described earlier in <xref rid="bib0090" ref-type="bibr">Hasson, Harel, Levy, &amp; Malach, 2003</xref>) sought to delineate motion-sensitive regions in the visual cortex (e.g., V5/MT+). The experiment comprised 2 conditions (“static” and “motion”) which were presented in blocks lasting 18 s, interleaved with 6-s fixation periods. Eight blocks of each condition were presented in the experiment. The stimuli for each condition consisted of low contrast rings (6% contrast, 2 cycles/° and a duty cycle = 0.2) surrounding the fixation point and forming a maximal visual angle of 16 × 16°. In the motion condition the rings either expanded or contracted (for 2 s in each direction of motion) at a rate of ∼6°/s, while in the static condition rings were displayed for 3 s each in a consecutive manner (hence not causing motion perception). LG was instructed to maintain fixation throughout the experiment. The experiment lasted 420 s.</p>
          </sec>
          <sec id="sec0145">
            <label>6.1.1.2</label>
            <title>Movie clips experiment</title>
            <p>In this experiment category-related video clips were presented in a block design. Each block lasted 15 s during which a clip was presented continuously. Based on their content, the clips formed four conditions: close-ups of people in various situations (“faces”), objects from different categories (tools, musical instruments, furniture, kitchenware, etc.; “objects”), navigation of the camera through open fields (“navigation”), and navigation through city buildings (“buildings”). The “faces” and “objects” conditions included biological motion of faces, hands and arms (manipulating the objects), while the other two conditions did not. Each condition was repeated 8 times with different clips at each repetition. The entire experiment lasted 12 min. Blocks were separated by a 6-s gray blank screen. The clips subtended a visual angle of 21° width × 17.3° height. LG was instructed to watch the movie-clips passively (see <xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>; and also <xref rid="bib0010" ref-type="bibr">Avidan et al., 2005</xref>).</p>
          </sec>
        </sec>
        <sec id="sec0150">
          <label>6.1.2</label>
          <title>MRI data acquisition</title>
          <p>Full details are provided in <xref rid="sec0185" ref-type="sec">Supplementary Methods</xref>.</p>
        </sec>
        <sec id="sec0155">
          <label>6.1.3</label>
          <title>fMRI data preprocessing and analysis</title>
          <p>Full details are provided in <xref rid="sec0185" ref-type="sec">Supplementary Methods</xref>. Briefly, preprocessing was applied to the functional data set of each experiment and the analysis was performed independently for each individual voxel. A general linear model (<xref rid="bib0060" ref-type="bibr">Friston et al., 1995</xref>) was fit to the time course of each voxel in the motion-selectivity experiment according to the experimental protocol.</p>
          <sec id="sec0160">
            <label>6.1.3.1</label>
            <title>V5/MT+ definition</title>
            <p>Motion-sensitive voxels were determined by contrasting the motion coefficient against the static coefficient. Right V5/MT+ ROI was determined for LG as the motion-sensitive region (motion &gt; static) in the right middle temporal cortex, located ventrolaterally, just posterior to the meeting point of the inferior temporal sulcus and the lateral occipital sulcus in the vicinity of the middle occipital gyrus/sulcus based on a minimum cluster size of 6 functional voxels.</p>
          </sec>
          <sec id="sec0165">
            <label>6.1.3.2</label>
            <title>Functional connectivity analyses</title>
            <p>This analysis is based on correlating fMRI activations in LG's brain while viewing movie clips that included clips conveying biological motion. For every voxel independently, the correlation between its time course and the average time course of right V5/MT+ (that served as a seed to the correlation analysis), was obtained. These were subjected to a minimum cluster size of 8 voxels. Whole brain Bonferroni-corrected significant correlations (<italic>r</italic> &gt;  = 0.377, <italic>t</italic>(235) = 6.24, <italic>p</italic>(corrected) &lt; 0.0001) are described in <xref rid="sec0185" ref-type="sec">Supplementary Methods</xref> and displayed in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>B.</p>
          </sec>
        </sec>
      </sec>
      <sec id="sec0170">
        <label>6.2</label>
        <title>fMRI connectivity: results</title>
        <p>Of special interest here was whether the network of brain areas that are linked to biological motion processing (here referred to as the Action Perception System or APS) would display normal functional connectivity to V5/MT+. To address this, we used LG's right V5/MT+ activation time course while viewing the movie clips in a correlation analysis in order to examine which parts of LG's brain were functionally correlated with this activity (see Section <xref rid="sec0130" ref-type="sec">6.1</xref>). As expected, activity in LG's intermediate visual regions was not correlated with V5/MT+ activity (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>B). However, surprisingly, despite a dominant component of LG's visual system that is abnormal, the regions comprising the APS exhibited activity that was significantly correlated with LG's V5/MT+ activity. The correlated regions included bilateral intraparietal sulcus, inferior frontal sulcus, and precentral sulcus, and the right superior temporal sulcus (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>B).</p>
      </sec>
    </sec>
    <sec id="sec0175">
      <label>7</label>
      <title>General discussion</title>
      <p>The extent to which biological motion perception relies upon processing of form by the ventral visual system is under debate (e.g., <xref rid="bib0020 bib0065" ref-type="bibr">Blake &amp; Shiffrar, 2007; Giese &amp; Poggio, 2003</xref>). Using point-light displays conveying biological and non-biological form from motion, we investigated the ability of LG, a rare case of developmental visual-integrative agnosia with visual integration deficits (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>) to process and perceive biological and non-biological form from motion.</p>
      <p>We found LG had normal perception of biological motion, even when tested with point-light stimuli, where the percept of a moving human figure emerges from spatially disconnected local motions of the point-lights, and integration of these into a coherent form is needed. In contrast, he was significantly deficient in processing non-biological form from motion. This pattern indicates that normal biological motion processing can be achieved independently from non-biological form from motion processing. Moreover, it emphasizes the necessity of proper ventral stream function for processing non-biological form from motion.</p>
      <p>While we cannot completely rule out the possibility that LG has a subtle deficit in biological motion perception, we believe this possibility to be unlikely, because the paradigms we used here were sensitive enough to detect deficits in biological motion processing in other populations (e.g., in stroke patients, a notoriously heterogeneous sample (<xref rid="bib0175" ref-type="bibr">Saygin, 2007</xref>)). Moreover, LG demonstrated normal ability to process biological motion in two different experiments featuring different tasks (detection for Experiment 1 and direction determination for Experiment 2), plus in an additional variant of the detection task with a paradigm similar to Experiment 2 (data not shown). Since the functioning of LG's ventral visual stream is deficient, it stands to reason that his normal perception of biological motion relies on his normally functioning dorsal system. Consistent with this, we found normal activation and connectivity patterns in LG's motion sensitive lateral temporal area V5/MT+. LG might also be able to rely on higher brain areas that are part of the APS, such as the STS and premotor cortex (<xref rid="bib0080 bib0165 bib0175 bib0190" ref-type="bibr">Grossman &amp; Blake, 2001; Puce &amp; Perrett, 2003; Saygin, 2007; Saygin et al., 2004</xref>), as functional connectivity in this network appeared normal in LG's brain. Thus, inputs to the APS from V5/MT+ can be sufficient for normal biological motion perception despite abnormal ventral stream function.</p>
      <p>In contrast to his ability to perform well on biological motion tasks, LG showed impairments in processing non-biological form from motion. In Experiments 2 and 3, we found significant differences between LG and controls for non-biological object motion processing. These experiments also utilized different tasks in order to allow us to ascertain any deficits were not task-specific. Whereas the stimuli in Experiment 2 were two dimensional shapes that translated, LG still exhibited difficulty with non-biological object motion when we used three dimensional objects that carried out more object-characterizing movements (<xref rid="bib0195" ref-type="bibr">Singer &amp; Sheinberg, 2008</xref>). Thus, LG's previously established deficits in form integration also extend to non-biological form from motion perception.</p>
      <p>The finding that biological motion processing can dissociate from form integration does not imply that biological motion operates independently of form processing in the healthy brain. In fact, several studies suggest this is unlikely (<xref rid="bib0110 bib0115 bib0230" ref-type="bibr">Lange, Georg, &amp; Lappe, 2006; Lange &amp; Lappe, 2006; Vangeneugden et al., 2009</xref>). However, the present findings show that biological motion can be processed successfully even with compromised ventral stream integration. Perhaps specific for biological motion, the brain appears to be able to compensate for the absence of the normal contribution ventral system makes in perceiving form from motion. It is possible that the visual system may compute biological motion largely relying on a form-based template matching strategy (<xref rid="bib0110 bib0115 bib0120" ref-type="bibr">Lange et al., 2006; Lange &amp; Lappe, 2006, 2007</xref>). In this framework, our data would indicate that these computations can be performed without reliance on ventral stream integration. <xref rid="bib0230" ref-type="bibr">Vangeneugden et al. (2009)</xref> recently discovered neurons in the STS that appear to be sensitive primarily to body posture rather than to the motion of biological motion stimuli (see also <xref rid="bib0100 bib0140" ref-type="bibr">Jellema &amp; Perrett, 2003; Oram &amp; Perrett, 1996</xref>). Given LG's functional neuroanatomy, it is possible that the form processing resources in lateral temporal cortex can be sufficient for biological motion processing. More generally, biological and non-biological form from motion processing may rely differentially on templates that are computed or stored in distinct brain areas (e.g., lateral temporal vs. ventral temporal areas).</p>
      <p>Taken together, these data indicate that normal inputs from V5/MT+ can be sufficient for the APS to process biological motion. In high-order ventral cortex, form inputs arriving from retinotopic regions are supported by motion cues from V5/MT+, to create a coherent percept (<xref rid="bib0055 bib0075 bib0200 bib0220" ref-type="bibr">Felleman &amp; Van Essen, 1991; Grill-Spector, Kushnir, Edelman, Itzchak, &amp; Malach, 1998; Singer &amp; Sheinberg, 2010; Ungerleider &amp; Desimone, 1986</xref>) but LG's case suggests that input from V5/MT+ cannot completely overcome the lack of inputs from intermediate retinotopic cortex.</p>
      <p>In conclusion, the present data demonstrate that although form from motion perception from point-light displays requires form integration, it is possible to process biological form from motion even if ventral stream integration is deficient. Our findings extend prior work showing biological motion can dissociate from other kinds of motion perception (e.g., <xref rid="bib0130 bib0175 bib0225" ref-type="bibr">McLeod, Dittrich, Driver, Perrett, &amp; Zihl, 1996; Saygin, 2007; Vaina, Lemay, Bienfang, Choi, &amp; Nakayama, 1990</xref>). In addition, we show that it can also dissociate from form integration. It is therefore possible that there are multiple (and flexible) substrates for biological motion processing, possibly due to the evolutionary importance of the domain.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ahlstrom</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Blake</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ahlstrom</surname>
              <given-names>U.</given-names>
            </name>
          </person-group>
          <article-title>Perception of biological motion</article-title>
          <source>Perception</source>
          <volume>26</volume>
          <issue>12</issue>
          <year>1997</year>
          <fpage>1539</fpage>
          <lpage>1548</lpage>
          <pub-id pub-id-type="pmid">9616481</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0010">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Hasson</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Detailed exploration of face-related processing in congenital prosopagnosia: 2. Functional neuroimaging findings</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <volume>17</volume>
          <issue>7</issue>
          <year>2005</year>
          <fpage>1150</fpage>
          <lpage>1167</lpage>
          <pub-id pub-id-type="pmid">16102242</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beintema</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Georg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Lappe</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perception of biological motion from limited-lifetime stimuli</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>68</volume>
          <issue>4</issue>
          <year>2006</year>
          <fpage>613</fpage>
          <lpage>624</lpage>
          <pub-id pub-id-type="pmid">16933426</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0020">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Blake</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Shiffrar</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perception of human motion</article-title>
          <source>Annual Review of Psychology</source>
          <volume>58</volume>
          <year>2007</year>
          <fpage>47</fpage>
          <lpage>73</lpage>
        </element-citation>
      </ref>
      <ref id="bib0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brainard</surname>
              <given-names>D.H.</given-names>
            </name>
          </person-group>
          <article-title>The Psychophysics Toolbox</article-title>
          <source>Spatial Vision</source>
          <volume>10</volume>
          <issue>4</issue>
          <year>1997</year>
          <fpage>433</fpage>
          <lpage>436</lpage>
          <pub-id pub-id-type="pmid">9176952</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bruce</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Desimone</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Gross</surname>
              <given-names>C.G.</given-names>
            </name>
          </person-group>
          <article-title>Visual properties of neurons in a polysensory area in superior temporal sulcus of the macaque</article-title>
          <source>Journal of Neurophysiology</source>
          <volume>46</volume>
          <issue>2</issue>
          <year>1981</year>
          <fpage>369</fpage>
          <lpage>384</lpage>
          <pub-id pub-id-type="pmid">6267219</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cavanagh</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Labianca</surname>
              <given-names>A.T.</given-names>
            </name>
            <name>
              <surname>Thornton</surname>
              <given-names>I.M.</given-names>
            </name>
          </person-group>
          <article-title>Attention-based visual routines: Sprites</article-title>
          <source>Cognition</source>
          <volume>80</volume>
          <issue>1–2</issue>
          <year>2001</year>
          <fpage>47</fpage>
          <lpage>60</lpage>
          <pub-id pub-id-type="pmid">11245839</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Corballis</surname>
              <given-names>M.C.</given-names>
            </name>
          </person-group>
          <article-title>Comparing a single case with a control sample: Refinements and extensions</article-title>
          <source>Neuropsychologia</source>
          <volume>47</volume>
          <issue>13</issue>
          <year>2009</year>
          <fpage>2687</fpage>
          <lpage>2689</lpage>
          <pub-id pub-id-type="pmid">19383504</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Crawford</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Garthwaite</surname>
              <given-names>P.H.</given-names>
            </name>
            <name>
              <surname>Howell</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>On comparing a single case with a control sample: An alternative perspective</article-title>
          <source>Neuropsychologia</source>
          <volume>47</volume>
          <issue>13</issue>
          <year>2009</year>
          <fpage>2690</fpage>
          <lpage>2695</lpage>
          <pub-id pub-id-type="pmid">19383506</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dittrich</surname>
              <given-names>W.H.</given-names>
            </name>
            <name>
              <surname>Troscianko</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Lea</surname>
              <given-names>S.E.</given-names>
            </name>
            <name>
              <surname>Morgan</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Perception of emotion from dynamic point-light displays represented in dance</article-title>
          <source>Perception</source>
          <volume>25</volume>
          <issue>6</issue>
          <year>1996</year>
          <fpage>727</fpage>
          <lpage>738</lpage>
          <pub-id pub-id-type="pmid">8888304</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0055">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Felleman</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>
          <source>Cerebral Cortex</source>
          <volume>1</volume>
          <issue>1</issue>
          <year>1991</year>
          <fpage>1</fpage>
          <lpage>47</lpage>
          <pub-id pub-id-type="pmid">1822724</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Grasby</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
          </person-group>
          <article-title>Analysis of fMRI time-series revisited</article-title>
          <source>Neuroimage</source>
          <volume>2</volume>
          <issue>1</issue>
          <year>1995</year>
          <fpage>45</fpage>
          <lpage>53</lpage>
          <pub-id pub-id-type="pmid">9343589</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Giese</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Poggio</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Neural mechanisms for the recognition of biological movements</article-title>
          <source>Nature Reviews Neuroscience</source>
          <volume>4</volume>
          <issue>3</issue>
          <year>2003</year>
          <fpage>179</fpage>
          <lpage>192</lpage>
        </element-citation>
      </ref>
      <ref id="bib0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gilaie-Dotan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Perry</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bonneh</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bentin</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Seeing with profoundly deactivated mid-level visual areas: Non-hierarchical functioning in the human visual cortex</article-title>
          <source>Cerebral Cortex</source>
          <volume>19</volume>
          <issue>7</issue>
          <year>2009</year>
          <fpage>1687</fpage>
          <lpage>1703</lpage>
          <pub-id pub-id-type="pmid">19015369</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0075">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kushnir</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Edelman</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Itzchak</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Cue-invariant activation in object-related areas of the human occipital lobe</article-title>
          <source>Neuron</source>
          <volume>21</volume>
          <issue>1</issue>
          <year>1998</year>
          <fpage>191</fpage>
          <lpage>202</lpage>
          <pub-id pub-id-type="pmid">9697863</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grossman</surname>
              <given-names>E.D.</given-names>
            </name>
            <name>
              <surname>Blake</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Brain activity evoked by inverted and imagined biological motion</article-title>
          <source>Vision Research</source>
          <volume>41</volume>
          <issue>10–11</issue>
          <year>2001</year>
          <fpage>1475</fpage>
          <lpage>1482</lpage>
          <pub-id pub-id-type="pmid">11322987</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0085">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grossman</surname>
              <given-names>E.D.</given-names>
            </name>
            <name>
              <surname>Blake</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Brain areas active during visual perception of biological motion</article-title>
          <source>Neuron</source>
          <volume>35</volume>
          <issue>6</issue>
          <year>2002</year>
          <fpage>1167</fpage>
          <lpage>1175</lpage>
          <pub-id pub-id-type="pmid">12354405</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hasson</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Harel</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Levy</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Large-scale mirror-symmetry organization of human occipito-temporal object areas</article-title>
          <source>Neuron</source>
          <volume>37</volume>
          <year>2003</year>
          <fpage>1027</fpage>
          <lpage>1041</lpage>
          <pub-id pub-id-type="pmid">12670430</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hiris</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Detection of biological and nonbiological motion</article-title>
          <source>Journal of Vision</source>
          <volume>7</volume>
          <issue>12</issue>
          <year>2007</year>
          <fpage>1</fpage>
          <lpage>16</lpage>
          <comment>(4)</comment>
          <pub-id pub-id-type="pmid">17997646</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jellema</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.I.</given-names>
            </name>
          </person-group>
          <article-title>Cells in monkey STS responsive to articulated body motions and consequent static posture: A case of implied motion?</article-title>
          <source>Neuropsychologia</source>
          <volume>41</volume>
          <issue>13</issue>
          <year>2003</year>
          <fpage>1728</fpage>
          <lpage>1737</lpage>
          <pub-id pub-id-type="pmid">14527537</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johansson</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Visual perception of biological motion and a model for its analysis</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>14</volume>
          <year>1973</year>
          <fpage>201</fpage>
          <lpage>211</lpage>
        </element-citation>
      </ref>
      <ref id="bib0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lange</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Georg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Lappe</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Visual perception of biological motion by form: A template-matching analysis</article-title>
          <source>Journal of Vision</source>
          <volume>6</volume>
          <issue>8</issue>
          <year>2006</year>
          <fpage>836</fpage>
          <lpage>849</lpage>
          <pub-id pub-id-type="pmid">16895462</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0115">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lange</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lappe</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A model of biological motion perception from configural form cues</article-title>
          <source>Journal of Neuroscience</source>
          <volume>26</volume>
          <issue>11</issue>
          <year>2006</year>
          <fpage>2894</fpage>
          <lpage>2906</lpage>
          <pub-id pub-id-type="pmid">16540566</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0120">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lange</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lappe</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The role of spatial and temporal information in biological motion perception</article-title>
          <source>Advances in Cognitive Psychology</source>
          <volume>3</volume>
          <issue>4</issue>
          <year>2007</year>
          <fpage>419</fpage>
          <lpage>428</lpage>
          <pub-id pub-id-type="pmid">20517525</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0125">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lerner</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Hendler</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Object-completion effects in the human lateral occipital complex</article-title>
          <source>Cerebral Cortex</source>
          <volume>12</volume>
          <issue>2</issue>
          <year>2002</year>
          <fpage>163</fpage>
          <lpage>177</lpage>
          <pub-id pub-id-type="pmid">11739264</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0130">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McLeod</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Dittrich</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Zihl</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Preserved and impaired detection of structure from motion by a “motion blind” patient</article-title>
          <source>Visual Cognition</source>
          <volume>3</volume>
          <year>1996</year>
          <fpage>363</fpage>
          <lpage>391</lpage>
        </element-citation>
      </ref>
      <ref id="bib0135">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Neri</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Morrone</surname>
              <given-names>M.C.</given-names>
            </name>
            <name>
              <surname>Burr</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Seeing biological motion</article-title>
          <source>Nature</source>
          <volume>395</volume>
          <issue>6705</issue>
          <year>1998</year>
          <fpage>894</fpage>
          <lpage>896</lpage>
          <pub-id pub-id-type="pmid">9804421</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0140">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oram</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.I.</given-names>
            </name>
          </person-group>
          <article-title>Integration of form and motion in the anterior superior temporal polysensory area (STPa) of the macaque monkey</article-title>
          <source>Journal of Neurophysiology</source>
          <volume>76</volume>
          <issue>1</issue>
          <year>1996</year>
          <fpage>109</fpage>
          <lpage>129</lpage>
          <pub-id pub-id-type="pmid">8836213</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pavlova</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sokolov</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Prior knowledge about display inversion in biological motion perception</article-title>
          <source>Perception</source>
          <volume>32</volume>
          <issue>8</issue>
          <year>2003</year>
          <fpage>937</fpage>
          <lpage>946</lpage>
          <pub-id pub-id-type="pmid">14580140</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0150">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pelli</surname>
              <given-names>D.G.</given-names>
            </name>
          </person-group>
          <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>
          <source>Spatial Vision</source>
          <volume>10</volume>
          <issue>4</issue>
          <year>1997</year>
          <fpage>437</fpage>
          <lpage>442</lpage>
          <pub-id pub-id-type="pmid">9176953</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0155">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Perry</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Troje</surname>
              <given-names>N.F.</given-names>
            </name>
            <name>
              <surname>Bentin</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Exploring motor system contributions to the perception of social information: Evidence from EEG activity in the mu/alpha frequency range</article-title>
          <source>Social Cognitive &amp; Affective Neuroscience</source>
          <volume>5</volume>
          <issue>3</issue>
          <year>2010</year>
          <fpage>272</fpage>
          <lpage>284</lpage>
        </element-citation>
      </ref>
      <ref id="bib0160">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pollick</surname>
              <given-names>F.E.</given-names>
            </name>
            <name>
              <surname>Paterson</surname>
              <given-names>H.M.</given-names>
            </name>
            <name>
              <surname>Bruderlin</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Sanford</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Perceiving affect from arm movement</article-title>
          <source>Cognition</source>
          <volume>82</volume>
          <issue>2</issue>
          <year>2001</year>
          <fpage>B51</fpage>
          <lpage>B61</lpage>
          <pub-id pub-id-type="pmid">11716834</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0165">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiology and brain imaging of biological motion</article-title>
          <source>Philosophical Transactions of the Royal Society of London Series B—Biological Sciences</source>
          <volume>358</volume>
          <issue>1431</issue>
          <year>2003</year>
          <fpage>435</fpage>
          <lpage>445</lpage>
        </element-citation>
      </ref>
      <ref id="bib0170">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rizzolatti</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Sinigaglia</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>The functional role of the parieto-frontal mirror circuit: Interpretations and misinterpretations</article-title>
          <source>Nature Reviews Neuroscience</source>
          <volume>11</volume>
          <issue>4</issue>
          <year>2010</year>
          <fpage>264</fpage>
          <lpage>274</lpage>
        </element-citation>
      </ref>
      <ref id="bib0175">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saygin</surname>
              <given-names>A.P.</given-names>
            </name>
          </person-group>
          <article-title>Superior temporal and premotor brain areas necessary for biological motion perception</article-title>
          <source>Brain</source>
          <volume>130</volume>
          <issue>Pt 9</issue>
          <year>2007</year>
          <fpage>2452</fpage>
          <lpage>2461</lpage>
          <pub-id pub-id-type="pmid">17660183</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0180">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saygin</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Cook</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Blakemore</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>Unaffected perceptual thresholds for biological and non-biological form-from-motion perception in autism spectrum conditions</article-title>
          <source>PLoS One</source>
          <volume>5</volume>
          <issue>10</issue>
          <year>2010</year>
          <fpage>e13491</fpage>
          <pub-id pub-id-type="pmid">20976151</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saygin</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>de Sa</surname>
              <given-names>V.R.</given-names>
            </name>
          </person-group>
          <article-title>In the footsteps of biological motion and multisensory perception: Judgments of audiovisual temporal relations are enhanced for upright walkers</article-title>
          <source>Psychological Science</source>
          <volume>19</volume>
          <issue>5</issue>
          <year>2008</year>
          <fpage>469</fpage>
          <lpage>475</lpage>
          <pub-id pub-id-type="pmid">18466408</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0190">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saygin</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Wilson</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Hagler</surname>
              <given-names>D.J.</given-names>
              <suffix>Jr.</suffix>
            </name>
            <name>
              <surname>Bates</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Sereno</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Point-light biological motion perception activates human premotor cortex</article-title>
          <source>Journal of Neuroscience</source>
          <volume>24</volume>
          <issue>27</issue>
          <year>2004</year>
          <fpage>6181</fpage>
          <lpage>6188</lpage>
          <pub-id pub-id-type="pmid">15240810</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0195">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Singer</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Sheinberg</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>A method for the real-time rendering of formless dot field structure-from-motion stimuli</article-title>
          <source>Journal of Vision</source>
          <volume>8</volume>
          <issue>5</issue>
          <year>2008</year>
          <fpage>1</fpage>
          <lpage>8</lpage>
          <comment>(8)</comment>
          <pub-id pub-id-type="pmid">18842079</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0200">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Singer</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Sheinberg</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Temporal cortex neurons encode articulated actions as slow sequences of integrated poses</article-title>
          <source>Journal of Neuroscience</source>
          <volume>30</volume>
          <issue>8</issue>
          <year>2010</year>
          <fpage>3133</fpage>
          <lpage>3145</lpage>
          <pub-id pub-id-type="pmid">20181610</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0205">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sumi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Upside-down presentation of the Johansson moving light-spot pattern</article-title>
          <source>Perception</source>
          <volume>13</volume>
          <issue>3</issue>
          <year>1984</year>
          <fpage>283</fpage>
          <lpage>286</lpage>
          <pub-id pub-id-type="pmid">6514513</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0210">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thurman</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Grossman</surname>
              <given-names>E.D.</given-names>
            </name>
          </person-group>
          <article-title>Temporal “Bubbles” reveal key features for point-light biological motion perception</article-title>
          <source>Journal of Vision</source>
          <volume>8</volume>
          <issue>3</issue>
          <year>2008</year>
          <fpage>1</fpage>
          <lpage>11</lpage>
          <comment>(28)</comment>
          <pub-id pub-id-type="pmid">18484834</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0215">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Troje</surname>
              <given-names>N.F.</given-names>
            </name>
          </person-group>
          <article-title>Decomposing biological motion: A framework for analysis and synthesis of human gait patterns</article-title>
          <source>Journal of Vision</source>
          <volume>2</volume>
          <issue>5</issue>
          <year>2002</year>
          <fpage>371</fpage>
          <lpage>387</lpage>
          <pub-id pub-id-type="pmid">12678652</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0220">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ungerleider</surname>
              <given-names>L.G.</given-names>
            </name>
            <name>
              <surname>Desimone</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Cortical connections of visual area MT in the macaque</article-title>
          <source>Journal of Comparative Neurology</source>
          <volume>248</volume>
          <issue>2</issue>
          <year>1986</year>
          <fpage>190</fpage>
          <lpage>222</lpage>
          <pub-id pub-id-type="pmid">3722458</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0225">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vaina</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Lemay</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bienfang</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Choi</surname>
              <given-names>A.Y.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Intact “biological motion” and “structure from motion” perception in a patient with impaired motion mechanisms: A case study</article-title>
          <source>Visual Neuroscience</source>
          <volume>5</volume>
          <issue>4</issue>
          <year>1990</year>
          <fpage>353</fpage>
          <lpage>369</lpage>
          <pub-id pub-id-type="pmid">2265150</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vangeneugden</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Pollick</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Vogels</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Functional differentiation of macaque visual temporal cortical neurons using a parametric action space</article-title>
          <source>Cerebral Cortex</source>
          <volume>19</volume>
          <issue>3</issue>
          <year>2009</year>
          <fpage>593</fpage>
          <lpage>611</lpage>
          <pub-id pub-id-type="pmid">18632741</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0235">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watson</surname>
              <given-names>A.B.</given-names>
            </name>
            <name>
              <surname>Pelli</surname>
              <given-names>D.G.</given-names>
            </name>
          </person-group>
          <article-title>QUEST: A Bayesian adaptive psychometric method</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>33</volume>
          <issue>2</issue>
          <year>1983</year>
          <fpage>113</fpage>
          <lpage>120</lpage>
          <pub-id pub-id-type="pmid">6844102</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="sec0185" sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p>
        <supplementary-material content-type="local-data" id="upi0005">
          <media xlink:href="mmc1.doc" mimetype="application" mime-subtype="msword"/>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="upi0010">
          <media xlink:href="mmc2.gif" mimetype="text" mime-subtype="plain"/>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="upi0015">
          <media xlink:href="mmc3.gif" mimetype="text" mime-subtype="plain"/>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="upi0020">
          <media xlink:href="mmc4.gif" mimetype="text" mime-subtype="plain"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgements</title>
      <p>This work was funded by a European Commission Marie-Curie fellowship to S.G.-D., RO1 MH 64458 to S.B., the Wellcome Trust (G.R.) and a European Commission Marie Curie fellowship FP6-025044 to A.P.S. We thank LG and his family for outstandingly friendly cooperation, Jennifer Cook and Sarah-Jayne Blakemore for help with acquiring some of the controls’ data and Marlene Behrmann for helpful suggestions.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="fig0005">
      <label>Fig. 1</label>
      <caption>
        <p>Functional organization of LG's visual cortex on flattened cortical maps. (A) Delineation of LG's visual system organization (see <xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>) displaying normal V1 and V5/MT+ response patterns (indicated by green contours), abnormal deactivations in intermediate visual regions (red contours). LG's dorsal stream appeared normal (dotted green). His ventral stream lateral occipital areas were activated above normal, but did not display the expected sensitivity to object stimuli (dotted red). (B) Functional connectivity of LG's right V5/MT+ (delineated in black contour) to the fronto-parietal nodes of the action perception system (APS) during viewing movie clips that included biological motion (see Section <xref rid="sec0130" ref-type="sec">6.1</xref>). Yellow to orange patches display regions that were significantly correlated with LG's right V5/MT+ activity while he was watching the video clips (<italic>r</italic> &gt;  = 0.377, <italic>p</italic><sub>corrected</sub> &lt; = 0.0001). LG's V5/MT+ functional connectivity pattern to the APS resembles the one seen in the normal brain (e.g., <xref rid="bib0190" ref-type="bibr">Saygin et al., 2004</xref>), in contrast to his intermediate visual cortical areas (shaded in turquoise). (C) Structural images of LG's brain. No discernable cortical abnormality was detected (<xref rid="bib0070" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>). IPS – intraparietal sulcus, PreCS – precentral sulcus, IFS – inferior frontal sulcus, STS – superior temporal sulcus, LS – lateral sulcus, CS – central sulcus, RH – right hemisphere, LH – left hemisphere, P – posterior, A – anterior, D – dorsal, V – ventral. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig0010">
      <label>Fig. 2</label>
      <caption>
        <p>Experiment 1: paradigm and results. (A) Example frames from the stimuli used in the experiment (<xref rid="bib0175" ref-type="bibr">Saygin, 2007</xref>). Top: Three still frames from one of the human motions used (see <xref rid="sec0185" ref-type="sec">Supplementary Materials</xref> for animations). Bottom: Scrambled version of the human motion (see text). Human motion and its scrambled version were presented simultaneously on either side of the screen and participants had to determine the side in which the human motion was presented, without time restrictions. Noise points were added in an adaptive manner to both animations to reach 82% accuracy. (B) Results showing the estimated thresholds (in number of noise points) for LG (gray) and 13 age-matched controls (white). LG's performance was within the normal range. Error bar indicates one standard deviation.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig0015">
      <label>Fig. 3</label>
      <caption>
        <p>Experiment 2: paradigm and results. (A) Examples (snapshots) of the targets from the three conditions. BM condition comprised of a point-light walker, nonBMO comprised a translating rectangle, and the nonBMU comprised a translating unstructured object. Participants had to determine whether the target was moving to the right or to the left while it was masked by an adaptive amount of noise points moving to both directions (see text). (B) Results showing the estimated thresholds (in number of noise points) for LG (gray) and 21 age-matched controls (white) for each of the conditions. LG's performance for biological motion (BM) was within the normal range (left), for the structured form translation (nonBMO) he was significantly below controls (middle, denoted by an asterisk), and for the unstructured form (nonBMU) within controls’ range (right). Error bars indicate one standard deviation.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig0020">
      <label>Fig. 4</label>
      <caption>
        <p>Experiment 3: paradigm and results. (A) Top: Snapshots of the random point/dot field stimuli of four conditions (FstRot, MedRot, SlwRot, and vSlwRot) varying the rotation speed of the object. Bottom: A depiction of the percept formed in normal observers by the local motion cues that are due to the object rotation. At very slow rotation speeds (vSlwRot condition and slower (data not shown)), the percept is reduced (depicted by a transparent object). Objects were spheres or cylinders rotating clockwise or anticlockwise (see Section <xref rid="sec0085" ref-type="sec">5.1</xref> for further details). (B) Object recognition accuracy for LG (gray) and controls (white). An asterisk indicates significant reduction in performance in LG relative to controls (<italic>p</italic> &lt; 0.005). Full details are provided in <xref rid="tbl0010" ref-type="table">Table 2</xref>. (C) Object detection accuracy levels (same format as in B). (D–F) Same as in A–C, when the number of points defining the random point/dot field are being varied (conditions 1600pnt, 500pnt, 100pnt, and 50pnt).</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <table-wrap id="tbl0005" position="float">
      <label>Table 1</label>
      <caption>
        <p>Schematic description of LG's perception and brain function of motion and form.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th align="left">Motion</th>
            <th align="left">Form</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="2" align="left">Behaviour</td>
            <td align="left"><italic>Normal</italic> (self report)</td>
            <td align="left">
              <italic>Deficient</italic>
            </td>
          </tr>
          <tr>
            <td align="left">“I recognize people by the way they walk”</td>
            <td align="left">e.g., Hooper Visual Organization Test: <italic>high probability of impairment</italic></td>
          </tr>
          <tr>
            <td colspan="3" align="left">  </td>
          </tr>
          <tr>
            <td rowspan="2" align="left">Brain</td>
            <td align="left"><italic>Normal</italic> V5/MT+ motion sensitivity</td>
            <td align="left"><italic>Abnormal</italic> visual hierarchy activations (from intermediate visual regions)</td>
          </tr>
          <tr>
            <td align="left"><italic>Normal</italic> V5/MT+ functional connectivity to ASP (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>)</td>
            <td align="left"><italic>Abnormal</italic> form sensitivity in ventral cortex (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>)</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="tbl0010" position="float">
      <label>Table 2</label>
      <caption>
        <p>Experiment 3: detailed results and statistical analysis. Results in bold indicate conditions that LG performed significantly below controls.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">No. of points</th>
            <th align="left">Rotation/s</th>
            <th align="left">Condition name</th>
            <th align="left">Task</th>
            <th colspan="3" align="left">Accuracy<hr/></th>
            <th align="left"><italic>t</italic>(7)<sub>Crawford</sub></th>
            <th align="left">
              <italic>p</italic>
              <sub>Crawford</sub>
            </th>
            <th align="left"><italic>t</italic>(7)<sub>Crawford</sub></th>
            <th align="left">
              <italic>p</italic>
              <sub>Corballis</sub>
            </th>
          </tr>
          <tr>
            <th/>
            <th/>
            <th/>
            <th/>
            <th align="left">Controls (mean)</th>
            <th align="left">Controls (S.D.)</th>
            <th align="left">LG</th>
            <th/>
            <th/>
            <th/>
            <th/>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="6" align="left">1600</td>
            <td rowspan="2" align="left">0.5</td>
            <td rowspan="2" align="left">FstRot/1600pnt</td>
            <td align="left">Recognize</td>
            <td align="char">100</td>
            <td align="char">0</td>
            <td align="char">100</td>
            <td align="char">0</td>
            <td align="left">1</td>
            <td align="char">0</td>
            <td align="left">1</td>
          </tr>
          <tr>
            <td align="left">
              <italic>Detect</italic>
            </td>
            <td align="char">
              <italic>99.38</italic>
            </td>
            <td align="char">
              <italic>1.77</italic>
            </td>
            <td align="char">
              <italic>100</italic>
            </td>
            <td align="char">
              <italic>0.33</italic>
            </td>
            <td align="left">
              <italic>0.75</italic>
            </td>
            <td align="char">
              <italic>0.35</italic>
            </td>
            <td align="left">
              <italic>0.73</italic>
            </td>
          </tr>
          <tr>
            <td align="left">0.0833</td>
            <td align="left">MedRot</td>
            <td align="left">Recognize</td>
            <td align="char">99.38</td>
            <td align="char">1.77</td>
            <td align="char">100</td>
            <td align="char">0.33</td>
            <td align="left">0.75</td>
            <td align="char">0.35</td>
            <td align="left">0.73</td>
          </tr>
          <tr>
            <td align="left">0.0167</td>
            <td align="left">SlwRot</td>
            <td align="left">Recognize</td>
            <td align="char">100</td>
            <td align="char">0</td>
            <td align="char">
              <bold>50</bold>
            </td>
            <td align="char">
              <bold>−4714</bold>
            </td>
            <td align="left">
              <bold>5 × 10</bold>
              <sup>
                <bold>−24</bold>
              </sup>
            </td>
            <td align="char">
              <bold>−5000</bold>
            </td>
            <td align="left">
              <bold>4 × 10</bold>
              <sup>
                <bold>−24</bold>
              </sup>
            </td>
          </tr>
          <tr>
            <td align="left">0.0033</td>
            <td rowspan="2" align="left">vSlwRot</td>
            <td align="left">Recognize</td>
            <td align="char">91.25</td>
            <td align="char">9.54</td>
            <td align="char">
              <bold>50</bold>
            </td>
            <td align="char">
              <bold>−4.075</bold>
            </td>
            <td align="left">
              <bold>0.0047</bold>
            </td>
            <td align="char">
              <bold>−4.322</bold>
            </td>
            <td align="left">
              <bold>0.0035</bold>
            </td>
          </tr>
          <tr>
            <td/>
            <td align="left">
              <italic>Detect</italic>
            </td>
            <td align="char">
              <italic>96.25</italic>
            </td>
            <td align="char">
              <italic>8.76</italic>
            </td>
            <td align="char">
              <italic>100</italic>
            </td>
            <td align="char">
              <italic>0.40</italic>
            </td>
            <td align="left">
              <italic>0.70</italic>
            </td>
            <td align="char">
              <italic>0.428</italic>
            </td>
            <td align="left">
              <italic>0.68</italic>
            </td>
          </tr>
          <tr>
            <td colspan="11" align="left">  </td>
          </tr>
          <tr>
            <td align="left">500</td>
            <td rowspan="4" align="left">0.5</td>
            <td align="left">500pnt</td>
            <td align="left">Recognize</td>
            <td align="char">100</td>
            <td align="char">0</td>
            <td align="char">100</td>
            <td align="char">0</td>
            <td align="left">1</td>
            <td align="char">0</td>
            <td align="left">1</td>
          </tr>
          <tr>
            <td rowspan="2" align="left">100</td>
            <td rowspan="2" align="left">100pnt</td>
            <td align="left">Recognize</td>
            <td align="char">98.13</td>
            <td align="char">2.59</td>
            <td align="char">
              <bold>65</bold>
            </td>
            <td align="char">
              <bold>−12.07</bold>
            </td>
            <td align="left">
              <bold>6.12 × 10</bold>
              <sup>
                <bold>−6</bold>
              </sup>
            </td>
            <td align="char">
              <bold>−12.8</bold>
            </td>
            <td align="left">
              <bold>4.12 × 10</bold>
              <sup>
                <bold>−6</bold>
              </sup>
            </td>
          </tr>
          <tr>
            <td align="left">
              <italic>Detect</italic>
            </td>
            <td align="char">
              <italic>98.75</italic>
            </td>
            <td align="char">
              <italic>2.31</italic>
            </td>
            <td align="char">
              <italic>100</italic>
            </td>
            <td align="char">
              <italic>0.51</italic>
            </td>
            <td align="left">
              <italic>0.63</italic>
            </td>
            <td align="char">
              <italic>0.54</italic>
            </td>
            <td align="left">
              <italic>0.61</italic>
            </td>
          </tr>
          <tr>
            <td align="left">50</td>
            <td align="left">50pnt</td>
            <td align="left">Recognize</td>
            <td align="char">90</td>
            <td align="char">12.82</td>
            <td/>
            <td/>
            <td/>
            <td/>
            <td/>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </floats-group>
</article>