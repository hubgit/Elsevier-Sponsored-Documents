<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3081064</article-id>
      <article-id pub-id-type="pmid">20624471</article-id>
      <article-id pub-id-type="publisher-id">YNIMG7465</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.004</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Flow of affective information between communicating brains</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Anders</surname>
            <given-names>Silke</given-names>
          </name>
          <email>silke.anders@neuro.uni-luebeck.de</email>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="cr0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Heinzle</surname>
            <given-names>Jakob</given-names>
          </name>
          <xref rid="af0010" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Weiskopf</surname>
            <given-names>Nikolaus</given-names>
          </name>
          <xref rid="af0015" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ethofer</surname>
            <given-names>Thomas</given-names>
          </name>
          <xref rid="af0020" ref-type="aff">d</xref>
          <xref rid="fn0005" ref-type="fn">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Haynes</surname>
            <given-names>John-Dylan</given-names>
          </name>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="af0025" ref-type="aff">e</xref>
          <xref rid="fn0005" ref-type="fn">1</xref>
        </contrib>
      </contrib-group>
      <aff id="af0005"><label>a</label>Department of Neurology and Neuroimage Nord, University of Lübeck, Lübeck, Germany</aff>
      <aff id="af0010"><label>b</label>Bernstein Center for Computational Neuroscience Berlin, Charité-Universitätsmedizin, Berlin, Germany</aff>
      <aff id="af0015"><label>c</label>Wellcome Trust Centre for Neuroimaging, UCL Institute of Neurology, University College London, London, UK</aff>
      <aff id="af0020"><label>d</label>Department of Psychiatry, University of Tübingen, Tübingen, Germany</aff>
      <aff id="af0025"><label>e</label>Max-Planck-Institute for Human Cognitive and Brain Sciences, Leipzig, Germany</aff>
      <author-notes>
        <corresp id="cr0005"><label>⁎</label>Corresponding author. Department of Neurology and Neuroimage Nord, University of Lübeck, Ratzeburger Alle 160, 23538 Lübeck, Germany. <email>silke.anders@neuro.uni-luebeck.de</email></corresp>
        <fn id="fn0005">
          <label>1</label>
          <p>These authors contributed equally.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>01</day>
        <month>1</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>1</month>
        <year>2011</year>
      </pub-date>
      <volume>54</volume>
      <issue>1-4</issue>
      <fpage>439</fpage>
      <lpage>446</lpage>
      <history>
        <date date-type="received">
          <day>28</day>
          <month>4</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>23</day>
          <month>6</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>5</day>
          <month>7</month>
          <year>2010</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 Elsevier Inc.</copyright-statement>
        <copyright-year>2010</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>When people interact, affective information is transmitted between their brains. Modern imaging techniques permit to investigate the dynamics of this brain-to-brain transfer of information. Here, we used information-based functional magnetic resonance imaging (fMRI) to investigate the flow of affective information between the brains of senders and perceivers engaged in ongoing facial communication of affect. We found that the level of neural activity within a distributed network of the perceiver's brain can be successfully predicted from the neural activity in the same network in the sender's brain, depending on the affect that is currently being communicated. Furthermore, there was a temporal succession in the flow of affective information from the sender's brain to the perceiver's brain, with information in the perceiver's brain being significantly delayed relative to information in the sender's brain. This delay decreased over time, possibly reflecting some ‘tuning in’ of the perceiver with the sender. Our data support current theories of intersubjectivity by providing direct evidence that during ongoing facial communication a ‘shared space’ of affect is successively built up between senders and perceivers of affective facial signals.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Research highlights</title>
        <p>►Information-based neuroimaging is used to map flow of affective information between brains. ►Information is encoded in a ‘shared network’ in the brains of senders and perceivers. ►Dynamics of information flow suggest some ‘tuning-in’ of the perceiver with the sender.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>fMRI</kwd>
        <kwd>Decoding</kwd>
        <kwd>Emotion</kwd>
        <kwd>Communication</kwd>
        <kwd>Facial expression</kwd>
        <kwd>Embodied simulation</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="s0005">
      <title>Introduction</title>
      <p>Exchange of information between brains is essential for successful human interaction. Interaction partners must continuously update information about their partner's inner state, intentions, motivation and affect, in order to anticipate the other one's behaviour and to adapt their own behaviour accordingly. One mechanism that has been proposed to play an important role in exchange of affective information between individuals is ‘embodied simulation’ (<xref rid="bb0070" ref-type="bibr">Gallese, 2003</xref>; see also <xref rid="bb0150 bb0005 bb0050 bb0020 bb0110" ref-type="bibr">Lipps, 1903; Adolphs et al., 2000; Decety and Jackson, 2004; Bastiaansen et al., 2009; Iacoboni, 2009</xref>). The idea is that when people observe another person's affective behaviour, their facial expression, gesture or movement, this automatically activates a ‘mirror’ representation of the other person's affect in the perceiver's brain. In other words, experiencing and perceiving affect are thought to activate similar neural networks, creating a ‘shared space of affect’ between senders and perceivers of affective information.</p>
      <p>A number of neuroimaging studies have found evidence that is consistent with the idea that ‘embodied stimulation’ plays a role in the exchange of affective information between brains. For example, it has been shown that when volunteers observe another person receiving a painful stimulus they activate part of a ‘pain network’ that is also activated when the volunteers themselves receive a painful stimulus (<xref rid="bb0160 bb0200 bb0025" ref-type="bibr">Morrison et al., 2004; Singer et al., 2004; Botvinick et al., 2005</xref>). Other studies provide evidence that a region in the anterior insula is recruited both when people experience disgust and when they observe another person experiencing disgust (<xref rid="bb0035 bb0220" ref-type="bibr">Calder et al., 2000; Wicker et al., 2003</xref>). More generally, it has been suggested that observing a facial expression of affect activates part of a somato-motor network that is also activated when volunteers express their own affect (<xref rid="bb0040 bb0135 bb0100 bb0210" ref-type="bibr">Carr et al., 2003; Leslie et al., 2004; Hennenlotter et al., 2005; van der Gaag et al., 2007</xref>).</p>
      <p>However, it has to date remained unclear whether these networks indeed carry similar affect-specific information in the sender and perceiver. Moreover, if ‘embodied simulation’ plays a role in the brain-to-brain transfer of affective information, then there should be a temporal succession of information in these networks from the sender to the perceiver. These temporal dynamics can only be studied by comparing brain processes in two individuals engaged in ongoing affective communication. We used information-based functional magnetic resonance imaging (fMRI) (<xref rid="bb0090 bb0095 bb0125 bb0165" ref-type="bibr">Haxby et al., 2001; Haynes and Rees, 2006; Kriegeskorte et al., 2006; Norman et al., 2006</xref>) to directly investigate the dynamics of the flow of information between the brains of senders and perceivers engaged in facial communication of affect. First, we aimed to identify a ‘shared network’ of affect that carries similar <italic>information</italic> in both the sender and the perceiver that is <italic>specific to the emotion</italic> that is currently being communicated. Second, we tested whether there was a <italic>temporal succession</italic> in the flow of information from the sender's brain to the perceiver's brain.</p>
    </sec>
    <sec sec-type="methods" id="s0010">
      <title>Methods</title>
      <sec id="s0015">
        <title>Participants</title>
        <p>Because it has been suggested that exchange of affective information is strongest between closely attached individuals (<xref rid="bb0200" ref-type="bibr">Singer et al., 2004</xref>), we investigated the flow of affective information between romantic partners. Six different-sex couples (mean age of women 22 years, range 20 to 25 years, mean age of men 24 years, range 22 to 28 years) who had been engaged in a romantic relation for at least one year at the time of scanning (mean 2 years, range 1 to 4 years) participated in the study. All participants were right-handed and reported no history of neurological or psychiatric disorders. Participants gave their written informed consent prior to participation and the study was approved by the local ethics committee.</p>
      </sec>
      <sec id="s0020">
        <title>Experimental design</title>
        <p>Partners were invited together to the scanning facility. After a brief introduction, they were informed that they would be scanned simultaneously and that the perceiver would see the sender's facial expression online during scanning via a video-camera. Partners were then separated and the female partner was informed that her task would be to indulge herself into emotional situations and to facially express her emotional feelings as soon as they arose. The female partner was selected as sender because women have been shown to be more accurate senders of affect than men (<xref rid="bb0030" ref-type="bibr">Buck et al., 1974</xref>). Particular care was taken to ensure that the sender understood that she was not meant to pose emotional expressions but to try to share her emotional feelings with her romantic partner as they arose. The male partner was completely uninformed about the sender's task and was simply asked to watch the senders' facial expression and to try to feel with her (i.e. the male partner did not know that the sender was asked to submerge herself into emotional situations, please see <xref rid="s0090" ref-type="sec">Supplemental online material</xref> for the wording of the instructions). In fact, the sender's facial expression was videotaped throughout scanning and shown to the perceiver when he was scanned in the same scanner immediately after scanning of the sender had been completed.</p>
        <p>Scanning consisted of ten runs; each run comprised four 20 s-periods during which affective information was to be communicated, and five interspersed periods during which the sender was instructed to relax (24 s, 22 s, 18 s, 22 s, and 18 s) (<xref rid="f0005" ref-type="fig">Fig. 1</xref>). A single emotion (joy, anger, disgust, fear, or sadness) was used in each run in order to avoid rapid switches between conflicting emotions. A single printed word (e.g. ‘joy’) signalled emotion periods to the sender. The order of emotions was chosen by the sender, with the restriction that no emotion could occur twice in a row and that each emotion had to be chosen once before an emotion could be chosen a second time. Please note that the perceiver was uninformed about the timing within runs.</p>
      </sec>
      <sec id="s0025">
        <title>Data acquisition</title>
        <p>Ninety-two (92) functional images covering the whole brain were acquired during each run (T2*weighted echoplanar images, 1.5 Tesla Siemens Avanto, Erlangen, Germany; tilt angle −30°, 64 × 64 matrix, in plane resolution 3 × 3 mm², 24 axial slices, interleaved order, slice thickness 6 mm with no gap, TE 40 ms, TR 2000 ms). An fMRI-compatible video camera (<xref rid="bb0230" ref-type="bibr">Wild et al., 2000</xref>) was used to video-tape the sender's facial expression throughout scanning. Additionally, we recorded skin conductance responses (SCR) as a peripheral index of autonomic activity during scanning with standard commercial recording equipment (Varioport, Becker Meditec, Karlsruhe, Germany). Details of skin conductance data acquisition have been described elsewhere (<xref rid="bb0010" ref-type="bibr">Anders et al., 2004</xref>). Stimulus presentation and data collection were synchronised with Presentation software (Neurobehavioral Systems Inc., Albany, CA, USA). After each run, perceivers were asked via the intercom what they thought the sender might have been feeling, and if they thought that they had felt the same as the sender, and responses were protocolled word-by-word by one of the experimenters. Skin conductance responses and verbal reports served to confirm that participants showed emotional engagement during emotion periods. No explicit emotion recognition data were collected in order to avoid subject priming.</p>
      </sec>
      <sec id="s0030">
        <title>Analysis of behavioural data</title>
        <p>Usable SCR data were obtained from three senders and five perceivers. Data of the remaining individuals could not be analysed due to recording errors. For analysis, linear trends were removed from the time series of each run, and the average level of SCR during the 20 s-emotion periods was contrasted the average of a 4 s rest period before the onset of each emotion period.</p>
        <p>Word-by-word protocols recorded after each run were used to derive a measure of emotion recognition accuracy for each run. Emotion recognition was parameterized as '1' if the perceiver correctly named the sender's emotion, or gave a description that was correctly identified by two independent raters, and '0' otherwise. Chi-Square statistics tested for differences in emotion recognition between emotion types.</p>
      </sec>
      <sec id="s0035">
        <title>Analysis of fMRI data</title>
        <p>Preprocessing of functional images included slice acquisition time correction, concurrent spatial realignment and correction of image distortions by use of individual static field maps (<xref rid="bb0235" ref-type="bibr">Andersson et al., 2001</xref>), normalization into standard MNI space (Montreal Neurological Institute) and spatial smoothing (10 mm Gaussian kernel) (SPM5, Wellcome Department of Imaging Neuroscience, London, UK).</p>
        <sec id="s0040">
          <title>Voxel-wise classification analysis</title>
          <p>Previous studies have shown that levels of activity within a distributed network of brain regions differ, depending on the individual's affective state (e.g. <xref rid="bb0045 bb0175" ref-type="bibr">Damasio et al., 2000; Phan et al., 2002</xref>). Thus, to identify a ‘shared network’ for affective information we searched for voxels where the <italic>level of emotion-specific activity</italic> in the sender's brain was reflected in the perceiver's brain. For this purpose, we first computed an image of voxel-wise parameter estimates for each emotion period (i.e. each trial) using a general linear model as implemented in SPM5. This resulted in 40 parameter estimates (4 trials per run × 10 runs) for each voxel and participant. To prewhite data for the classification analysis, the global mean was subtracted from each image and the 40 parameter estimates for a given voxel were normalized to zero mean and unity across all emotion periods.</p>
          <p>Classification analysis was carried out separately for each voxel. First, in a given voxel, mean values were computed across the eight parameter estimates of each emotion (4 trials per run × 2 runs per emotion) for the sender (‘Training’). Second, these mean values were used to classify the perceiver's brain activity. The perceiver's brain response in a given emotion period was classified according to the smallest distances between the perceiver's brain response and these mean values (‘Test’) (<xref rid="s0090" ref-type="sec">Fig. S1 Supplemental online material</xref>). This approach is similar to a univariate k-nearest-neighbour classification except that classification is based on the nearest mean value instead of k nearest neighbours. This yielded a total of 40 binary classification accuracies per voxel. To derive a single measure of decoding accuracy per voxel for each sender-perceiver pair, voxel-wise classification accuracies were averaged across all trials.</p>
          <p>For group statistical inference, the images of voxel-wise decoding accuracies were subtracted with chance level (p = .20), spatially smoothed (10 mm Gaussian kernel) to allow for Random Field Theory statistical inference (<xref rid="bb0225" ref-type="bibr">Worsley et al., 1996</xref>), and fed into a one-sample T-test with random factor subject as implemented in SPM5. The resulting statistical parametric map (SPM) tested the H<sub>0</sub> that decoding accuracies were not greater than chance. Because previous work has shown that single voxels carry limited information only and that information is be encoded in extended brain regions (<xref rid="bb0170" ref-type="bibr">Pessoa and Padmala, 2007</xref>) we used a voxel-wise height threshold of T = 3.3 (corresponding to a probability of false positives of p = .01) and assessed statistical significance at cluster level (p = .01, corrected for multiple comparisons according to Random Field Theory [<xref rid="bb0225" ref-type="bibr">Worsley et al., 1996</xref>]; this corresponded to a minimal cluster size of 100 contiguous voxels). Please note, however, that the number and location of clusters was highly stable across different height thresholds.</p>
        </sec>
        <sec id="s0045">
          <title>Time-resolved classification analysis</title>
          <p>Next, we sought to investigate the temporal dynamics of the flow of affective information from the sender's brain to the perceiver's brain. Particularly, we were interested whether early information from the sender's brain was encoded early in the perceiver's brain, and late information from the sender's brain was encoded later in the perceiver's brain. This would indicate that there was a temporal succession in the flow of emotion-specific information from the sender's brain to the perceiver's brain. For this purpose we used a time-resolved multivariate decoder. As before, a classifier was trained on the sender's brain activity and tested on the perceiver's brain activity. However, the time-resolved classification analysis was based on intensity values in single functional images. After preprocessing, global means were removed from each image and voxel-wise intensities were normalized as described above. Functional images were then temporally aligned with respect to the onset of an emotion period. This resulted in 40 time series (10 runs × 4 emotion periods per run) of 18 functional images per subject, each covering a 36 s-time interval from 2 scans before the onset of an emotion period to 6 scans after offset of the emotion period.</p>
          <p>Because we were interested in the temporal dynamics with which information in voxels known to carry emotion-specific information (i.e. the ‘shared network’) was transferred from the sender to the perceiver we aimed to restrict the analysis to these voxels. To avoid circularity, we identified voxels that carried emotion-specific information separately for each sender–perceiver pair, based on data from the remaining sender–perceiver pairs only. Thus, for each sender–perceiver pair the most significant 2500 voxels in the group SPM derived from the remaining sender–perceiver pairs were selected (corresponding roughly to the number of above-threshold voxels in the voxel-wise analysis).</p>
          <p>For classification, the intensity values of these voxels within a 2 s-time window (corresponding to one functional scan) were represented as a vector in m-dimensional space, where m is the number of voxels. Classification was based on Euclidian distances between vectors. First, for each 2 s-time window, mean vectors were computed across the eight intensity vectors of each emotion (4 trials per run × 2 runs per emotion) for the sender (‘Training’). Second, these mean vectors were used to classify the perceiver's brain activity. The perceiver's response in a given 2s-time window was classified according to the smallest Euclidian distances in m-dimensional space between the perceiver's response and these mean vectors (‘Test’) (<xref rid="s0090" ref-type="sec">Fig. S2 Supplemental online material</xref>). Classification of the perceiver's brain activity was carried out separately for each time window of the sender's brain activity and each time window of the perceiver's brain activity, and separately for each emotion period. This yielded a total of 40 binary classification accuracies for each combination of time windows. To derive one measure of decoding accuracy for each combination of time windows, classification accuracies were averaged across all emotion periods. This resulted in an n-by-n matrix of time-resolved decoding accuracies for each sender–perceiver pair, where n is the number of time windows. Each row of the time-resolved matrix of decoding accuracies represents the time course f<sub>i</sub>(p<sub>i</sub>) with which information from the sender's brain in a specific 2 s-time window s<sub>i</sub> was encoded in the perceiver's brain.</p>
          <p>To extract the dynamics of information flow from the time-resolved matrices, time-resolved matrices were first temporally smoothed with a filter width corresponding the time course of the hemodynamic response function (4s × 4s Gaussian filter). Then, time courses were averaged across all time windows s<sub>i</sub> and this average was subtracted from each individual time course. This resulted in a new n-by-n matrix for each sender–perceiver pair. For each time course f′<sub>i</sub>(p<sub>i</sub>) in this new matrix we determined the time window p<sub>imax</sub> in which information from the sender's brain in time window s<sub>i</sub> was most accurately encoded in the perceiver's brain [i.e. f′<sub>i</sub>(p<sub>imax</sub>) = max(f′<sub>i</sub>(p<sub>i</sub>))]. To test whether there was a temporal succession in the flow of information (i.e. whether there was a positive linear relation between time windows s<sub>i</sub> and p<sub>imax</sub>) we used a linear contrast within a repeated-measures ANOVA with fixed factor time window of the senders brain activity and random factor subject. Because we were mainly interested in the flow of <italic>affective</italic> information, the ANOVA was restricted to the time interval covered by the expected time course of the hemodynamic response during the affective communication period (i.e. from 2 scans after beginning of an emotion period to 2 scans after the end of an emotion period). The delay between information in the sender's brain and information in the perceiver's brain for a given time window s<sub>i</sub> was defined as p<sub>imax</sub> − s<sub>i</sub>. A linear contrast within a repeated-measures ANOVA with fixed factor time window of the senders brain activity and random factor subject was used to test for changes of delay over time. Average group matrices and time courses are shown for visualisation (<xref rid="f0015" ref-type="fig">Fig. 3</xref>), but analyses of the time course of information flow were carried out separately for each sender–perceiver pair and statistical analyses are based on data of individual sender–perceiver pairs.</p>
        </sec>
        <sec id="s0050">
          <title>Supplemental analysis</title>
          <p>As stated above, all of the above analyses were carried out within true sender–perceiver pairs. To test the possibility that the ‘shared network’ carried information in individual sender–perceiver pairs that was specific to each sender–perceiver pair and that exceeded information that was present in all senders and perceivers, we performed an additional analysis that compared classification accuracies within true sender–perceiver pairs to classification accuracies within arbitrary sender–perceiver dyads. To this end we combined information across all m voxels in the shared network as described above. However, because this time we were not interested in the time course with which information was transferred, vectors in m-dimensional space now represented m parameter estimates as in the first analysis (rather than m intensity values from single functional images). Because we reasoned that information that was specific to specific sender–perceiver pairs would vary across trials we performed a separate classification analysis for each trial. First, a vector was computed for each trial for the sender (‘Training’). The perceiver's response in a given emotion period was then classified according to the smallest Euclidian distance in m-dimensional space between the perceiver's response and the five vectors representing the sender's emotion-specific response during the corresponding trials (‘Test’). This resulted in 40 classification accuracies for each sender–perceiver pair. We then repeated the same analysis, this time pairing each sender with each perceiver except her true communication partner, and each perceiver with each sender except his true communication partner. To derive one sender – other-perceivers classification accuracy for each sender, and one other-senders – perceiver classification accuracy for each perceiver, classification accuracies were averaged across perceivers and senders, respectively. To avoid circularity, voxels that carried emotion-specific information were identified separately for each sender–perceiver pair, based on data from all remaining sender–perceiver pairs only.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s0055">
      <title>Results</title>
      <sec id="s0060">
        <title>Skin conductance and emotion recognition</title>
        <p>Average time series of skin conductance responses of senders and perceivers are shown in <xref rid="s0090" ref-type="sec">Fig. S3 Supplemental online material</xref>. In both senders and perceivers SCR increased during emotion periods (senders, .63 ± .07 μS [mean ± s.e.m.]; perceivers, .09 ± .02 μS; all participants, T(7) = 2.6, p &lt; .05; perceivers only, T(4) = 3.9, p &lt; .01). This indicates that affective communication led to an increase of autonomic arousal. Furthermore, in line with the assumption that the perceiver's autonomic response reflected the sender's autonomic response over time, visual inspection of the time series indicates that the increase in perceivers was delayed relative to the increase in senders.</p>
        <p>Perceivers recognized the sender's emotion in 70 percent of the runs. Recognition rates were highest for joy (1.00) and lowest for anger (.50), but recognition was above chance (.20) for each and every type of emotion (binomial p &lt;= .05 for all types of emotion), and there was no statistically significant difference in recognition rates between emotion types (Chi-Square = 2.5, df = 4, p &gt; .50, <xref rid="s0090" ref-type="sec">Fig. S4 Supplemental online material</xref>).</p>
      </sec>
      <sec id="s0065">
        <title>A shared network of affect</title>
        <p>First, we aimed to identify brain regions where the perceiver's brain activity could be predicted from the sender's brain activity, depending on the specific emotion that was currently being communicated. For this purpose we trained a simple univariate classifier to identify the sender's current emotion based on the level of activity in a given voxel in the sender's brain, and tested whether the same classifier could identify this emotion from the level of activity in the same voxel in the perceiver's brain. This procedure revealed that the perceiver's emotion-specific brain activity could successfully be predicted from the sender's emotion-specific brain activity in a distributed network, including temporal, parietal, insular and frontal brain regions (<xref rid="f0010" ref-type="fig">Fig. 2</xref> and <xref rid="s0090" ref-type="sec">Table S1 Supplemental online material</xref>). In other words, these brain regions carried highly similar information in the sender's and perceiver's brain, and this information was encoded by highly similar signals in the sender's and perceiver's brain.</p>
      </sec>
      <sec id="s0070">
        <title>Dynamics of information flow</title>
        <p>Next, we sought to investigate the temporal dynamics of the flow of affective information. Particularly, we were interested whether early information from the sender's brain was encoded early in the perceiver's brain, and late information from the sender's brain was encoded later in the perceiver's brain. This would indicate that there was a temporal succession in the flow of emotion-specific information from the sender's brain to the perceiver's brain. For this purpose we used a time-resolved multivariate decoder. As before, a classifier was trained on the sender's brain activity and tested on the perceiver's brain activity. However, this time the classifier was trained on the sender's brain activity in all voxels of the shared network within a specific 2 s-time window and then tested on the perceiver's brain activity in another 2 s-time window.</p>
        <p>Each row of the time-resolved matrix of decoding accuracies (<xref rid="f0015" ref-type="fig">Fig. 3</xref>A) represents the time course with which information from the sender's brain in a specific 2 s-time window was encoded in the perceiver's brain. Initially, these time courses all appear highly similar (<xref rid="f0015" ref-type="fig">Fig. 3</xref>B). This would suggest that brain activity within the shared network was specific to each emotion but did not change much over a given emotion period. Importantly, however, the temporal dynamics of information flow became visible when the average time course (i.e. the stationary component) was subtracted from each individual time course. This revealed that the accuracy with which information in the sender's brain in a specific time window was reflected in the perceiver's brain was not stationary, but changed in a systematic manner over time. Early information from the sender's brain was most accurately encoded in the perceiver's brain at early time points; and late information from the sender's brain was most accurately encoded in the perceiver's brain at later time points (T = 2.2, p &lt; .05, one-tailed, <xref rid="f0015" ref-type="fig">Fig. 3</xref>C).</p>
        <p><xref rid="f0015" ref-type="fig">Fig. 3</xref>D also shows that there was a considerable delay between information in the sender's brain and information in the perceiver's brain. The bar chart shows, for each time window, the delay with which information from the sender's brain was reflected in the perceiver's brain. This delay was large (up to 8 s) just after the beginning of an affective period and decreased towards the end of an affective period (close to 0 s) (T = −3.6, p &lt; .05, two-tailed). Please note that this delay cannot be explained by the latency of the hemodynamic response because time courses of information flow were computed from fMRI signals of the sender and the perceiver and the hemodynamic delay is thus a common component to both signals.</p>
      </sec>
      <sec id="s0075">
        <title>Specificity of information within the shared network</title>
        <p>As additional analysis, we tested whether the ‘shared network’ carried information in individual sender–perceiver pairs that was specific to each sender–perceiver pair and that exceeded information that was present in all senders and perceivers (<xref rid="f0020" ref-type="fig">Fig. 4</xref>). Specifically, we tested whether classification accuracies within true sender–perceiver pairs were higher than classification accuracies within sender – other-perceiver dyads and within other-sender – perceiver dyads. This was indeed the case. Classification accuracies were still above chance for sender – other-perceiver dyads (mean accuracy = .29, T = 10.1, df = 5, p &lt; .001) and other-sender – perceiver dyads (mean accuracy = .29, T = 5.9, df = 5, p &lt; .001), indicating that similar information was present in all senders and perceivers. Critically, however, classification accuracy was significantly lower within sender – other-perceiver dyads than within true sender – perceiver pairs (paired T-test, T = 2.3, p = .03) and significantly lower within other-sender – perceiver dyads than within true sender – perceiver pairs (paired T-test, T = 2.4, p = .03). This provides clear evidence that the shared network does not only represent ‘prototypical’ emotional information but indeed carries information about a communication partner's <italic>individual</italic> affective state.</p>
      </sec>
    </sec>
    <sec id="s0080">
      <title>Discussion</title>
      <p>In sum, our data show that during ongoing facial communication of affect, emotion-specific information is encoded in similar distributed networks in the sender's and perceiver's brain. Furthermore, there is a temporal succession in the flow of affective information from the sender's to the perceiver's brain, with information in the perceiver's brain being delayed relative to information in the sender's brain. These findings extend existing knowledge on the neural basis of affective communication in two important ways.</p>
      <p>First, we show that distributed anterior temporal, insular and somato-motor brain regions that have been associated with ‘embodied simulation’ during affective communication not only show common activity during emotion observation and first-hand emotional experience (<xref rid="bb0220 bb0040 bb0135 bb0100 bb0210" ref-type="bibr">Wicker et al., 2003; Carr et al., 2003; Leslie et al., 2004; Hennenlotter et al., 2005; van der Gaag et al., 2007</xref>), but indeed carry emotion-specific information in the sender and perceiver. Moreover, our data show that this information is encoded by highly similar signals in the sender and perceiver. This can be seen from the fact that information about the specific emotion that was communicated by the sender could be decoded from the level of activity in individual voxels within this network in the perceiver's brain even though the decoder was trained on the sender's brain activity only. Thus, our analyses provide evidence for a ‘common coding’ of emotion-specific information in a distributed network in the sender's and perceiver's brain. Interestingly, the ventral premotor cortex, which is often activated when people imitate or observe posed affective facial expressions (<xref rid="bb0040 bb0135 bb0100 bb0210" ref-type="bibr">Carr et al., 2003; Leslie et al., 2004; Hennenlotter et al., 2005; van der Gaag et al., 2007</xref>), was not part of this network.</p>
      <p>Second, our approach allowed us to directly measure how information from the sender's brain is subsequently encoded in the perceiver's brain. Thus, we could show that there was a temporal succession in the flow of affective information, with early information from the sender's brain being encoded early in the perceiver's brain, and later information from the sender's brain being encoded later in the perceiver's brain. This illustrates that information from the sender's brain was dynamically reflected in the perceiver's brain.</p>
      <p>A very recent study by <xref rid="bb0185" ref-type="bibr">Schippers et al. (2010)</xref> used a design similar to that in the current study except that senders in that study did not communicate their affective state, but gestured arbitrary words to the perceiver. Using between-subject Granger causality analysis that study showed that changes of activity in certain regions of the sender's brain preceded changes of activity in other regions of the perceiver's brain. The current study supports and extends those findings by showing that information about the <italic>specific content</italic> of communication (in this case the sender's affective state) from the sender's brain is subsequently reflected in the perceiver's brain.</p>
      <p>Notably, there was a considerable delay between information in the sender's brain and information in the perceiver's brain. This delay (up to eight seconds) was much longer than it would be expected due to the very brief physical delay of the video signal or neuronal transmission delays in low-level motor and sensory systems in the sender and perceiver. Also, delays were computed directly from the sender's and perceiver's fMRI signal and thus cannot be explained the latency of the hemodynamic response. At first glance this result seems to be at odds with behavioural studies that have shown that covert mimicking reactions to facial and bodily expressions of emotion can occur very rapidly (e.g. <xref rid="bb0055 bb0215" ref-type="bibr">Dimberg and Thunberg, 1998; van Heijnsbergen et al., 2007</xref>). However, the finding that it may take several seconds until the sender's affective state is fully reflected in the perceiver's brain is in line with the view the human emotions comprise different response components (e.g. <xref rid="bb0015" ref-type="bibr">Anders et al., 2009</xref>) that unfold over time (<xref rid="bb0140" ref-type="bibr">Leventhal and Scherer, 1987</xref>). Interestingly, the delay between information in the sender's brain and information in the perceiver's brain decreased over an affective period. This possibly reflects some ‘tuning in’ of the perceiver with the sender. In other words, while it may initially take some time for the ‘shared space’ (<xref rid="bb0070" ref-type="bibr">Gallese, 2003</xref>) of affect to build up between the sender and perceiver, information transfer seems to become faster once the shared space has been established.</p>
      <p>Finally, our data provide evidence that the ‘shared network’ does not only carry ‘prototypical’ emotional information but indeed carries information about an interaction partner's <italic>individual</italic> affective state. This can be derived from the finding that classification accuracies within the shared network were higher within true sender–perceiver pairs than within arbitrary sender–perceiver dyads. This underlines a possible role of the ‘shared network’ in simulating another person's current affective state rather than in solely reflecting prototypical information.</p>
      <p>The current study, like most previous studies, investigated ‘embodied simulation’ during facial communication in a context in which perceivers were biased to share the sender's affective state. In real-life situations this might not always be the case. In certain contexts, situational demands might lead to an inhibition of ‘embodied simulation’ (e.g. <xref rid="bb0130" ref-type="bibr">Lamm et al., 2007</xref>). The current study provides a tool to directly study such influences by assessing the amount of specific information that is reflected in the perceiver's brain, depending on the context.</p>
      <p>One important question that has to be considered when investigating a possible role of ‘embodied stimulation’ in social interaction is how such a mechanism might be implemented at the neuronal level. A seminal finding in this regard was the detection of neurons in the macaque area F5 (a premotor area) that fire not only when the monkey performs a goal-directed hand movement, but also when the monkey observes the same action being performed by another individual (<xref rid="bb0075 bb0180" ref-type="bibr">Gallese et al., 1996; Rizzolatti et al., 1996</xref>). This and subsequent findings have been taken as evidence that ‘mirror neurons’ (i.e. neurons that fire during observation and action) might link third-person observation and first-hand experience and thereby provide an important basis for insightful social interaction (e.g. <xref rid="bb0070" ref-type="bibr">Gallese, 2003</xref>). The search for such ‘mirror neurons’ in the human brain has been restricted by the limited spatial resolution of recording methods available for human research. Nevertheless, along with a single record of a ‘mirror neuron’ for pain in the human brain (<xref rid="bb0105" ref-type="bibr">Hutchison et al., 1999</xref>) there are a number of studies that have shown that some regions in the human brain respond during observation and execution of specific actions (<xref rid="bb0115 bb0195 bb0060 bb0080 bb0190" ref-type="bibr">Iacoboni et al., 1999; Shmuelof and Zohary, 2006; Dinstein et al., 2007; Gazzola and Keysers, 2009; Schippers et al., 2009</xref>), or observation and first-hand experience of affect (<xref rid="bb0220 bb0040 bb0135 bb0100 bb0210" ref-type="bibr">Wicker et al., 2003; Carr et al., 2003; Leslie et al., 2004; Hennenlotter et al., 2005; van der Gaag et al., 2007</xref>). However, there is an ongoing debate whether common activity in neuroimaging studies indeed reflects the existence of ‘mirror neurons’ in these regions. Alternatively, observed and executed actions, or observed and experienced affect, could be represented by different subpopulations of neurons within the same region (<xref rid="bb0155" ref-type="bibr">Morrison and Downing, 2007</xref>; <xref rid="bb0065 bb0145" ref-type="bibr">Dinstein et al., 2008; Lingnau et al., 2009</xref>). The current study shows that affective information is represented in similar neural networks in the sender's and perceiver's brain, and that affective information within these networks is encoded by highly similar signals. It will remain a challenging task for future studies to examine the neurophysiological bases of this information transfer below the current resolution of neuroimaging studies.</p>
      <p>In conclusion, our data support current theories of intersubjectivity by showing that affect-specific information is encoded in a very similar way in the brains of senders and perceivers engaged in facial communication of affect. Information is successively transferred from the sender's brain to the perceiver's brain, eventually leading to what has been called a ‘shared space’ of affect (<xref rid="bb0070" ref-type="bibr">Gallese, 2003</xref>). At the same time, our approach extends the individual-focussed approach of previous neuroimaging studies on the social cognition to a dyadic, inter-individual perspective. Previous studies have examined how common stimulation synchronizes brain activity of individuals (<xref rid="bb0085" ref-type="bibr">Hasson et al., 2004</xref>), and have investigated brain responses of individuals involved in ongoing social interaction (<xref rid="bb0120 bb0205" ref-type="bibr">King-Casas et al., 2005; Tognoli et al., 2007</xref>), but have not directly studied how activity in one individual's brain influences, or depends on, activity in another individual's brain. However, to understand the neurobiological bases of social interaction it is fundamental to understand how the brains of individuals interact. The approach presented here, using information-based imaging to directly compare brain activity of individuals engaged in ongoing social interaction, provides a tool that might open a new perspective in social neuroscience that seeks to examine the neurobiology of human social behaviour from an inter-individual point of view.</p>
    </sec>
    <sec id="s0085">
      <title>Author contributions</title>
      <p>S.A., T.E. and N.W. conceived the experiment, S.A. and T.E. carried out the experiment, S.A. and J.-D.H. analysed the data, J.H. provided analysis tools, S.A. and J.-D.H. wrote the manuscript, S.A., J.H., N.W., T.E. and J.-D.H. edited the manuscript.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bb0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adolphs</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Tranel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Cooper</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
          </person-group>
          <article-title>A role for somatosensory cortices in the visual recognition of emotion as revealed by three-dimensional lesion mapping</article-title>
          <source>J. Neurosci.</source>
          <volume>20</volume>
          <issue>7</issue>
          <year>2000</year>
          <fpage>2683</fpage>
          <lpage>2690</lpage>
          <pub-id pub-id-type="pmid">10729349</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0010">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anders</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lotze</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Erb</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Grodd</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Birbaumer</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Brain activity underlying emotional valence and arousal: a response-related fMRI study</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>23</volume>
          <issue>4</issue>
          <year>2004</year>
          <fpage>200</fpage>
          <lpage>209</lpage>
          <pub-id pub-id-type="pmid">15449355</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anders</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Eippert</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Wiens</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Birbaumer</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Lotze</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wildgruber</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>When seeing outweighs feeling: a role for prefrontal cortex in passive control of negative affect in blindsight</article-title>
          <source>Brain</source>
          <volume>132</volume>
          <issue>Pt 11</issue>
          <year>2009</year>
          <fpage>3021</fpage>
          <lpage>3031</lpage>
          <pub-id pub-id-type="pmid">19767414</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0235">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Andersson</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Hutton</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Modeling geometric deformations in EPI time series</article-title>
          <source>Neuroimage</source>
          <volume>13</volume>
          <issue>5</issue>
          <year>2001</year>
          <fpage>903</fpage>
          <lpage>919</lpage>
          <pub-id pub-id-type="pmid">11304086</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0020">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bastiaansen</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Thioux</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Evidence for mirror systems in emotions</article-title>
          <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source>
          <volume>364</volume>
          <issue>1528</issue>
          <year>2009</year>
          <fpage>2391</fpage>
          <lpage>2404</lpage>
          <pub-id pub-id-type="pmid">19620110</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Botvinick</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jha</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Bylsma</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Fabian</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Solomon</surname>
              <given-names>P.E.</given-names>
            </name>
            <name>
              <surname>Prkachin</surname>
              <given-names>K.M.</given-names>
            </name>
          </person-group>
          <article-title>Viewing facial expressions of pain engages cortical areas involved in the direct experience of pain</article-title>
          <source>Neuroimage</source>
          <volume>25</volume>
          <issue>1</issue>
          <year>2005</year>
          <fpage>312</fpage>
          <lpage>319</lpage>
          <pub-id pub-id-type="pmid">15734365</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Buck</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Caul</surname>
              <given-names>W.F.</given-names>
            </name>
          </person-group>
          <article-title>Sex, personality, and physiological variables in the communication of affect via facial expression</article-title>
          <source>J. Pers. Soc. Psychol.</source>
          <volume>30</volume>
          <issue>4</issue>
          <year>1974</year>
          <fpage>587</fpage>
          <lpage>596</lpage>
          <pub-id pub-id-type="pmid">4455775</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Keane</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Manes</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Antoun</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Impaired recognition and experience of disgust following brain injury</article-title>
          <source>Nat. Neurosci.</source>
          <volume>3</volume>
          <issue>11</issue>
          <year>2000</year>
          <fpage>1077</fpage>
          <lpage>1078</lpage>
          <pub-id pub-id-type="pmid">11036262</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carr</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Iacoboni</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dubeau</surname>
              <given-names>M.C.</given-names>
            </name>
            <name>
              <surname>Mazziotta</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Lenzi</surname>
              <given-names>G.L.</given-names>
            </name>
          </person-group>
          <article-title>Neural mechanisms of empathy in humans: a relay from neural systems for imitation to limbic areas</article-title>
          <source>Proc. Natl Acad. Sci. USA</source>
          <volume>100</volume>
          <issue>9</issue>
          <year>2003</year>
          <fpage>5497</fpage>
          <lpage>5502</lpage>
          <pub-id pub-id-type="pmid">12682281</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Grabowski</surname>
              <given-names>T.J.</given-names>
            </name>
            <name>
              <surname>Bechara</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Ponto</surname>
              <given-names>L.L.</given-names>
            </name>
            <name>
              <surname>Parvizi</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hichwa</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <article-title>Subcortical and cortical brain activity during the feeling of self-generated emotions</article-title>
          <source>Nat. Neurosci.</source>
          <volume>3</volume>
          <issue>10</issue>
          <year>2000</year>
          <fpage>1049</fpage>
          <lpage>1056</lpage>
          <pub-id pub-id-type="pmid">11017179</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Decety</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Jackson</surname>
              <given-names>P.L.</given-names>
            </name>
          </person-group>
          <article-title>The functional architecture of human empathy</article-title>
          <source>Behav. Cogn. Neurosci. Rev.</source>
          <volume>3</volume>
          <issue>2</issue>
          <year>2004</year>
          <fpage>71</fpage>
          <lpage>100</lpage>
          <pub-id pub-id-type="pmid">15537986</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0055">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dimberg</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Thunberg</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Rapid facial reactions to emotional facial expressions</article-title>
          <source>Scand. J. Psychol.</source>
          <volume>39</volume>
          <issue>1</issue>
          <year>1998</year>
          <fpage>39</fpage>
          <lpage>45</lpage>
          <pub-id pub-id-type="pmid">9619131</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dinstein</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Hasson</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Rubin</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Brain areas selective for both observed and executed movements</article-title>
          <source>J. Neurophysiol.</source>
          <volume>98</volume>
          <issue>3</issue>
          <year>2007</year>
          <fpage>1415</fpage>
          <lpage>1427</lpage>
          <pub-id pub-id-type="pmid">17596409</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dinstein</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Gardner</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Jazayeri</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Executed and observed movements have different distributed representations in human aIPS</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <issue>44</issue>
          <year>2008</year>
          <fpage>11231</fpage>
          <lpage>11239</lpage>
          <pub-id pub-id-type="pmid">18971465</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gallese</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>The manifold nature of interpersonal relations: the quest for a common mechanism</article-title>
          <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source>
          <volume>358</volume>
          <issue>1431</issue>
          <year>2003</year>
          <fpage>517</fpage>
          <lpage>528</lpage>
          <pub-id pub-id-type="pmid">12689377</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0075">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gallese</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Fadiga</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Fogassi</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Rizzolatti</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Action recognition in the premotor cortex</article-title>
          <source>Brain</source>
          <volume>119</volume>
          <issue>Pt 2</issue>
          <year>1996</year>
          <fpage>593</fpage>
          <lpage>609</lpage>
          <pub-id pub-id-type="pmid">8800951</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gazzola</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>The observation and execution of actions share motor and somatosensory voxels in all tested subjects: single-subject analyses of unsmoothed fMRI data</article-title>
          <source>Cereb. Cortex</source>
          <volume>19</volume>
          <issue>6</issue>
          <year>2009</year>
          <fpage>1239</fpage>
          <lpage>1255</lpage>
          <pub-id pub-id-type="pmid">19020203</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0085">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hasson</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Nir</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Levy</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Fuhrmann</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Malach</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Intersubject synchronization of cortical activity during natural vision</article-title>
          <source>Science</source>
          <volume>303</volume>
          <issue>5664</issue>
          <year>2004</year>
          <fpage>1634</fpage>
          <lpage>1640</lpage>
          <pub-id pub-id-type="pmid">15016991</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Furey</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Ishai</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Schouten</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Pietrini</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>
          <source>Science</source>
          <volume>293</volume>
          <issue>5539</issue>
          <year>2001</year>
          <fpage>2425</fpage>
          <lpage>2430</lpage>
          <pub-id pub-id-type="pmid">11577229</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haynes</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Decoding mental states from brain activity in humans</article-title>
          <source>Nat. Rev. Neurosci.</source>
          <volume>7</volume>
          <issue>7</issue>
          <year>2006</year>
          <fpage>523</fpage>
          <lpage>534</lpage>
          <pub-id pub-id-type="pmid">16791142</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hennenlotter</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Schroeder</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Erhard</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Castrop</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Haslinger</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Stoecker</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Lange</surname>
              <given-names>K.W.</given-names>
            </name>
            <name>
              <surname>Ceballos-Baumann</surname>
              <given-names>A.O.</given-names>
            </name>
          </person-group>
          <article-title>A common neural basis for receptive and expressive communication of pleasant facial affect</article-title>
          <source>Neuroimage</source>
          <volume>26</volume>
          <issue>2</issue>
          <year>2005</year>
          <fpage>581</fpage>
          <lpage>591</lpage>
          <pub-id pub-id-type="pmid">15907315</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hutchison</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Davis</surname>
              <given-names>K.D.</given-names>
            </name>
            <name>
              <surname>Lozano</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Tasker</surname>
              <given-names>R.R.</given-names>
            </name>
            <name>
              <surname>Dostrovsky</surname>
              <given-names>J.O.</given-names>
            </name>
          </person-group>
          <article-title>Pain-related neurons in the human cingulate cortex</article-title>
          <source>Nat. Neurosci.</source>
          <volume>2</volume>
          <issue>5</issue>
          <year>1999</year>
          <fpage>403</fpage>
          <lpage>405</lpage>
          <pub-id pub-id-type="pmid">10321241</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Iacoboni</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Imitation, empathy, and mirror neurons</article-title>
          <source>Annu. Rev. Psychol.</source>
          <volume>60</volume>
          <year>2009</year>
          <fpage>653</fpage>
          <lpage>670</lpage>
          <pub-id pub-id-type="pmid">18793090</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0115">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Iacoboni</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Woods</surname>
              <given-names>R.P.</given-names>
            </name>
            <name>
              <surname>Brass</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bekkering</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Mazziotta</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Rizzolatti</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Cortical mechanisms of human imitation</article-title>
          <source>Science</source>
          <volume>286</volume>
          <issue>5449</issue>
          <year>1999</year>
          <fpage>2526</fpage>
          <lpage>2528</lpage>
          <pub-id pub-id-type="pmid">10617472</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0120">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>King-Casas</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Tomlin</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Anen</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Camerer</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Quartz</surname>
              <given-names>S.R.</given-names>
            </name>
            <name>
              <surname>Montague</surname>
              <given-names>P.R.</given-names>
            </name>
          </person-group>
          <article-title>Getting to know you: reputation and trust in a two-person economic exchange</article-title>
          <source>Science</source>
          <volume>308</volume>
          <issue>5718</issue>
          <year>2005</year>
          <fpage>78</fpage>
          <lpage>83</lpage>
          <pub-id pub-id-type="pmid">15802598</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0125">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kriegeskorte</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Goebel</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bandettini</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Information-based functional brain mapping</article-title>
          <source>Proc. Natl Acad. Sci. USA</source>
          <volume>103</volume>
          <issue>10</issue>
          <year>2006</year>
          <fpage>3863</fpage>
          <lpage>3868</lpage>
          <pub-id pub-id-type="pmid">16537458</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0130">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lamm</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Batson</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Decety</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>The neural substrate of human empathy: effects of perspective-taking and cognitive appraisal</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>19</volume>
          <issue>1</issue>
          <year>2007</year>
          <fpage>42</fpage>
          <lpage>58</lpage>
          <pub-id pub-id-type="pmid">17214562</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0135">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leslie</surname>
              <given-names>K.R.</given-names>
            </name>
            <name>
              <surname>Johnson-Frey</surname>
              <given-names>S.H.</given-names>
            </name>
            <name>
              <surname>Grafton</surname>
              <given-names>S.T.</given-names>
            </name>
          </person-group>
          <article-title>Functional imaging of face and hand imitation: towards a motor theory of empathy</article-title>
          <source>Neuroimage</source>
          <volume>21</volume>
          <issue>2</issue>
          <year>2004</year>
          <fpage>601</fpage>
          <lpage>607</lpage>
          <pub-id pub-id-type="pmid">14980562</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0140">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leventhal</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Scherer</surname>
              <given-names>K.R.</given-names>
            </name>
          </person-group>
          <article-title>The relationship of emotion to cognition: a functional approach to a semantic controversy</article-title>
          <source>Cogn. emotion</source>
          <volume>1</volume>
          <issue>1</issue>
          <year>1987</year>
          <fpage>3</fpage>
          <lpage>28</lpage>
        </element-citation>
      </ref>
      <ref id="bb0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lingnau</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Gesierich</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Caramazza</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Asymmetric fMRI adaptation reveals no evidence for mirror neurons in humans</article-title>
          <source>Proc. Natl Acad. Sci. USA</source>
          <volume>106</volume>
          <issue>24</issue>
          <year>2009</year>
          <fpage>9925</fpage>
          <lpage>9930</lpage>
          <pub-id pub-id-type="pmid">19497880</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0150">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lipps</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Einfühlung, innere Nachahmung und Organempfindung</article-title>
          <source>Arch. Gesamte Psychol.</source>
          <volume>1</volume>
          <year>1903</year>
          <fpage>465</fpage>
          <lpage>519</lpage>
        </element-citation>
      </ref>
      <ref id="bb0155">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morrison</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Downing</surname>
              <given-names>P.E.</given-names>
            </name>
          </person-group>
          <article-title>Organization of felt and seen pain responses in anterior cingulate cortex</article-title>
          <source>Neuroimage</source>
          <volume>37</volume>
          <issue>2</issue>
          <year>2007</year>
          <fpage>642</fpage>
          <lpage>651</lpage>
          <pub-id pub-id-type="pmid">17588777</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0160">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morrison</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Lloyd</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>di Pellegrino</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Vicarious responses to pain in anterior cingulate cortex: is empathy a multisensory issue?</article-title>
          <source>Cogn. Affect. Behav. Neurosci.</source>
          <volume>4</volume>
          <issue>2</issue>
          <year>2004</year>
          <fpage>270</fpage>
          <lpage>278</lpage>
          <pub-id pub-id-type="pmid">15460933</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0165">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Norman</surname>
              <given-names>K.A.</given-names>
            </name>
            <name>
              <surname>Polyn</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Detre</surname>
              <given-names>G.J.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
          </person-group>
          <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>10</volume>
          <issue>9</issue>
          <year>2006</year>
          <fpage>424</fpage>
          <lpage>430</lpage>
          <pub-id pub-id-type="pmid">16899397</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0170">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pessoa</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Padmala</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Decoding near-threshold perception of fear from distributed single-trial brain activation</article-title>
          <source>Cereb. Cortex</source>
          <volume>17</volume>
          <issue>3</issue>
          <year>2007</year>
          <fpage>691</fpage>
          <lpage>701</lpage>
          <pub-id pub-id-type="pmid">16627856</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0175">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Phan</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Wager</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>S.F.</given-names>
            </name>
            <name>
              <surname>Liberzon</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Functional neuroanatomy of emotion: a meta-analysis of emotion activation studies in PET and fMRI</article-title>
          <source>Neuroimage</source>
          <volume>16</volume>
          <issue>2</issue>
          <year>2002</year>
          <fpage>331</fpage>
          <lpage>348</lpage>
          <pub-id pub-id-type="pmid">12030820</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0180">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rizzolatti</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Fadiga</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Gallese</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Fogassi</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Premotor cortex and the recognition of motor actions</article-title>
          <source>Brain Res. Cogn. Brain Res.</source>
          <volume>3</volume>
          <issue>2</issue>
          <year>1996</year>
          <fpage>131</fpage>
          <lpage>141</lpage>
          <pub-id pub-id-type="pmid">8713554</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schippers</surname>
              <given-names>M.B.</given-names>
            </name>
            <name>
              <surname>Roebroeck</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Renken</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Nanetti</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Mapping the information flow from one brain to another during gestural communication</article-title>
          <source>Proc. Natl Acad. Sci. USA</source>
          <volume>107</volume>
          <issue>20</issue>
          <year>2010</year>
          <fpage>9388</fpage>
          <lpage>9393</lpage>
          <pub-id pub-id-type="pmid">20439736</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0190">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schippers</surname>
              <given-names>M.B.</given-names>
            </name>
            <name>
              <surname>Gazzola</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Goebel</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Playing charades in the fMRI: are mirror and/or mentalizing areas involved in gestural communication?</article-title>
          <source>PLoS ONE</source>
          <volume>4</volume>
          <issue>8</issue>
          <year>2009</year>
          <fpage>e6801</fpage>
          <pub-id pub-id-type="pmid">19710923</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0195">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shmuelof</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Zohary</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>A mirror representation of others' actions in the human anterior parietal cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>26</volume>
          <issue>38</issue>
          <year>2006</year>
          <fpage>9736</fpage>
          <lpage>9742</lpage>
          <pub-id pub-id-type="pmid">16988044</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0200">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Singer</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Seymour</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>O'Doherty</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kaube</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
          </person-group>
          <article-title>Empathy for pain involves the affective but not sensory components of pain</article-title>
          <source>Science</source>
          <volume>303</volume>
          <issue>5661</issue>
          <year>2004</year>
          <fpage>1157</fpage>
          <lpage>1162</lpage>
          <pub-id pub-id-type="pmid">14976305</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0205">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tognoli</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Lagarde</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>DeGuzman</surname>
              <given-names>G.C.</given-names>
            </name>
            <name>
              <surname>Kelso</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>The phi complex as a neuromarker of human social coordination</article-title>
          <source>Proc. Natl Acad. Sci. USA</source>
          <volume>104</volume>
          <issue>19</issue>
          <year>2007</year>
          <fpage>8190</fpage>
          <lpage>8195</lpage>
          <pub-id pub-id-type="pmid">17470821</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0210">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>van der Gaag</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Minderaa</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Facial expressions: what the mirror neuron system can and cannot tell us</article-title>
          <source>Soc. Neurosci.</source>
          <volume>2</volume>
          <issue>3–4</issue>
          <year>2007</year>
          <fpage>179</fpage>
          <lpage>222</lpage>
          <pub-id pub-id-type="pmid">18633816</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0215">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>van Heijnsbergen</surname>
              <given-names>C.C.</given-names>
            </name>
            <name>
              <surname>Meeren</surname>
              <given-names>H.K.</given-names>
            </name>
            <name>
              <surname>Grezes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>de Gelder</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Rapid detection of fear in body expressions, an ERP study</article-title>
          <source>Brain Res.</source>
          <volume>1186</volume>
          <year>2007</year>
          <fpage>233</fpage>
          <lpage>241</lpage>
          <pub-id pub-id-type="pmid">17996856</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0220">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wicker</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Keysers</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Plailly</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Royet</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Gallese</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Rizzolatti</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Both of us disgusted in my insula: the common neural basis of seeing and feeling disgust</article-title>
          <source>Neuron</source>
          <volume>40</volume>
          <issue>3</issue>
          <year>2003</year>
          <fpage>655</fpage>
          <lpage>664</lpage>
          <pub-id pub-id-type="pmid">14642287</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wild</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Erb.</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lemke</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Scholz</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Bartels</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Grodd</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Video camera and light system for application in magnetic resonance scanners</article-title>
          <source>Magn. Reson. Imaging</source>
          <volume>18</volume>
          <issue>7</issue>
          <year>2000</year>
          <fpage>893</fpage>
          <lpage>896</lpage>
          <pub-id pub-id-type="pmid">11027885</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0225">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Worsley</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Marrett</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Neelin</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Vandal</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Evans</surname>
              <given-names>A.C.</given-names>
            </name>
          </person-group>
          <article-title>A unified statistical approach for determining significant signals in mages of cerebral activation</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>4</volume>
          <year>1996</year>
          <fpage>58</fpage>
          <lpage>73</lpage>
          <pub-id pub-id-type="pmid">20408186</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="s0090" sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p>
        <supplementary-material content-type="local-data" id="ec0005">
          <caption>
            <p>Supplementary materials.</p>
          </caption>
          <media xlink:href="mmc1.doc" mimetype="application" mime-subtype="msword"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was supported by the Junior Science Program of the Heidelberg Academy of Science and Humanities and the Bundesministerium für Bildung und Forschung (Federal Ministry of Education and Research, grant 01GW0752). N.W. was supported by the Wellcome Trust. Scanning was performed at the Section for Experimental MR of the CNS, Department of Neuroradiology, University of Tübingen, Germany. We thank Falk Eippert, Michael Erb, Susanne Leiberg and Martin Lotze for help with scanning, and Wolfgang Grodd and Barbara Wild for their kind permission to use the fMRI-compatible camera.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="f0005">
      <label>Fig. 1</label>
      <caption>
        <p>Experimental design. Senders and perceivers participated in 10 runs of fMRI. Colours indicate emotion periods; each colour indicates a different emotion (joy, anger, disgust, fear, or sadness), grey indicates resting periods. The order of runs was chosen by the sender with the restriction that each emotion had to be chosen once before an emotion could occur a second time. The sender's facial expression was video-taped throughout scanning and shown to the perceiver while he was scanned immediately after scanning of the sender had been completed.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="f0010">
      <label>Fig. 2</label>
      <caption>
        <p>The ‘shared network of affect’. A. Clusters in which the perceiver’s brain activity could successfully be predicted from the level of the sender’s brain activity, depending on the communicated affect (p = .01, corrected for multiple comparisons at cluster level). Significant clusters are projected onto the surface of a standard brain (MNI). B. Average voxel-wise decoding accuracies within each cluster, projected onto axial slices of the same brain as in A. Slices are shown in neurological convention (left is left). Numbers below slices indicate z coordinates.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="f0015">
      <label>Fig. 3</label>
      <caption>
        <p>Dynamics of information flow. Each row of the time-resolved matrix of decoding accuracies (A) represents the time course (B) with which information from the sender's brain in a specific time window was encoded in the perceiver's brain. Subtracting the average from these time courses reveals the temporal dynamics of information flow (C). Time courses of delta accuracy in C are scaled to the overall maximum of delta accuracy. Red lines indicate the peak of each individual time course; dashed lines and numbers on the right indicate the time window the sender's brain activity was taken from. The bar chart (D) shows the delay with which information from the sender's brain was reflected in the perceiver's brain. Dark grey bars in C and D represent an approximation of the interval covered by the predicted time course of the hemodynamic response during affective communication.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="f0020">
      <label>Fig. 4</label>
      <caption>
        <p>Specificity of information within the ‘shared network of affect’. Bar charts represent average classification accuracies when information was combined across all voxels within the ‘shared network of affect’. Classification accuracy was significantly lower within sender – other-perceiver dyads and other-sender – perceiver dyads than within true sender–perceiver pairs. Error bars represent standard errors of the mean.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
  </floats-group>
</article>