<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title>Neuroimage</journal-title>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2644453</article-id>
      <article-id pub-id-type="pmid">19000769</article-id>
      <article-id pub-id-type="publisher-id">YNIMG5730</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.048</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Dynamic causal models of steady-state responses</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Moran</surname>
            <given-names>R.J.</given-names>
          </name>
          <email>r.moran@fil.ion.ucl.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Stephan</surname>
            <given-names>K.E.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Seidenbecher</surname>
            <given-names>T.</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Pape</surname>
            <given-names>H.-C.</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Dolan</surname>
            <given-names>R.J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Friston</surname>
            <given-names>K.J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line><sup>a</sup>Wellcome Trust Centre for Neuroimaging, Institute of Ne.urology, University College London, 12 Queen Square, London WC1N 3BG, UK</addr-line>
      </aff>
      <aff id="aff2">
        <addr-line><sup>b</sup>Laboratory for Social and Neural Systems Research, Institute for Empirical Research in Economics, University of Zurich, Switzerland</addr-line>
      </aff>
      <aff id="aff3">
        <addr-line><sup>c</sup>Institute of Physiology, University of Münster, Germany</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author. Fax: +44 207 813 1445. <email>r.moran@fil.ion.ucl.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>2</month>
        <year>2009</year>
      </pub-date>
      <volume>44</volume>
      <issue>3</issue>
      <fpage>796</fpage>
      <lpage>811</lpage>
      <history>
        <date date-type="received">
          <day>29</day>
          <month>5</month>
          <year>2008</year>
        </date>
        <date date-type="rev-recd">
          <day>1</day>
          <month>9</month>
          <year>2008</year>
        </date>
        <date date-type="accepted">
          <day>28</day>
          <month>9</month>
          <year>2008</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2009 Elsevier Inc.</copyright-statement>
        <copyright-year>2008</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</p>
        </license>
      </permissions>
      <abstract>
        <title>Abstract</title>
        <p>In this paper, we describe a dynamic causal model (DCM) of steady-state responses in electrophysiological data that are summarised in terms of their cross-spectral density. These spectral data-features are generated by a biologically plausible, neural-mass model of coupled electromagnetic sources; where each source comprises three sub-populations. Under linearity and stationarity assumptions, the model's biophysical parameters (e.g., post-synaptic receptor density and time constants) prescribe the cross-spectral density of responses measured directly (e.g., local field potentials) or indirectly through some lead-field (e.g., electroencephalographic and magnetoencephalographic data). Inversion of the ensuing DCM provides conditional probabilities on the synaptic parameters of intrinsic and extrinsic connections in the underlying neuronal network. This means we can make inferences about synaptic physiology, as well as changes induced by pharmacological or behavioural manipulations, using the cross-spectral density of invasive or non-invasive electrophysiological recordings. In this paper, we focus on the form of the model, its inversion and validation using synthetic and real data. We conclude with an illustrative application to multi-channel local field potential data acquired during a learning experiment in mice.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Frequency domain electrophysiology</kwd>
        <kwd>Bayesian inversion</kwd>
        <kwd>Cross-spectral densities</kwd>
        <kwd>DCM</kwd>
        <kwd>Fear conditioning</kwd>
        <kwd>Hippocampus</kwd>
        <kwd>Amygdala</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec>
      <title>Introduction</title>
      <p>This paper is concerned with modelling steady-state or (quasi) stationary responses recorded electrophysiologically using invasive or non-invasive techniques. Critically, the models are parameterised in terms of neurophysiologically meaningful parameters, describing the physiology and connectivity of coupled neuronal populations subtending observed responses. The model generates or predicts the cross-spectral density of observed responses, which are a simple but comprehensive summary of steady-state dynamics under linearity and stationarity assumptions. Furthermore, these cross-spectral features can be extracted quickly and simply from empirical data. In this paper, we describe the model and its inversion, with a focus on system identifiability and the validity of the proposed approach. This method is demonstrated using local field potentials (LFP) recorded from Pavlovian fear conditioned mice. In subsequent papers, we will apply the model to LFP data recorded during pharmacological experiments.</p>
      <p>The approach described below represents the denouement of previous work on dynamic causal modelling of spectral responses. In <xref rid="bib23" ref-type="bibr">Moran et al., (2007)</xref>, we described how neural-mass models, used originally to model evoked responses in the electroencephalogram (EEG) and magnetoencephalogram (MEG) (<xref rid="bib6 bib7" ref-type="bibr">David et al., 2003, 2005</xref>; <xref rid="bib18" ref-type="bibr">Kiebel et al., 2007</xref>), could also model spectral responses as recorded by LFPs. This work focussed on linear systems analysis and structural stability, in relation to model parameters. We then provided a face validation of the basic idea, using single-channel local field potentials recorded from two groups of rats. These groups expressed different glutamatergic neurotransmitter function, as verified with microdialysis (<xref rid="bib24" ref-type="bibr">Moran et al., 2008</xref>). Using the model, we were able to recover the anticipated changes in synaptic function.</p>
      <p>Here, we generalise this approach to provide a full dynamic causal model (DCM) of coupled neuronal sources, where the ensuing network generates electrophysiological responses that are observed directly or indirectly. This generalisation rests on two key advances. First, we model not just the spectral responses from each electromagnetic source but the cross-spectral density among sources. This enables us to predict the cross-spectral density in multi-channel data, even if it has been recorded non-invasively through, for example, scalp electrodes. Second, in our previous work we made the simplifying assumption that the neuronal innovations (i.e. the baseline cortical activity) driving spectral responses were white (i.e., had uniform spectral power). In this work, we relax this assumption and estimate, from the data, the spectral form of these innovations, using a more plausible mixture of white and pink (1/<italic>f</italic>) components.</p>
      <p>This paper comprises three sections. In the first, we describe the DCM, the cross-spectral data-features generated by the model and model inversion given these features. In the second section, we address the face validity of the model, using synthetic data to establish that both the form of the model and its key parameters can be recovered in terms of conditional probability densities. The parameters we look at are those that determine post-synaptic sensitivity to glutamate from extrinsic and intrinsic afferents. In the final section, we repeat the analysis of synthetic data using multi-channel LFP data from mice, acquired during cued recall of a conditioned fear memory. This section tries to establish the construct validity of DCM in relation to the previous analyses of functional connectivity using cross-correlogram analysis. These show an increase in the coupling between the hippocampus and amygdala using responses induced by conditioned fear-stimuli. We try to replicate this finding and, critically, extend it to establish the changes in directed connections that mediate this increased coupling.</p>
    </sec>
    <sec>
      <title>The dynamic causal model</title>
      <p>In this section, we describe the model of cross-spectral density responses. Much of this material is based on linear systems theory and the differential equations that constitute our neural-mass model of underlying dynamics. We will use a tutorial style and refer interested readers to appendices and previous descriptions of the neural-mass model for details. We first consider the generative model for cross-spectral density and then describe how these cross-spectral features are evaluated. Finally, we review model inversion and inference.</p>
      <sec>
        <title>A generative model for cross-spectral density</title>
        <p>Under stationarity assumptions, one can summarize arbitrarily long electrophysiological recordings from multi-channel data in terms of cross-spectral density matrices, <italic>g</italic>(ω)<sub><italic>c</italic></sub> at frequency ω (radians per second). Heuristically, these can be considered as a covariance matrix at each frequency of interest. As such, these second-order data-features specify, completely, the second-order moments of the data under Gaussian assumptions. Cross-spectral density is useful because it represents the important information, in long time-series, compactly. Furthermore, it brings our data modelling into the domain of conventional spectral analysis and linear systems theory. The use of linear systems theory to derive the predicted spectral response from a non-linear dynamical system assumes that changes in the (neuronal) states of the system can be approximated with small perturbations around some fixed-point. This assumption depends on the experimental design and is more easily motivated when data are harvested during periods of limited perturbations to the subject's neuronal state. In short, we discount the possibility of phase-transitions and bifurcations (e.g., oscillatory dynamics) due to the non-linear properties of cortical macrocolumns (e.g. <xref rid="bib2" ref-type="bibr">Breakspear et al., 2006</xref>).</p>
        <sec>
          <title>The neural mass model</title>
          <p>The underlying dynamic causal model is defined by the equations of motion <mml:math id="M1" altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mtext>,</mml:mtext><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math> at the neuronal level. In this context, they correspond to a neural-mass model that has been used extensively in the causal modelling of EEG and MEG data and has been described previously for modelling spectral responses (<xref rid="bib23 bib24" ref-type="bibr">Moran et al., 2007, 2008</xref>). This model ascribes three sub-populations to each neuronal source, corresponding roughly to spiny stellate input cells, deep pyramidal output cells and inhibitory interneurons. Following standard neuroanatomic rules (<xref rid="bib11" ref-type="bibr">Felleman and Van Essen 1991</xref>), we distinguish between forward connections (targeting spiny stellate cells), backward connections (targeting pyramidal cells and inhibitory interneurons with slower kinetics) and lateral connections (targeting all subpopulations); see <xref rid="fig1" ref-type="fig">Fig. 1</xref> and <xref rid="bib23" ref-type="bibr">Moran et al., (2007)</xref>. Each neuronal source could be regarded as a three-layer structure, in which spiny stellate cells occupy the granular layer, while infragranular and supragranular layers contain both pyramidal cells and inhibitory interneurons.</p>
          <p>Each subpopulation is modelled with pairs of first-order differential equations of the following form:<disp-formula id="fd1"><label>(1)</label><mml:math id="M2" altimg="si2.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mi>v</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>κ</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>κ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mi>κ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>v</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
          <p>The column vectors <italic>x</italic><sub><italic>v</italic></sub> and <italic>x</italic><sub><italic>I</italic></sub>, correspond to the mean voltages and currents, where each element corresponds to the hidden state of the subpopulation at each source. These differential equations implement a convolution of a subpopulation's presynaptic input to produce a postsynaptic response. The output of each source is modelled as a mixture of the depolarisation of each subpopulation. Due to the orientation of deep pyramidal cell dendrites, tangential to the cortical surface, this population tends to dominate LFP recordings. We accommodate this by making the output of each source, <italic>g</italic>(<italic>x</italic>) a weighted mixture of <italic>x</italic><sub><italic>v</italic></sub> with weights of 60% for the pyramidal subpopulation and 20% for the others. The presynaptic input to each subpopulation comprises endogenous, <italic>E</italic>(<italic>x</italic>), and exogenous, <italic>C</italic>(<italic>u</italic>), components</p>
        </sec>
        <sec>
          <title>Endogenous inputs</title>
          <p>In a DCM comprising <italic>s</italic> sources, endogenous input <italic>E</italic>(<italic>x</italic>) is a weighted mixture of the mean firing rates in other subpopulations (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>). These firing rates are a sigmoid activation function of depolarisation, which we approximate with a linear gain function; <italic>S</italic>(<italic>x</italic><sub><italic>i</italic></sub>) = <italic>Sx</italic><sub><italic>i</italic></sub> ∈ ℜ<sup><italic>s</italic></sup><sup>x1</sup>. Firing rates provide endogenous inputs from subpopulations that are intrinsic or extrinsic to the source. Subpopulations within each source are coupled by intrinsic connections, whose strengths are parameterised by <italic>γ</italic> = {<italic>γ</italic><sub>1</sub>,…,<italic>γ</italic><sub>5</sub>}. These endogenous intrinsic connections can arise from any subpopulation and present with small delays. Conversely, endogenous extrinsic connections arise only from the excitatory pyramidal cells of other sources and effect a longer delay than intrinsic connections. The strengths of these connections are parameterised by the forward, backward and lateral extrinsic connection matrices <italic>A</italic><sup><italic>F</italic></sup> ∈ ℜ<sup><italic>s</italic></sup><sup>xs</sup>, <italic>A</italic><sup><italic>B</italic></sup> ∈ ℜ<sup><italic>s</italic></sup><sup>xs</sup> and <italic>A</italic><sup><italic>L</italic></sup> ∈ ℜ<sup><italic>s</italic></sup><sup>xs</sup> respectively. The postsynaptic efficacy of connections is encoded by the maximum amplitude of postsynaptic potentials <italic>H</italic><sub><italic>e,i</italic></sub> = <italic>diag</italic>(<italic>H</italic><sub>1</sub>,…,<italic>H</italic><sub>s</sub>) (note the subscripts in <xref rid="fig1" ref-type="fig">Fig. 1</xref>) and by the rate-constants of postsynaptic potentials, <italic>κ</italic> = <italic>diag</italic>(<italic>κ</italic><sub>1</sub>,…,<italic>κ</italic><sub>s</sub>) for each source. The rate-constants are lumped representations of passive membrane properties and other spatially distributed dynamics in the dendritic tree.</p>
        </sec>
        <sec>
          <title>Exogenous inputs</title>
          <p>Exogenous inputs <italic>C</italic>(<italic>u</italic>) = <italic>Cu</italic> are scaled by the exogenous input matrix <italic>C</italic> ∈ ℜ<sup><italic>s</italic></sup><sup>xs</sup> so that each source-specific innovation <italic>u</italic>(<italic>t</italic>) ∈ ℜ<sup><italic>s</italic></sup><sup>x1</sup> excites the spiny stellate subpopulation. We parameterise the spectral density of this exogenous input, <italic>g</italic>(ω)<sub><italic>u</italic></sub>, in terms of white (<italic>α</italic>) and pink (<italic>β</italic>) spectral components:<disp-formula id="fd2"><label>(2)</label><mml:math id="M3" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>ω</mml:mi></mml:mrow></mml:math></disp-formula></p>
        </sec>
        <sec>
          <title>Neuronal responses</title>
          <p>The cross-spectral density is a description of the dependencies among the observed outputs of these neuronal sources. We will consider a linear mapping from <italic>s</italic> sources to <italic>c</italic> channels. In EEG and MEG this mapping is a lead-field or gain-matrix function, <italic>L</italic>(<italic>θ</italic>) ∈ ℜ<sup><italic>c</italic></sup><sup>x<italic>s</italic></sup>, of unknown spatial parameters, <italic>θ</italic>, such as source location and orientation. Generally, this function rests upon the solution of a well-posed electromagnetic forward model. For invasive LFP recordings that are obtained directly from the neuronal sources, this mapping is a leading diagonal gain-matrix, <italic>L</italic> = <italic>diag</italic>(<italic>θ</italic><sub>1</sub>,...<italic>θ</italic><sub><italic>s</italic></sub>) where the parameters model electrode-specific gains. The observed output at channel <italic>i</italic> is thus <italic>S</italic><sub><italic>i</italic></sub>(<italic>t</italic>) = <italic>L<sub>i</sub>g</italic>(<italic>x</italic>), where <italic>g</italic>(<italic>x</italic>) is the source output (a mixture of depolarisations) and <italic>L</italic><sub><italic>i</italic></sub> represents the <italic>i</italic>-th lead-field or row of the gain-matrix. In other words, <italic>L</italic> = ℜ<sup>1x<italic>s</italic></sup> is the change in observed potential caused by changes in source activity. These observed outputs can now be used in a generative model of source cross-spectral measures.</p>
        </sec>
        <sec>
          <title>Cross-spectral density</title>
          <p>The neuronal model comprises a network of neuronal sources, each of which generates stationary time-series in a set of recording channels. These steady-state dynamics are expressed, in the frequency domain, as cross-spectral densities, g<sub><italic>ij</italic></sub>(<italic>ω</italic>), at radial frequencies ω, between channels <italic>i</italic> and <italic>j</italic>. Under linear systems theory, the cross-spectral density induced by the <italic>k</italic>-th input or innovation <italic>u</italic><sub><italic>k</italic></sub>(<italic>t</italic>), is simply the cross-transfer function Γ<italic><sub>ij</sub><sup>k</sup></italic>(<italic>ω</italic>) times the spectral density of that innovation, <italic>g</italic><sub><italic>k</italic></sub>(<italic>ω</italic>)<sub><italic>u</italic></sub>. This transfer function is the cross-product of the Fourier transforms of the corresponding first-order kernels, <italic>κ<sub>i</sub><sup>k</sup></italic>(<italic>t</italic>) and <italic>κ<sub>i</sub><sup>k</sup></italic>(<italic>t</italic>) and in the case of <italic>i</italic> = <italic>j</italic> may be regarded as the modulation or self-transfer function).<disp-formula id="fd3"><label>(3)</label><mml:math id="M4" altimg="si4.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:msup><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
          <p>The convolution kernels mediate the effect of the <italic>k</italic>-th input, at time <italic>t</italic> in the past, on the current response recorded at each channel. In general, they can be regarded as impulse response functions and describe the output at the <italic>i</italic>-th channel, <italic>S</italic><sub><italic>i</italic></sub>(<italic>t</italic>), produced by a spike of the <italic>k</italic>-th exogenous input, <italic>u</italic><sub><italic>k</italic></sub>(<italic>t</italic>). The kernel for each channel obtains analytically from the Jacobian ℑ = ∂<italic>f</italic>/∂<italic>x</italic> describing how the system's hidden neuronal states, <italic>x</italic>(<italic>t</italic>), couple inputs to outputs. For channel <italic>i</italic>, and input <italic>k</italic> the kernel is<disp-formula id="fd4"><label>(4)</label><mml:math id="M5" altimg="si5.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mi>κ</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="true">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>·</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>·</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mo>exp</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="fraktur">I</mml:mi><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="fraktur">I</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
          <p>This means the kernels are analytic functions of <mml:math id="M6" altimg="si6.gif" overflow="scroll"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>·</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math> and <italic>s</italic>(<italic>t</italic>) = <italic>Lg</italic>(<italic>x</italic>); the network's equations of motion and output function respectively. The use of the chain rule follows from the fact that the only way past inputs can affect current channel outputs is through the hidden states. It is these states that confer memory on the system. In <xref rid="app1" ref-type="sec">Appendix A</xref>, we present an alternative derivation of the cross-spectral density using the Laplace transform of the dynamics in state-space form. This gives a more compact, if less intuitive, series of expressions that are equivalent to the kernel expansion. In this form, the Jacobian is known as the state transition matrix. To accommodate endogenous input delays between different sources and intrinsic transmission delays between different populations within one source, we augment the Jacobian using a Hadamard product; <mml:math id="M7" altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="fraktur">I</mml:mi><mml:mo>←</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mi mathvariant="fraktur">I</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="fraktur">I</mml:mi></mml:mrow></mml:math>, which is based on a Taylor approximation to the effect of delays, τ (see <xref rid="app1" ref-type="sec">Appendix A.1</xref> of <xref rid="bib8" ref-type="bibr">David et al., 2006</xref> for details).</p>
          <p>To furnish a likelihood model for observed data-features we include a cross-spectral density <italic>ψ</italic><sub><italic>ij</italic></sub> induced by channel noise and add a random observation error to the predicted cross-spectral density. Finally, we apply a square root transform to the observed and predicted densities to render the observation error approximately Gaussian. Cross-spectral densities will asymptote to a Wishart distribution at a large sample limit (Brillinger, 1969). However, when averaging each cross or auto-spectral frequency variate across multiple trials, one can appeal to the central limit theorem and assume a near normal distribution. In cases where multiple realisations are limited (see <xref rid="sec1" ref-type="sec">Empirical Demonstration below</xref>) the square-root transform renders a Gaussian assumption more valid (see <xref rid="bib17" ref-type="bibr">Kiebel et al., 2005</xref> for a comprehensive treatment). The advantage of being able to assume Gaussian errors is that we can invert the model using established variational techniques under something called the Laplace assumption (<xref rid="bib10" ref-type="bibr">Friston et al., 2007</xref>); this means the current DCM is inverted using exactly the same scheme as all the other DCMs of neurophysiological data we have described.<disp-formula id="fd5"><label>(5)</label><mml:math id="M8" altimg="si8.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msqrt><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:msqrt><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ψ</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mo>+</mml:mo><mml:mi>ɛ</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>ψ</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>ψ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>ω</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>ψ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>ω</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
          <p>The spectral densities, <italic>ψ</italic><sub><italic>c</italic></sub> and <italic>ψ</italic><sub><italic>s</italic></sub> model the contributions of common noise sources (e.g., a common reference channel) and channel-specific noise respectively. As with the neuronal innovations we parameterise these spectral densities as an unknown mixture of white and pink components. The observation error <italic>ɛ</italic> ~ <italic>N</italic>(0, Σ (<italic>λ</italic>)) has a covariance function, Σ(<italic>λ</italic>) = exp(<italic>λ</italic>)<italic>V</italic>(<italic>ω</italic>), where <italic>λ</italic> are unknown hyperparameters and <italic>V</italic>(<italic>ω</italic>) encodes correlations over frequencies<xref rid="fn1" ref-type="fn">1</xref>.</p>
          <p>Eqs. (<xref rid="fd1" ref-type="disp-formula">1</xref>) to (<xref rid="fd5" ref-type="disp-formula">5</xref>) specify the predicted cross-spectral density between any two channels given the parameters of the observation model {<italic>α</italic>, <italic>β</italic>, <italic>λ</italic>, <italic>θ</italic>} and the neuronal state equations, {<italic>κ</italic>, <italic>H</italic>, <italic>γ</italic>, <italic>A</italic>, <italic>C</italic>}. This means that the cross-spectral density is an analytic function of the parameters <italic>ϑ</italic> = {<italic>α</italic>, <italic>β</italic>, <italic>κ</italic>,<italic>H</italic>, <italic>γ</italic>, <italic>A</italic>, <italic>C</italic>, <italic>λ</italic>,<italic>θ</italic>} and specifies the likelihood <italic>p</italic>(<italic>g</italic><sub><italic>c</italic></sub> |<italic>ϑ</italic>) of observing any given pattern of cross-spectral densities at any frequency. When this likelihood function is supplemented with a prior density on the parameters, <italic>p</italic>(<italic>ϑ</italic>) (see <xref rid="bib23" ref-type="bibr">Moran et al., 2007</xref> and <xref rid="tbl1" ref-type="table">Table 1</xref>), we have a full probabilistic generative model for cross-spectral density features <italic>p</italic>(<italic>g</italic><sub><italic>c</italic></sub>,<italic>ϑ</italic>) = <italic>p</italic>(<italic>g</italic><sub><italic>c</italic></sub> |<italic>ϑ</italic>) <italic>p</italic>(<italic>ϑ</italic>) that is specified in terms of biophysical parameters. Next, we look at how to extract the data features this model predicts.</p>
        </sec>
      </sec>
      <sec>
        <title>Evaluating the cross-spectral density</title>
        <p>The assumptions above establish a generative model for cross-spectral features of observed data under linearity and local stationarity assumptions. To invert or fit this model we need to perform an initial feature selection on the raw LFP or M/EEG data. In this section, we describe this procedure, using a vector auto-regression (VAR) model of the multi-channel data and comment briefly on its advantages over alternative schemes. We use a <italic>p</italic>-order VAR-model of the channel data <italic>y</italic>, to estimate the underlying auto-regression coefficients <italic>A</italic>(<italic>p</italic>) ∈ ℜ<sup><italic>c</italic></sup><sup>xc</sup> (where <italic>c</italic> is the number of channels<xref rid="fn2" ref-type="fn">2</xref>).<disp-formula id="fd7"><label>(6)</label><mml:math id="M9" altimg="si10.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math></disp-formula></p>
        <p>Here the channel data at the <italic>n</italic>-th time point,<italic>y</italic><sub><italic>n</italic></sub>, represents a signal vector over channels. The autoregressive coefficients <italic>A</italic><sup>(<italic>k</italic>)</sup> are estimated using both auto-and cross-time-series components. These, along with an estimated channel noise covariance, <italic>E</italic><sub><italic>ij</italic></sub> provide a direct estimate of the cross-spectral density, <italic>g</italic><sub><italic>ij</italic></sub>(<italic>ω</italic>)<sub><italic>c</italic></sub> = <italic>f</italic>(A(<italic>p</italic>)), using the following transform:<disp-formula id="fd8"><label>(7)</label><mml:math id="M10" altimg="si11.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn><mml:mi>w</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>…</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:msubsup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p>The estimation of the auto-regression coefficients, <italic>A</italic><sup>(<italic>k</italic>)</sup> ∈ <italic>A</italic>(<italic>p</italic>) uses the spectral toolbox in SPM (<ext-link xlink:href="http://www.fil.ion.ucl.ac.uk" ext-link-type="uri">http://www.fil.ion.ucl.ac.uk</ext-link>) that allows for Bayesian point estimators of <italic>A</italic>(<italic>p</italic>), under various priors on the coefficients. Details concerning the Bayesian estimation of the VAR-coefficients can be found in Roberts and Penny (2002). Briefly, this entails a variational approach that estimates the posterior densities of the coefficients. This posterior density is approximated in terms of its conditional mean and covariance; <italic>p</italic>(<italic>A</italic>|<italic>y</italic>, <italic>p</italic>) = <italic>N</italic>(<italic>μ</italic><sub>A</sub>,Σ<sub>A</sub>). These moments are optimised through hyperparameters <italic>v</italic><sub><italic>E</italic></sub> and <italic>v</italic><sub><italic>A</italic></sub> (with Gamma hyperpriors; Γ(10<sup>3</sup>, 10<sup>− 3</sup>)) encoding the precision of the innovations <italic>e</italic> and the prior precision, respectively<xref rid="fn3" ref-type="fn">3</xref>:<disp-formula id="fd9"><label>(8)</label><mml:math id="M11" altimg="si13.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mo>∑</mml:mo><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mi>I</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>Equation <xref rid="fd8" ref-type="disp-formula">7</xref> uses the posterior mean of the coefficients to provide the cross-spectral density features.</p>
        <p>The advantage of our parametric approach is its structural equivalence to the generative model itself. We use uninformative priors but place formal constraints on the estimation of cross-spectral density through the order <italic>p</italic> of the VAR-model. This has important regularising properties when estimating the spectral features. Alternatively, non-parametric methods could be used to quantify the cross-spectral density; e.g., a fast Fourier transform (FFT). However, in the case of <italic>a priori</italic> information regarding model order, several advantages exist for parametric approaches over the conventional FFT. One inherent problem of the FFT is its limited ability to distinguish between signal components at neighbouring frequencies. This resolution in Hertz is roughly reciprocal to the time interval in seconds, over which data are sampled. This is particularly problematic for short time segments where low delta (2–4 Hz) or theta (4–8 Hz) activity may be of interest. Secondly, when long data sequences are evaluated, averaging methods using a windowed FFT must trade-off spectral leakage and masking from side-lobes with broadening in the main lobe, which further decreases resolution. These limitations can be overcome using an AR model since frequencies can be estimated at any frequency point up to the Nyquist rate, and do not require windowing to obtain average steady-state estimates (<xref rid="bib15" ref-type="bibr">Kay and Marple, 1981</xref>). The principle concern in using these AR methods is frequency splitting (the appearance of a spurious spectral peak), that ensues with overestimation of the model order (<xref rid="bib36" ref-type="bibr">Spyers-Ashby et al., 1998</xref>). However, we can avoid this problem by exploiting our neural mass model: principled constraints on the order are furnished by the DCM above and follow from the fact that the order of the underlying VAR process is prescribed by the number of hidden neuronal states in the DCM. Heuristically, if one considers a single source, the evolution of its hidden states can be expressed as a <italic>p</italic>-variate VAR(1) process<disp-formula id="fd10"><label>(9)</label><mml:math id="M12" altimg="si14.gif" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>exp</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mstyle mathvariant="fraktur"><mml:mi>I</mml:mi></mml:mstyle><mml:mi>τ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>η</italic>(<italic>t</italic>) corresponds to exogenous input convolved with the system's kernel. Alternatively, we can represent this process with a univariate AR(<italic>p</italic>) process on a single state. Because there is a bijective mapping between source activity and measurement space, the multivariate data can be represented as a VAR(<italic>p</italic>) process. We provide a formal argument in <xref rid="app2" ref-type="sec">Appendix B</xref> for interested readers.</p>
        <p>The number of hidden states per source is twelve (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>) and this places an upper bound on the order of the VAR model<xref rid="fn4" ref-type="fn">4</xref>. The relationship between the VAR model order and the number of hidden states can be illustrated in terms of the log-evidence ln <italic>p</italic>(<italic>y</italic>|<italic>p</italic>) for VAR models with different orders: we convolved a mixture of pink and white noise innovations with the DCM's first-order kernel (using the prior expectations) and used these synthetic data to invert a series of VAR models of increasing order. <xref rid="fig2" ref-type="fig">Fig. 2</xref> shows the ensuing model evidence jumps to a high value when the order reaches twelve, with smaller increases thereafter.</p>
      </sec>
      <sec>
        <title>Model inversion and inference</title>
        <p>Model inversion means estimating the conditional density of the unknown model parameters <italic>p</italic>(<italic>ϑ</italic>|<italic>g</italic><sub><italic>c</italic></sub>,<italic>m</italic>) given the VAR-based cross-spectral density features <italic>g</italic><sub><italic>c</italic></sub> for any model <italic>m</italic> defined by the network architecture and priors on the parameters, <italic>p</italic>(<italic>ϑ</italic>|<italic>m</italic>). These unknown parameters include (i) the biophysical parameters of the neural-mass model, (ii) parameters controlling the spectral density of the neuronal innovations and channel noise, (iii) gain parameters and (iv) hyperparameters controlling the amplitude of the observation error in Eq. (<xref rid="fd5" ref-type="disp-formula">5</xref>). The model is inverted using standard variational approaches described in previous publications and summarised in <xref rid="bib10" ref-type="bibr">Friston et al., (2007)</xref>. These procedures use a variational scheme in which the conditional density is optimized under a fixed-form (Laplace) assumption. This optimisation entails maximising a free-energy bound on the log-evidence, 1n <italic>p</italic>(<italic>g</italic><sub><italic>c</italic></sub> |<italic>m</italic>). Once optimised, this bound can be used as an approximate log-evidence for model comparison in the usual way. Comparing DCMs in a way that is independent of their parameters is useful when trying to identify the most plausible architectures subtending observed responses (<xref rid="bib27" ref-type="bibr">Penny et al., 2004</xref>; <xref rid="bib39" ref-type="bibr">Stephan et al., 2007</xref>) and is used extensively in subsequent sections. The focus of this paper is on the approximate log-evidence 1n <italic>p</italic>(<italic>g</italic><sub><italic>c</italic></sub> |<italic>m</italic>) and conditional densities <italic>p</italic>(<italic>ϑ</italic>|<italic>g</italic><sub><italic>c</italic></sub>,<italic>m</italic>) and, in particular, whether they can support robust inferences on neural-mass models and their parameters.</p>
      </sec>
    </sec>
    <sec>
      <title>Identifiability and face validity</title>
      <p>In this section, we try to establish the face validity of the DCM and inversion scheme described in the previous section. Here, we use synthetic datasets generated by models with known parameters. We then try to recover the best model and its parameters, after adding noise to the data. We will address both inference on models and their parameters. This involves searching over a space or set of models to find the model with the greatest evidence. One then usually proceeds by characterising the parameters of the best model in terms of their conditional density. In both inference on models and parameters, we used the same model employed to analyse the empirical data of the next section. This enabled us to relate the empirical results to the simulations presented below.</p>
      <sec>
        <title>Inference on model-space</title>
        <p>For inference on models, we generated data from three two-source networks using extrinsic connections from the first to the second source, from the second to the first and reciprocal connections. To assess inference on model-space, we first performed a model comparison using a small set of two source networks, delimited by their forward connections only. Specifically, each of the three models that were used to generate the model-specific data sets, were compared across each set of data. We hope to show that the inversion scheme identified the correct model in all three cases. In all three models exogenous neuronal inputs entered both sources and the connections were all of the forward type. These three models are also evaluated in the empirical analysis. The parameter values for all three models were set to their prior expectations<xref rid="fn5" ref-type="fn">5</xref>, with the exception of the extrinsic connections, for which we used the conditional estimates of the empirical analysis. Data were generated over frequencies from 4 to 48 Hz and observation noise was added (after the square root transform). The variance of this noise corresponded to the conditional estimate of the error variance from the empirical analysis.</p>
        <p>The resulting three data sets were then inverted using each of the three models. For each data set, this provided three log-evidences (one for each model used to fit the spectral data). We normalised these to the log-evidence of the weakest model to produce log-likelihood ratios or log-Bayes factors. The results for the three models are shown in <xref rid="tbl2" ref-type="table">Table 2</xref>a. These indicate that, under this level of noise, DCM was able to identify the model that actually generated the data. In terms of inference on model-space, we computed the posterior probability of each model by assuming flat or uniform priors on models; under this assumption <italic>p</italic>(<italic>y</italic>|<italic>m</italic><sub><italic>i</italic></sub>) ∝ <italic>p</italic>(<italic>m</italic><sub><italic>i</italic></sub>|<italic>y</italic>), which means we can normalise the evidence for each model, given one data set and interpret the result as the conditional probability on models. These are expressed as percentages in <xref rid="tbl3" ref-type="table">Table 3</xref>b and show that we can be almost certain that the correct model will be selected from the three-model set, with conditional probabilities close to one for correct models and close to zero for incorrect models Following the suggestions of our reviewers, we performed a second analysis where we compared all possible two-source DCM networks. This model space, which comprised 256 models in total, was derived by considering all possible permutations of inputs and connections. We would like to emphasize that this brute force method of testing all possible models (which can be very expensive in terms of computation time) is appropriate only when using small networks with a limited number of free variables. In the applied case of analysing empirical data, DCM is used to test a limited number of hypotheses regarding the type of neuronal architecture that subtends observed experimental responses (e.g. <xref rid="bib12 bib38 bib39" ref-type="bibr">Grol et al., 2007; Stephan et al., 2006a, 2007</xref>). This is because (i) the precision of inference with DCM generally favours a strongly hypothesis-driven approach and (ii) the combinatorics of possible DCMs quickly explodes with the number of sources and connections.</p>
        <p>The results of this second analysis show that DCM can correctly identify the generative model, even when all 256 possible models are considered. For each of the three data sets that were inverted, the log-evidence was greatest for the correct generative model (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). The relative log-evidence or log Bayes-factors for the best compared to the second best model offered strong support for the correct model, in all three cases (ln <italic>BF</italic><sup><italic>1</italic></sup> = 14.6 ; ln <italic>BF</italic><sup><italic>2</italic></sup> = 16.2 ; ln <italic>BF</italic><sup><italic>3</italic></sup> = 16.4). Note that when we talk of the ‘best' model, we mean a model for which there is strong evidence relative to any competing model. In other words, we can be 95% confident that the evidence for the best model is greater than any other (this corresponds to a relative log-evidence of about three). In summary, Bayesian model comparison with DCM seems to be able to identify these sorts of models with a high degree of confidence.</p>
      </sec>
      <sec>
        <title>Inference on parameter-space</title>
        <p>For inference on parameters, we looked at the effects of changing the maximum amplitudes of excitatory postsynaptic potentials (EPSP), which control the efficacy of intrinsic and extrinsic connections and the effects of changing the extrinsic connections themselves. These effects are encoded in the parameters <italic>H</italic><sub><italic>e</italic></sub> ∈ <italic>ϑ</italic> and <italic>A</italic><sup><italic>F</italic></sup> ∈ <italic>ϑ</italic>, respectively. We addressed identifiability by inverting a single model using synthetic data with different levels of noise. By comparing the true parameter values to the conditional confidence intervals, under different levels of noise, we tried to establish the accuracy of model inversion and how this depends upon the quality of the data. As above, we chose different levels of noise based upon the error variance estimated using real data. Specifically, we varied the noise levels from 0.001 to 2 times the empirical noise variance, allowing a broad exploration of relative signal-to-noise ratios (SNR) .</p>
        <p>The model we used is the same model identified by the empirical analyses of the next section. This model comprised two sources and two LFP channels with no cross-talk between the channels. The parameter values were based on the estimates from the empirical analysis. Specifically, source 1 sent a strong extrinsic connection to source 2, whose excitatory cells had a relatively low postsynaptic response (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). All parameter values were set to their prior expectation, except for the parameters of interest <italic>H</italic><sub><italic>e</italic></sub><sup>(2)</sup> and <italic>A</italic><sub>21</sub><sup><italic>F</italic></sup>.</p>
        <p>In our DCM, parameters are optimised by multiplying their prior expectation with an unknown log-scale parameter that is exponentiated to ensure positivity. Hence, a log-scale parameter of zero corresponds to a scale-parameter of one, which renders the parameter value equal to its prior expectation. By imposing Gaussian priors on the log-scale parameters we place log-normal priors on the parameters <italic>per se</italic>. To model reduced postsynaptic amplitudes in source 2, <italic>H</italic><sub><italic>e</italic></sub><sup>2</sup> had a log-scale parameter of − 0.4 representing a exp(− 0.4) = 67% decrease from its prior expectation. The log-scale parameter encoding the forward connection from source 1 to source 2, namely <italic>A</italic><sub>2,1</sub><sup><italic>F</italic></sup>, was set to 1.5, representing a exp(1.5) = 448% increase from its prior expectation. Both sources received identical neuronal innovations, comprising white and pink spectral components (as specified in Equation <xref rid="fd2" ref-type="disp-formula">2</xref> above). Data were generated over frequencies from 4 to 48 Hz.</p>
        <p>Posterior density estimates for all parameters, <italic>p</italic>(<italic>ϑ</italic> | <italic>g</italic><sub><italic>c</italic></sub>,<italic>m</italic>) were obtained for 128 intermediate noise levels between one thousandth and twice the empirical noise variance. The conditional expectation or MAP (maximum <italic>a posteriori</italic>) estimates of <italic>H</italic><sub><italic>e</italic></sub><sup>(2)</sup> and <italic>A</italic><sub>2,1</sub><sup><italic>F</italic></sup> are shown in <xref rid="fig5" ref-type="fig">Fig. 5</xref> (hashed red line). The (constant) true parameter values are indicated by the solid red line, and the prior value is in grey. The shaded areas correspond to the 90% confidence intervals based on the conditional or posterior density. The lower panels show the conditional probabilities <italic>p</italic>(<italic>H</italic><sub><italic>e</italic></sub><sup>(2)</sup> &lt; 8) and <italic>p</italic>(<italic>A</italic><sub>2,1</sub><sup><italic>F</italic></sup> &gt; 32) that the parameters differed from their prior expectations.</p>
        <p>It can be seen that the conditional expectation remained close to the true values for both parameters, despite differences in their conditional precision, which decreased with increasing levels of observation noise. This can be seen in the shrinking Bayesian confidence intervals (grey area) and in the small increase in conditional probabilities with less noise. This effect is more marked for the estimates of <italic>H</italic><sub><italic>e</italic></sub><sup>(2)</sup>; where the confidence intervals splay at higher noise levels. This jagged variance in the confidence interval itself reflects the simulation protocol, in which each data set comprised a different noise realisation. In addition, the lowest conditional probability (that the parameter posterior estimate differed from the prior) for all simulations, occurred for this EPSP parameter where <italic>p</italic>(<italic>H</italic><sub><italic>e</italic></sub><sup>(2)</sup> &lt; 8) = .74 at a high noise level of 1.83. In contrast, the connection strength parameter remained within tight confidence bounds for all noise levels and produced a minimum conditional probability, <italic>p</italic>(<italic>A</italic><sub>2,1</sub><sup><italic>F</italic></sup> &lt; 32) = .99. This minimum occurred again as expected, at a high noise levels of 1.72 times the empirical noise level. One can also see, for both parameters a trend for conditional estimates to shrink towards the prior values at higher noise levels; this shrinkage is typical of Bayesian estimators; i.e. when data become noisy, the estimation relies more heavily upon priors and the prior expectation is given more weight (<xref rid="bib9" ref-type="bibr">Friston et al., 2003</xref>). Importantly, while the 90% confidence bounds generally encompass the true values, the prior values remain outside. In summary, under the realistic levels of noise considered, it appears possible to recover veridical parameter estimates and be fairly confident that these estimates differ from their prior expectation.</p>
      </sec>
    </sec>
    <sec id="sec1">
      <title>Empirical demonstration</title>
      <p>In this section, we present a similar analysis to that of the previous section but using real data. Furthermore, to pursue construct-validity, we invert the model using data acquired under different experimental conditions to see if the conditional estimates of various synaptic parameters change in a way that is consistent with previous analyses of functional connectivity using cross-correlograms. These analyses suggest an increase in coupling between the amygdala and hippocampus that is expressed predominantly in the theta range. This section considers the empirical data set-up, experimental design and inference on models and parameters. We interpret the conditional estimates of the parameters, in relation to the underlying physiology, in the Discussion.</p>
      <sec>
        <title>Empirical LFP data</title>
        <p>Local field potential data were acquired from mice (adult male C57B/6J mice, 10 to 12 weeks old) during retrieval of a fear-memory, learned in a Pavlovian conditioning paradigm using acoustic tones (CS+ and CS-) and foot-shock (US). A previous analysis of these data (<xref rid="bib35" ref-type="bibr">Seidenbecher et al., 2003</xref>) points to the importance of theta rhythms (∼ 5 Hz) during fear-memory retrieval (<xref rid="bib25 bib4" ref-type="bibr">Pape and Stork, 2003; Buzsaki, 2002</xref>). Specifically, <xref rid="bib35" ref-type="bibr">Seidenbecher et al., (2003)</xref> demonstrated an increase in theta-band coupling between area CA1 of the hippocampus and the lateral nucleus of the amygdala (LA) during presentation of the CS+. Moreover, theta synchrony onset was correlated with freezing, a behavioural index of fear-memory (<xref rid="bib21" ref-type="bibr">Maren et al., 1997</xref>). For the purposes of demonstrating our DCM, we here revisit the data of a single animal and show that this ‘on/off’ theta synchrony can be explained with plausible neurobiological mechanisms at the synaptic level, using the methodology described in the previous sections. These data represent quasi-stationary signals as evidenced by small time variations in signal strength (<xref rid="fig5" ref-type="fig">Figs. 5</xref>a and b). The term “steady-state” refers to the frequency estimates that represent only the constant spectral amplitude and are the complete data feature captured by this DCM. Below, we examine induced steady-state responses, where spectral estimates are averaged over independent trials. However, there is no principled reason why the current model may not be inverted using spectra from a time-frequency analysis of evoked responses or event related responses, under the assumption of local stationarity over a few hundred milliseconds (e.g. <xref rid="bib32" ref-type="bibr">Robinson et al., 2008</xref>; <xref rid="bib16" ref-type="bibr">Kerr et al., 2008</xref>).</p>
        <p>LFP data were recorded from two electrodes in the LA and the CA1 of the dorsal hippocampus. The data comprised 6 min of recording, during which four consecutive CS- tones and four consecutive CS+ tones were presented, each lasting 10 s. Freezing behaviour was seen prominently during the CS+. Preliminary analysis, using time-frequency spectrograms, revealed that the hippocampal region exhibited strong background theta rhythms, during CS+ and CS- epochs (<xref rid="fig5" ref-type="fig">Figs. 5</xref>a and b); whereas theta activity in lateral amygdala was prominent only during the CS+ stimulus. <xref rid="fig6" ref-type="fig">Fig. 6</xref> displays the first CS+ and CS- epochs of fear recall. Cross-spectra were computed for three-second epochs that followed the onset of freezing behaviour in the four CS+ epochs and order-time matched CS- epochs. Cross-spectral densities were computed from 4 to 48 Hz, using an eighth-order VAR model, for each epoch and averaged across conditions (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). This revealed spectral features that corroborated the analysis of <xref rid="bib35" ref-type="bibr">Seidenbecher et al., (2003)</xref>; with pronounced fast theta activity in the hippocampus and a marked theta peak in the cross-spectral density. The amygdala showed a broader spectrum, with a preponderance of lower theta activity and a theta peak in, and only in, the CS+ trial.</p>
      </sec>
      <sec>
        <title>Dynamic causal modelling</title>
        <p>These cross-spectral densities were then inverted using a series of generative models. These models were used to test the direction of information flow during heightened theta synchrony following CS+. Given key experimental differences between CS- and CS+ trials, we introduced log-scale parameters <italic>β</italic><sub><italic>ki</italic></sub> to model trial-specific variations in specified parameters:<disp-formula id="fd11"><label>(10)</label><mml:math id="M13" altimg="si15.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mo>ϑ</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mo>ϑ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>exp</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><italic>β</italic><sub><italic>ki</italic></sub> is the <italic>k</italic>-th experimental effect on the <italic>i</italic>-th parameter and <italic>ϑ<sub>i</sub><sup>j</sup></italic> is the value of the <italic>i</italic>-th parameter <italic>ϑ</italic><sub><italic>i</italic></sub> in the <italic>j</italic>-th trial or condition. These effects are meditated by an experimental design matrix <italic>X</italic>, which encodes how experimental effects are expressed in each trial.</p>
        <p>Eq. (<xref rid="fd11" ref-type="disp-formula">10</xref>) is a generic device that we use to specify fully parameterised experimental effects on specific parameters in multi-trial designs. In this example, <italic>β</italic><sub>1<italic>i</italic></sub> is simply a log-scale parameter (<xref rid="tbl1" ref-type="table">Table 1</xref>) specifying the increase (or decrease) in CS+ relative to CS- trials. The parameters showing trial-specific effects were the extrinsic connections and excitatory post synaptic amplitudes; all other parameters we fixed over trials.</p>
        <sec>
          <title>Inference on models</title>
          <p>The extrinsic connection types in our DCM are based on connections between isocortical areas (<xref rid="bib11" ref-type="bibr">Felleman and Van Essen 1991</xref>); however, in this analysis we are dealing with allocortical (CA1) and subcortical (LA) brain regions that have no clearly defined hierarchical relationship. Therefore, our first step was to establish which connection type best explained the measured LFP data. We approached this using model comparison using DCMs with reciprocal connections between CA1 and LA. The connections in these models were (model 1) forward; (model 2) backward; (model 3) lateral; (model 4) a combination of forward and backward and (model 5) a combination of all three. Bayesian model comparison based on the log-evidence indicated that the most likely type of inter-regional connections was of the ‘forward’ type (model 1); where connections originate from pyramidal cells and target excitatory interneurons. <xref rid="fig8" ref-type="fig">Fig. 8</xref>a shows the relative model evidences for the five models (i.e., the log-Bayes factor with respect to the worst model).</p>
          <p>Next, employing the optimal connection type, three different input schemes were tested to find where driving inputs, i.e. from cortical regions, enter during CS+ and CS- epochs. These DCM's included; (model 1) comprising exogenous inputs to both CA1 and LA; (model 2) exogenous input to hippocampal region CA1 only and (model 3) the lateral amygdala only. <xref rid="fig8" ref-type="fig">Fig. 8</xref>b shows that the best model is model 1; where inputs enter both the lateral amygdala and hippocampal CA1.</p>
          <p>Having established a causal architecture for the inputs, three further models were tested to examine whether connections were bidirectional or unidirectional. These results are displayed in <xref rid="fig8" ref-type="fig">Fig. 8</xref>c, where model 1 had bidirectional connections, model 2 had unidirectional hippocampal to amygdala connections and model 3 had connections from amygdala to hippocampus. We see that the most plausible model contains bidirectional connections between hippocampus and amygdala.</p>
          <p>In principle, as in the analysis of synthetic data above, there are 256 possible DCMs that could explain the empirical data. However, to provide an exemplar strategy for when where exhaustive model searches are not possible, we finessed the search of model space by optimising various model attributes sequentially. This series of line searches can be regarded as a heuristic search over model space to identify the most likely model. One concern in using this sort of heuristic search is that conditional dependencies among the free-parameters do not guarantee the global maximum is found. To address this, we performed a further analysis of the ‘complete’ model, which comprised reciprocal connections of all types (forward and backward and lateral), and inputs to both regions. The resulting conditional covariance matrix was examined in order to investigate potential co-dependencies between the parameters. The posterior correlation matrix is shown in <xref rid="fig9" ref-type="fig">Fig. 9</xref> and shows only relatively small interdependencies between the search parameters. Overall, the accuracy of the best performing model was impressive; the fits to the cross-spectral data or shown in <xref rid="fig10" ref-type="fig">Fig. 10</xref> and are almost indistinguishable from the observed spectra. Having identified this model we now turn to inference on its parameters.</p>
        </sec>
        <sec>
          <title>Inference on parameters</title>
          <p>We now look at the conditional probabilities of key parameters showing trial-specific or conditioning effects, under the most plausible model. These parameters were the extrinsic connection strengths and intrinsic postsynaptic efficacies. When comparing the CS- and CS+ trials, we observe decreased amygdala-hippocampal connectivity and increased hippocampal-amygdala connectivity. <xref rid="fig11" ref-type="fig">Fig. 11</xref> shows the MAP estimates of ln <italic>β</italic><sub>1<italic>i</italic></sub>, which scale the extrinsic connections relative to 100% connectivity in CS-. In addition, there were small increases in postsynaptic efficacy in the amygdala for the CS+ relative to CS- Quantitatively, hippocampus-amygdala connectivity increased by 26%, with a conditional probability of 99.97% that this effect was greater than zero. In contrast, amygdala-hippocampus forward connections decreased by 72%, with a conditional probability of almost one. The relative change of intrinsic amygdala excitatory postsynaptic amplitude was 8% with a high conditional probability 99.85% that the increase was greater than zero. In contrast, changes in hippocampal excitatory postsynaptic amplitude were unremarkable, (0.002%) and with a conditional probability that was close to chance (69.70%).</p>
          <p>In summary, these results suggest that the hippocampus and amygdala influence each other through bidirectional connections. Steady states responses induced by CS+, relative to CS- stimuli appear to increase the intrinsic sensitivity of postsynaptic responses in the amygdala and with an additional sensitization to extrinsic afferents from the hippocampus. At the same time the reciprocal influence of the amygdala on the hippocampus is suppressed. These conclusions are exactly consistent with early hypotheses based on correlations (see below).</p>
        </sec>
      </sec>
    </sec>
    <sec>
      <title>Discussion</title>
      <p>We have described a dynamic causal model (DCM) of steady-state responses that are summarised in terms of cross-spectral densities. These spectral data-features are generated by a biologically plausible, neural-mass model of coupled electromagnetic sources. Under linearity and stationarity assumptions, inversion of the DCM provides conditional probabilities on both the models and the synaptic parameters of any particular model. The model employed here has previously been shown to produce oscillatory activity at all standard EEG frequency bands, in its linear approximation (<xref rid="bib23" ref-type="bibr">Moran et al., 2007</xref>). A nonlinear model analysis could uncover interesting dynamics in some of these bands and will be the subject of further research. This would call for a relaxation of the linearization assumption and present an interesting challenge for model inversion (<italic>c.f</italic>., <xref rid="bib40" ref-type="bibr">Valdes et al., 1999</xref>).</p>
      <p>Recently, a number of studies have established the utility neural mass models for interrogating EEG data. The motivations behind this approach are varied. In <xref rid="bib29" ref-type="bibr">Riera et al., (2006)</xref> neural masses are used to investigate local electrovascular coupling and their multi-modal time domain expression in EEG and fMRI data; while <xref rid="bib40" ref-type="bibr">Valdes et al. (1999)</xref> employ neural masses to examine the emergent dynamic properties of alpha-band activity. Closer to the work presented here, <xref rid="bib31" ref-type="bibr">Robinson et al., (2004)</xref> have developed a frequency domain description of EEG activity that highlights the importance of corticothalamic interactions, using neural field models. As in <xref rid="bib31" ref-type="bibr">Robinson et al., (2004)</xref>, the goal of DCM for steady-state responses is to make inferences about, regionally-specific neurotransmitter and neuromodulatory action that unfolds in a connected but distributed network. The DCM presented in this paper assumes a network of point sources (c.f., equivalent current dipoles) that may be usefully extended to cover neural field models of the sort considered by <xref rid="bib31" ref-type="bibr">Robinson et al., (2004)</xref>. DCM enables inference about synaptic physiology and changes induced by pharmacological or behavioural manipulations both within and between neural ensembles; furthermore, the methodology can be applied to the cross-spectral density of invasive or non-invasive electrophysiological recordings.</p>
      <p>Usually, in Dynamic Causal Modelling, data prediction involves the integration of a dynamical system to produce a time-series. In the current application, the prediction is over frequencies; however, the form of the inversion remains exactly the same. This is because in DCM for deterministic systems (i.e., models with no system or state noise) the time-series prediction is treated as a finite-length static observation, which is replaced here with a prediction over frequencies. The only difference between DCM for time-series and DCM for cross-spectral density is that the data-features are represented by a three dimensional array, covering <italic>c</italic> × <italic>c</italic> channels and <italic>b</italic> frequency-bins. In conventional time-series analysis the data-features correspond to a two-dimensional array covering <italic>c</italic> channels and <italic>b</italic> time-bins. The spectral summary used for data inversion comprises the magnitude of cross-spectra, which is a sufficient data-feature, under quasi-stationarity assumptions. Information regarding instantaneous phase or phase-coupling among sources are not considered in this treatment. In some settings, phase-coupling has been used in linear and nonlinear settings to model information exchange across discrete brain sources (e.g., <xref rid="bib3 bib34" ref-type="bibr">Brovelli et al., 2004, Rosenblum et al., 1996</xref>). The DCM presented here represents a complement to this approach by offering a biophysically meaningful, mechanistic description of neuronal interactions. An alternative DCM approach for M/EEG analysis has been developed to describe (time-dependent) phenomenological coupling among frequencies at different brain sources that occur through both linear and nonlinear mechanisms (<xref rid="bib5" ref-type="bibr">Chen et al., 2008</xref>). However, neither DCM model the instantaneous phase. Other recent developments in M/EEG data analysis have tackled this issue: Approaches involving ICA (<xref rid="bib1" ref-type="bibr">Anemüller et al., 2003</xref>) have been used to describe the phases of induced responses on a trial by trial basis, and make use of complex lead-field distributions to retain the imaginary parts of the source signals at the scalp level. However this approach studies independent components of brain activity and as such, is not directly comparable to DCM. DCM for phase responses is an active area of research (<xref rid="bib28" ref-type="bibr">Penny et al., 2008</xref>) and will receive a full treatment elsewhere.</p>
      <p>Our simulation studies provide some face validity for DCM, in terms of internal consistency. DCM was able to identify the correct model and, under one model, parameter values were recovered reliably in settings of high observation noise. Changes in the postsynaptic responsiveness, encoded by the population maximum EPSP, were estimated veridically at levels below prior threshold, with a conditional confidence of more than 74%; even for the highest levels of noise. Similarly, inter-area connection strength estimates were reasonably accurate under high levels of noise. With noisy data, parameter estimates tend to shrink towards their prior expectation, reflecting the adaptive nature of the weights afforded to prior and data information in Bayesian schemes.</p>
      <p>We have presented an analysis of empirical LFP data, obtained by invasive recordings in rat CA1 and LA during a fear conditioning paradigm. A previous analysis of these data (<xref rid="bib35" ref-type="bibr">Seidenbecher et al., 2003</xref>) showed prominent theta band activity in CA1 during both CS+ and CS- conditions, whereas LA expresses significant theta activity during CS+ trials only. Using an analysis of functional connectivity<xref rid="fn6" ref-type="fn">6</xref>, based on cross-correlograms of LA/CA1 activity in the theta range, <xref rid="bib35" ref-type="bibr">Seidenbecher et al., (2003)</xref> demonstrated an increase in connectivity between these two brain regions during CS+ trials. This is consistent with a trial-specific enabling or gating of the CA1 → LA connection during retrieval of conditioned fear in the CS+ condition, leading to a transient coupling of LA responses to the condition-independent theta activity in CA1. However, this analysis of functional connectivity was unable to provide direct evidence for directed or causal interactions. This sort of evidence requires a model of effective connectivity like DCM. The DCM analysis in the present study confirmed the hypothesis based on the cross-correlogram results of <xref rid="bib35" ref-type="bibr">Seidenbecher et al., (2003)</xref>. The DCM analysis showed a selective increase in CA1 → LA connectivity during CS+ trials, accompanied by a decrease in LA → CA1 connection strength. An additional finding was the increase in the amplitude of postsynaptic responses in LA during CS+ trials. This result may represent the correlate of long term potentiation of LA neurons following fear conditioning (<xref rid="bib33 bib19" ref-type="bibr">Rodrigues et al., 2004; LeDoux, 2000</xref>). In summary, one could consider these results as a demonstration of construct validity for DCM, in relation to the previous analyses of functional connectivity using cross-correlograms.</p>
      <p>The analysis of parameter estimates was performed only after Bayesian model selection. In the search for an optimum model, we asked (i) which connection type was most plausible, (ii) whether neuronal inputs drive CA1, LA or both regions; and (iii) which extrinsic connectivity pattern was most likely to have generated the observed data (directed CA1 → LA or LA → CA1 or reciprocal connections). The results of sequential model comparisons showed that there was a very strong evidence for a model in which (i) extrinsic connections targeted excitatory neurons, (ii) neuronal inputs drove both CA1 and LA and (iii) the two regions were linked by reciprocal connections. While there is, to our knowledge, no decisive empirical data concerning the first two issues, the last conclusion from our model comparisons is supported strongly by neuroanatomic data from tract-tracing studies. These have demonstrated prominent and reciprocal connections between CA1 and LA (see <xref rid="bib26" ref-type="bibr">Pitkänen et al., 2000</xref> for a review). This correspondence between neuroanatomic findings and our model structure, which was inferred from the LFP data, provides further construct validity, in relation to neuroanatomy.</p>
      <p>In conclusion, this study has introduced a novel variant of DCM that provides mechanistic explanations, at the level of synaptic physiology, for the cross-spectral density of invasive (LFP) or non-invasive (EEG) electrophysiological recordings. We have demonstrated how this approach can be used to investigate hypotheses about directed interactions among brain regions that cannot be addressed by conventional analyses of functional connectivity. A previous (single-source) DCM study (<xref rid="bib24" ref-type="bibr">Moran et al., 2008</xref>) of invasive LFP recordings in rats demonstrated the consistency of model parameter estimates with concurrent microdialysis measurements. The current study is another step towards establishing the validity of models, which we hope will be useful for deciphering the neurophysiological mechanisms that underlie pharmacological effects and pathophysiological processes (<xref rid="bib37" ref-type="bibr">Stephan et al., 2006b</xref>).</p>
    </sec>
    <sec>
      <title>Software note</title>
      <p>Matlab routines and demonstrations of the inversion described in this paper are available as academic freeware from the SPM website (<ext-link xlink:href="http://www.fil,ion.ucl.ac.uk/spm" ext-link-type="uri">http://www.fil,ion.ucl.ac.uk/spm</ext-link>) and will be found under the ‘api_erp’, ‘spectral’ and ‘Neural_Models’ toolboxes in SPM8.</p>
    </sec>
    <sec id="app1">
      <title>Appendix A. Laplace description of cross-spectral density</title>
      <p>Consider the State Space Model for a particular neuronal source<disp-formula id="fd12"><mml:math id="M14" altimg="si16.gif" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>·</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>u</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>u</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>where <italic>A</italic> is the state transition matrix or Jacobian, <italic>x</italic> are the hidden states (cf. Eq. (<xref rid="fd1" ref-type="disp-formula">1</xref>)) and <italic>y</italic> is the source output. The Laplace transform gives<disp-formula id="fd13"><label>(AI.1)</label><mml:math id="M15" altimg="si17.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mi>X</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>X</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>U</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>X</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>U</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⇒</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>X</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>B</mml:mi><mml:mi>U</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>⇒</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>U</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>Evaluating at <italic>s</italic> = <italic>jω</italic> gives the frequency output of the system. Given that the cross-spectrum for two signals <italic>i</italic> and <italic>j</italic> is defined as <italic>S</italic><sub><italic>ij</italic></sub> = <italic>Y<sub>i</sub>Y<sub>j</sub></italic><sup>⁎</sup> and that inputs to the system are seen by both sources, we can write the output cross-spectral density as<disp-formula id="fd14"><label>(AI.2)</label><mml:math id="M16" altimg="si18.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>H</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mi>U</mml:mi><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p>where <italic>H</italic><sub><italic>i</italic></sub> is computed from the transition matrices of each source directly. Furthermore, assuming white noise input we see from<disp-formula id="fd15"><label>(AI.3)</label><mml:math id="M17" altimg="si19.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>ω</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>ω</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>ω</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p>that <italic>H</italic><sub><italic>i</italic></sub> are the Fourier Transforms of the impulse responses. In our model, we supplement the input with pink (<italic>1/f</italic>) noise to render the input biologically plausible input. We can now see directly how the cross-spectral density in Eqs. (<xref rid="fd14" ref-type="disp-formula">A1.2</xref>) and (<xref rid="fd3" ref-type="disp-formula">3</xref>) are equivalent, in terms of system response to the unit impulse.</p>
      <sec id="app2">
        <title>Appendix B. VAR model order selection from the number of hidden states</title>
        <p>Consider the discrete-time signal described by the difference equation<disp-formula id="fd16"><label>(AII.1)</label><mml:math id="M18" altimg="si20.gif" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>…</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>ɛ</mml:mi></mml:mrow></mml:math></disp-formula></p>
        <p>The Laplace transform of a sampled signal is known as the Z-transform<disp-formula id="fd17"><label>(AII.2)</label><mml:math id="M19" altimg="si21.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>∞</mml:mo></mml:munderover><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:msup><mml:mn>0</mml:mn><mml:mo>−</mml:mo></mml:msup></mml:mrow><mml:mo>∞</mml:mo></mml:munderover><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>∞</mml:mo></mml:munderover><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p>For the AR model of AII.1 we obtain a Z domain representation<disp-formula id="fd18"><label>(AII.3)</label><mml:math id="M20" altimg="si22.gif" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ɛ</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p>Now consider again the state-space form of each source in Eq. (<xref rid="fd13" ref-type="disp-formula">AI.1</xref>). We see that the form of <italic>H</italic>(<italic>s</italic>) is a polynomial quotient, where the denominator is the characteristic polynomial of the Jacobian <italic>A</italic>. This contains powers of <italic>s</italic> up to the number of columns in <italic>A</italic>, indexed by the number of hidden states; i.e. the length of vector <italic>x.</italic> Hence, for <italic>q</italic> roots by partial fraction expansion we obtain<disp-formula id="fd19"><label>(AII.4)</label><mml:math id="M21" altimg="si23.gif" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="true">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>A</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mi>B</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mfrac><mml:mi>K</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
        <p>Using the s–z relation <italic>s</italic> + <italic>β</italic> = 1 – <italic>z</italic><sup>− 1</sup><italic>e</italic><sup>− </sup><italic><sup>βT</sup></italic>, we obtain the order of the AR model <italic>p</italic>, determined by the number of roots of the Jacobian <italic>q</italic> to give the delay <italic>z</italic><sup>− <italic>p</italic></sup> in Eq. (<xref rid="fd18" ref-type="disp-formula">AII.3</xref>).</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>The Wellcome Trust funded this work. Rosalyn Moran was funded by an Award from the Max Planck Society to RJD. We would like to thank Marcia Bennett for invaluable help preparing this manuscript.</p>
    </ack>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p>In our work, we use an AR(1) autoregression model of errors over frequencies, with an AR coefficient of one half and ensure that the error covariance components associated with the cross-spectral density between channels <italic>i</italic> and <italic>j</italic> are the same as the corresponding component for the cross-spectral density between channels <italic>j</italic> and <italic>i</italic>.</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p>For computational expediency, if there are more than eight channels, we project the data and predictions onto an eight-dimensional subspace defined by the principal components of the prior covariance matrix in channel space</p>
        <p>
          <disp-formula id="fd6">
            <mml:math id="M22" altimg="si9.gif" overflow="scroll">
              <mml:mrow>
                <mml:munder>
                  <mml:mo>∑</mml:mo>
                  <mml:mi>i</mml:mi>
                </mml:munder>
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:mi>L</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:msub>
                        <mml:mi>θ</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:msubsup>
                    <mml:mi>σ</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mn>2</mml:mn>
                  </mml:msubsup>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:msup>
                        <mml:mi>L</mml:mi>
                        <mml:mi>T</mml:mi>
                      </mml:msup>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>∂</mml:mo>
                      <mml:msub>
                        <mml:mi>θ</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mfrac>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </p>
        <p>where <italic>σ<sub>i</sub><sup>2</sup></italic> is the prior variance of the <italic>i</italic>-th spatial or gain parameter.</p>
      </fn>
      <fn id="fn3">
        <label>3</label>
        <p><mml:math id="M23" altimg="si12.gif" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math>comprise the time lagged data.</p>
      </fn>
      <fn id="fn4">
        <label>4</label>
        <p>In practice, we do not use the upper bound but use <italic>p</italic> = 8 for computational expediency; this seems to give robust and smooth spectral features.</p>
      </fn>
      <fn id="fn5">
        <label>5</label>
        <p>These expectations are biologically plausible amplitudes and rate constants that have been used in previous instances of the model (<xref rid="bib14" ref-type="bibr">Jansen et al., 1993</xref>; <xref rid="bib7" ref-type="bibr">David et al., 2005</xref>) and are summarized in <xref rid="bib23" ref-type="bibr">Moran et al., 2007</xref> and <xref rid="tbl1" ref-type="table">Table 1</xref>. In this study, prior variances on the intrinsic connectivity parameters were set to zero.</p>
      </fn>
      <fn id="fn6">
        <label>6</label>
        <p>Functional connectivity is defined as the statistical dependence between two biophysical time-series, whereas effective connectivity refers to the directed and casual influence one biophysical system exerts over another (<xref rid="bib9" ref-type="bibr">Friston et al., 2003</xref>)</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <label>Anemüller et al., 2003</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anemüller</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Sejnowski</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Makeig</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Complex independent component analysis of frequency-domain electroencephalographic data</article-title>
          <source>Neural Netw.</source>
          <year>2003</year>
          <volume>16</volume>
          <fpage>1311</fpage>
          <lpage>1323</lpage>
          <pub-id pub-id-type="pmid">14622887</pub-id>
        </citation>
      </ref>
      <ref id="bib2">
        <label>Breakspear et al., 2006</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Breakspear</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Terry</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Rodrigues</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mahant</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>P.A.</given-names>
            </name>
          </person-group>
          <article-title>A unifying explanation of primary seizures through nonlinear brain modeling and bifurcation analysis</article-title>
          <source>Cereb. Cortex</source>
          <year>2006</year>
          <volume>16</volume>
          <fpage>1296</fpage>
          <lpage>1313</lpage>
          <pub-id pub-id-type="pmid">16280462</pub-id>
        </citation>
      </ref>
      <ref id="bib3">
        <label>Brovelli et al., 2004</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brovelli</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ding</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ledberg</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Nakamura</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bressler</surname>
              <given-names>S.L.</given-names>
            </name>
          </person-group>
          <article-title>Beta oscillations in a large-scale sensorimotor cortical network: directional influences revealed by Granger causality,</article-title>
          <source>Proc. Natl. Acad. Sci.</source>
          <year>2004</year>
          <volume>101</volume>
          <fpage>9849</fpage>
          <lpage>9854</lpage>
          <pub-id pub-id-type="pmid">15210971</pub-id>
        </citation>
      </ref>
      <ref id="bib4">
        <label>Buzsaki, 2002</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Buzsaki</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Theta oscillations in the hippocampus</article-title>
          <source>Neuron</source>
          <year>2002</year>
          <volume>33</volume>
          <issue>3</issue>
          <fpage>325</fpage>
          <lpage>340</lpage>
          <pub-id pub-id-type="pmid">11832222</pub-id>
        </citation>
      </ref>
      <ref id="bib5">
        <label>Chen et al., 2008</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>C.C.</given-names>
            </name>
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic causal modelling of induced responses</article-title>
          <source>NeuroImage</source>
          <year>2008</year>
          <volume>41</volume>
          <issue>4</issue>
          <fpage>1293</fpage>
          <lpage>1312</lpage>
          <pub-id pub-id-type="pmid">18485744</pub-id>
        </citation>
      </ref>
      <ref id="bib6">
        <label>David and Friston, 2003</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>David</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>A neural-mass model for MEG/EEG: coupling and neuronal dynamics</article-title>
          <source>NeuroImage</source>
          <year>2003</year>
          <volume>20</volume>
          <issue>3</issue>
          <fpage>1743</fpage>
          <lpage>1755</lpage>
          <pub-id pub-id-type="pmid">14642484</pub-id>
        </citation>
      </ref>
      <ref id="bib7">
        <label>David et al., 2005</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>David</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Modelling event-related responses in the brain</article-title>
          <source>NeuroImage</source>
          <year>2005</year>
          <volume>25</volume>
          <issue>3</issue>
          <fpage>756</fpage>
          <lpage>770</lpage>
          <pub-id pub-id-type="pmid">15808977</pub-id>
        </citation>
      </ref>
      <ref id="bib8">
        <label>David et al., 2006</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>David</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Mattout</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kilner</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic causal modeling of evoked responses in EEG and MEG</article-title>
          <source>Neuroimage</source>
          <year>2006</year>
          <volume>30</volume>
          <issue>4</issue>
          <fpage>1255</fpage>
          <lpage>1272</lpage>
          <comment>(May 1)</comment>
          <pub-id pub-id-type="pmid">16473023</pub-id>
        </citation>
      </ref>
      <ref id="bib9">
        <label>Friston et al., 2003</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic causal modelling</article-title>
          <source>NeuroImage</source>
          <year>2003</year>
          <volume>19</volume>
          <issue>4</issue>
          <fpage>1273</fpage>
          <lpage>1302</lpage>
          <pub-id pub-id-type="pmid">12948688</pub-id>
        </citation>
      </ref>
      <ref id="bib10">
        <label>Friston et al., 2007</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Mattout</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Trujillo-Barreto</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Variational free energy and the Laplace approximation</article-title>
          <source>NeuroImage</source>
          <year>2007</year>
          <volume>34</volume>
          <fpage>220</fpage>
          <lpage>234</lpage>
          <pub-id pub-id-type="pmid">17055746</pub-id>
        </citation>
      </ref>
      <ref id="bib11">
        <label>Felleman and Van Essen, 1991</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Felleman</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>
          <source>Cereb. Cortex</source>
          <year>1991</year>
          <volume>1</volume>
          <issue>1</issue>
          <fpage>1</fpage>
          <lpage>47</lpage>
          <pub-id pub-id-type="pmid">1822724</pub-id>
        </citation>
      </ref>
      <ref id="bib12">
        <label>Grol et al., 2007</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grol</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Majdandzic</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Verhagen</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Dijkerman</surname>
              <given-names>H.C.</given-names>
            </name>
            <name>
              <surname>Bekkering</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Verstraten</surname>
              <given-names>F.A.J.</given-names>
            </name>
            <name>
              <surname>Toni</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Parieto-frontal Connectivity during Visually Guided Grasping</article-title>
          <source>J. Neurosci.</source>
          <year>2007</year>
          <volume>27</volume>
          <issue>44</issue>
          <fpage>11877</fpage>
          <lpage>11887</lpage>
          <pub-id pub-id-type="pmid">17978028</pub-id>
        </citation>
      </ref>
      <ref id="bib13">
        <label>Jansen and Rit, 1995</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jansen</surname>
              <given-names>B.H.</given-names>
            </name>
            <name>
              <surname>Rit</surname>
              <given-names>V.G.</given-names>
            </name>
          </person-group>
          <article-title>Electroencephalogram and visual evoked potential generation in a mathematical model of coupled cortical columns</article-title>
          <source>Biol. Cybern.</source>
          <year>1995</year>
          <volume>73</volume>
          <fpage>357</fpage>
          <lpage>366</lpage>
          <pub-id pub-id-type="pmid">7578475</pub-id>
        </citation>
      </ref>
      <ref id="bib14">
        <label>Jansen et al., 1993</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jansen</surname>
              <given-names>B.H.</given-names>
            </name>
            <name>
              <surname>Zouridakis</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Brandt</surname>
              <given-names>M.E.</given-names>
            </name>
          </person-group>
          <article-title>A neurophysiologically-based mathematical model of flash visual evoked potentials</article-title>
          <source>Biol. Cybern.</source>
          <year>1993</year>
          <volume>68</volume>
          <fpage>275</fpage>
          <lpage>283</lpage>
          <pub-id pub-id-type="pmid">8452897</pub-id>
        </citation>
      </ref>
      <ref id="bib15">
        <label>Kay and Marple, 1981</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kay</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Marple</surname>
              <given-names>S.L.</given-names>
            </name>
          </person-group>
          <article-title>Spectrum analysis — a modern perspective</article-title>
          <source>Procs. of the IEEE</source>
          <year>1981</year>
          <volume>69</volume>
          <issue>11</issue>
          <fpage>1380</fpage>
          <lpage>1419</lpage>
        </citation>
      </ref>
      <ref id="bib16">
        <label>Kerr et al., 2008</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kerr</surname>
              <given-names>C.C.</given-names>
            </name>
            <name>
              <surname>Rennie</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>P.A.</given-names>
            </name>
          </person-group>
          <article-title>Physiology-based modelling of cortical auditory potentials</article-title>
          <source>Biological Cybernetics</source>
          <year>2008</year>
          <volume>98</volume>
          <fpage>171</fpage>
          <lpage>184</lpage>
          <pub-id pub-id-type="pmid">18057953</pub-id>
        </citation>
      </ref>
      <ref id="bib17">
        <label>Kiebel et al., 2005</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Tallon-Baudry</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Parametric analysis of oscillatory activity as measured with EEG/MEG</article-title>
          <source>Human Brain Mapping</source>
          <year>2005</year>
          <volume>26</volume>
          <fpage>170</fpage>
          <lpage>177</lpage>
          <pub-id pub-id-type="pmid">15929085</pub-id>
        </citation>
      </ref>
      <ref id="bib18">
        <label>Kiebel et al., 2007</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Garrido</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic causal modelling of evoked responses: The role of intrinsic connections</article-title>
          <source>NeuroImage</source>
          <year>2007</year>
          <volume>36</volume>
          <fpage>332</fpage>
          <lpage>345</lpage>
          <pub-id pub-id-type="pmid">17462916</pub-id>
        </citation>
      </ref>
      <ref id="bib19">
        <label>LeDoux, 2000</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>LeDoux</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Emotion circuits in the brain</article-title>
          <source>Annu. Rev. Neurosci.</source>
          <year>2000</year>
          <volume>23</volume>
          <fpage>155</fpage>
          <lpage>184</lpage>
          <pub-id pub-id-type="pmid">10845062</pub-id>
        </citation>
      </ref>
      <ref id="bib21">
        <label>Maren et al., 1997</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maren</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Aharonov</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Fanselow</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <article-title>Neurotoxic lesions of the dorsal hippocampus and Pavlovian fear conditioning in rats</article-title>
          <source>Behav. Brain Res.</source>
          <year>1997</year>
          <volume>88</volume>
          <issue>2</issue>
          <fpage>261</fpage>
          <lpage>274</lpage>
          <pub-id pub-id-type="pmid">9404635</pub-id>
        </citation>
      </ref>
      <ref id="bib23">
        <label>Moran et al., 2007</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moran</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Reilly</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Daunizeau</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>A Neural-mass Model of spectral responses in electrophysiology</article-title>
          <source>NeuroImage</source>
          <year>2007</year>
          <volume>37</volume>
          <issue>3</issue>
          <fpage>706</fpage>
          <lpage>720</lpage>
          <pub-id pub-id-type="pmid">17632015</pub-id>
        </citation>
      </ref>
      <ref id="bib24">
        <label>Moran et al., 2008</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moran</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Kiebel</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Rombach</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>O'Connor</surname>
              <given-names>W.T.</given-names>
            </name>
            <name>
              <surname>Murphy</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Reilly</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian estimation of synaptic physiology from the spectral responses of neural masses</article-title>
          <source>NeuroImage</source>
          <year>2008</year>
          <volume>42</volume>
          <fpage>272</fpage>
          <lpage>284</lpage>
          <pub-id pub-id-type="pmid">18515149</pub-id>
        </citation>
      </ref>
      <ref id="bib25">
        <label>Pape and Stork, 2003</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pape</surname>
              <given-names>H.-C.</given-names>
            </name>
            <name>
              <surname>Stork</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Genes and mechanisms in the amygdala involved in the formation of fear memory</article-title>
          <source>Ann. N.Y. Acad. Sci.</source>
          <year>2003</year>
          <volume>985</volume>
          <fpage>92</fpage>
          <lpage>105</lpage>
          <pub-id pub-id-type="pmid">12724151</pub-id>
        </citation>
      </ref>
      <ref id="bib26">
        <label>Pitkänen et al., 2000</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pitkänen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Pikkarainen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Nurminen</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ylinen</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Reciprocal connections between the amygdala and the hippocampal formation, perirhinal cortex, and postrhinal cortex in rat. A review</article-title>
          <source>Ann. N.Y. Acad. Sci.</source>
          <year>2000</year>
          <volume>911</volume>
          <fpage>369</fpage>
          <lpage>391</lpage>
          <pub-id pub-id-type="pmid">10911886</pub-id>
        </citation>
      </ref>
      <ref id="bib27">
        <label>Penny et al., 2004</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Penny</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Mechelli</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Comparing dynamic causal models</article-title>
          <source>NeuroImage</source>
          <year>2004</year>
          <volume>22</volume>
          <issue>3</issue>
          <fpage>1157</fpage>
          <lpage>1172</lpage>
          <pub-id pub-id-type="pmid">15219588</pub-id>
        </citation>
      </ref>
      <ref id="bib28">
        <label>Penny et al., 2008</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Penny</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Duzel</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Ojemann</surname>
              <given-names>J.G.</given-names>
            </name>
          </person-group>
          <article-title>Testing for nested oscillations</article-title>
          <source>J. Neurosci. Methods</source>
          <year>2008</year>
        </citation>
      </ref>
      <ref id="bib29">
        <label>Riera et al., 2006</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Riera</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Wan</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Jimenez</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Kawashima</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Nonlinear local electrovascular coupling. I: a theoretical model</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>2006</year>
          <volume>27</volume>
          <fpage>896</fpage>
          <lpage>914</lpage>
          <pub-id pub-id-type="pmid">16729288</pub-id>
        </citation>
      </ref>
      <ref id="bib31">
        <label>Robinson et al., 2004</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Robinson</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Rennie</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Rowe</surname>
              <given-names>D.L.</given-names>
            </name>
            <name>
              <surname>O'Connor</surname>
              <given-names>S.C.</given-names>
            </name>
          </person-group>
          <article-title>Estimation of multiscale neurophysiologic parameters by electroencephalographic means</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>2004</year>
          <volume>23</volume>
          <issue>1</issue>
          <fpage>53</fpage>
          <lpage>72</lpage>
          <pub-id pub-id-type="pmid">15281141</pub-id>
        </citation>
      </ref>
      <ref id="bib32">
        <label>Robinson et al., 2008</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Robinson</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Chen Po-chia</surname>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Physiologically based calculation of steady-state evoked potentials and cortical wave velocities</article-title>
          <source>Biological Cybernetics</source>
          <year>2008</year>
          <volume>98</volume>
          <fpage>1</fpage>
          <lpage>10</lpage>
          <pub-id pub-id-type="pmid">17962977</pub-id>
        </citation>
      </ref>
      <ref id="bib33">
        <label>Rodrigues et al., 2004</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rodrigues</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Schafe</surname>
              <given-names>G.E.</given-names>
            </name>
            <name>
              <surname>LeDoux</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>Molecular mechanisms underlying emotional learning and memory in the lateral amygdala</article-title>
          <source>Neuron</source>
          <year>2004</year>
          <volume>44</volume>
          <issue>1</issue>
          <fpage>75</fpage>
          <lpage>91</lpage>
          <pub-id pub-id-type="pmid">15450161</pub-id>
        </citation>
      </ref>
      <ref id="bib34">
        <label>Rosenblum et al., 1996</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rosenblum</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Pikovsky</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kurths</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Phase synchronization of chaotic oscillators, Phys</article-title>
          <source>Rev. Lett.</source>
          <year>1996</year>
          <volume>76</volume>
          <fpage>1804</fpage>
          <lpage>1807</lpage>
        </citation>
      </ref>
      <ref id="bib35">
        <label>Seidenbecher et al., 2003</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Seidenbecher</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Laxmi</surname>
              <given-names>T.R.</given-names>
            </name>
            <name>
              <surname>Stork</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Pape</surname>
              <given-names>H.C.</given-names>
            </name>
          </person-group>
          <article-title>Amygdalar and hippocampal theta rhythm synchronization during fear memory retrieval</article-title>
          <source>Science</source>
          <year>2003</year>
          <volume>301</volume>
          <fpage>846</fpage>
          <lpage>850</lpage>
          <pub-id pub-id-type="pmid">12907806</pub-id>
        </citation>
      </ref>
      <ref id="bib36">
        <label>Spyers-Ashby et al., 1998</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Spyers-Ashby</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Bain</surname>
              <given-names>P.G.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>A comparison of fast fourier transform (FFT) and autoregressive (AR) spectral estimation techniques for the analysis of tremor data</article-title>
          <source>J. Neurosci. Methods</source>
          <year>1998</year>
          <volume>83</volume>
          <fpage>35</fpage>
          <lpage>43</lpage>
          <pub-id pub-id-type="pmid">9765049</pub-id>
        </citation>
      </ref>
      <ref id="bib38">
        <label>Stephan et al., 2006a</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Marshall</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Fink</surname>
              <given-names>G.R.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Investigating the functional role of callosal connections with dynamic causal models</article-title>
          <source>Ann. N.Y. Acad. Sci.</source>
          <year>2006</year>
          <volume>1066</volume>
          <fpage>16</fpage>
          <lpage>36</lpage>
        </citation>
      </ref>
      <ref id="bib37">
        <label>Stephan et al., 2006b</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Baldeweg</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Synaptic plasticity and dysconnection in schizophrenia</article-title>
          <source>Biol. Psychiatry</source>
          <year>2006</year>
          <volume>59</volume>
          <fpage>929</fpage>
          <lpage>939</lpage>
          <pub-id pub-id-type="pmid">16427028</pub-id>
        </citation>
      </ref>
      <ref id="bib39">
        <label>Stephan et al., 2007</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Weiskopf</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Drysdale</surname>
              <given-names>P.M.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Comparing hemodynamic models with DCM</article-title>
          <source>NeuroImage</source>
          <year>2007</year>
          <volume>38</volume>
          <fpage>387</fpage>
          <lpage>401</lpage>
          <pub-id pub-id-type="pmid">17884583</pub-id>
        </citation>
      </ref>
      <ref id="bib40">
        <label>Valdes et al., 1999</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Valdes</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Jimenez</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Riera</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Biscay</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ozaki</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Nonlinear EEG analysis based on a neural mass model</article-title>
          <source>Biol. Cybern.</source>
          <year>1999</year>
          <volume>81</volume>
          <fpage>415</fpage>
          <lpage>424</lpage>
          <pub-id pub-id-type="pmid">10592017</pub-id>
        </citation>
      </ref>
    </ref-list>
  </back>
  <floats-wrap>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>Schematic of the source model with intrinsic connections. This schematic includes the differential equations describing the motion of hidden electrophysiological states. Each source is modelled with three subpopulations (pyramidal, spiny-stellate and inhibitory interneurons) as described in (<xref rid="bib13" ref-type="bibr">Jansen and Rit, 1995</xref>). In this figure these subpopulations have been assigned to granular and agranular cortical layers, which receive forward, backward and lateral connections from extrinsic sources in the network.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>The log-evidence for different order VAR models. The variational Bayes approach described in the text provides the log model evidence for different VAR model orders. This analysis illustrates a large increase in model evidence up to order twelve (black) and small increases thereafter (grey). This increase in evidence occurs at an order that is equal to the number of poles of the DCMs transfer function (see <xref rid="app2" ref-type="sec">Appendix B</xref>).</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p>The log-evidence for models tested from three different generative architectures. These are the results of a full test over all possible two-source DCM models, comprising 256 in total. Red bars and arrow indicate the model with the greatest log evidence. In all three cases this corresponds to the correct generative model (a) Generative model 1 comprising forward connections from the first to the second source, (b) Generative model 2 comprising forward connections from the second to the first source and (c) Generative model 3 comprising reciprocal forward connections.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>Simulated two source model where excitatory responses are modulated via a scaling of an intrinsic maximum EPSP parameter in source 2: <italic>H<sub>e</sub><sup>(2)</sup></italic> and an extrinsic connection from source 1 to source 2: <italic>A</italic><sub>21</sub><sup><italic>F</italic></sup>. The inversion scheme was tested by recovering the posterior estimates of these parameters, under different levels of observation noise.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Fig. 5</label>
      <caption>
        <p>Conditional densities of parameter estimates using the two-source simulations. The data were generated under known parameter values (red line) and mixed with noise (one thousandth to twice the empirical noise estimate). The EPSP parameter (Top left) was exp (− 0.4) = 67% of its prior expectation. The MAP estimates for this log-scale parameter (plotted in hashed red) display a characteristic shrinkage toward the prior of zero at high levels of noise (90% confidence intervals are plotted in grey). The extrinsic connection parameter (Top right) <italic>A</italic><sub>21</sub><sup><italic>F</italic></sup> displays a similar behaviour, when simulated at exp(1.5) = 448% of its prior expectation. The grey lines show the prior value (of zero) used for the simulations. The bottom graphs show the conditional probabilities that the MAP estimates of the log-scale parameters differ from their prior expectation.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig6">
      <label>Fig. 6</label>
      <caption>
        <p>CS+ (Left) and CS- (Right) spectrograms. Time-frequency data demonstrating theta activity at hippocampal (Top) and amygdala (Bottom) electrodes during the CS+ and CS-. These plots are scaled relative to the maximum theta peak in the CS+ hippocampal image. They are displayed with corresponding behavioural modes represented as colour-bars; where ‘f’ demarks freezing periods (the behavioural correlate of fear recall), ‘e’ exploration, ‘r’ risk assessment and ‘s’ stereotypical behaviour. During the CS+ condition theta activity can be observed in both electrodes, in contrast, during the CS- condition, theta activity is evident in hippocampal data but much less in the amygdala.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig7">
      <label>Fig. 7</label>
      <caption>
        <p>Average cross-spectral densities across all CS+ (red) and CS- (blue) trials. Top left: hippocampal autospectrum, Top right: hippocampal-amygdala cross spectrum, Bottom right: amygdala autospectrum. These spectral data features were evaluated from three second epochs after the first freezing behaviour during CS+ and the time/order matched CS- trials. Peaks at theta frequency are evident in both CS+ and CS- conditions with reduced theta activity in the amygdala during CS-.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <fig id="fig8">
      <label>Fig. 8</label>
      <caption>
        <p>Results of the Bayesian model comparison. Log Bayes factors are plotted relative to the worst model in each comparison. (a) Optimal connection type is found in Model 1, where the connections are of the ‘forward’ type. (b) Model evidence supports Model 1, where exogenous inputs enter both the hippocampus and amygdala. (c) Model evidences suggest reciprocal connections between the hippocampus and amygdala.</p>
      </caption>
      <graphic xlink:href="gr8"/>
    </fig>
    <fig id="fig9">
      <label>Fig. 9</label>
      <caption>
        <p>Posterior Correlation matrix of the DCM for the empirical data set. Data from a DCM comprising all forward, backward and lateral connections as well as inputs to both sources was used to demonstrate minimal posterior correlations in the set of parameters comprising the hierarchical search. Red boxes highlight the correlations among these parameters. The mean of the absolute value of correlations within this set was − 0.24.</p>
      </caption>
      <graphic xlink:href="gr9"/>
    </fig>
    <fig id="fig10">
      <label>Fig. 10</label>
      <caption>
        <p>Model fits for all empirical data (CS+ : red, CS-: blue). Top left: hippocampal autospectrum, Top right: hippocampal-amygdala cross spectrum, Bottom right: amygdala autospectrum. The measured spectra are shown with a dashed line and the conditional model predictions with a full line.</p>
      </caption>
      <graphic xlink:href="gr10"/>
    </fig>
    <fig id="fig11">
      <label>Fig. 11</label>
      <caption>
        <p>Trial-specific effects encoding differences between the CS+, relative to CS- trials. Top left: Hippocampal EPSP displays &lt; 1% change on CS+ trials. Top right: amygdala to hippocampus forward connection strength decreases by 72% on CS+ trials. Bottom left: Hippocampus to amygdala forward connection strength increases by 26% on CS+ trials. Bottom right: amygdala EPSP increases by 8% in CS+ relative to CS- trials.</p>
      </caption>
      <graphic xlink:href="gr11"/>
    </fig>
    <table-wrap position="float" id="tbl1">
      <label>Table 1</label>
      <caption>
        <p>Parameter Priors for model parameters including the observation model, neuronal sources, and experimental effects</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th valign="top">Parameter ϑ<italic><sub>i</sub> </italic>= π<sub><italic>i</italic></sub>exp(Θ<sub><italic>i</italic></sub>)</th>
            <th valign="top">Interpretation</th>
            <th colspan="2" valign="top">Prior<hr/></th>
          </tr>
          <tr>
            <th valign="top"/>
            <th valign="top"/>
            <th valign="top">Mean: π<sub><italic>i</italic></sub></th>
            <th valign="top">Variance: Θ<sub><italic>i</italic></sub> = <italic>N</italic>(0,<italic>σ</italic><sub><italic>i</italic></sub>)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="4" valign="top">
              <italic>Observation model</italic>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <italic>α</italic>
              <sub>
                <italic>u</italic>
              </sub>
            </td>
            <td valign="top">Exogenous white input</td>
            <td valign="top"><italic>π</italic><sub><italic>α</italic></sub><sub><sub><italic>u</italic></sub></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>α</italic></sub><sub><sub><italic>u</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>α</italic>
              <sub>
                <italic>s</italic>
              </sub>
            </td>
            <td valign="top">Channel specific white noise</td>
            <td valign="top"><italic>π</italic><sub><italic>α</italic></sub><sub><sub><italic>s</italic></sub></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>α</italic></sub><sub><sub><italic>s</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>α</italic>
              <sub>
                <italic>c</italic>
              </sub>
            </td>
            <td valign="top">White noise common to all channels</td>
            <td valign="top"><italic>π</italic><sub><italic>α</italic></sub><sub><sub><italic>c</italic></sub></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>α</italic></sub><sub><sub><italic>c</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>β</italic>
              <sub>
                <italic>u</italic>
              </sub>
            </td>
            <td valign="top">Exogenous pink input</td>
            <td valign="top"><italic>π</italic><sub><italic>β</italic></sub><sub><sub><italic>s</italic></sub></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>β</italic></sub><sub><sub><italic>u</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>β</italic>
              <sub>
                <italic>s</italic>
              </sub>
            </td>
            <td valign="top">Channel specific pink noise</td>
            <td valign="top"><italic>π</italic><sub><italic>β</italic></sub><sub><sub><italic>c</italic></sub></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>β</italic></sub><sub><sub><italic>s</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>β</italic>
              <sub>
                <italic>c</italic>
              </sub>
            </td>
            <td valign="top">Pink noise common to all channels</td>
            <td valign="top"><italic>π</italic><sub><italic>θ</italic></sub><sub><sub><italic>i</italic></sub></sub> = 1</td>
            <td valign="top"><italic>σ</italic><sub><italic>θ</italic></sub><sub><sub><italic>i</italic></sub></sub> = exp(8)</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>θ</italic>
              <sub>1…<italic>s</italic></sub>
            </td>
            <td valign="top">Lead-field gain</td>
            <td valign="top"><italic>π</italic><sub><italic>λ</italic></sub> = 0</td>
            <td valign="top"><italic>σ</italic><sub><italic>λ</italic></sub> = 1</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>λ</italic>
            </td>
            <td valign="top">Noise hyperparameter</td>
            <td valign="top"/>
            <td valign="top"/>
          </tr>
          <tr>
            <td colspan="4" valign="top">  </td>
          </tr>
          <tr>
            <td colspan="4" valign="top">
              <italic>Neuronal sources</italic>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <italic>κ</italic>
              <sub>
                <italic>e</italic>
              </sub>
              <sub>/<italic>i</italic></sub>
            </td>
            <td valign="top">Excitatory/inhibitory rate constants</td>
            <td valign="top"><italic>π</italic><sub><italic>κ</italic></sub><sub><sub><italic>e</italic></sub></sub> = 4 <italic>ms</italic><sup>− 1</sup><italic>π</italic><sub><italic>κ</italic></sub><sub><sub><italic>i</italic></sub></sub> = 16 <italic>ms</italic><sup>− 1</sup></td>
            <td valign="top"><italic>σ</italic><sub><italic>κ</italic></sub><sub><sub><italic>e</italic></sub></sub> = 1/8 <italic>σ</italic><sub><italic>κ</italic></sub><sub><sub><italic>i</italic></sub></sub> = 1/8</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>H</italic>
              <sub>
                <italic>e</italic>
              </sub>
              <sub>/<italic>i</italic></sub>
            </td>
            <td valign="top">Excitatory/inhibitory maximum post-synaptic potentials</td>
            <td valign="top"><italic>π</italic><sub><italic>H</italic></sub><sub><sub><italic>e</italic></sub></sub> = 8 <italic>mV π</italic><sub><italic>H</italic></sub><sub><sub><italic>i</italic></sub></sub> = 32 <italic>mV</italic></td>
            <td valign="top"><italic>σ</italic><sub><italic>H</italic></sub><sub><sub><italic>e</italic></sub></sub> = 1/16 <italic>σ</italic><sub><italic>H</italic></sub><sub><sub><italic>i</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td rowspan="5" valign="top">
              <italic>γ</italic>
              <sub>1,2,3,4,5</sub>
            </td>
            <td rowspan="5" valign="top">Intrinsic connections</td>
            <td valign="top"><italic>π</italic><sub><italic>γ</italic></sub><sub><sub>1</sub></sub> = 128</td>
            <td valign="top"><italic>σ</italic><sub><italic>γ</italic></sub><sub><sub>1</sub></sub> = 0</td>
          </tr>
          <tr>
            <td valign="top"><italic>π</italic><sub><italic>γ</italic></sub><sub><sub>2</sub></sub> = 128</td>
            <td valign="top"><italic>σ</italic><sub><italic>γ</italic></sub><sub><sub>2</sub></sub> = 0</td>
          </tr>
          <tr>
            <td valign="top"><italic>π</italic><sub><italic>γ</italic></sub><sub><sub>3</sub></sub> = 64</td>
            <td valign="top"><italic>σ</italic><sub><italic>γ</italic></sub><sub><sub>3</sub></sub> = 0</td>
          </tr>
          <tr>
            <td valign="top"><italic>π</italic><sub><italic>γ</italic></sub><sub><sub>4</sub></sub> = 64</td>
            <td valign="top"><italic>σ</italic><sub><italic>γ</italic></sub><sub><sub>4</sub></sub> = 0</td>
          </tr>
          <tr>
            <td valign="top"><italic>π</italic><sub><italic>γ</italic></sub><sub><sub>5</sub></sub> = 4</td>
            <td valign="top"><italic>σ</italic><sub><italic>γ</italic></sub><sub><sub>5</sub></sub> = 0</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>A</italic>
              <sup>
                <italic>F</italic>
              </sup>
            </td>
            <td valign="top">Forward extrinsic connections</td>
            <td valign="top"><italic>π</italic><sub><italic>A</italic><sup><italic>F</italic></sup></sub> = 32</td>
            <td valign="top"><italic>σ</italic><sub><italic>A</italic><sup><italic>F</italic></sup></sub> = 1/2</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>A</italic>
              <sup>
                <italic>B</italic>
              </sup>
            </td>
            <td valign="top">Backward extrinsic connections</td>
            <td valign="top"><italic>π</italic><sub><italic>A</italic><sup><italic>B</italic></sup></sub> = 16</td>
            <td valign="top"><italic>σ</italic><sub><italic>A</italic><sup><italic>B</italic></sup></sub> = 1/2</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>A</italic>
              <sup>
                <italic>L</italic>
              </sup>
            </td>
            <td valign="top">Lateral extrinsic connections</td>
            <td valign="top"><italic>π</italic><sub><italic>A</italic><sup><italic>L</italic></sup></sub> = 4</td>
            <td valign="top"><italic>σ</italic><sub><italic>A</italic><sup><italic>L</italic></sup></sub> = 1/2</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>C</italic>
            </td>
            <td valign="top">Exogenous input</td>
            <td valign="top"><italic>π</italic><sub><italic>C</italic></sub> = 1</td>
            <td valign="top"><italic>σ</italic><sub><italic>c</italic></sub> = 1/32</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>d</italic>
              <sub>
                <italic>i</italic>
              </sub>
            </td>
            <td valign="top">Intrinsic delays</td>
            <td valign="top"><italic>π</italic><sub><italic>d</italic></sub><sub><sub><italic>i</italic></sub></sub> = 2</td>
            <td valign="top"><italic>σ</italic><sub><italic>d</italic></sub><sub><sub><italic>i</italic></sub></sub> = 1/16</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>d</italic>
              <sub>
                <italic>e</italic>
              </sub>
            </td>
            <td valign="top">Extrinsic delays</td>
            <td valign="top"><italic>π</italic><sub><italic>d</italic></sub><sub><sub><italic>e</italic></sub></sub> = 10</td>
            <td valign="top"><italic>σ</italic><sub><italic>d</italic></sub><sub><sub><italic>e</italic></sub></sub> = 1/32</td>
          </tr>
          <tr>
            <td valign="top">Design <italic>β</italic><sub><italic>ki</italic></sub></td>
            <td valign="top">Trial specific changes</td>
            <td valign="top"><italic>π</italic><sub><italic>β</italic></sub><sub><sub><italic>ki</italic></sub></sub> = 1</td>
            <td valign="top"><italic>σ</italic><sub><italic>β</italic></sub><sub><sub><italic>ki</italic></sub></sub> = 1/2</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>In practice, the non-negative parameters of this model are given log-normal priors, by assuming a Gaussian density on a scale parameter, Θ<sub><italic>i</italic></sub> = <italic>N</italic> (0,<italic>σ</italic><sub><italic>i</italic></sub>), where <italic>ϑ</italic><sub><italic>i</italic></sub> = <italic>π</italic><sub><italic>i</italic></sub>exp(Θ<sub><italic>i</italic></sub>), and <italic>π</italic><sub><italic>i</italic></sub> is the prior expectation and <italic>σ</italic><sub><italic>i</italic></sub><sup>2</sup> is its log-normal dispersion.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="tbl2">
      <label>Table 2a</label>
      <caption>
        <p>Inference on model space: results of the Bayesian inversion on data simulated using three different network architectures (column-wise)</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th valign="top">Simulated network connections</th>
            <th valign="top">
              <italic>A<sub>2,1</sub><sup>F</sup></italic>
            </th>
            <th valign="top">
              <italic>A<sub>1,2</sub><sup>F</sup></italic>
            </th>
            <th valign="top"><italic>A<sub>2,1</sub><sup>F</sup></italic> and <italic>A<sub>1,2</sub><sup>F</sup></italic></th>
          </tr>
          <tr>
            <th colspan="4" valign="top">Modelled connections</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top">
              <italic>A<sub>2,1</sub><sup>F</sup></italic>
            </td>
            <td align="char" valign="top">
              <bold>416.6</bold>
            </td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">0</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>A<sub>1,2</sub><sup>F</sup></italic>
            </td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">
              <bold>399.2000</bold>
            </td>
            <td align="char" valign="top">0.5000</td>
          </tr>
          <tr>
            <td valign="top"><italic>A<sub>2,1</sub><sup>F</sup></italic> and <italic>A<sub>1,2</sub><sup>F</sup></italic></td>
            <td align="char" valign="top">398.4</td>
            <td align="char" valign="top">381.6000</td>
            <td align="char" valign="top">
              <bold>561.2000</bold>
            </td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Log-Bayes factors are presented relative to the worst model for each network. Best performing models are in bold. For all three simulations, the corresponding model-architecture was found to have the highest Log-Bayes factor.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="tbl3">
      <label>Table 2b</label>
      <caption>
        <p>Inference on model space: Posterior probabilities of each model are computed by assuming flat or uniform priors on models; normalising these values gives the conditional probability of the models presented here as percentages</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th valign="top">Simulated network connections<hr/></th>
            <th valign="top">
              <italic>A<sub>2,1</sub><sup>F</sup></italic>
              <hr/>
            </th>
            <th valign="top">
              <italic>A<sub>1,2</sub><sup>F</sup></italic>
              <hr/>
            </th>
            <th valign="top"><italic>A<sub>2,1</sub><sup>F</sup></italic> and <italic>A<sub>1,2</sub><sup>F</sup></italic><hr/></th>
          </tr>
          <tr>
            <th valign="top">Modelled connections</th>
            <th colspan="3" valign="top">%</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top">
              <italic>A<sub>2,1</sub><sup>F</sup></italic>
            </td>
            <td align="char" valign="top">100</td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">0</td>
          </tr>
          <tr>
            <td valign="top">
              <italic>A<sub>1,2</sub><sup>F</sup></italic>
            </td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">100</td>
            <td align="char" valign="top">0</td>
          </tr>
          <tr>
            <td valign="top"><italic>A<sub>2,1</sub><sup>F</sup></italic> and <italic>A<sub>1,2</sub><sup>F</sup></italic></td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">0</td>
            <td align="char" valign="top">100</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </floats-wrap>
</article>