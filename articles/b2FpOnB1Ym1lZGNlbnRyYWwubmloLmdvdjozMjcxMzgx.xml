<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3271381</article-id>
      <article-id pub-id-type="pmid">21945789</article-id>
      <article-id pub-id-type="publisher-id">YNIMG8687</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.006</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Cortical responses to changes in acoustic regularity are differentially modulated by attentional load</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Chait</surname>
            <given-names>Maria</given-names>
          </name>
          <email>m.chait@ucl.ac.uk</email>
          <xref rid="af0005" ref-type="aff">a</xref>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="cr0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ruff</surname>
            <given-names>Christian C.</given-names>
          </name>
          <xref rid="af0015" ref-type="aff">c</xref>
          <xref rid="af0020" ref-type="aff">d</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Griffiths</surname>
            <given-names>Timothy D.</given-names>
          </name>
          <xref rid="af0010" ref-type="aff">b</xref>
          <xref rid="af0025" ref-type="aff">e</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>McAlpine</surname>
            <given-names>David</given-names>
          </name>
          <xref rid="af0005" ref-type="aff">a</xref>
        </contrib>
      </contrib-group>
      <aff id="af0005"><label>a</label>Ear Institute, University College London, London, UK</aff>
      <aff id="af0010"><label>b</label>Wellcome Trust Centre for Neuroimaging, University College London, London, UK</aff>
      <aff id="af0015"><label>c</label>Institute of Cognitive Neuroscience, University College London, London, UK</aff>
      <aff id="af0020"><label>d</label>Laboratory for Social and Neural Systems Research (SNS), University of Zurich, Switzerland</aff>
      <aff id="af0025"><label>e</label>Newcastle University Medical School, Newcastle, UK</aff>
      <author-notes>
        <corresp id="cr0005"><label>⁎</label>Corresponding author at: UCL Ear Institute 332 Gray's Inn Road, London WC1X 8EE, UK. <email>m.chait@ucl.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>16</day>
        <month>1</month>
        <year>2012</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>16</day>
        <month>1</month>
        <year>2012</year>
      </pub-date>
      <volume>59</volume>
      <issue>2-5</issue>
      <fpage>1932</fpage>
      <lpage>1941</lpage>
      <history>
        <date date-type="received">
          <day>6</day>
          <month>6</month>
          <year>2011</year>
        </date>
        <date date-type="rev-recd">
          <day>31</day>
          <month>8</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>3</day>
          <month>9</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2012 Elsevier Inc.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>This study investigates how acoustic change-events are represented in a listener's brain when attention is strongly focused elsewhere. Using magneto-encephalography (MEG) we examine whether cortical responses to different kinds of changes in stimulus statistics are similarly influenced by attentional load, and whether the processing of such acoustic changes in auditory cortex depends on modality-specific or general processing resources. We investigated these issues by examining cortical responses to two basic forms of acoustic transitions: (1) Violations of a simple acoustic pattern and (2) the emergence of a regular pattern from a random one. To simulate a complex sensory environment, these patterns were presented concurrently with streams of auditory and visual decoys. Listeners were required to perform tasks of high- and low-attentional-load in these domains. Results demonstrate that while auditory attentional-load does not influence the cortical representation of simple violations of regularity, it significantly reduces the magnitude of responses to the emergence of a regular acoustic pattern, suggesting a fundamentally skewed representation of the unattended auditory scene. In contrast, visual attentional-load had no effect on either transition response, consistent with the hypothesis that processing resources necessary for change detection are modality-specific.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Highlights</title>
        <p>► We investigate MEG responses to acoustic changes when attention is focused away. ► Two change-types were studied: violation and emergence of a regular pattern. ► Auditory attentional-load reduces brain responses to emergence of regularity. ► However, responses to violation of regularity are not affected. ► Visual attentional-load has no effect on either transition response.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Auditory evoked response</kwd>
        <kwd>Magnetoencephalography</kwd>
        <kwd>MEG</kwd>
        <kwd>Auditory cortex</kwd>
        <kwd>Attention</kwd>
        <kwd>Attentional load</kwd>
        <kwd>Change detection</kwd>
        <kwd>Edge detection</kwd>
        <kwd>Scene analysis</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="s0095">
      <title>Introduction</title>
      <p>The ability to detect and respond quickly to changes in our surroundings – such as the appearance, disappearance or movement of an object – is critical to survival. Hearing plays a major role in this process by serving as an ‘early warning device', rapidly directing attention to new objects and events in the environment, and monitoring sources beyond the field of vision, in the dark, or in visually-cluttered surroundings. Indeed, we often <italic>hear</italic> changes in the environment before we <italic>see</italic> them.</p>
      <p>The present study investigates whether the neural processes that sub-serve auditory change detection are automatic or depend on attentional resources — a question that is critical to understanding the fidelity of our pre-conscious representation of the ‘state of the world’, i.e. those aspects of the non-attended acoustic environment monitored by the brain while listeners' attention is focused elsewhere in the scene (<xref rid="bb0075" ref-type="bibr">Fritz et al., 2007</xref>).</p>
      <p>The early, automatic, auditory change detection system has been traditionally studied with the mismatch-negativity (MMN) paradigm (<xref rid="bb0080 bb0155 bb0185" ref-type="bibr">Garrido et al., 2009; Näätänen et al., 1978; Polich, 2003</xref>). The MMN, a response generated by infrequent ‘deviant’ events embedded in a stream of repeating standard events, is hypothesized to reflect a discrepancy between the memory trace, or expectations, generated by the standard stimulus, and the new, deviant information (<xref rid="bb0260 bb0255" ref-type="bibr">Winkler, 2007; Winkler et al., 1996</xref>). The degree to which MMN responses are dependent on attention has been a focus of investigation for several decades (e.g. <xref rid="bb0160" ref-type="bibr">Näätänen, 1992</xref>). It is widely asserted that attention directed beyond the auditory modality does not influence passively-elicited MMN responses (e.g. <xref rid="bb0015 bb0145 bb0140 bb0200 bb0230 bb0235 bb0275" ref-type="bibr">Alho et al., 1992; Muller-Gass et al., 2006, 2007; Restuccia et al., 2005; SanMiguel et al., 2008; Sculthorpe et al., 2008; Woods et al., 1992</xref>; but see <xref rid="bb0285" ref-type="bibr">Zhang et al., 2006</xref>), indicating modality-specific processing and generation of the MMN. Within the auditory modality, some reports have suggested that MMN responses are attenuated when attention is strongly focused on a competing sound stream (<xref rid="bb0005 bb0265" ref-type="bibr">Alain and Izenberg, 2003; Woldorff and Hillyard, 1991</xref>). However, these data might be explained as a ‘competition’ effect resulting from the presence of identical deviants in both the attended and ignored auditory streams (<xref rid="bb0245" ref-type="bibr">Sussman et al., 2003</xref>). Tasks that eliminate this factor usually demonstrate no effect of attention on the MMN (e.g. <xref rid="bb0025" ref-type="bibr">Bendixen and Schröger, 2008</xref>; <xref rid="bb0170 bb0240" ref-type="bibr">Näätänen et al., 2007; Sussman, 2007</xref>), resulting in the commonly held view that early auditory cortical mechanisms responsible for detecting changes in the auditory scene are generally independent of attention.</p>
      <p>However, all previous studies on the role of attention for the MMN have focused exclusively on one kind of change — violation of regularity, i.e. a change that is manifested by the arrival of a signal that violates a previously established regular pattern. The majority of published work measured MMN responses using a fixed ‘standard’ stimulus and a ‘deviant’ that differs from the standard on some acoustic dimension (e.g. <xref rid="bb0135 bb0145 bb0200 bb0230" ref-type="bibr">Müller et al., 2002; Muller-Gass et al., 2006; Restuccia et al., 2005; SanMiguel et al., 2008</xref>). More recently, the effect of attention has been measured for MMN responses elicited by violations of more complex patterns, such as an alternating pattern of two tones (ABAB…; <xref rid="bb0235" ref-type="bibr">Sculthorpe et al., 2008</xref>), or regularities defined by the frequency relation between successive tones (ascending vs. descending; <xref rid="bb0025" ref-type="bibr">Bendixen and Schröger, 2008</xref>). While changes, evidenced as a violation of a previously-acquired regularity, are commonly encountered by listeners (for example when a source embedded in the scene disappears, or changes its fluctuation properties), there exists another type of change, equally ubiquitous in natural scenes, that consists of the <italic>emergence</italic> of a regular pattern out of random fluctuation (as when an acoustic source appears from an ongoing random background). These kinds of changes have been much less explored (<xref rid="bb0270 bb0100" ref-type="bibr">Wolff and Schröger, 2001; Horváth and Winkler, 2004</xref>; See also <xref rid="bb0020" ref-type="bibr">Bendixen et al., 2007</xref>) and, to our knowledge, no previous work has examined how processing of such changes depends on attentional resources.</p>
      <p>To model ‘violation of regularity’ and ‘emergence of regularity’ changes we use stimuli that contain a step change (‘temporal edge’) in the ongoing pattern of fluctuation (<xref rid="f0005" ref-type="fig">Fig. 1</xref>, right; <xref rid="bb0035 bb0045" ref-type="bibr">Chait et al., 2007a, 2008</xref>). These stimuli are constructed as a sequence of tone pips with constant frequency that changes to a sequence of pips of random frequencies (constant to random, or ‘CR’ stimulus) or a sequence of tone pips of random frequency that changes to a sequence of pips of constant frequency (‘RC’ stimulus). These signals are conceptually similar to MMN step-change paradigms (e.g. <xref rid="bb0020 bb0050" ref-type="bibr">Bendixen et al., 2007; Costa-Faidella et al., 2011</xref>) except that we use them to examine responses to the transitions between different sequences (rather than subtracting responses of deviants from standards). More importantly, these on-going stimuli also allow measurement of the responses to different (statistically diverse) acoustic transitions within a single experimental block.</p>
      <p>While physically symmetric, RC and CR transitions are fundamentally different in nature. In the case of a CR transition, an observer can detect the event immediately as a violation of the current regularity. The opposite transition – RC – necessarily takes longer to detect because the observer must sample a sufficiently long epoch of the stimulus to distinguish the onset of regularity (repeating frequency) from a chance pattern within the on-going random sequence. We have previously demonstrated different neural processing for these transitions (<xref rid="bb0035 bb0045" ref-type="bibr">Chait et al., 2007a, 2008</xref>) consistent with the theoretical argument that the two transitions require fundamentally different kinds of computations.</p>
      <p>Here we ask two questions: (1) Is the detection of different forms of acoustic transitions similarly influenced by attentional load? Ostensibly, detecting violations of regularity might be computationally less expensive than detecting the emergence of a regular pattern and may therefore be less influenced by attentional load. (2) Does this process depend on modality-specific or modality-general computational resources?</p>
      <p>To simulate a complex, multi-sensory environment and varying degrees of attentional involvement, ‘auditory edge’ stimuli were presented concurrently with streams of auditory and visual decoys. The form of the sensory input was identical in all conditions, and attentional load was manipulated by instructing participants to attend to either auditory or visual decoy streams, while performing a high- or low-attentional load task. Importantly, the auditory edge stream (the focus of this experiment) was always task-irrelevant. The pattern of auditory cortical responses to transitions in the auditory-edge stimuli were assessed in the context of the tasks performed by the listeners in order to determine whether and how auditory cortical sensitivity to (ignored) temporal-edges is affected by limited availability of processing resources.</p>
    </sec>
    <sec id="s0015">
      <title>Experimental methods</title>
      <sec id="s0020">
        <title>Participants</title>
        <p>Nineteen subjects participated in the experiment. Data for two participants were excluded due to excessive magnetic artifacts. The mean age of the 17 remaining subjects (8 females) was 26.6 years. All but one were right handed (<xref rid="bb0175" ref-type="bibr">Oldfield, 1971</xref>), all reported normal hearing, normal or corrected-to-normal vision, and had no history of neurological disorders. Experimental procedures were approved by the research ethics committee of University College London, and written informed consent was obtained from each participant. Subjects were paid for their participation.</p>
        <p>Due to a hardware malfunction, a significant number of button presses were not registered for the first 5 participants. The behavioral performance measures reported here are therefore based on the data from 12 subjects.</p>
      </sec>
      <sec id="s0025">
        <title>Stimuli</title>
        <p><xref rid="f0005" ref-type="fig">Fig. 1</xref> schematizes the experimental paradigm. Three streams of stimuli were presented concurrently, two auditory (in opposite ears) and one visual. Stimulation was identical in all conditions, but the behavioral task differed between conditions. MEG responses were analyzed relative to one auditory stream (‘auditory edge stimuli’) while the task involved either the other auditory stream (‘auditory decoys’) or the visual stream (‘visual decoys’), as detailed below.</p>
        <p>‘<italic>Auditory edge stimuli</italic>’ consisted of a train of 30-ms tone pips (0 ms inter-tone interval) presented for a total duration of 1440 ms. Tone frequencies were drawn from a set of 20 values equally spaced on a logarithmic scale between 222 and 2000 Hz. The amplitude of each pip was shaped by initial and final 5 ms raised-cosine ramps. Four patterns of frequencies were presented: C (‘constant’), R (‘random’), CR (‘constant to random’) and RC (‘random to constant’). The C stimulus consisted of a sequence of tone pips of a constant frequency, the R stimulus of a sequence of pips with frequencies drawn randomly from the set of 20 values, the CR stimulus of an initial 840-ms constant frequency sequence followed by a 600-ms random sequence, and the RC stimulus of an initial 840-ms random sequence followed by a 600-ms constant frequency sequence. The C and R patterns served as controls for the RC and CR transitions that were the primary focus of the study (see <xref rid="f0015" ref-type="fig">Fig. 3</xref>) and also made the occurrence of transitions unpredictable. This was important since predictability of transitions seems to modify auditory cortical responses to edges (<xref rid="bb0040" ref-type="bibr">Chait et al., 2007b</xref>).</p>
        <p>Forty signals were generated for each of the 4 patterns (C, R, CR, RC). CR and RC stimuli were created as mirror images of each other and trimmed to the required duration. Frequencies were drawn randomly from the above frequency set with the constraint that the change in frequency at the transition (at 840 ms post onset) was at least 20% in order to make it sufficiently salient. In a random sequence, it could happen by chance that two consecutive pips shared the same frequency: this occurred with a rate of about 5%.</p>
        <p>The stimuli were created off-line and saved in 16-bit stereo wave format at a sampling rate of 44 kHz. They were presented to the listeners in a random order with an inter stimulus interval (ISI) randomized between 500 and 1000 ms.</p>
        <p>‘<italic>Visual decoy’ stimuli</italic> consisted of five different shapes (circle, square, triangle, upside–down triangle and diamond) drawn in one of three colors (red, green or blue) and two sizes (visual angle of 7.4 or 2.86°), as well as a ‘random’ shape which was presented in only one size (visual angle of 13.7°). The ‘random’ shape stimulus consisted of a visual checker pattern, generated by multiple random-sized ellipses that were each drawn in a random color (red, green, or blue), and at a random position within the target square (see <xref rid="f0005" ref-type="fig">Fig. 1</xref> for an example). Stimuli were presented in the center of a gray screen (RGB: 190,190,190) at a distance of about 52 cm from the subject's eyes. Overall, 31 different visual stimuli were presented with an inter-onset interval randomized between 200 and 300 ms and with zero ISI.</p>
        <p>‘<italic>Auditory decoy’ stimuli</italic> consisted of nine different ‘auditory shapes’: (1) 200 Hz pure tone (2) 400 Hz pure tone (3) 800 Hz pure tone (4) 300 Hz pure tone amplitude modulated at 20 Hz (5) 600 Hz pure tone amplitude modulated at 20 Hz (6) 1200 Hz pure tone amplitude modulated at 20 Hz (7) Downwards FM glide from 800 to 400 Hz (8) upwards FM glide from 400 to 800 Hz (9) wide-band noise. Stimuli were 250 ms in duration and shaped by initial and final 25 ms raised-cosine ramps. All stimuli, except for the white noise, had a soft and louder version (24 dB difference). Overall, 17 different ‘auditory decoy’ stimuli were created off-line and saved in 16-bit stereo wave format at a sampling rate of 44 kHz. These stimuli were presented in a random order with ISI randomized between 150 and 350 ms.</p>
        <p>The computer that controlled the presentation of the ‘auditory edge’ signals was different from the one that controlled the presentation of the decoy stimuli, to assure that stimulus sequences were not synchronized.</p>
        <sec id="s0030">
          <title>Paradigm</title>
          <p>Participants sat in a darkened magnetically shielded room. The visual signals were presented on a screen, placed approximately half a meter in front of the subjects' eyes. Auditory signals were delivered dichotically to the subjects' ears (‘auditory edge’ signals to one ear and ‘auditory decoy’ to the other) with tubephones (E-A-RTONE 3A 10 Ω, Etymotic Research, Inc) inserted into the ear-canal. The level of the ‘auditory edge’ signals was 6 dB higher than the ‘auditory decoy’ signals. The overall stimulus level was adjusted, for each subject, to a comfortable listening level.</p>
          <p>The experimental session was divided into blocks of about 6 min during which all three stimulus streams were present concurrently. The task (modality and difficulty) was constant within a block, but varied between blocks. Before the beginning of a block a message appeared on the screen instructing subjects to attend to the ‘visual decoy’ or ‘auditory decoy’ stimuli. The block was divided into 30 s long trials. At the beginning of a trial, the subject was briefly presented with a target in the attended modality, and had to memorize it and subsequently detect its occurrence during the trial, by pressing a button held in their right hand (rapid serial search paradigm). The target could occur between 0 and 3 times during a trial. The instructions encouraged speed and accuracy. Hits were defined as responses falling within a 1000 ms time window from a target. At the end of the trial the numbers of misses and false positives were briefly presented to the subject, immediately followed by the next trial, with a new target to memorize. The ear of presentation for ‘auditory edge’ and ‘auditory decoy’ stimuli was counter-balanced across blocks.</p>
          <p>For each modality, the task was either easy (‘low attentional load’) or hard (‘high attentional load’). In auditory low-load blocks, the target to be detected was the same in each trial and was always the noise stimulus. This stimulus is physically very different from the rest (wide band vs. narrow band) and was easily detected within the stimulus stream. In auditory high-load blocks the target could be any of the other signals, and changed from trial to trial. Subjects had to memorize correctly both the signal ‘shape’ and loudness. Similarly, in visual low-load blocks the target was always the multi-colored random shape stimulus and in high-load blocks subject had to memorize a different shape, color and size combination in each trial. In sum, 8 different blocks (2 modalities × 2 loads × counter balanced ear of presentation for auditory signals) were presented in random order. To ensure that sensory stimulation was identical across blocks, subjects were instructed to fixate at the center of the screen at all times and this was verified with eye tracking (iView X, SMI, Germany). Between blocks, subjects were permitted a short rest but were required to stay still.</p>
          <p>An important aspect of our decoy tasks is the fast stimulus presentation rate (<xref rid="bb0145 bb0180" ref-type="bibr">Muller-Gass et al., 2006; Otten et al., 2000</xref>). When decoy stimuli are presented at a fast rate attentional switches between the attended and ignored streams are unlikely. Indeed, when questioned at the end of the experiment, subjects mostly reported not noticing that the ignored ‘auditory edge’ stream included transitions within stimuli.</p>
        </sec>
      </sec>
      <sec id="s0035">
        <title>Procedure</title>
        <p>The experimental session included three phases: First, for approximately 15 min, subjects practiced the tasks (<italic>in situ</italic>). Recording sessions then began with a preliminary functional source-localizer recording, followed by the main experiment (8 blocks). In the functional source-localizer recording subjects listened to 200 repetitions of a 1 kHz 50 ms sinusoidal tone (ISI randomized between 750 and 1550 ms). These responses were used to verify that the subject was positioned properly in the machine, that signals from auditory cortex had a satisfactory signal to noise ratio (SNR), and to determine which MEG channels best responded to activity within auditory cortex.</p>
      </sec>
      <sec id="s0040">
        <title>Neuromagnetic recording and data analysis</title>
        <p>The magnetic signals were recorded using a CTF-275 MEG system (axial gradiometers, 275 channels, 30 reference channels; VSMMedTech, Canda). Data were acquired continuously with a sampling rate of 300 Hz and a 100 Hz hardware low pass filter. Offline, the data were noise-reduced using the Time-Shift Principle Component Analysis algorithm (TSPCA; <xref rid="bb0055" ref-type="bibr">de Cheveigné and Simon, 2007</xref>) and then low pass filtered (zero-phase Butterworth filter) at 30 Hz.</p>
        <p>Functional localizer data were divided into 700 ms epochs, including 200 ms pre-onset, and baseline-corrected to the pre-onset interval. The M100 onset response (<xref rid="bb0290 bb0215" ref-type="bibr">Hari, 1990; Roberts et al., 2000</xref>) was identified for each subject as a dipole-like pattern (i.e. a source/sink pair) in the magnetic field contour plots distributed over the temporal region of each hemisphere. The M100 current source is quite robustly localized to the upper banks of the superior temporal gyrus in both hemispheres (<xref rid="bb0290 bb0125" ref-type="bibr">Hari, 1990; Lütkenhöner and Steinsträter, 1998</xref>). For each subject, the 40 strongest channels at the peak of the M100 (20 in each hemisphere) were considered to best reflect activity in the auditory cortex and thus chosen for the analysis of the experimental data. This procedure serves the dual purpose of enhancing the auditory response components over other response components, and compensating for any channel-misalignment between subjects.</p>
        <p>For the main experiment data, 2200 ms epochs (including 200 ms pre onset) were created for each of the stimulus conditions (2 (vis/aud) × 2 (high/low attentional load) × 4 auditory edge stimuli (C, R, CR, RC)), resulting in 80 epochs per condition. Epochs with amplitudes larger than 3 pT (~ 3%), such as what would be caused by eye blinks, were considered artifactual and discarded. Additionally, epochs during which subjects were not fixating in the center of the screen (&lt; 1%) were excluded from analysis. The rest were averaged. In each hemisphere, the root mean square (RMS) of the field strength across the 20 channels, selected in the functional source-localizer run, was calculated for each sample point. Thirty-two RMS time series (16 conditions × two hemispheres) were thus created for each subject.</p>
        <p>The time course of the RMS, reflecting instantaneous amplitude of neural responses, was used as a measure of the dynamics of brain responses. The congruence of activation time course across subjects was evaluated using the bootstrap method (<xref rid="bb0070" ref-type="bibr">Efron and Tibshirani, 1993</xref>; 1000 iterations; balanced) based on the individual RMS time series as described in <xref rid="bb0035" ref-type="bibr">Chait et al. (2007a)</xref>. For illustration purposes, we plot a group-RMS (RMS of individual subject RMSs), but statistical analysis was always performed over subjects, independently for each hemisphere.</p>
        <p>To compare the activation between conditions, we used a repeated-measures analysis in which, for each subject, the squared RMS value of one condition was subtracted from the squared RMS value of the other condition, and the 17 individual difference time-series were subjected to a bootstrap analysis (1000 iterations; balanced; <xref rid="bb0070" ref-type="bibr">Efron and Tibshirani, 1993</xref>). At each time point, the proportion of iterations below the zero line was counted. If that proportion was less than 1%, or more than 99% for 8 adjacent samples, the difference was judged to be significant. This figure (8 samples) was determined based on a permutation analysis designed to measure the ‘false discovery rate’. In brief, we ran an iterative analysis (1000 repetitions) to simulate the H0 hypothesis (no difference between conditions), where instead of the actual data time-series we used random time-series (created by permuting the samples in the original data; to simulate the level of temporal coherence introduced by the low-pass filter, the permuted time-series underwent the same pre-processing procedures as for the true data). Using the repeated-measure analysis described above, the maximum number of consecutive samples that fell outside of the 1%/99% criterion was computed. The longest such sequence was of length 7 (and occurred roughly 1% of the time) and, therefore, only sequences of 8 samples or longer were considered statistically significant.</p>
        <p>Peak latencies and amplitudes were measured by selecting, for each subject and condition, the maximum (or minimum) value within the relevant time window, defined as ± 20 ms centered around the group-RMS peak. These data were submitted to a repeated-measures ANOVA. The α level was set, a-priori, to 0.05. The Greenhouse–Geisser correction was applied where appropriate.</p>
      </sec>
    </sec>
    <sec id="s0005">
      <title>Results</title>
      <sec id="s0045">
        <title>Behavioral data</title>
        <p>Subjects had little difficulty performing auditory and visual tasks requiring low attentional load, resulting in ceiling performance in both cases (<xref rid="f0010" ref-type="fig">Fig. 2</xref>A; mean miss rate of 2.1% and 2.5%, respectively). However, performance was significantly reduced for tasks requiring high attentional load (mean miss rate of 25.6% and 19.1%, respectively). A repeated-measures ANOVA with factors ‘modality’ and ‘load’ showed a significant main effect for ‘load’ only (<italic>p</italic> &lt; 0.001), and no interaction, confirming that our choice of tasks was effective in manipulating attentional load to a similar degree for both sensory domains. False positive rates were small, but subjects generated more false positives in the high-load auditory task (3%) than the high-load visual task (0.5%).</p>
        <p>Response times (RTs) in low-load tasks were similar for both modalities (auditory: 534.12 ms; visual: 540.3 ms), and were significantly longer for high-load tasks (auditory: 676.5 ms; visual: 617.8 ms). A repeated-measures ANOVA with ‘modality’ and ‘load’ as factors revealed significant main effects of load (<italic>p</italic> = 0.012) and modality (<italic>p</italic> &lt; 0.001) as well as an interaction (<italic>p</italic> = 0.019). This was due to the fact that RTs in the high-load auditory task were slower (by about 60 ms) than in the high-load visual task, presumably because the features distinguishing auditory decoy stimuli related to temporally evolving properties whose extraction required longer exposure to the stimulus. Importantly, for purposes of the present study, both the RT and accuracy data confirmed that the attentional load manipulation was effective in influencing behavioral performance in both the visual and the auditory tasks, with comparable detection levels in both domains.</p>
      </sec>
      <sec id="s0050">
        <title>MEG data</title>
        <sec id="s0055">
          <title>MEG responses to auditory edge stimuli</title>
          <p>To demonstrate the general response pattern to the two forms of transition, MEG activity was first assessed across all attentional load conditions (<xref rid="f0015" ref-type="fig">Fig. 3</xref>). Plotted are group root-mean-square (group-RMS; RMS of individual subject RMSs) of auditory-evoked responses to constant-to-random (CR) and random-to-constant (RC) transitions and the control conditions (C and R, respectively). Responses to C and R tone sequences show a similar pattern – an onset response (peaking about 100 ms post stimulus onset) followed by a rise to a sustained response – maintained for the duration of the stimulus, and a return to baseline following stimulus offset. The dynamics of the response to the transition, however, differ substantially for the CR and RC conditions. Upon transition from a sequence of constant to random tone pips, the MEG signal shows a sharp drop in the sustained response (‘1a’ in <xref rid="f0015" ref-type="fig">Fig. 3</xref>), reaching a minimum some 70-ms following the transition (‘M50’ response). A repeated-measures bootstrap (see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section) indicates that the initial difference in MEG responses between the CR stimulus and its control (C) stimulus emerges some 60-ms post transition in the right hemisphere, and 63-ms post transition in the left. This initial deflection (‘1a’ in <xref rid="f0015" ref-type="fig">Fig. 3</xref>) is then followed by a peak, ‘1b’ in <xref rid="f0015" ref-type="fig">Fig. 3</xref>, with a latency of 136-ms post transition in the right hemisphere and 177 ms in the left. Together, these peaks are reminiscent of the MEG M50–M100 response complex (P1–N1 in the electroencephalogram) commonly evoked by stimulus onset or transitions (e.g. <xref rid="bb0110 bb0130 bb0210 bb0295 bb0280" ref-type="bibr">Krumbholz et al., 2003; Martin and Boothroyd, 2000; Ritter et al., 2005; Ross et al., 2004; Yamashiro et al., 2011</xref>).</p>
          <p>In response to the opposite transition – from random to constant frequency – MEG activity peaks much later, about 200 ms following the transition (‘2’ in <xref rid="f0015" ref-type="fig">Fig. 3</xref>) and with a very different shape (increase in magnetic field strength) to that evoked by the CR transition. A repeated-measures bootstrap indicates that the first difference from the control (no change stimuli) emerges 126 ms after the transition in the right hemisphere and 140 ms post-transition in the left. The striking absence of a M50 response here reveals a functional dissociation between the transition-evoked M50 and M100 responses. Cortical detection of the RC transition is therefore not only delayed with respect to the CR transition, but also involves a different sequence of MEG deflections.</p>
          <p>These findings replicate previous studies which demonstrated different responses for the two kinds of temporal edges (<xref rid="bb0035 bb0045" ref-type="bibr">Chait et al., 2007a, 2008</xref>), but now for conditions in which attention was directed <italic>away</italic> from the edge stimuli.</p>
        </sec>
        <sec id="s0060">
          <title>Effects of attentional load</title>
          <p>To assess the effect of attentional load on responses to temporal edges, the data were examined in 4 conditions: auditory low load (AL), auditory high load (AH), visual low load (VL) and visual high load (VH). Each condition represented data from 80 trials for each of the C, R, CR, RC stimuli.</p>
        </sec>
        <sec id="s0065">
          <title>Attention directed to the auditory modality</title>
          <p>For blocks in which attention was focused on the auditory decoys, a significant reduction in the amplitude of response to RC transitions was observed for the high-load (AH) condition. Panel 4E shows average peak amplitudes for the three deflections marked in <xref rid="f0015" ref-type="fig">Fig. 3</xref>. A repeated-measures ANOVA with ‘deflection’ (‘1a’, ‘1b’, ‘2’; see <xref rid="f0015" ref-type="fig">Fig. 3</xref>), ‘load’, and ‘hemisphere’ as factors showed a trivial main effect of ‘deflection’ (due to the different absolute amplitudes of each peak) and a significant interaction of ‘deflection’ × ‘load’ (<italic>p</italic> = 0.007). <italic>Post hoc</italic> analysis revealed that only the random-to-constant (RC) transition was significantly influenced by attentional load (<italic>p</italic> = 0.005; for other deflections <italic>p</italic> &gt; 0.24), with a reduction in MEG amplitude of around 20% compared to that for the low-load condition. There was no influence of attentional load on the latency of the various deflections.</p>
          <p>In addition to this temporal ‘region of interest’ analysis, a ‘blind’ method was used to explore the extent to which these intervals emerge from the data: <xref rid="f0020" ref-type="fig">Figs. 4</xref>A and B show the group-RMS of the auditory evoked responses to CR and RC edges, respectively. Gray shading indicates the temporal intervals where a repeated-measures bootstrap indicated a significant difference between low- and high-load conditions. Whereas no significant differences appear in the CR stimuli between attentional conditions, a significant decrease in the amplitude of the RC transition response is observed in the high-load task. To demonstrate the significance of the effects, panels 4C and 4D display the results of the repeated measures bootstrap analysis. For each point in time, the minimum ratio (capped at 10% for clarity) of bootstrap iterations located above or below zero is plotted. For a difference to be judged as significant, this number has to be &lt; 1% (99% of the iterations have to lie on one side of the zero line; see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section for additional constraints). Such effects were clearly evident for RC transitions (<xref rid="f0020" ref-type="fig">Fig. 4</xref>D), but not for CR transitions (<xref rid="f0020" ref-type="fig">Fig. 4</xref>C).</p>
          <p>While a slow-wave shift appears to occur prior to the transition in the RC stimuli (<xref rid="f0020" ref-type="fig">Fig. 4</xref>B), the bootstrap analysis (<xref rid="f0020" ref-type="fig">Fig. 4</xref>D) indicates that this effect is not statistically significant, and that the difference between the high and low load curves emerges only at around 980-ms post onset (140-ms post transition) and is restricted to the interval around the response peak. An additional analysis (see <xref rid="ec0005" ref-type="supplementary-material">Supplementary Fig. 1A</xref>), involving base-line correction of the response relative to the pre-transition interval, resulted in an essentially identical significance pattern. This confirms that the effect is restricted to the response peak and is not due to a baseline shift. Additionally, load had no significant effect on responses to the control (no transition; C or R) stimuli (<xref rid="ec0005" ref-type="supplementary-material">Supplementary Fig. 1B</xref>), further suggesting that the effects seen in <xref rid="f0020" ref-type="fig">Fig. 4</xref> are specific to transition responses and are not due to a baseline shift in the R stimulus.</p>
          <p>While a slow-wave shift appears to occur prior to the transition in the RC stimuli (<xref rid="f0020" ref-type="fig">Fig. 4</xref>B), the bootstrap analysis (<xref rid="f0020" ref-type="fig">Fig. 4</xref>D) indicates that this effect is not statistically significant, and that the difference between the high and low load curves emerges only at around 980-ms post onset (140-ms post transition) and is restricted to the interval around the response peak. An additional analysis (see Supplementary Fig. 1A), involving base-line correction of the response relative to the pre-transition interval, resulted in an essentially identical significance pattern. This confirms that the effect is restricted to the response peak and is not due to a baseline shift. Additionally, load had no significant effect on responses to the control (no transition; C or R) stimuli (Supplementary Fig. 1B), further suggesting that the effects seen in <xref rid="f0020" ref-type="fig">Fig. 4</xref> are specific to transition responses and are not due to a baseline shift in the R stimulus.</p>
        </sec>
        <sec id="s0070">
          <title>Attention directed to the visual modality</title>
          <p>In contrast to auditory attentional load, visual attentional load had no effect on the MEG response (<xref rid="f0025" ref-type="fig">Fig. 5</xref>). A repeated measures bootstrap indicated no significant difference between low- and high-load conditions in either transition (panels 5C and 5D). Panel 5E shows average peak latencies for the three deflections marked in <xref rid="f0015" ref-type="fig">Fig. 3</xref>. A repeated measures ANOVA with ‘deflection’ (‘1a’, ‘1b’, ‘2’), ‘load’, and ‘hemisphere’ as factors, revealed no significant effects (for all <italic>p</italic> &gt; 0.19).</p>
          <p>Consequently, these data reveal a fundamental difference in the effects of attentional load in the visual and auditory domain on cortical processing of unattended auditory temporal edges. This difference was confirmed statistically by means of a repeated-measures ANOVA with ‘modality’, ‘load’, ‘deflection’ and ‘hemisphere’ as factors, which revealed a significant interaction of ‘modality’ × ‘load’ × ‘deflection’ (<italic>p</italic> = 0.006), again demonstrating that the effect of attentional load is found only for the RC deflection under conditions of high auditory attentional load.</p>
          <p>The data demonstrate that the amplitude differences observed at the response peaks are probably not attributable to differences in sustained responses which preceded the transition. Furthermore, while the low- and high-load tasks differed in the number of executed button presses, this also cannot be the source of the observed effect, as only RC transitions in the auditory high-load condition were affected. Indeed, any explanation of the effect in terms of certain deflections in the MEG signal being inherently more susceptible to task-related ‘brain noise’ must be discarded on the grounds that such an explanation would predict identical patterns in visual and auditory tasks.</p>
        </sec>
        <sec id="s0075">
          <title>Effect of attentional load on onset/sustained responses to auditory edge stimuli</title>
          <p>As evident from <xref rid="f0020" ref-type="fig">Fig. 4</xref> there is no effect of auditory attentional load on stimulus onset responses (0–200 ms post stimulus onset). The data in <xref rid="f0025" ref-type="fig">Fig. 5</xref> show a possible effect of visual load at the onset of C but not R signals, but since this onset effect is restricted to visual load conditions it is difficult to interpret. In neither modality does attentional load appear to influence sustained responses (300–840 ms post stimulus onset; see also <xref rid="bb0145" ref-type="bibr">Muller-Gass et al., 2006</xref>).</p>
        </sec>
      </sec>
    </sec>
    <sec id="s0010">
      <title>Discussion</title>
      <p>The present study examined the effect of attentional load on cortical processing of acoustic transitions in which the sound pattern changed from a constant-frequency to a random-frequency sequence, or <italic>vice versa</italic>. The major finding is that auditory cortical responses to the emergence of a repeating pattern, but not to violations of this regularity, are influenced by the level of attentional load required to perform a competing auditory task. This observation suggests that the mechanisms for detecting the emergence or violation of such a simple regularity in the auditory domain are not equally automatic. Notably, these effects are limited to conditions where attention is directed to the auditory modality; a structurally similar competing visual task had no effect on cortical processing of either form of acoustic transition, underlining the dependence of these operations on modality-specific attentional resources.</p>
      <sec id="s0080">
        <title>Auditory cortical responses to CR and RC transitions</title>
        <p>As has been shown previously (<xref rid="bb0035 bb0040 bb0045" ref-type="bibr">Chait et al., 2007a, 2007b, 2008</xref>), CR and RC transitions evoke different sequences of brain responses. A transition from a sequence of constant to random tone pips, gives rise to a M50–M100-like response complex, whereas responses to the opposite transition, from random to constant frequency, peak much later and are dominated by a late M100-like response without a preceding M50 deflection. Previous studies have observed an essentially-identical MEG response profile for a variety of signals that differed physically but nevertheless shared the abstract property of transitions from – or to – a predictable pattern. For example, transitions between regular and random frequency patterns (<xref rid="bb0035 bb0045" ref-type="bibr">Chait et al., 2007a, 2008</xref>), transitions between regular and random patterns in the dimension of inter-aural correlation (<xref rid="bb0030" ref-type="bibr">Chait et al., 2005</xref>), transitions between random noise, and ‘regular’ iterated noise (<xref rid="bb0300" ref-type="bibr">Rupp et al., 2005</xref>) or between regular and random click trains (<xref rid="bb0090" ref-type="bibr">Gutschalk et al., 2004</xref>). This suggests that the observed dynamics are not specific to transitions in any particular acoustic feature, but rather depend on the statistical patterns (regular to irregular, irregular to regular) common to these stimuli.</p>
        <p><xref rid="bb0270 bb0100" ref-type="bibr">Wolff and Schröger (2001) and Horváth and Winkler (2004</xref>; see also <xref rid="bb0165 bb0205" ref-type="bibr">Näätänen and Rinne, 2002; Ritter et al., 1992</xref>) examined responses to occasionally repeating sounds in a sequence of random frequency tones, comparable to the RC stimulus here, and reported the presence of an MMN response, time locked to the second repeating tone. However, while the MMN response obtained in those studies resembled a standard oddball MMN (MMN to a violation of regularity), the present paradigm reveals fundamental differences between responses to CR and RC transitions that are not usually reported for MMN responses (<xref rid="bb0045" ref-type="bibr">Chait et al., 2008</xref>; see also <xref rid="bb0085" ref-type="bibr">Grimm et al., 2011</xref>) . Thus, while it is likely that some of the neural processes contributing to the responses we observe overlap with those underlying the MMN, in certain cases the present ‘transition-response’ paradigm allows a more refined view of the different processes at work during auditory change detection.</p>
        <p>The differences we observe between CR and RC transitions contradict a simple default hypothesis that all transitions are processed by the same underlying neural hardware, in which case we would expect the same pattern of responses to both types of transitions distinguishable only by a latency difference. Instead, our data suggest, in line with previous results, that at least partially separate neural computations are employed in the process of auditory temporal edge detection, depending on the type of transition encountered (see also <xref rid="bb0045" ref-type="bibr">Chait et al., 2008</xref>). The current study demonstrates that the two mechanisms are differentially affected by attention, which further strengthens our theoretical synthesis based on distinct underlying neural mechanisms.</p>
      </sec>
      <sec id="s0085">
        <title>Auditory attentional load effects</title>
        <p>Our data suggest, in accordance with results from the MMN literature (e.g. <xref rid="bb0015 bb0025" ref-type="bibr">Alho et al., 1992; Bendixen and Schröger, 2008</xref>; <xref rid="bb0145 bb0140 bb0170 bb0200 bb0230 bb0235 bb0240 bb0275" ref-type="bibr">Muller-Gass et al., 2006, 2007; Näätänen et al., 2007; Restuccia et al., 2005; SanMiguel et al., 2008; Sculthorpe et al., 2008; Sussman, 2007; Woods et al., 1992</xref>), that sensitivity to violation-of-regularity edges (which are similar to the kinds of changes which have been previously studied with the classic oddball MMN paradigm), does not deteriorate with increasing auditory load. In contrast to these established findings, we find here that sensitivity to changes manifested as the emergence of structure from a random sequence (a type of change which has been relatively unexplored; see e.g. <xref rid="bb0020" ref-type="bibr">Bendixen et al., 2007</xref>) is significantly reduced when listeners' attention is strongly focused on a competing auditory task.</p>
        <p>Indeed, while formally symmetric, RC and CR transitions are fundamentally different in nature. In the case of CR transitions, an observer can detect the event immediately as a violation of the current regularity. To detect the opposite transition – RC – the observer must sample a sufficiently-long epoch of the stimulus and compare past and present fluctuation statistics. The data thus suggest that regularity build-up requires substantial computational resources. However once a regularity model has been established, detection of deviations is automatic and independent of attention. This result represents a conceptual shift from the traditional approach, which so far did not differentiate changes according to their statistical properties. The present data indeed suggest that cortical processing of changes in the environment, beyond the focus of attention, critically depends on the statistical nature of those changes.</p>
        <p>Assuming that the observed responses reflect mechanisms which pre-consciously encode external change events into some sort of internal representation of the ‘state of the world’, the finding that brain responses to different events that are equally un-attended (and equally salient) can nevertheless be differentially influenced by attentional load, suggests that strongly focused attention may lead to a skewed internal model of the (ignored) acoustic environment. That is to say, certain events would be represented with more fidelity than others, potentially leading to behavioral consequences (e.g. listeners being more distracted by CR- rather than RC-type events).</p>
      </sec>
      <sec id="s0090">
        <title>Modality specificity of attentional load effects</title>
        <p>A fundamental question in the study of attention concerns the relation of the processing resources engaged by each of the different senses. Are resources shared across a single, central pool accessible to all sensory modalities, or are specialized sensory resources reserved for each modality independently (e.g. <xref rid="bb0010 bb0060 bb0115" ref-type="bibr">Alais et al., 2006; Duncan et al., 1997; Larsen et al., 2003</xref>)? In the context of attentional load, this issue concerns the degree to which strongly focused attention affects the processing of <italic>task-irrelevant</italic> (‘to be ignored’) stimuli of the same or different modality as the attended stimulus stream (<xref rid="bb0120" ref-type="bibr">Lavie, 2005</xref>). Typically, studies which employ fast target-stream stimulation rates that reduce the chance of shifting attention to the to-be-ignored modality demonstrate that brain responses to task-irrelevant stimuli are independent of attentional load when attention is focused on a different modality (<xref rid="bb0065 bb0150 bb0195 bb0200 bb0235 bb0250" ref-type="bibr">Dyson et al., 2005; Muller-Gass et al., 2005; Rees et al., 2001; Restuccia et al., 2005; Sculthorpe et al., 2008; Talsma et al., 2006</xref>). For example, <xref rid="bb0190 bb0195" ref-type="bibr">Rees et al. (1997, 2001)</xref> showed that visual load, but not auditory load, modulates processing of a task-irrelevant visual motion stimulus. <xref rid="bb0250" ref-type="bibr">Talsma et al. (2006)</xref> reported that cortical responses elicited by a repeating visual-letter stream were significantly larger when concurrent auditory stimuli were attended than when other concurrent visual stimuli were attended. Likewise, numerous studies investigating the effect of visual load on auditory MMN responses report no influence of strongly focused visual attention on the detection of change in the auditory stimulus stream (<xref rid="bb0065 bb0135 bb0150 bb0200 bb0235" ref-type="bibr">Dyson et al., 2005; Müller et al., 2002; Muller-Gass et al., 2005; Restuccia et al., 2005; Sculthorpe et al., 2008</xref>).</p>
        <p>The present study differs from these previous studies in two basic aspects. First, the effects of auditory and visual decoy tasks <italic>simultaneously</italic> were investigated, within the same recording session and using identical sensory stimulation in all conditions. This allowed the exclusion of confounding effects of stimulus differences, highlighting effects that can be ascribed specifically to the task. Second, as discussed above, the stimulus set contains more dimensions of change than those widely employed in the MMN paradigm, revealing that different types of changes (RC and CR) are differentially influenced by attentional load.</p>
        <p>While it is difficult to exclude the possibility that other visual tasks with different stimuli or spatial arrangements might elicit a different set of results, it is worth noting that the null effect in the visual load condition appears convincing (<xref rid="f0025" ref-type="fig">Fig. 5</xref>), with no obvious trends. The data are therefore consistent with modality-specific effects of attentional load on the processing of acoustic changes, and suggest that mechanisms contributing to detection of the emergence of regularity rely on processing resources reserved exclusively for the auditory modality. Responses to RC transitions were attenuated only when attention prioritized processing of concurrent auditory signals, thereby depleting available processing resources in the auditory domain.</p>
        <p>The following are the supplementary materials related to this article.<supplementary-material content-type="local-data" id="ec0005"><caption><title>Supplementary Fig. 1</title><p>A: Re-analysis of the data in <xref rid="f0020" ref-type="fig">Fig. 4</xref>, base-corrected relative to the pre-transition interval (-50:0 relative to the transition time). Plotted are group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) conditions. Shaded areas mark time intervals where a significant difference is found between load conditions. Bottom panels show the repeated measures bootstrap analysis. For each time point, we plot the minimum percentage (capped at 10% for clarity) of bootstrap iteration located above or below zero. For a difference to be judged as significant this number must not exceed 1% (see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section for additional constraints). The figure demonstrates that the effect of load on the amplitude of the RC transition survives this re-analysis, confirming that the difference between ‘high’ and ‘low’ load in the RC transition is restricted to the interval around the peak, and is likely not due to a baseline shift which precedes the transition. B: The effect of varying the attentional load in the auditory decoy task on responses to the control (no transition) stimuli. Plotted are group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) conditions. Shaded areas mark time intervals where a significant difference is found between load conditions. Bottom panels show the repeated measures bootstrap analysis. For each time point, we plot the minimum percentage (capped at 10% for clarity) of bootstrap iteration located above or below zero. For a difference to be judged as significant this number must not exceed 1% (see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section for additional constraints). The figure demonstrates that load had no significant effect on either C or R responses, further suggesting that the effects seen in <xref rid="f0020" ref-type="fig">Fig. 4</xref> are specific to transition responses and are not due to a baseline shift in the R stimulus.</p></caption><media xlink:href="mmc1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></p>
        <p>Supplementary materials related to this article can be found online at <ext-link ext-link-type="doi" xlink:href="10.1016/j.neuroimage.2011.09.006">doi:10.1016/j.neuroimage.2011.09.006</ext-link>.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bb0005">
        <element-citation publication-type="journal" id="rf0005">
          <person-group person-group-type="author">
            <name>
              <surname>Alain</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Izenberg</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Effects of attentional load on auditory scene analysis</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>15</volume>
          <year>2003</year>
          <fpage>1063</fpage>
          <lpage>1073</lpage>
          <pub-id pub-id-type="pmid">14614816</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0010">
        <element-citation publication-type="journal" id="rf0010">
          <person-group person-group-type="author">
            <name>
              <surname>Alais</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Morrone</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Burr</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Separate attentional resources for vision and audition</article-title>
          <source>Proc. Biol. Sci.</source>
          <volume>273</volume>
          <year>2006</year>
          <fpage>1339</fpage>
          <lpage>1345</lpage>
          <pub-id pub-id-type="pmid">16777721</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0015">
        <element-citation publication-type="journal" id="rf0015">
          <person-group person-group-type="author">
            <name>
              <surname>Alho</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Woods</surname>
              <given-names>D.L.</given-names>
            </name>
            <name>
              <surname>Algazi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Intermodal selective attention. II. Effects of attentional load on processing of auditory and visual stimuli in central space</article-title>
          <source>Electroencephalogr. Clin. Neurophysiol.</source>
          <volume>82</volume>
          <year>1992</year>
          <fpage>356</fpage>
          <lpage>368</lpage>
          <pub-id pub-id-type="pmid">1374704</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0025">
        <element-citation publication-type="journal" id="rf0025">
          <person-group person-group-type="author">
            <name>
              <surname>Bendixen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Schröger</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Memory trace formation for abstract auditory features and its consequences in different attentional contexts</article-title>
          <source>Biol. Psychol.</source>
          <volume>78</volume>
          <year>2008</year>
          <fpage>231</fpage>
          <lpage>241</lpage>
          <pub-id pub-id-type="pmid">18439740</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0020">
        <element-citation publication-type="journal" id="rf0020">
          <person-group person-group-type="author">
            <name>
              <surname>Bendixen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Roeber</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Schröger</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Regularity extraction and application in dynamic auditory stimulus sequences</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>19</volume>
          <year>2007</year>
          <fpage>1664</fpage>
          <lpage>1677</lpage>
          <pub-id pub-id-type="pmid">18271740</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0030">
        <element-citation publication-type="journal" id="rf0030">
          <person-group person-group-type="author">
            <name>
              <surname>Chait</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>de Cheveigné</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>J.Z.</given-names>
            </name>
          </person-group>
          <article-title>Human auditory cortical processing of changes in interaural correlation</article-title>
          <source>J. Neurosci.</source>
          <volume>25</volume>
          <year>2005</year>
          <fpage>8518</fpage>
          <lpage>8527</lpage>
          <pub-id pub-id-type="pmid">16162933</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0035">
        <element-citation publication-type="journal" id="rf0035">
          <person-group person-group-type="author">
            <name>
              <surname>Chait</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>de Cheveigné</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>J.Z.</given-names>
            </name>
          </person-group>
          <article-title>Processing asymmetry of transitions between order and disorder in human auditory cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>27</volume>
          <year>2007</year>
          <fpage>5207</fpage>
          <lpage>5214</lpage>
          <pub-id pub-id-type="pmid">17494707</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0040">
        <element-citation publication-type="journal" id="rf0040">
          <person-group person-group-type="author">
            <name>
              <surname>Chait</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>J.Z.</given-names>
            </name>
          </person-group>
          <article-title>Stimulus context affects auditory cortical responses to changes in interaural correlation</article-title>
          <source>J. Neurophysiol.</source>
          <volume>98</volume>
          <year>2007</year>
          <fpage>224</fpage>
          <lpage>231</lpage>
          <pub-id pub-id-type="pmid">17493921</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0045">
        <element-citation publication-type="journal" id="rf0045">
          <person-group person-group-type="author">
            <name>
              <surname>Chait</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>J.Z.</given-names>
            </name>
          </person-group>
          <article-title>Auditory temporal edge detection in human auditory cortex</article-title>
          <source>Brain Res.</source>
          <volume>1213</volume>
          <year>2008</year>
          <fpage>78</fpage>
          <lpage>90</lpage>
          <pub-id pub-id-type="pmid">18455707</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0050">
        <element-citation publication-type="journal" id="rf0050">
          <person-group person-group-type="author">
            <name>
              <surname>Costa-Faidella</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Grimm</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Slabu</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Díaz-Santaella</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Escera</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Multiple time scales of adaptation in the auditory system as revealed by human evoked potentials</article-title>
          <source>Psychophysiology</source>
          <volume>48</volume>
          <year>2011</year>
          <fpage>774</fpage>
          <lpage>783</lpage>
          <pub-id pub-id-type="pmid">20946129</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0055">
        <element-citation publication-type="journal" id="rf0055">
          <person-group person-group-type="author">
            <name>
              <surname>de Cheveigné</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Simon</surname>
              <given-names>J.Z.</given-names>
            </name>
          </person-group>
          <article-title>Denoising based on Time-Shift PCA</article-title>
          <source>J. Neurosci. Methods</source>
          <volume>165</volume>
          <year>2007</year>
          <fpage>297</fpage>
          <lpage>305</lpage>
          <pub-id pub-id-type="pmid">17624443</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0060">
        <element-citation publication-type="journal" id="rf0060">
          <person-group person-group-type="author">
            <name>
              <surname>Duncan</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Martens</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ward</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Restricted attentional capacity within but not between sensory modalities</article-title>
          <source>Nature</source>
          <volume>387</volume>
          <year>1997</year>
          <fpage>808</fpage>
          <lpage>810</lpage>
          <pub-id pub-id-type="pmid">9194561</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0065">
        <element-citation publication-type="journal" id="rf0065">
          <person-group person-group-type="author">
            <name>
              <surname>Dyson</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Alain</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Effects of visual attentional load on low-level auditory scene analysis</article-title>
          <source>Cogn. Affect. Behav. Neurosci.</source>
          <volume>5</volume>
          <year>2005</year>
          <fpage>319</fpage>
          <lpage>338</lpage>
          <pub-id pub-id-type="pmid">16396093</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0070">
        <element-citation publication-type="book" id="rf0070">
          <person-group person-group-type="author">
            <name>
              <surname>Efron</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Tibshirani</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <chapter-title>An introduction to the Bootstrap</chapter-title>
          <year>1993</year>
          <publisher-name>Chapman and Hall</publisher-name>
          <publisher-loc>NY, NY, USA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0075">
        <element-citation publication-type="journal" id="rf0075">
          <person-group person-group-type="author">
            <name>
              <surname>Fritz</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Elhilali</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>David</surname>
              <given-names>S.V.</given-names>
            </name>
            <name>
              <surname>Shamma</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Auditory attention — focusing the searchlight on sound</article-title>
          <source>Curr. Opin. Neurobiol.</source>
          <volume>17</volume>
          <year>2007</year>
          <fpage>437</fpage>
          <lpage>455</lpage>
          <pub-id pub-id-type="pmid">17714933</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0080">
        <element-citation publication-type="journal" id="rf0080">
          <person-group person-group-type="author">
            <name>
              <surname>Garrido</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Kilner</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>The mismatch negativity: a review of underlying mechanisms</article-title>
          <source>Clin. Neurophysiol.</source>
          <volume>120</volume>
          <year>2009</year>
          <fpage>453</fpage>
          <lpage>463</lpage>
          <pub-id pub-id-type="pmid">19181570</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0085">
        <element-citation publication-type="journal" id="rf0085">
          <person-group person-group-type="author">
            <name>
              <surname>Grimm</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Escera</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Slabu</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Costa-Faidella</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological evidence for the hierarchical organization of auditory change detection in the human brain</article-title>
          <source>Psychophysiology</source>
          <volume>48</volume>
          <year>2011</year>
          <fpage>377</fpage>
          <lpage>384</lpage>
          <pub-id pub-id-type="pmid">20636288</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0090">
        <element-citation publication-type="journal" id="rf0090">
          <person-group person-group-type="author">
            <name>
              <surname>Gutschalk</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Patterson</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Scherg</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Uppenkamp</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Rupp</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Temporal dynamics of pitch in human auditory cortex</article-title>
          <source>Neuroimage</source>
          <volume>22</volume>
          <year>2004</year>
          <fpage>755</fpage>
          <lpage>766</lpage>
          <pub-id pub-id-type="pmid">15193604</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0290">
        <element-citation publication-type="book" id="rf0275">
          <person-group person-group-type="author">
            <name>
              <surname>Hari</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <chapter-title>The neuromagnetic method in the study of the human auditory cortex</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Grandori</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <source>Auditory Evoked Magnetic Fields and the Electric Potentials</source>
          <year>1990</year>
          <publisher-name>Krager-Verlag</publisher-name>
          <publisher-loc>Basel</publisher-loc>
          <fpage>222</fpage>
          <lpage>282</lpage>
        </element-citation>
      </ref>
      <ref id="bb0100">
        <element-citation publication-type="journal" id="rf0095">
          <person-group person-group-type="author">
            <name>
              <surname>Horváth</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Winkler</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>How the human auditory system treats repetition amongst change</article-title>
          <source>Neurosci. Lett.</source>
          <volume>368</volume>
          <year>2004</year>
          <fpage>157</fpage>
          <lpage>161</lpage>
          <pub-id pub-id-type="pmid">15351440</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0110">
        <element-citation publication-type="journal" id="rf0105">
          <person-group person-group-type="author">
            <name>
              <surname>Krumbholz</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Patterson</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Seither-Preisler</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lammertmann</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Lütkenhöner</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Neuromagnetic evidence for a pitch processing center in Heschl's gyrus</article-title>
          <source>Cereb. Cortex</source>
          <volume>13</volume>
          <year>2003</year>
          <fpage>765</fpage>
          <lpage>772</lpage>
          <pub-id pub-id-type="pmid">12816892</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0115">
        <element-citation publication-type="journal" id="rf0110">
          <person-group person-group-type="author">
            <name>
              <surname>Larsen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McIlhagga</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Baert</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bundesen</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Seeing or hearing? Perceptual independence, modality confusions, and crossmodal congruity effects with focused and divided attention</article-title>
          <source>Percept. Psychophys.</source>
          <volume>65</volume>
          <year>2003</year>
          <fpage>568</fpage>
          <lpage>574</lpage>
          <pub-id pub-id-type="pmid">12812279</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0120">
        <element-citation publication-type="journal" id="rf0115">
          <person-group person-group-type="author">
            <name>
              <surname>Lavie</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Distracted and confused?: selective attention under load</article-title>
          <source>Trends Cogn. Sci.</source>
          <volume>9</volume>
          <year>2005</year>
          <fpage>75</fpage>
          <lpage>82</lpage>
          <pub-id pub-id-type="pmid">15668100</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0125">
        <element-citation publication-type="journal" id="rf0120">
          <person-group person-group-type="author">
            <name>
              <surname>Lütkenhöner</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Steinsträter</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>High-precision neuromagnetic study of the functional organization of the human auditory cortex</article-title>
          <source>Audiol. Neurootol.</source>
          <volume>3</volume>
          <year>1998</year>
          <fpage>191</fpage>
          <lpage>213</lpage>
          <pub-id pub-id-type="pmid">9575385</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0130">
        <element-citation publication-type="journal" id="rf0125">
          <person-group person-group-type="author">
            <name>
              <surname>Martin</surname>
              <given-names>B.A.</given-names>
            </name>
            <name>
              <surname>Boothroyd</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Cortical, auditory, evoked potentials in response to changes of spectrum and amplitude</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>107</volume>
          <year>2000</year>
          <fpage>2155</fpage>
          <lpage>2161</lpage>
          <pub-id pub-id-type="pmid">10790041</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0135">
        <element-citation publication-type="journal" id="rf0130">
          <person-group person-group-type="author">
            <name>
              <surname>Müller</surname>
              <given-names>B.W.</given-names>
            </name>
            <name>
              <surname>Achenbach</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Oades</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Bender</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>U.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of mismatch negativity by stimulus deviance and modality of attention</article-title>
          <source>Neuroreport</source>
          <volume>13</volume>
          <year>2002</year>
          <fpage>1317</fpage>
          <lpage>1320</lpage>
          <pub-id pub-id-type="pmid">12151795</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0150">
        <element-citation publication-type="journal" id="rf0145">
          <person-group person-group-type="author">
            <name>
              <surname>Muller-Gass</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Stelmack</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Campbell</surname>
              <given-names>K.B.</given-names>
            </name>
          </person-group>
          <article-title>“…and were instructed to read a self-selected book while ignoring the auditory stimuli”: the effects of task demands on the mismatch negativity</article-title>
          <source>Clin. Neurophysiol.</source>
          <volume>116</volume>
          <year>2005</year>
          <fpage>2142</fpage>
          <lpage>2152</lpage>
          <pub-id pub-id-type="pmid">16029961</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0145">
        <element-citation publication-type="journal" id="rf0140">
          <person-group person-group-type="author">
            <name>
              <surname>Muller-Gass</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Stelmack</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Campbell</surname>
              <given-names>K.B.</given-names>
            </name>
          </person-group>
          <article-title>The effect of visual task difficulty and attentional direction on the detection of acoustic change as indexed by the Mismatch Negativity</article-title>
          <source>Brain Res.</source>
          <volume>1078</volume>
          <year>2006</year>
          <fpage>112</fpage>
          <lpage>130</lpage>
          <pub-id pub-id-type="pmid">16497283</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0140">
        <element-citation publication-type="journal" id="rf0135">
          <person-group person-group-type="author">
            <name>
              <surname>Muller-Gass</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Macdonald</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Schröger</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Sculthorpe</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Campbell</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Evidence for the auditory P3a reflecting an automatic process: elicitation during highly-focused continuous visual attention</article-title>
          <source>Brain Res.</source>
          <volume>1170</volume>
          <year>2007</year>
          <fpage>71</fpage>
          <lpage>78</lpage>
          <pub-id pub-id-type="pmid">17692834</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0160">
        <element-citation publication-type="book" id="rf0155">
          <person-group person-group-type="author">
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <chapter-title>Attention and Brain Function</chapter-title>
          <year>1992</year>
          <publisher-name>Lawrence Erlbaum Associates</publisher-name>
          <publisher-loc>Hillsdale, NJ, USA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0165">
        <element-citation publication-type="journal" id="rf0160">
          <person-group person-group-type="author">
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rinne</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Electric brain response to sound repetition in humans: an index of long-term-memory — trace formation?</article-title>
          <source>Neurosci. Lett.</source>
          <volume>318</volume>
          <year>2002</year>
          <fpage>49</fpage>
          <lpage>51</lpage>
          <pub-id pub-id-type="pmid">11786222</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0155">
        <element-citation publication-type="journal" id="rf0150">
          <person-group person-group-type="author">
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Gaillard</surname>
              <given-names>A.W.K.</given-names>
            </name>
            <name>
              <surname>Mäntysalo</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Early selective attention effect on evoked potential reinterpreted</article-title>
          <source>Acta Psychol.</source>
          <volume>42</volume>
          <year>1978</year>
          <fpage>313</fpage>
          <lpage>329</lpage>
        </element-citation>
      </ref>
      <ref id="bb0170">
        <element-citation publication-type="journal" id="rf0165">
          <person-group person-group-type="author">
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Paavilainen</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Rinne</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Alho</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>The mismatch negativity (MMN) in basic research of central auditory processing: a review</article-title>
          <source>Clin. Neurophysiol.</source>
          <volume>118</volume>
          <year>2007</year>
          <fpage>2544</fpage>
          <lpage>2590</lpage>
          <pub-id pub-id-type="pmid">17931964</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0175">
        <element-citation publication-type="journal" id="rf0170">
          <person-group person-group-type="author">
            <name>
              <surname>Oldfield</surname>
              <given-names>R.C.</given-names>
            </name>
          </person-group>
          <article-title>The assessment and analysis of handedness: the Edinburgh inventory</article-title>
          <source>Neuropsychologia</source>
          <volume>9</volume>
          <year>1971</year>
          <fpage>97</fpage>
          <lpage>113</lpage>
          <pub-id pub-id-type="pmid">5146491</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0180">
        <element-citation publication-type="journal" id="rf0175">
          <person-group person-group-type="author">
            <name>
              <surname>Otten</surname>
              <given-names>L.J.</given-names>
            </name>
            <name>
              <surname>Alain</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Picton</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>Effects of visual attentional load on auditory processing</article-title>
          <source>Neuroreport</source>
          <volume>11</volume>
          <year>2000</year>
          <fpage>875</fpage>
          <lpage>880</lpage>
          <pub-id pub-id-type="pmid">10757537</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0185">
        <element-citation publication-type="book" id="rf0180">
          <person-group person-group-type="author">
            <name>
              <surname>Polich</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <chapter-title>Detection of Change: Event Related Potential and fMRI Findings</chapter-title>
          <year>2003</year>
          <publisher-name>Kluwer Academic Press</publisher-name>
          <publisher-loc>Boston, MA, USA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bb0190">
        <element-citation publication-type="journal" id="rf0185">
          <person-group person-group-type="author">
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Lavie</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Modulating irrelevant motion perception by varying attentional load in an unrelated task</article-title>
          <source>Science</source>
          <volume>278</volume>
          <year>1997</year>
          <fpage>1616</fpage>
          <lpage>1619</lpage>
          <pub-id pub-id-type="pmid">9374459</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0195">
        <element-citation publication-type="journal" id="rf0190">
          <person-group person-group-type="author">
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Lavie</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Processing of irrelevant visual motion during performance of an auditory attention task</article-title>
          <source>Neuropsychologia</source>
          <volume>39</volume>
          <year>2001</year>
          <fpage>937</fpage>
          <lpage>949</lpage>
          <pub-id pub-id-type="pmid">11516446</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0200">
        <element-citation publication-type="journal" id="rf0195">
          <person-group person-group-type="author">
            <name>
              <surname>Restuccia</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Della Marca</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Marra</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Rubino</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Valeriani</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Attentional load of the primary task influences the frontal but not the temporal generators of mismatch negativity</article-title>
          <source>Brain Res. Cogn. Brain Res.</source>
          <volume>25</volume>
          <year>2005</year>
          <fpage>891</fpage>
          <lpage>899</lpage>
          <pub-id pub-id-type="pmid">16289727</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0205">
        <element-citation publication-type="journal" id="rf0200">
          <person-group person-group-type="author">
            <name>
              <surname>Ritter</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Paavilainen</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Lavikainen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Reinikainen</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Alho</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Sams</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Event-related potentials to repetition and change of auditory stimuli</article-title>
          <source>Electroencephalogr. Clin. Neurophysiol.</source>
          <volume>83</volume>
          <year>1992</year>
          <fpage>306</fpage>
          <lpage>321</lpage>
          <pub-id pub-id-type="pmid">1385087</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0210">
        <element-citation publication-type="journal" id="rf0205">
          <person-group person-group-type="author">
            <name>
              <surname>Ritter</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gunter Dosch</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Specht</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Rupp</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Neuromagnetic responses reflect the temporal pitch change of regular interval sounds</article-title>
          <source>Neuroimage</source>
          <volume>27</volume>
          <year>2005</year>
          <fpage>533</fpage>
          <lpage>543</lpage>
          <pub-id pub-id-type="pmid">15964207</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0215">
        <element-citation publication-type="journal" id="rf0210">
          <person-group person-group-type="author">
            <name>
              <surname>Roberts</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Ferrari</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Stufflebeam</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Latency of the auditory evoked neuromagnetic field components: stimulus dependence and insights towards perception</article-title>
          <source>J. Clin. Neuropsychol.</source>
          <volume>17</volume>
          <year>2000</year>
          <fpage>114</fpage>
          <lpage>129</lpage>
        </element-citation>
      </ref>
      <ref id="bb0295">
        <element-citation publication-type="journal" id="rf0280">
          <person-group person-group-type="author">
            <name>
              <surname>Ross</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Herdman</surname>
              <given-names>A.T.</given-names>
            </name>
            <name>
              <surname>Wollbrink</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Pantev</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Auditory cortex responses to the transition from monophonic to pseudo-stereo sound</article-title>
          <source>Neurol. Clin. Neurophysiol.</source>
          <volume>18</volume>
          <year>2004</year>
        </element-citation>
      </ref>
      <ref id="bb0300">
        <element-citation publication-type="book" id="rf0285">
          <person-group person-group-type="author">
            <name>
              <surname>Rupp</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Uppenkamp</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bailes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Gutschalk</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Patterson</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <chapter-title>Time constants in temporal pitch extraction: a comparison of psychophysical and magnetic data</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Pressnitzer</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>de Cheveigné</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McAdams</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Collet</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <source>Auditory Signal Processing: Physiology, Psychoacoustics, and Model</source>
          <year>2005</year>
          <publisher-name>Springer Verlag</publisher-name>
          <publisher-loc>NY, NY, USA</publisher-loc>
          <fpage>119</fpage>
          <lpage>125</lpage>
        </element-citation>
      </ref>
      <ref id="bb0230">
        <element-citation publication-type="journal" id="rf0215">
          <person-group person-group-type="author">
            <name>
              <surname>SanMiguel</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Corral</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Escera</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>When loading working memory reduces distraction: behavioral and electrophysiological evidence from an auditory-visual distraction paradigm</article-title>
          <source>J. Cogn. Neurosci.</source>
          <volume>20</volume>
          <year>2008</year>
          <fpage>1131</fpage>
          <lpage>1145</lpage>
          <pub-id pub-id-type="pmid">18284343</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0235">
        <element-citation publication-type="journal" id="rf0220">
          <person-group person-group-type="author">
            <name>
              <surname>Sculthorpe</surname>
              <given-names>L.D.</given-names>
            </name>
            <name>
              <surname>Collin</surname>
              <given-names>C.A.</given-names>
            </name>
            <name>
              <surname>Campbell</surname>
              <given-names>K.B.</given-names>
            </name>
          </person-group>
          <article-title>The influence of strongly focused visual attention on the detection of change in an auditory pattern</article-title>
          <source>Brain Res.</source>
          <volume>1234</volume>
          <year>2008</year>
          <fpage>78</fpage>
          <lpage>86</lpage>
          <pub-id pub-id-type="pmid">18674520</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0240">
        <element-citation publication-type="journal" id="rf0225">
          <person-group person-group-type="author">
            <name>
              <surname>Sussman</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>A new view on the MMN and attention debate: the role of context in processing auditory events</article-title>
          <source>J. Psychophysiol.</source>
          <volume>21</volume>
          <year>2007</year>
          <fpage>60</fpage>
          <lpage>69</lpage>
        </element-citation>
      </ref>
      <ref id="bb0245">
        <element-citation publication-type="journal" id="rf0230">
          <person-group person-group-type="author">
            <name>
              <surname>Sussman</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Winkler</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>MMN and attention: competition for deviance detection</article-title>
          <source>Psychophysiology</source>
          <volume>40</volume>
          <year>2003</year>
          <fpage>430</fpage>
          <lpage>435</lpage>
          <pub-id pub-id-type="pmid">12946116</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0250">
        <element-citation publication-type="journal" id="rf0235">
          <person-group person-group-type="author">
            <name>
              <surname>Talsma</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Doty</surname>
              <given-names>T.J.</given-names>
            </name>
            <name>
              <surname>Strowd</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Woldorff</surname>
              <given-names>M.G.</given-names>
            </name>
          </person-group>
          <article-title>Attentional capacity for processing concurrent stimuli is larger across sensory modalities than within a modality</article-title>
          <source>Psychophysiology</source>
          <volume>43</volume>
          <year>2006</year>
          <fpage>541</fpage>
          <lpage>549</lpage>
          <pub-id pub-id-type="pmid">17076810</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0260">
        <element-citation publication-type="journal" id="rf0245">
          <person-group person-group-type="author">
            <name>
              <surname>Winkler</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Interpreting the mismatch negativity (MMN)</article-title>
          <source>J. Psychophysiol.</source>
          <volume>21</volume>
          <year>2007</year>
          <fpage>60</fpage>
          <lpage>69</lpage>
        </element-citation>
      </ref>
      <ref id="bb0255">
        <element-citation publication-type="journal" id="rf0240">
          <person-group person-group-type="author">
            <name>
              <surname>Winkler</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Karmos</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Näätänen</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Adaptive modeling of the unattended acoustic environment reflected in the mismatch negativity event-related potential</article-title>
          <source>Brain Res.</source>
          <volume>742</volume>
          <year>1996</year>
          <fpage>239</fpage>
          <lpage>252</lpage>
          <pub-id pub-id-type="pmid">9117400</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0265">
        <element-citation publication-type="journal" id="rf0250">
          <person-group person-group-type="author">
            <name>
              <surname>Woldorff</surname>
              <given-names>M.G.</given-names>
            </name>
            <name>
              <surname>Hillyard</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of early auditory processing during selective listening to rapidly presented tones</article-title>
          <source>Electroencephalogr. Clin. Neurophysiol.</source>
          <volume>79</volume>
          <year>1991</year>
          <fpage>170</fpage>
          <lpage>191</lpage>
          <pub-id pub-id-type="pmid">1714809</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0270">
        <element-citation publication-type="journal" id="rf0255">
          <person-group person-group-type="author">
            <name>
              <surname>Wolff</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Schröger</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Activation of the auditory pre-attentive change detection system by tone repetitions with fast stimulation rate</article-title>
          <source>Brain Res. Cogn. Brain Res.</source>
          <volume>10</volume>
          <year>2001</year>
          <fpage>323</fpage>
          <lpage>327</lpage>
          <pub-id pub-id-type="pmid">11167055</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0275">
        <element-citation publication-type="journal" id="rf0260">
          <person-group person-group-type="author">
            <name>
              <surname>Woods</surname>
              <given-names>D.L.</given-names>
            </name>
            <name>
              <surname>Alho</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Algazi</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Intermodal selective attention. I. Effects on event-related potentials to lateralized auditory and visual stimuli</article-title>
          <source>Electroencephalogr. Clin. Neurophysiol.</source>
          <volume>82</volume>
          <year>1992</year>
          <fpage>341</fpage>
          <lpage>355</lpage>
          <pub-id pub-id-type="pmid">1374703</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0280">
        <element-citation publication-type="journal" id="rf0265">
          <person-group person-group-type="author">
            <name>
              <surname>Yamashiro</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Inui</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Otsuru</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kakigi</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Change-related responses in the human auditory cortex: an MEG study</article-title>
          <source>Psychophysiology</source>
          <volume>48</volume>
          <year>2011</year>
          <fpage>23</fpage>
          <lpage>30</lpage>
          <pub-id pub-id-type="pmid">20525009</pub-id>
        </element-citation>
      </ref>
      <ref id="bb0285">
        <element-citation publication-type="journal" id="rf0270">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Yuan</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The effect of visuospatial attentional load on the processing of irrelevant acoustic distractors</article-title>
          <source>Neuroimage</source>
          <volume>33</volume>
          <year>2006</year>
          <fpage>715</fpage>
          <lpage>724</lpage>
          <pub-id pub-id-type="pmid">16956775</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <ack>
      <title>Acknowledgments</title>
      <p>We are grateful to David Bradbury for excellent MEG technical support and to Alain de Cheveigne' for comments and discussion. MC is supported by <funding-source id="gts0005">EU Marie Curie</funding-source> mobility grant, a Deafness Research UK fellowship and Wellcome Trust project grant <xref rid="gts0005" ref-type="funding-source">093292/Z/10/Z</xref>. DM is supported by <funding-source id="gts0010">MRC</funding-source> small program grant.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="f0005">
      <label>Fig. 1</label>
      <caption>
        <p>Schematic representation of the experimental set-up. Three streams of stimuli, ‘<italic>auditory edge signals</italic>’, ‘<italic>auditory decoy signals</italic>’ and ‘<italic>visual decoy signals</italic>’ were presented simultaneously to the participant. Attentional load was manipulated by instructing subjects to selectively attend to the auditory or visual decoy streams and perform a high- or low-attentional load task. Auditory edge signals were always ignored.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="f0010">
      <label>Fig. 2</label>
      <caption>
        <p>Behavioral performance. AH: Auditory high load; AL: Auditory low load; VH: Visual high load; VL: Visual low load. A: Miss rates. B: Response times. Error bars are one standard error of the mean.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="f0015">
      <label>Fig. 3</label>
      <caption>
        <p>Group-RMS (RMS of individual subject RMSs) of right hemisphere auditory cortical responses evoked by auditory edge stimuli (top: constant-to-random, CR; bottom: random to constant, RC) collapsed over attentional load conditions (left hemisphere responses are comparable). Change stimuli (CR and RC) in black and their respective control (no change) conditions in gray. The origin of the time scale coincides with the onset of the signals and the transition occurs at 840 ms post stimulus onset. Transition responses exhibit temporal/morphological differences between conditions. ‘1a’, ‘1b’ and ‘2’ tag the prominent deflections in each transition.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="f0020">
      <label>Fig. 4</label>
      <caption>
        <p>The effect of varying the attentional load in the auditory decoy task on edge detection responses in auditory cortex. A: CR transition. Group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) conditions. B: RC transition Group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) condition. Shaded areas mark time intervals where a significant difference is found between load conditions. B,D Repeated measures bootstrap analysis. For each time point, we plot the minimum percentage (capped at 10% for clarity) of bootstrap iteration located above or below zero. For a difference to be judged as significant this number must not exceed 1% (see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section for additional constraints). E peak amplitudes of the two main CR peaks (‘1a’ and ‘1b’) and the RC peak (‘2’) in both hemispheres under the different load conditions. Load had a significant effect on the amplitude of the RC response only.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="f0025">
      <label>Fig. 5</label>
      <caption>
        <p>The effect of varying the attentional load in the visual decoy task on edge detection responses in auditory cortex. A: CR transition. Group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) condition. B: RC transition Group-RMS of right hemisphere auditory cortical evoked responses in the low load (blue) and high load (red) condition. Shaded areas mark time intervals where a significant difference is found between load conditions. B,D Repeated measures bootstrap analysis. For each time point, we plot the minimum percentage (capped at 10% for clarity) of bootstrap iteration located above or below zero. For a difference to be judged as significant this number must not exceed 1% (see <xref rid="s0015" ref-type="sec">Experimental methods</xref> section for additional constraints). E peak amplitudes of the two main CR peaks (‘1a’ and ‘1b’) and the RC peak (‘2’) in both hemispheres under the different load conditions. Load had no significant effect on either RC or CR responses.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
  </floats-group>
</article>