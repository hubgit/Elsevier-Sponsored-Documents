<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuron</journal-id>
      <journal-title-group>
        <journal-title>Neuron</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0896-6273</issn>
      <issn pub-type="epub">1097-4199</issn>
      <publisher>
        <publisher-name>Cell Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3133688</article-id>
      <article-id pub-id-type="pmid">21689603</article-id>
      <article-id pub-id-type="publisher-id">NEURON10703</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuron.2011.04.030</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Contrast Gain Control in Auditory Cortex</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Rabinowitz</surname>
            <given-names>Neil C.</given-names>
          </name>
          <email>neil.rabinowitz@merton.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="fn1" ref-type="fn">2</xref>
          <xref rid="cor1" ref-type="corresp">∗</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Willmore</surname>
            <given-names>Ben D.B.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="fn1" ref-type="fn">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Schnupp</surname>
            <given-names>Jan W.H.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>King</surname>
            <given-names>Andrew J.</given-names>
          </name>
          <email>andrew.king@dpag.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">1</xref>
          <xref rid="cor2" ref-type="corresp">∗∗</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>1</label>Department of Physiology, Anatomy, and Genetics, Sherrington Building, Parks Road, University of Oxford, Oxford OX1 3PT, UK</aff>
      <author-notes>
        <corresp id="cor1"><label>∗</label>Corresponding author <email>neil.rabinowitz@merton.ox.ac.uk</email></corresp>
        <corresp id="cor2"><label>∗∗</label>Corresponding author <email>andrew.king@dpag.ox.ac.uk</email></corresp>
        <fn id="fn1">
          <label>2</label>
          <p>These authors contributed equally to this work</p>
        </fn>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>23</day>
        <month>6</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <day>23</day>
        <month>6</month>
        <year>2011</year>
      </pub-date>
      <volume>70</volume>
      <issue>6</issue>
      <fpage>1178</fpage>
      <lpage>1191</lpage>
      <history>
        <date date-type="accepted">
          <day>21</day>
          <month>4</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 ELL &amp; Excerpta Medica.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Inc.</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract>
        <title>Summary</title>
        <p>The auditory system must represent sounds with a wide range of statistical properties. One important property is the spectrotemporal contrast in the acoustic environment: the variation in sound pressure in each frequency band, relative to the mean pressure. We show that neurons in ferret auditory cortex rescale their gain to partially compensate for the spectrotemporal contrast of recent stimulation. When contrast is low, neurons increase their gain, becoming more sensitive to small changes in the stimulus, although the effectiveness of contrast gain control is reduced at low mean levels. Gain is primarily determined by contrast near each neuron's preferred frequency, but there is also a contribution from contrast in more distant frequency bands. Neural responses are modulated by contrast over timescales of ∼100 ms. By using contrast gain control to expand or compress the representation of its inputs, the auditory system may be seeking an efficient coding of natural sounds.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <title>Highlights</title>
        <p>► We find evidence for spectrotemporal contrast gain control in auditory cortex ► Gain is determined by a combination of spectrally local and global contrast ► Within a limited range, mean stimulus level also affects neural gain ► Contrast gain control is fast (∼100 ms); gain decreases are faster than increases</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <title>Introduction</title>
      <p>The brain must be able to detect and represent both small and large changes in sound level. Not only do we experience a wide range of sound levels, from the quietness of a night in the forest to the hooting drama of crossing a street, but the important sensory information within these contexts may lie either in small or large deviations from the average sound. For example, detecting a subtle increase in the loudness of an approaching car's engine in a mostly constant background of traffic noise can be just as crucial as hearing a pronounced honk. This highlights a fundamental challenge for the auditory system: using neurons with limited dynamic range, the system has to represent large changes in sounds that are highly variable (high contrast), without losing the ability to represent subtle changes in sounds whose level is relatively constant (low contrast).</p>
      <p>One way of managing a range of contrasts is to use separate circuits to process stimuli with different statistics. However, maintaining such a division-of-labor strategy across a sensory pathway requires a potentially costly duplication of resources. A more efficient solution is contrast gain control—where the responsiveness of neurons is dynamically adjusted according to the contrast of recent stimulation. Considerable evidence suggests that the mammalian visual system uses contrast gain control (<xref rid="bib43" ref-type="bibr">Shapley and Victor, 1978</xref>) so that it can operate in both high- and low-contrast environments. This mechanism is well described by “divisive normalization,” whereby the range of visual input is adjusted according to the contrast of recent visual stimulation (<xref rid="bib28 bib13 bib42 bib11" ref-type="bibr">Heeger, 1992; Carandini et al., 1997; Schwartz and Simoncelli, 2001; Bonin et al., 2005</xref>).</p>
      <p>In the auditory system, several studies have investigated the effects of temporal (i.e., within-band) contrast on neural responses and have provided evidence both for gain control and for multiple independent circuits. A simple way of controlling temporal contrast is to vary the modulation depth of sinusoidally amplitude-modulated tones; neurons from the auditory nerve (<xref rid="bib30" ref-type="bibr">Joris and Yin, 1992</xref>) to the auditory cortex (<xref rid="bib34" ref-type="bibr">Malone et al., 2007</xref>) can rescale their gain to partially compensate for reduced modulation depths. Similar effects have been found in the inferior colliculus (IC) (<xref rid="bib32 bib20" ref-type="bibr">Kvale and Schreiner, 2004; Dean et al., 2005</xref>) and in the songbird forebrain (<xref rid="bib37" ref-type="bibr">Nagel and Doupe, 2006</xref>) when the temporal contrast of more complex stimuli is altered. Such gain changes improve the efficiency with which neurons encode frequently presented levels (<xref rid="bib20" ref-type="bibr">Dean et al., 2005</xref>).</p>
      <p>Other studies have found that mean firing rates of IC neurons can have nonmonotonic dependencies on spectrotemporal contrast, while retaining their spectrotemporal preferences (<xref rid="bib25" ref-type="bibr">Escabí et al., 2003</xref>). Similar tuning of mean firing rate to spectral contrast (measured across frequency, but not across time) has been reported in auditory cortex (<xref rid="bib7" ref-type="bibr">Barbour and Wang, 2003</xref>). These findings suggest a division-of-labor strategy. However, such effects are also compatible with contrast gain control, so long as gain changes are slow (compared to spike generation) or do not completely compensate for changes in contrast.</p>
      <p>In this study, we ask whether the mammalian auditory cortex adjusts neural gain according to the spectrotemporal contrast of recent stimulation. One possibility is that neurons' responses are invariant to the statistics of recent stimulation, suggesting that the problem is ignored. Alternatively, neurons may be informative only about stimuli with a particular contrast, suggesting a division-of-labor strategy. Finally, they may undergo more complex changes in their spectrotemporal tuning as contrast varies, suggesting a reallocation of resources in the auditory system. Tuning of auditory cortical neurons has been shown to depend on stimulus context, such as tone density (<xref rid="bib10" ref-type="bibr">Blake and Merzenich, 2002</xref>), stimulus bandwidth (<xref rid="bib27" ref-type="bibr">Gourévitch et al., 2009</xref>), and the history of recent stimulation (<xref rid="bib3" ref-type="bibr">Ahrens et al., 2008</xref>). To distinguish between these hypotheses, we designed a set of stimuli where the statistics of level variations could be controlled within individual frequency bands. This allowed us to measure the spiking responses of neurons in the auditory cortex to sounds with different means and contrasts, from which we estimated spectrotemporal receptive fields (STRFs), using both linear (<xref rid="bib22 bib41" ref-type="bibr">deCharms et al., 1998; Schnupp et al., 2001</xref>) and linear-nonlinear (LN) (<xref rid="bib16 bib44 bib18" ref-type="bibr">Chichilnisky, 2001; Simoncelli et al., 2004; Dahmen et al., 2010</xref>) models.</p>
      <p>We also sought to quantify which combination of stimulus statistics might inform cortical gain control. This requires a formal definition of the contrast of a sound. In the visual system, the contrast of a simple stimulus is defined as the ratio of the intensity difference to the mean intensity (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>c</italic>=Δ<italic>I</italic> / <italic>I</italic></textual-form><mml:math id="M1" altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mo>Δ</mml:mo><mml:mi>I</mml:mi><mml:mo>/</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>); this definition can be generalized to complex stimuli as the ratio of the standard deviation to the mean (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>c</italic>=σ<sub><italic>I</italic></sub> / μ<sub><italic>I</italic></sub></textual-form><mml:math id="M2" altimg="si6.gif" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>). In principle, the same definitions can be applied directly in the auditory system. However, it is normal to describe sounds using sound pressure level (SPL), <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>L</italic>=20 log<sub>10</sub>(<italic>p</italic> / <italic>p</italic><sub><italic>R</italic><italic>E</italic><italic>F</italic></sub>)</textual-form><mml:math id="M3" altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mspace width="0.25em"/><mml:msub><mml:mtext>log</mml:mtext><mml:mn>10</mml:mn></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, rather than (RMS) pressure, <italic>p</italic>, itself. The effect of this log transform is that the standard deviation of the SPL of a sound (<italic>σ<sub>L</sub></italic>) can provide an excellent approximation of the contrast, <italic>σ<sub>P</sub></italic>/<italic>μ<sub>P</sub></italic>, of the sound pressure:<disp-formula id="fd1"><label>(1)</label><mml:math id="M4" altimg="si8.gif" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:mi>a</mml:mi><mml:mo>.</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p>
      <p>Thus, an auditory contrast gain mechanism would adjust neural gain according to <italic>σ<sub>L</sub></italic>, the standard deviation of the SPL of recent stimulation.</p>
      <p>Finally, we investigated whether gain control is a local or a network mechanism. If a neuron's gain depends only on the statistics of the stimuli presented within its STRF, then gain control could be implemented locally, e.g., by synaptic depression within individual neurons (<xref rid="bib14" ref-type="bibr">Carandini et al., 2002</xref>). However, synaptic depression is unlikely to account for gain effects that result from the statistics of stimuli outside the STRF, in which case gain control is more likely to arise from network mechanisms, such as the leveraging of balanced excitation and inhibition (e.g., <xref rid="bib35" ref-type="bibr">Mante et al., 2005</xref>). We therefore changed the stimulus contrast both inside and outside narrow frequency bands in our stimuli, in order to assess whether neuronal sensitivity to small changes in a sound depends on the statistics of its spectrally local or more global context.</p>
    </sec>
    <sec id="sec2">
      <title>Results</title>
      <p>We recorded from 1840 sites in the primary auditory cortex (A1) and anterior auditory field (AAF) of eight anesthetized ferrets, while diotically presenting dynamic random chord (DRC) sequences. The chords were changed within each sequence every 25 ms, with the levels of their constituent tones (1/6 octave spaced) drawn from uniform distributions in SPL space. The contrast of the sequences was manipulated by changing the (SPL) standard deviation (<italic>σ<sub>L</sub></italic>) of these distributions. The tone level distributions had identical mean (<italic>μ<sub>L</sub></italic> = 40 dB SPL) but different widths: ± 5 dB (low contrast; <italic>σ<sub>L</sub></italic> ≈2.9 dB, <italic>c</italic> = <italic>σ<sub>P</sub>/μ<sub>P</sub></italic> = 33%), ± 10 dB (medium contrast; <italic>σ<sub>L</sub></italic> ≈5.8 dB, <italic>c</italic> = <italic>σ<sub>P</sub>/μ<sub>P</sub></italic> = 63.8%), or ± 15 dB (high contrast; <italic>σ<sub>L</sub></italic> ≈8.7 dB, <italic>c</italic> = <italic>σ<sub>P</sub>/μ<sub>P</sub></italic> = 91.6%) (<xref rid="fig1" ref-type="fig">Figure 1</xref>). The close relationship between contrast in sound pressure (<italic>σ<sub>P</sub>/μ<sub>P</sub></italic>) and <italic>σ<sub>L</sub></italic> for these distributions is shown in <xref rid="app2" ref-type="sec">Figures S1</xref>A and S1B; these, together with other stimulus statistics, are documented in <xref rid="app2" ref-type="sec">Table S1</xref>. As these distributions are primarily defined in SPL space, and as we performed analyses on units' stimulus-response relationships using stimulus representations in SPL space, we present our data and models here in terms of <italic>σ<sub>L</sub></italic> rather than <italic>σ<sub>P</sub>/μ<sub>P</sub></italic>, so as not to mix together the sound pressure and level domains.</p>
      <p>The RMS sound level of the total stimulus ranged from 70 to 80 dB SPL. We identified 1001 units that responded reliably to the DRCs, as measured via a maximum noise level criterion (see <xref rid="sec4" ref-type="sec">Experimental Procedures</xref>).</p>
      <p>Although the anesthetized preparation allowed for precise control of stimulation and eliminated the possibility of attentional modulation, to confirm that the observations made under anesthesia apply in awake animals, we also presented the same stimuli through a free-field speaker to an awake, passively listening ferret and recorded spiking activity from 62 sites in A1 and AAF. We identified 19 units that responded reliably to the DRCs. We found no differences in the response characteristics of neurons in the two preparations and therefore combined these data in subsequent analyses.</p>
      <sec id="sec2.1">
        <title>Stimulus Contrast Has Little Systematic Effect on Spectrotemporal Tuning</title>
        <p>We first asked whether the tuning of cortical neurons is affected by changes in stimulus contrast. If this were the case, it would not be appropriate to describe such a response as gain control. We characterized the tuning of each unit by estimating one STRF for each contrast condition (e.g., <xref rid="fig2" ref-type="fig">Figure 2</xref>A; see Model 1 in <xref rid="app2" ref-type="sec">Table S2</xref>). Only STRFs that had predictive power (see <xref rid="sec4" ref-type="sec">Experimental Procedures</xref>) were included in the further analysis; generally, the prediction scores were worse under lower-contrast stimulation (<xref rid="app2" ref-type="sec">Table S3</xref>).</p>
        <p>Changing stimulus contrast produced only small changes in STRF shape (<xref rid="fig2" ref-type="fig">Figures 2</xref>C and 2D). Of 261 units with predictive STRFs, 223 maintained the same best frequency (BF) across conditions (within 1/6 of an octave; <xref rid="fig2" ref-type="fig">Figure 2</xref>C). Twenty-six units had STRFs that were too diffuse to give clear BF estimates. Only 12 units showed evidence of changes (≤1/3 octave) in BF across conditions. Tuning bandwidths were slightly broader under low-contrast stimulation (sign-rank test; p &lt;&lt; 0.001); however, this may reflect the noisier estimates of STRF coefficients at low contrast. Tuning bandwidth did not change systematically between medium- and high-contrast regimes (p &gt; 0.5) (<xref rid="fig2" ref-type="fig">Figure 2</xref>D). We also observed no systematic changes in the temporal structure of STRFs, though this was limited by the 25 ms time resolution of the analysis.</p>
        <p>To assess the importance of any unmeasured STRF shape changes, we modeled each neuron by a single linear STRF multiplied by a variable gain factor (Model 2 in <xref rid="app2" ref-type="sec">Table S2</xref>). STRFs from one stimulus condition predicted responses in the other conditions as well as the within-condition STRFs (<xref rid="fig2" ref-type="fig">Figure 2</xref>F), indicating that any shape changes in the STRFs were negligible. Thus, auditory cortex neurons exhibit similar spectrotemporal preferences regardless of contrast. This is similar to previous observations in the IC (<xref rid="bib25" ref-type="bibr">Escabí et al., 2003</xref>), but different from the visual system, where contrast has a considerable effect on the temporal dynamics of neural responses (<xref rid="bib35" ref-type="bibr">Mante et al., 2005</xref>).</p>
      </sec>
      <sec id="sec2.2">
        <title>Increased Response Gain Partially Compensates for Lower Stimulus Contrast</title>
        <p>We observed substantial changes in gain between conditions, as measured by comparing the largest-magnitude coefficients of the STRFs (<xref rid="fig2" ref-type="fig">Figure 2</xref>E). To characterize gain changes more accurately, we extended the simple linear model to a LN one (Figures <xref rid="fig1" ref-type="fig">1</xref>G and <xref rid="fig3" ref-type="fig">3</xref>; <xref rid="fd5" ref-type="disp-formula">Equation 5</xref>; Model 3 in <xref rid="app2" ref-type="sec">Table S2</xref>). This comprised a single linear STRF for each unit, estimated from its responses across all conditions, followed by a sigmoidal output nonlinearity. Separate nonlinearities were fitted for each contrast condition. The LN model far outperformed the linear models: prediction scores were a median 38.5% higher than the within-condition linear models (p &lt;&lt; 0.001; sign-rank). We found 315 units where LN models were predictive in all three contrast conditions. Analyses on the remaining units are presented in <xref rid="app2" ref-type="sec">Figure S3</xref>G, showing results similar to those presented below.</p>
        <p>In an LN model, differences in gain manifest through changes in the shape of the output nonlinearity. To quantify these changes, we calculated the set of linear transformations required to map the output nonlinearity for high-contrast stimulation (<italic>σ<sub>L</sub></italic> = 8.7 dB, <italic>c</italic> = 92%) onto those for other stimulus conditions. In principle, this mapping could combine a scaling of the curve along the horizontal and vertical axes and a translation of the curve along these axes (x- and y-offset, respectively). However, none of the units under investigation operated near their saturation point, making an estimate of vertical scaling difficult. Thus, we measured changes in the remaining three degrees of freedom (<xref rid="fd6" ref-type="disp-formula">Equation 6</xref>; Model 4 in <xref rid="app2" ref-type="sec">Table S2</xref>). Horizontal scaling corresponds to a change in gain, x-offset to a threshold shift and y-offset to a change in minimum firing rate.</p>
        <p>We observed a robust relationship between stimulus contrast and gain across the population of units. An approximately 3-fold decrease in contrast from 8.7 dB (<italic>c</italic> = 92%) to 2.9 dB (<italic>c =</italic> 33%) increased gain by a median factor of 2.01; for an ∼1.5-fold decrease in contrast from 8.7 dB (<italic>c</italic> = 92%) to 5.8 dB (<italic>c</italic> = 64%), gain increased by 1.34× (<xref rid="fig4" ref-type="fig">Figure 4</xref>A). The gain effect was also strongest among units with the most robust, repeatable spike trains (<xref rid="app2" ref-type="sec">Figure S3</xref>D). Gain therefore changes in the appropriate direction to compensate for changes in stimulus contrast, but this compensation is not complete.</p>
        <p>Decreasing stimulus contrast also caused nonlinearities to shift by a small amount to the right (median x-offset of 5.5% and 1.4% for low and medium contrast; p &lt; 0.001 and p &lt; 0.05, respectively, sign-rank test; <xref rid="fig4" ref-type="fig">Figure 4</xref>B), but there was no corresponding vertical translation of these curves (<xref rid="fig4" ref-type="fig">Figure 4</xref>C). Although the change in x-offset is nominally indicative of a small increase in threshold, the gain and x-offset measures were correlated with each other across units (r<sup>2</sup> = 0.195 in high-to-low- and 0.11 in high-to-medium-contrast curve transformations; <xref rid="fig4" ref-type="fig">Figure 4</xref>D), suggesting that the rightwards shift in curves partly acts to compensate for gain (see <xref rid="app2" ref-type="sec">Figure S3</xref>E). The lack of systematic y-offset changes indicated that minimum firing rate did not change across conditions. Therefore, the primary consequence of decreasing stimulus contrast is that cortical cells increase their gain.</p>
        <p>By transforming output nonlinearities across conditions, we could predict neural responses to each contrast stimulus as successfully as by using separate nonlinearities for each condition as described above (median difference in prediction scores of 0.7%; sign-rank, p &gt; 0.5).</p>
        <p>These effects are similar to the changes in coding accuracy previously observed in the IC (<xref rid="bib20" ref-type="bibr">Dean et al., 2005</xref>). Neuronal firing is most sensitive to and hence most informative about stimulus changes when the slope of the input/output function is at its greatest. This occurs at a median position of <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M5" altimg="si9.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> = 5.3, 10.1, and 14.3 under low, medium, and high contrast, respectively (<xref rid="app2" ref-type="sec">Figure S2</xref>). These lie at approximately the same percentile (∼70%) of each stimulus distribution, relative to their projection onto <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M6" altimg="si10.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Neurons in auditory cortex thus adapt their sensitivity to be most informative about stimuli within the current stimulus distribution.</p>
        <p>To fully quantify the relationship between stimulus contrast and gain, we presented to a subset of these cells a larger set of DRCs with eight different <italic>σ<sub>L</sub></italic> values ranging from 1.4 dB to 11.5 dB (<italic>c</italic> = 17% to 116%). We obtained 80 units for which the above analysis could be performed over the whole contrast range. On average, these showed a clear, monotonic increase in gain as the contrast of the stimulus was reduced (<xref rid="fig4" ref-type="fig">Figure 4</xref>E). The relationship between relative gain and contrast was extremely well described by a standard normalization equation (<xref rid="bib28 bib13" ref-type="bibr">Heeger, 1992; Carandini et al., 1997</xref>):<disp-formula id="fd2"><label>(2)</label><mml:math id="M7" altimg="si11.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace width="0.25em"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <italic>G</italic> denotes the gain and <italic>a</italic>, <italic>b</italic>, and <italic>n</italic> are constants (see Model 5 in <xref rid="app2" ref-type="sec">Table S2</xref>). This model explained 99.9% of the variance in the population average of relative gain values.</p>
        <p>This model also provided a good description of the relative gain values for individual units (<xref rid="app2" ref-type="sec">Figure S3</xref>H). However, in some units, the model failed at the lowest contrasts. For these units, gain increased as contrast was reduced down to a threshold, below which gain either leveled off or decreased. For 46/80 units, this threshold was <italic>σ<sub>L</sub></italic> = 2.9 dB (<italic>c =</italic> 33%); for a further 26 units, this threshold was 4.3 dB (<italic>c</italic> = 49%); and a further four units had a threshold of <italic>σ<sub>L</sub></italic> = 5.8 dB (<italic>c =</italic> 64%). At these thresholds and above, gain was well fit on a cell-by-cell basis by <xref rid="fd2" ref-type="disp-formula">Equation 2</xref> for 76/80 units. The model produced marginally better predictions of neural responses than fitting individual nonlinearities to each contrast condition (<xref rid="app2" ref-type="sec">Table S2</xref>). Thus, across a wide range of contrasts, gain normalization is a robust phenomenon for individual units.</p>
      </sec>
      <sec id="sec2.3">
        <title>Contrast Gain Control Is Weak at Low Mean Levels and Saturates at High Mean Levels</title>
        <p>In the experiments presented so far, the mean SPL of each tone in the DRC, <italic>μ<sub>L</sub></italic>, was kept fixed. To explore the effect of mean, we presented a further set of stimuli in which both the mean of the level distributions (<italic>μ<sub>L</sub></italic>) and the contrast (<italic>σ<sub>L</sub></italic>) were manipulated independently. We estimated LN models from responses to a range of mean/contrast conditions, together with curve transformations from each stimulus condition relative to the <italic>μ<sub>L</sub></italic> = 40 dB SPL, <italic>σ<sub>L</sub></italic> = 8.7 dB (<italic>c =</italic> 92%) nonlinearity. Of the 1001 units above, 56 units yielded predictive LN models across the whole range of conditions. Only data from these 56 units are analyzed below, in order to maintain the same sample set across stimulus conditions. Nevertheless, data from all units where LN models were predictive in only a subset of conditions (n = 217) yielded similar results (data not shown).</p>
        <p>At all mean levels tested, decreasing contrast caused gain to increase across the population of cells. However, the degree of gain normalization depended on the mean level: at low <italic>μ<sub>L</sub></italic>, reducing contrast did not yield as much compensatory gain change compared with reducing contrast at high <italic>μ<sub>L</sub></italic>. While increasing <italic>μ<sub>L</sub></italic> therefore increased the dependence of gain on contrast, this trend saturated above <italic>μ<sub>L</sub></italic> ≈35 dB SPL (<xref rid="fig5" ref-type="fig">Figure 5</xref>A). At higher mean levels, gain was decoupled from the mean sound level and varied with contrast alone. Interestingly, although changing mean level had no systematic effect on x-offset in our data (<xref rid="fig5" ref-type="fig">Figure 5</xref>B), reducing the mean level typically increased y-offset, i.e., raised the minimum firing rate (<xref rid="fig5" ref-type="fig">Figure 5</xref>C; examples in <xref rid="app2" ref-type="sec">Figures S4</xref>A and S4B).</p>
        <p>Given the success of <xref rid="fd2" ref-type="disp-formula">Equation 2</xref> in modeling the relationship between <italic>σ<sub>L</sub></italic> and gain, we extended this model to include mean level, <italic>μ<sub>L</sub></italic>. The most explanatory model (<xref rid="fd8" ref-type="disp-formula">Equation 8</xref>) was a simple extension of the contrast-dependent model where <italic>b</italic> could vary with <italic>μ<sub>L</sub></italic>. This allows <italic>μ<sub>L</sub></italic> to directly modulate the dependence of gain on contrast. Fitted values for <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M8" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> are presented in <xref rid="fig5" ref-type="fig">Figure 5</xref>D, showing that at low <italic>μ<sub>L</sub></italic>, <italic>b</italic> is modulated by <italic>μ<sub>L</sub></italic>, whereas <italic>b</italic> saturates with high <italic>μ<sub>L</sub></italic>. For simplicity, we modeled this with an exponential function (<xref rid="fd8" ref-type="disp-formula">Equation 8</xref>; see also Model 6 in <xref rid="app2" ref-type="sec">Table S2</xref>). This model explained 97% of the total variance in the data set (<xref rid="fig5" ref-type="fig">Figure 5</xref>E). We did not estimate the parameters for individual units, and therefore did not cross-validate this model.</p>
        <p>All of the above results remained unchanged when gain was expressed as a function of <italic>σ<sub>P</sub></italic>/<italic>μ<sub>P</sub></italic> rather than <italic>σ<sub>L</sub></italic> (<xref rid="app2" ref-type="sec">Figure S4</xref>C).</p>
      </sec>
      <sec id="sec2.4">
        <title>Responses to a Fixed Sound Depend on Context</title>
        <p>The above results suggest that the recent spectrotemporal statistics of the stimulus modulate neural responses to a sound. We predicted that if a particular sound was presented in a low-contrast context, it would generate stronger responses than if presented in high-contrast context.</p>
        <p>To test this prediction, we embedded a fixed “test sound” into DRC segments of differing contrasts. This sound was designed to drive all units within an electrode penetration, by having stimulus energy within the receptive fields of the units recorded there (<xref rid="fig6" ref-type="fig">Figure 6</xref>A). The different contexts were provided by a DRC sequence that alternated between high (<italic>σ<sub>L</sub></italic> = 8.7 dB, <italic>c</italic> = 92%) and low contrast (<italic>σ<sub>L</sub></italic> = 2.9 dB, <italic>c =</italic> 33%) every 1 s. The same test sound was presented once per 1 s block at a random time relative to the onset of that block, i.e., the last switch in context. Among 63 units that responded reliably to the test sound, all but two responded more vigorously when this sound was presented in a low-contrast context than in a high-contrast context; the firing rate was a median 2.6 times greater in low-contrast context (p ≪ 0.001, sign-rank; <xref rid="fig6" ref-type="fig">Figures 6</xref>B–6D). This confirmed our prediction.</p>
        <p>This experiment also allowed a finer-grained comparison of the time course of responses in high and low context. Similar to the STRF analysis, we found no systematic difference between these (<xref rid="app2" ref-type="sec">Figure S5</xref>).</p>
        <p>The variable timing of the test sound relative to the time of context switch allowed us to estimate the time course of the adaptation to stimulus contrast (<xref rid="fig6" ref-type="fig">Figure 6</xref>E). This could, in turn, inform a time-dependent model of gain control (e.g., Model 7 in <xref rid="app2" ref-type="sec">Table S2</xref>), though we did not cross-validate such a model. Reliable estimates of time constants were obtained for both the switch from low- to high-contrast context (<italic>τ<sub>L→H</sub></italic>) and the switch from high- to low-contrast context (<italic>τ<sub>H→L</sub></italic>) for 18 units. Adaptation to high-contrast context occurred with a median <italic>τ<sub>L→H</sub></italic> of 86 ms, compared with a slower adaptation to low-contrast context with a median <italic>τ<sub>H→L</sub></italic> of 157 ms. This difference was significant (p &lt; 0.001, sign-rank) and evident for 14/18 of the individual units (<xref rid="fig6" ref-type="fig">Figure 6</xref>F). Thus, the time courses for increases and decreases in neural gain are asymmetric.</p>
      </sec>
      <sec id="sec2.5">
        <title>Neuronal Gain Is Dependent on Stimulus Contrast both Within and Outside the Tuning Curve</title>
        <p>To explore the mechanism for gain control, we asked whether gain is modulated by the contrast within a local region of frequency space or whether it is a function of the global statistics of the input. To address this, we varied the contrast of the DRC stimuli within two separate frequency regions. One region was denoted the “test,” centered around a chosen unit's BF and spanning 0.5, 0.67, or 1.2 octaves. The remaining frequency bands were denoted the “mask” (<xref rid="fig7" ref-type="fig">Figure 7</xref>A). We aimed to situate the test stimulus over the “responsive frequency range” (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M9" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>; see <xref rid="sec4" ref-type="sec">Experimental Procedures</xref>), the frequencies to which a given neuron (linearly) responded. However, since we recorded multiple units simultaneously (usually bilaterally), we actually sampled a range of conditions where the test stimulus covered the neuron's responsive frequency range, overlapped it, or lay entirely outside it. This enabled us to measure how contrast gain depended on the amount of overlap between the test stimulus and <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M10" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>We presented nine separate DRCs, where the contrasts in the test (<italic>σ<sub>test</sub></italic>) and mask (<italic>σ<sub>mask</sub></italic>) were independently chosen from <italic>σ<sub>L</sub></italic> = 2.9 dB, 5.8 dB, or 8.7 dB (<italic>c =</italic> 33%, 64%, or 92%). We found that the gain of each neuron was most strongly modulated by contrast within the responsive frequency range. Thus, varying <italic>σ<sub>test</sub></italic> had the strongest effect on gain when the test stimulus completely covered <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M11" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (<xref rid="fig7" ref-type="fig">Figure 7</xref>B). Similarly, varying <italic>σ<sub>mask</sub></italic> had the strongest effect when the mask completely covered <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M12" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (<xref rid="fig7" ref-type="fig">Figure 7</xref>C).</p>
        <p>However, contrast away from the responsive frequency range also had an impact on gain. For example, even when the test stimulus completely covered <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M13" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, decreasing <italic>σ<sub>mask</sub></italic> still resulted in an increase in gain (<xref rid="fig7" ref-type="fig">Figure 7</xref>C). There were also interactions between contrast within and outside <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M14" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (compare <xref rid="fig7" ref-type="fig">Figure 7</xref>B with <xref rid="fig7" ref-type="fig">7</xref>D and <xref rid="fig7" ref-type="fig">Figure 7</xref>C with <xref rid="fig7" ref-type="fig">7</xref>E). This is summarized in <xref rid="fig7" ref-type="fig">Figure 7</xref>F for 24 units where the test completely covered <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M15" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>To quantify these effects, we extended the (<italic>μ<sub>L</sub></italic>-independent) model (<xref rid="fd2" ref-type="disp-formula">Equation 2</xref>) to include contributions to gain normalization from stimulus statistics both within and outside the responsive frequency range (“RF” and “global,” respectively):<disp-formula id="fd3"><label>(3)</label><mml:math id="M16" altimg="si13.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Using only those units where the test covered their responsive frequency range, we fitted the model in <xref rid="fd3" ref-type="disp-formula">Equation 3</xref> assuming <italic>σ<sub>RF</sub></italic> = <italic>σ<sub>test</sub></italic>. This fit estimated a 2.4× stronger weighting of local stimulus contrast over global contrast (Model 8 in <xref rid="app2" ref-type="sec">Table S2</xref>; <xref rid="app2" ref-type="sec">Table S4</xref>) and captured the asymmetric interactions between <italic>σ<sub>test</sub></italic> and <italic>σ<sub>mask</sub></italic> (<xref rid="fig7" ref-type="fig">Figure 7</xref>F). In turn, the model was also successful at predicting the gain exhibited by units whose <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M17" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> only partially overlapped the test or lay completely outside it (<xref rid="app2" ref-type="sec">Table S4</xref>). The predictive value of this model points to either the existence of a gain control mechanism that strongly weights local over global stimulus statistics or else to the presence of two stages of gain control: one local and one global.</p>
      </sec>
    </sec>
    <sec id="sec3">
      <title>Discussion</title>
      <p>Our data show that the gain of neurons in auditory cortex is dynamically modulated according to the spectrotemporal statistics of recently heard sounds. The primary determinant of gain is stimulus contrast, which is well approximated by the standard deviation of the SPL (<italic>σ<sub>L</sub></italic>). Gain decreases as stimulus contrast increases, thereby partially compensating for changes in contrast. Mean stimulus level also influences gain: when the mean level is low, the effectiveness of contrast gain control is reduced.</p>
      <sec id="sec3.1">
        <title>Mechanisms for Gain Control</title>
        <p>Our data focus on the effects of gain control, rather than on its specific implementation. Thus, although our models refer to stimulus contrast and level, we do not know how (or even whether) these parameters are explicitly computed by the brain. Nevertheless, by investigating how the gain signal depends on the spectral and temporal integration of stimulus statistics, we obtain insight into the mechanisms underlying gain changes. We find that gain is mainly determined by spectrotemporal contrast near the preferred frequency of each neuron, but there is also a significant contribution from the contrast outside the neuron's STRF (<xref rid="fig7" ref-type="fig">Figure 7</xref>). The time course of gain changes is asymmetric (<xref rid="fig6" ref-type="fig">Figure 6</xref>): time constants for increases and decreases in gain are 157 ms and 86 ms, respectively.</p>
        <p>The observation that gain is regulated through wide spectral integration places some constraints on possible mechanisms. This suggests that gain control is not mediated entirely by a within-neuron mechanism, since single neurons do not have access to all the information required to calculate spectrotemporal contrast and adjust gain accordingly. This, along with the time course of gain changes, potentially argues against synaptic depression (<xref rid="bib14" ref-type="bibr">Carandini et al., 2002</xref>), which could, in principle, operate much faster. It may, however, be necessary to integrate information over a number of successive stimuli before gain can be adjusted in this fashion; this argument incidentally provides a computational justification for the asymmetry in adaptation times (<xref rid="bib23" ref-type="bibr">DeWeese and Zador, 1998</xref>). The influence of distant frequent bands is also unlikely to result from masking in the auditory periphery: although higher spectrotemporal contrast produces larger variation in the level of each frequency band, the total level of the DRCs remains relatively constant both over time and between conditions.</p>
        <p>Alternative possibilities are that gain control is mediated by an intracortical network (<xref rid="bib13" ref-type="bibr">Carandini et al., 1997</xref>) or through cortico-thalamic feedback, via recurrent excitation and inhibition (e.g., <xref rid="bib1" ref-type="bibr">Abbott and Chance, 2005</xref>). Both hypotheses are compatible with the spectral and temporal integration we find here. Nevertheless, it is likely that gain control in cortex is at least partly inherited from earlier auditory structures. It has been shown, for example, that responses of neurons in the mammalian IC (<xref rid="bib32 bib20 bib21" ref-type="bibr">Kvale and Schreiner, 2004; Dean et al., 2005, 2008</xref>) alter their gain to compensate for the temporal contrast of the level of a noise stimulus. The time constants of these effects are similar to those we observe in cortex and show a similar asymmetry for increases and decreases in gain. If the mechanisms in cortex and midbrain are identical, we would expect gain modulation in the IC to show the same spectral spread as we observe here. Characterization of both the spectral and temporal properties of gain control is likely to be informative in either linking or distinguishing between gain effects in cortex and more peripheral stations, such as those observed by varying the modulation depth of sinusoidally amplitude-modulated tones in the auditory nerve (<xref rid="bib30" ref-type="bibr">Joris and Yin, 1992</xref>) or by varying the spectral contrast of complex chords in the brainstem (<xref rid="bib38" ref-type="bibr">Reiss et al., 2007</xref>).</p>
        <p>Finally, there may be a number of independent gain control stages at different levels of the auditory system. These may have different characteristics and time constants, reflecting different underlying mechanisms. Such a hierarchy has been observed in the visual system, where at least both the retina and V1 engage separate gain control mechanisms (<xref rid="bib13 bib12 bib15 bib6" ref-type="bibr">Carandini et al., 1997; Brown and Masland, 2001; Chander and Chichilnisky, 2001; Baccus and Meister, 2002</xref>). In the extreme, gain control may be performed at every stage along the pathway (for review, see <xref rid="bib31" ref-type="bibr">Kohn, 2007</xref>). If there are multiple, independent stages of gain control, then the local (within-receptive-field) gain effects and the global (extra-receptive-field) gain effects may be realized by different mechanisms and at different levels of the pathway. Further experiments will be required to distinguish these components by separately measuring their spectral and temporal parameters.</p>
        <p>If distinct local and global mechanisms are involved, perhaps with different time courses, then synaptic depression could still be a strong candidate mechanism for the local mechanism, as it has been implicated in gain control across a broad range of neural systems (<xref rid="bib47 bib14 bib17" ref-type="bibr">Stratford et al., 1996; Carandini et al., 2002; Chung et al., 2002</xref>). Within the auditory system itself, forward suppression—whereby the response of neurons to a sound is reduced when another sound precedes it—lasts for &gt;100 ms in A1, which corresponds to a suppression of synaptic conductances (<xref rid="bib53" ref-type="bibr">Wehr and Zador, 2005</xref>) or activation of hyperpolarizing currents (<xref rid="bib2" ref-type="bibr">Abolafia et al., 2011</xref>). Synaptic depression also shows temporal asymmetry similar to that observed here (<xref rid="bib29 bib24 bib17" ref-type="bibr">Hosoya et al., 2005; Dobrunz et al., 1997; Chung et al., 2002</xref>).</p>
      </sec>
      <sec id="sec3.2">
        <title>The Role of Contrast Gain Control</title>
        <p>Gain control is primarily useful for adapting the limited dynamic range of a neuron to the statistics of the stimulus. When spectrotemporal contrast is low, firing rates are sensitive to smaller changes within their spectral “region of interest” than under higher-contrast conditions. Thus, the representation of stimulus space is effectively expanded under low-contrast stimulation and compressed under high-contrast stimulation. Consequently, gain control should improve the ability of individuals to detect small changes in low-contrast sounds. Indeed, a related phenomenon has been demonstrated in the adaptation to reverberation, whereby listeners are better able to discriminate (low-contrast) reverberant words when embedded within a reverberant context sentence than within a (high-contrast) anechoic context (<xref rid="bib50" ref-type="bibr">Watkins, 2005</xref>), an effect that is also frequency-band specific (<xref rid="bib52" ref-type="bibr">Watkins and Makin, 2007</xref>). Perceptual adaptation is not, however, complete, as a general increase in the spectrotemporal contrast of speech leads to demonstrable gains in intelligibility (<xref rid="bib46 bib48 bib36" ref-type="bibr">Steeneken and Houtgast, 1980; van Veen and Houtgast, 1985; Miller et al., 1999</xref>). Our data predict that perceptual adaptation to stimulus contrast should be observable with nonspeech stimuli as well.</p>
        <p>Neurons in the visual system are subject to contrast gain control, which is thought to be desirable for efficient coding of natural images (<xref rid="bib42" ref-type="bibr">Schwartz and Simoncelli, 2001</xref>). Since the contrast of natural images is correlated across space and time, normalization by stimulus contrast reduces the redundancy of the neural code (<xref rid="bib8 bib49" ref-type="bibr">Barlow, 1961; Vinje and Gallant, 2002</xref>). The contrast of a complex visual stimulus can be defined as <italic>σ<sub>I</sub></italic>/<italic>μ<sub>I</sub></italic>, which is strongly related to the two contrast measures that we have shown to determine auditory gain control (<italic>σ<sub>L</sub></italic>, <xref rid="fig5" ref-type="fig">Figure 5</xref>A; <italic>σ<sub>P</sub>/μ<sub>P</sub></italic>, <xref rid="app2" ref-type="sec">Figure S4</xref>C). Auditory gain control may therefore have a similar redundancy-reducing effect. Although the ensemble (i.e., long time scale) distributions of natural sounds have been explored (<xref rid="bib4 bib25 bib45" ref-type="bibr">Attias and Schreiner, 1997; Escabí et al., 2003; Singh and Theunissen, 2003</xref>), a deeper understanding of the relationship between contrast gain control and the statistics of natural sounds will require a characterization of natural sound level distributions at the temporal scales over which gain control operates.</p>
        <p>We show that when stimulus level statistics are not uniform across the spectrum, gain control is also unevenly applied to neurons, depending on their frequency tuning. A spectrally limited band of high contrast has the greatest compressive effect on neurons if their tuning curves overlap this band. Conversely, neurons tuned to other frequencies maintain sensitivity to small changes in their input. Because natural sounds do not cover the entire audible frequency range evenly, such an arrangement might make it possible to match contrast adaptation to the challenges posed by each particular acoustic environment.</p>
      </sec>
      <sec id="sec3.3">
        <title>Gain Control and Contrast Tuning</title>
        <p>Although the gain change we observe is strong, it does not completely compensate for changes in stimulus contrast: even at high mean stimulus levels (where contrast gain control is most effective and independent of sound level), an approximately 3-fold reduction in spectrotemporal contrast yields only an ∼2-fold increase in gain. Thus, gain control does not result in contrast invariance. Indeed, previous studies (<xref rid="bib7 bib25" ref-type="bibr">Barbour and Wang, 2003; Escabí et al., 2003</xref>) have found that some auditory neurons are contrast tuned, firing more in response to some contrasts than others. Such a result would be incompatible with contrast invariance, but is compatible with the incomplete contrast compensation observed here. Taken together, these results suggest that auditory cortex uses both a division-of-labor strategy and adaptive gain control. Gain control reduces the range of stimulus values that must be separately encoded; within the remaining narrow range, a division-of-labor strategy may be used.</p>
        <p>The incompleteness of gain control also suggests that there is a preferred range of stimulus contrasts for which neural coding is optimal; outside this range, gain control will fail to adjust gain enough to bring the stimuli into the neurons' dynamic range. It is possible that this preferred distribution is defined by the ensemble of natural sounds (<xref rid="bib5 bib8 bib42 bib33" ref-type="bibr">Attneave, 1954; Barlow, 1961; Schwartz and Simoncelli, 2001; Lewicki, 2002</xref>).</p>
        <p>It does not appear that gain normalization operates with equal measure from neuron to neuron. Not only does the strength of the effect differ across neurons, but only a subset continues to increase their gain as stimulus contrast is reduced to ever smaller levels (<xref rid="app2" ref-type="sec">Figure S3</xref>H). This implies that different cortical neurons will be optimal encoders of different spectrotemporal level distributions. Similar diversity in adaptive properties has also been found in awake marmoset cortex, where subclasses of cells either adapt to the mean sound level of a stimulus or maintain a fixed preference for a particular intensity range (<xref rid="bib51" ref-type="bibr">Watkins and Barbour, 2008</xref>). Just as such cells retain the ability to detect soft sounds in a loud environment, a variation in the degree of gain normalization between neurons may help retain the ability to detect small changes in high-contrast environments. These are particularly important tasks in audition, where superimposed sound sources need to be detected and dissected.</p>
        <p>Finally, given the strength of gain normalization observed in this study, we predict that including gain control will prove to be a generally important factor in improving the predictive power of STRF models of auditory processing. However, the implementation details may prove crucial. For instance, normalizing by global stimulus contrast, without taking into account spectrally local contrast, does not result in an improvement in the predictive power of STRF models (<xref rid="bib19" ref-type="bibr">David et al., 2009</xref>). This suggests that a detailed implementation of the spectral and temporal integration that informs the gain signal, such as that initiated in this study, will be needed before such improvements can be made.</p>
      </sec>
    </sec>
    <sec sec-type="methods" id="sec4">
      <title>Experimental Procedures</title>
      <sec id="sec4.1">
        <title>Animals and Anesthesia</title>
        <p>All animal procedures were approved by the local ethical review committee and performed under license from the UK Home Office. Eight adult pigmented ferrets (6 male, 2 female) were chosen for electrophysiological recordings under ketamine-medetomidine anesthesia. Extracellular recordings were made using silicon probe electrodes (Neuronexus Technologies, Ann Arbor, MI) with 16 sites on a single probe, vertically spaced at 50 μm or 150 μm. Stimuli were presented via Panasonic RPHV27 earphones (Bracknell, UK), coupled to otoscope specula that were inserted into each ear canal, and driven by Tucker-Davis Technologies (Alachua, FL) System III hardware (48 kHz sample rate). Further recordings were made in an awake, passively listening female ferret, with free field stimulation presented in an anechoic room via an Audax TWO26M0 speaker (Audax Industries, Château du Loir, France) ∼80 cm from the animal's head. Full experimental procedures are described in <xref rid="bib9" ref-type="bibr">Bizley et al. (2010)</xref>.</p>
        <p>Offline spike sorting was performed using spikemonger, an in-house software package (see <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>). We included only units that showed acoustically responsive activity.</p>
      </sec>
      <sec id="sec4.2">
        <title>Dynamic Random Chords</title>
        <p>The main stimulus was a DRC: a superposition of 34 pure tones, with frequencies log-spaced between 500 Hz and 22.6 kHz at 1/6 octave intervals. The tone levels during each chord were independently drawn from a uniform distribution, with mean level <italic>μ<sub>L</sub></italic> (dB SPL). The distribution was uniform across (logarithmic) level, not (linear) RMS pressure, as this better matches the range of sound intensities and modulations present in natural signals (<xref rid="bib25 bib26" ref-type="bibr">Escabí et al., 2003; Gill et al., 2006</xref>). The distribution width was varied, giving three stimulus contrasts (<xref rid="fig1" ref-type="fig">Figure 1</xref>). For a subset of recordings, a broader range of widths was presented (from ±2.5 dB to ±20 dB in 2.5 dB steps). A full range of stimulus statistics is given in <xref rid="app2" ref-type="sec">Table S1</xref>.</p>
        <p>Chords were 25 ms in duration and presented in sequences of 15 s or 30 s duration. The overall RMS level of the stimuli was 71.0 ± 0.5 dB SPL in low contrast, 72.4 ± 1.0 dB SPL in medium contrast, and 74.5 ± 1.5 dB SPL in high contrast, when <italic>μ<sub>L</sub></italic> = 40. A control experiment was performed to show that these small differences in the overall level did not account for gain control (data not shown).</p>
        <p>To build the sequences, we first generated random levels for each tone in each chord. A new random seed was used for each electrode penetration and stimulus condition. We synthesized each tone, applied envelopes based on the random levels (with 5 ms linear ramps between chords), and then superimposed them. This ensured there were no amplitude or phase discontinuities in the signal. Each DRC sequence was presented 5–20 times (10 times for the awake animal), randomly interleaved, with 15–20 s silence between each sequence. The first 2 s of data from each presentation were discarded to ensure that a constant adaptation state had been reached.</p>
      </sec>
      <sec id="sec4.3">
        <title>Signal Power and Noise Power</title>
        <p>Since the analyses carried out here can only be applied to acoustically driven units that produce reasonably reliable, repeatable responses, we calculated the noise ratio (NR) for the PSTHs of each unit (<xref rid="bib40" ref-type="bibr">Sahani and Linden, 2003b</xref>):<disp-formula id="fd4"><label>(4)</label><mml:math id="M18" altimg="si14.gif" overflow="scroll"><mml:mrow><mml:mtext>noise</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>ratio</mml:mtext><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mtext>noise</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>power</mml:mtext></mml:mrow><mml:mrow><mml:mtext>signal</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>power</mml:mtext></mml:mrow></mml:mfrac><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mtext>total</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>variance</mml:mtext><mml:mo>−</mml:mo><mml:mtext>explainable</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>variance</mml:mtext></mml:mrow><mml:mrow><mml:mtext>explainable</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>variance</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
        <p>An NR of 0 indicates that responses were identical for repeated stimulus presentations. Higher NR indicates that responses are less reliable. Units with NR &gt; 10 in any one stimulus condition, i.e., whose explainable variance was &lt;9.1% of the total variance, were excluded from further analysis. NRs were highest in the low-contrast condition (<xref rid="app2" ref-type="sec">Table S3</xref>). Thus, we used data from the high-contrast condition as the reference for comparisons.</p>
      </sec>
      <sec id="sec4.4">
        <title>STRF Estimation</title>
        <p>STRFs were estimated by correlating the stimulus history with the spike peristimulus time histogram (PSTH). The PSTH was binned at 25 ms; bins were offset by between 0 and 25 ms to allow for response latency. The offset was chosen to minimize the NR. We estimated a separable kernel, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic><italic>t</italic></sub></textual-form><mml:math id="M19" altimg="si15.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, such that <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic><italic>t</italic></sub>=<bold>w</bold><sub><italic>f</italic></sub>⊗<bold>w</bold><sub><italic>t</italic></sub></textual-form><mml:math id="M20" altimg="si16.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic></sub></textual-form><mml:math id="M21" altimg="si17.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the frequency kernel, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>t</italic></sub></textual-form><mml:math id="M22" altimg="si18.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> the time kernel, and ⊗ the outer product, via maximum likelihood (<xref rid="bib39 bib3" ref-type="bibr">Sahani and Linden, 2003a; Ahrens et al., 2008</xref>). Separable STRFs gave more accurate predictions than fully inseparable STRFs (which had more parameters). STRFs were trained on 9/10 of the available data for each unit and were used to predict a PSTH for the remaining 1/10. The prediction score is defined as the proportional reduction in the mean squared error of the response; if this was positive, the STRF was deemed predictive.</p>
        <p>STRFs were estimated separately for each stimulus condition and for the pooled data set. The separate set of STRFs was used for the linear analysis (<xref rid="fig2" ref-type="fig">Figure 2</xref>); the pooled STRFs were used thereafter. In each case, units whose STRFs or LN models (see below) were not predictive on the validation data set were excluded from analysis.</p>
        <p>The measurement of BF and bandwidth of each STRF is described in the <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>.</p>
      </sec>
      <sec id="sec4.5">
        <title>Nonlinearities</title>
        <p>We refined the linear STRF by fitting a LN model to units' responses (<xref rid="bib16" ref-type="bibr">Chichilnisky, 2001</xref>). The STRF is a linear approximation of the relationship between the stimulus <bold>X</bold> and response <italic>Y</italic>, via <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Y</italic>=<bold>X</bold>⋅<bold>w</bold>+ɛ</textual-form><mml:math id="M23" altimg="si20.gif" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>+</mml:mo><mml:mi>ɛ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. To capture nonlinearities in this relationship, we fitted a nonlinear function to the output of the linear model, such that <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Y</italic>=<italic>F</italic>[<bold>X</bold>⋅<bold>v</bold>]+ɛ</textual-form><mml:math id="M24" altimg="si21.gif" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>ɛ</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Here, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>v</bold>=<bold>w</bold> / ‖<bold>w</bold>‖</textual-form><mml:math id="M25" altimg="si22.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the unit vector in the direction of the STRF, i.e., the direction of stimulus space to which the cell is (linearly) sensitive. <italic>F</italic> was approximated by dividing the stimulus/response pairs into 40 bins along the <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M26" altimg="si23.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> axis and averaging responses within each bin. A logistic curve (sigmoid) was fitted to the data via gradient descent:<disp-formula id="fd5"><label>(5)</label><mml:math id="M27" altimg="si24.gif" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mspace width="0.25em"/><mml:mtext>exp</mml:mtext><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
        <p>To check that pooling responses from different stimulus conditions in the initial STRF estimation was valid, we built LN models for each cell using STRFs estimated from only one stimulus condition. Results were similar, regardless of which condition was used to build the STRF (<xref rid="app2" ref-type="sec">Figures S3</xref>A–S3C).</p>
      </sec>
      <sec id="sec4.6">
        <title>Curve Transformations</title>
        <p>Independent sigmoids were fitted to the responses from each contrast condition. To describe the differences between the sigmoids, we chose the nonlinearity for the <italic>σ<sub>L</sub></italic> = 8.7 dB (<italic>c</italic> = 92%) condition for every unit as a reference and found the linear transformations required to map the reference sigmoid onto the sigmoids obtained under the other conditions (see main text). This amounts to solving the equation:<disp-formula id="fd6"><label>(6)</label><alternatives><textual-form specific-use="jats-markup"><italic>F</italic><sub>σ<sub><italic>L</italic></sub></sub>[<bold>X</bold>⋅<bold>v</bold>]=<italic>F</italic><sub>σ<sub>0</sub></sub>[<italic>g</italic>.(<bold>X</bold>⋅<bold>v</bold>)+Δ<italic>x</italic>]+Δ<italic>y</italic></textual-form><mml:math id="M28" altimg="si25.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>.</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mo>Δ</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>where <inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub>0</sub>=8.7</textual-form><mml:math id="M29" altimg="si26.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>8.7</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> is the reference condition, <italic>g</italic> is the horizontal scale factor (gain change), <inline-formula><alternatives><textual-form specific-use="jats-markup">Δ<italic>x</italic></textual-form><mml:math id="M30" altimg="si27.gif" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is the x-offset, and <inline-formula><alternatives><textual-form specific-use="jats-markup">Δ<italic>y</italic></textual-form><mml:math id="M31" altimg="si28.gif" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is the y-offset. Details of this fit are provided in the <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>. For a given unit, <inline-formula><alternatives><textual-form specific-use="jats-markup">Δ<italic>x</italic></textual-form><mml:math id="M32" altimg="si27.gif" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is expressed as a percentage of the size of the domain of <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M33" altimg="si29.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> in the reference condition for that unit, while <inline-formula><alternatives><textual-form specific-use="jats-markup">Δ<italic>y</italic></textual-form><mml:math id="M34" altimg="si28.gif" overflow="scroll"><mml:mrow><mml:mo>Δ</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is expressed as a percentage of <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>F</italic><sub>σ<sub>0</sub></sub>[0]</textual-form><mml:math id="M35" altimg="si30.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      </sec>
      <sec id="sec4.7">
        <title>Test Sound</title>
        <p>For a subset of electrode penetrations, the STRF of a representative unit was estimated online, and used to create a test sound. The frequency component of the STRF, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic></sub></textual-form><mml:math id="M36" altimg="si31.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, was scaled to create a single chord of 25 ms duration, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold><sub><italic>T</italic></sub></textual-form><mml:math id="M37" altimg="si32.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, that roughly fit the statistics of a DRC segment with medium contrast (<xref rid="fig6" ref-type="fig">Figure 6</xref>A). A set of new DRCs was generated for that electrode penetration, consisting of 25 alternating 1 s segments of low (<italic>σ<sub>L</sub></italic> = 2.9 dB, <italic>c =</italic> 33%) and high contrast (<italic>σ<sub>L</sub></italic> = 8.7 dB, <italic>c =</italic> 92%). <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold><sub><italic>T</italic></sub></textual-form><mml:math id="M38" altimg="si33.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> was inserted once into each segment, at a random delay after each segment transition. Forty sequences, with different random seeds and test sound timing, were presented. To ensure that the test sound actually drove all the units in a given electrode penetration, only those units for which <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold><sub><italic>T</italic></sub>⋅<bold>v</bold>  &gt;  10 dB</textual-form><mml:math id="M39" altimg="si34.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mspace width="0.25em"/><mml:mo>&gt;</mml:mo><mml:mspace width="0.25em"/><mml:mn>10</mml:mn><mml:mspace width="0.25em"/><mml:mtext>dB</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> were retained for analysis. Responses to the test sound were averaged for each combination of context (contrast of the DRC segment) and timing (delay after transition) conditions.</p>
        <p>To estimate response latency, we binned the spiking response to the test sound at 5 ms resolution, averaged over all conditions, and defined a 15 ms window about the peak of the PSTH. Spiking within this window was defined as the peak response, <italic>r(t)</italic>. For units whose peak responses satisfied a reliability criterion (see <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>), time constants for adaptation were estimated by fitting the equation <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>r</italic>(<italic>t</italic>)=<italic>a</italic>+<italic>b</italic>.exp(−<italic>t</italic> / τ)</textual-form><mml:math id="M40" altimg="si35.gif" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>.</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      </sec>
      <sec id="sec4.8">
        <title>Test/Mask</title>
        <p>To assess whether neuronal responses depend on stimulus contrast both within and outside the frequency range of their STRFs, a subset of units were probed with a set of specially constructed test/mask stimuli.</p>
        <p>During recording, units' STRFs and BFs were estimated. From the set of 34 tone frequencies used in the DRCs (<italic>Φ</italic>), tones in a “test” band of 7 frequencies (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>t</italic><italic>e</italic><italic>s</italic><italic>t</italic></sub></textual-form><mml:math id="M41" altimg="si37.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), spanning half an octave above and half an octave below the unit's BF, had levels drawn from a different distribution from those in the remaining “mask” frequency bands (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>m</italic><italic>a</italic><italic>s</italic><italic>k</italic></sub></textual-form><mml:math id="M42" altimg="si38.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>). Nine different stimuli (<xref rid="fig7" ref-type="fig">Figure 7</xref>A) were presented five times each, randomly interleaved. Some units' BFs lay in the 2–3 highest-frequency bands of the DRCs; for these units, the test band was reduced to a width of either 3/6 or 4/6 octaves. Results from these units were similar, and so results from all three cases were pooled. For all units, a linear STRF was calculated from the pooled data set, and individual nonlinearities were calculated for each stimulus condition.</p>
        <p>The responsive frequency range of each unit (<inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M43" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) was defined by which components of <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic></sub></textual-form><mml:math id="M44" altimg="si39.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> were significantly nonzero, via bootstrapping (see <xref rid="app2" ref-type="sec">Supplemental Experimental Procedures</xref>). We then defined the overlap between <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M45" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and test:<disp-formula id="fd7"><label>(7)</label><mml:math id="M46" altimg="si40.gif" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.25em"/><mml:mo>∈</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.25em"/><mml:mo>∈</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="italic">Φ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>w</italic><sub><italic>f</italic><sub><italic>i</italic></sub></sub></textual-form><mml:math id="M47" altimg="si41.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the component of <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>w</bold><sub><italic>f</italic></sub></textual-form><mml:math id="M48" altimg="si42.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> corresponding to frequency <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>f</italic><sub><italic>i</italic></sub></textual-form><mml:math id="M49" altimg="si43.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
      </sec>
      <sec id="sec4.9">
        <title>Normalization Models</title>
        <p>To model the effects of stimulus statistics on neural gain, we extended a well-known class of gain normalization equations used in the visual system, which take the general form of <xref rid="fd2" ref-type="disp-formula">Equation 2</xref>. As all gain values were computed relative to a reference curve (<inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub><italic>r</italic><italic>e</italic><italic>f</italic></sub>=8.7dB</textual-form><mml:math id="M50" altimg="si44.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>8.7</mml:mn><mml:mtext>dB</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula>), we fixed <inline-formula><mml:math id="M51" altimg="si45.gif" overflow="scroll"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace width="0.25em"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> to constrain <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>G</italic>(σ<sub><italic>r</italic><italic>e</italic><italic>f</italic></sub>)=1</textual-form><mml:math id="M52" altimg="si46.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>To model the effects of varying both <italic>σ<sub>L</sub></italic> and <italic>μ<sub>L</sub></italic>, we fitted separate values for <italic>b</italic> (and therefore for <italic>a</italic>) for each mean level:<disp-formula id="fd8"><label>(8)</label><mml:math id="M53" altimg="si47.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>L</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M54" altimg="si48.gif" overflow="scroll"><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> so that <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>G</italic>(σ<sub><italic>r</italic><italic>e</italic><italic>f</italic></sub>, μ<sub><italic>L</italic></sub>)=1</textual-form><mml:math id="M55" altimg="si49.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for all <italic>μ<sub>L</sub></italic> (as observed in the data); <italic>n</italic> is constant with respect to <italic>μ<sub>L</sub></italic>. The fit obtained was slightly better than if <italic>n</italic> was allowed to vary as a function of <italic>μ<sub>L</sub></italic> and <italic>b</italic> was kept constant with respect to <italic>μ<sub>L</sub></italic>.</p>
        <p>Following the empirical fitting of <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M56" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> values, <italic>b</italic> was parameterized using the form <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)=<italic>b</italic><sub><italic>m</italic><italic>a</italic><italic>x</italic></sub>(1−<italic>e</italic><sup>−<italic>c</italic>(μ<sub><italic>L</italic></sub>+<italic>k</italic>)</sup>)</textual-form><mml:math id="M57" altimg="si50.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> to capture the saturation of <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M58" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> at high <italic>μ<sub>L</sub></italic>.</p>
        <p>For the test/mask analysis, we fitted <xref rid="fd3" ref-type="disp-formula">Equation 3</xref> for units where the test completely covered their responsive frequency range, assuming that <inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub><italic>R</italic><italic>F</italic></sub>=σ<sub><italic>t</italic><italic>e</italic><italic>s</italic><italic>t</italic></sub></textual-form><mml:math id="M59" altimg="si51.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <italic>n</italic> given from fitting <xref rid="fd2" ref-type="disp-formula">Equation 2</xref>, and <italic>a</italic> constrained by <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>G</italic>(σ<sub><italic>r</italic><italic>e</italic><italic>f</italic></sub>, σ<sub><italic>r</italic><italic>e</italic><italic>f</italic></sub>)=1</textual-form><mml:math id="M60" altimg="si52.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. As above, this gave slightly better fits than fixing <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic><sub><italic>R</italic><italic>F</italic></sub>=<italic>b</italic><sub><italic>t</italic><italic>e</italic><italic>s</italic><italic>t</italic></sub>=<italic>b</italic></textual-form><mml:math id="M61" altimg="si53.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and using separate exponents for <inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M62" altimg="si54.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub><italic>g</italic><italic>l</italic><italic>o</italic><italic>b</italic><italic>a</italic><italic>l</italic></sub></textual-form><mml:math id="M63" altimg="si55.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. The fitted parameters were used with <xref rid="fd3" ref-type="disp-formula">Equation 3</xref> to predict the gain for units where the test only partially covered <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>Φ</italic><sub><italic>R</italic><italic>F</italic></sub></textual-form><mml:math id="M64" altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> or lay outside of it. The local contrast in this region and the global contrast were then calculated via the weighted sums:<disp-formula id="fd9"><label>(9)</label><mml:math id="M65" altimg="si56.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>∈</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="italic">Φ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="fd10"><label>(10)</label><mml:math id="M66" altimg="si57.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="italic">Φ</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>∈</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="italic">Φ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><alternatives><textual-form specific-use="jats-markup">σ<sub><italic>L</italic></sub>(<italic>f</italic>)</textual-form><mml:math id="M67" altimg="si58.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the contrast in frequency band <italic>f</italic>.</p>
        <p>Successive models used to fit the response and relative gain of neurons in this study, together with best fit parameter values, are summarized in <xref rid="app2" ref-type="sec">Table S2</xref>. Further information on the test/mask model, including alternate fits, is provided in <xref rid="app2" ref-type="sec">Table S4</xref>.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abbott</surname>
              <given-names>L.F.</given-names>
            </name>
            <name>
              <surname>Chance</surname>
              <given-names>F.S.</given-names>
            </name>
          </person-group>
          <article-title>Drivers and modulators from push-pull and balanced synaptic input</article-title>
          <source>Prog. Brain Res.</source>
          <volume>149</volume>
          <year>2005</year>
          <fpage>147</fpage>
          <lpage>155</lpage>
          <pub-id pub-id-type="pmid">16226582</pub-id>
        </element-citation>
      </ref>
      <ref id="bib2">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abolafia</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Vergara</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Arnold</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Reig</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sanchez-Vives</surname>
              <given-names>M.V.</given-names>
            </name>
          </person-group>
          <article-title>Cortical auditory adaptation in the awake rat and the role of potassium currents</article-title>
          <source>Cereb. Cortex</source>
          <volume>21</volume>
          <year>2011</year>
          <fpage>977</fpage>
          <lpage>990</lpage>
          <pub-id pub-id-type="pmid">20851851</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ahrens</surname>
              <given-names>M.B.</given-names>
            </name>
            <name>
              <surname>Linden</surname>
              <given-names>J.F.</given-names>
            </name>
            <name>
              <surname>Sahani</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>1929</fpage>
          <lpage>1942</lpage>
          <pub-id pub-id-type="pmid">18287509</pub-id>
        </element-citation>
      </ref>
      <ref id="bib4">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Attias</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Schreiner</surname>
              <given-names>C.E.</given-names>
            </name>
          </person-group>
          <chapter-title>Temporal low-order statistics of natural sounds</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Mozer</surname>
              <given-names>M.C.</given-names>
            </name>
            <name>
              <surname>Jordan</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kearns</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Solla</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <source>Advances in neural information processing systems</source>
          <year>1997</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
          <fpage>27</fpage>
          <lpage>33</lpage>
        </element-citation>
      </ref>
      <ref id="bib5">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Attneave</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Some informational aspects of visual perception</article-title>
          <source>Psychol. Rev.</source>
          <volume>61</volume>
          <year>1954</year>
          <fpage>183</fpage>
          <lpage>193</lpage>
          <pub-id pub-id-type="pmid">13167245</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baccus</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Meister</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Fast and slow contrast adaptation in retinal circuitry</article-title>
          <source>Neuron</source>
          <volume>36</volume>
          <year>2002</year>
          <fpage>909</fpage>
          <lpage>919</lpage>
          <pub-id pub-id-type="pmid">12467594</pub-id>
        </element-citation>
      </ref>
      <ref id="bib7">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Barbour</surname>
              <given-names>D.L.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>X.</given-names>
            </name>
          </person-group>
          <article-title>Contrast tuning in auditory cortex</article-title>
          <source>Science</source>
          <volume>299</volume>
          <year>2003</year>
          <fpage>1073</fpage>
          <lpage>1075</lpage>
          <pub-id pub-id-type="pmid">12586943</pub-id>
        </element-citation>
      </ref>
      <ref id="bib8">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Barlow</surname>
              <given-names>H.B.</given-names>
            </name>
          </person-group>
          <chapter-title>Possible principles underlying the transformation of sensory messages</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Rosenblith</surname>
              <given-names>W.A.</given-names>
            </name>
          </person-group>
          <source>Sensory Communication</source>
          <year>1961</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
          <fpage>217</fpage>
          <lpage>234</lpage>
        </element-citation>
      </ref>
      <ref id="bib9">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bizley</surname>
              <given-names>J.K.</given-names>
            </name>
            <name>
              <surname>Walker</surname>
              <given-names>K.M.M.</given-names>
            </name>
            <name>
              <surname>King</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Schnupp</surname>
              <given-names>J.W.H.</given-names>
            </name>
          </person-group>
          <article-title>Neural ensemble codes for stimulus periodicity in auditory cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>30</volume>
          <year>2010</year>
          <fpage>5078</fpage>
          <lpage>5091</lpage>
          <pub-id pub-id-type="pmid">20371828</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Blake</surname>
              <given-names>D.T.</given-names>
            </name>
            <name>
              <surname>Merzenich</surname>
              <given-names>M.M.</given-names>
            </name>
          </person-group>
          <article-title>Changes of AI receptive fields with sound density</article-title>
          <source>J. Neurophysiol.</source>
          <volume>88</volume>
          <year>2002</year>
          <fpage>3409</fpage>
          <lpage>3420</lpage>
          <pub-id pub-id-type="pmid">12466457</pub-id>
        </element-citation>
      </ref>
      <ref id="bib11">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bonin</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Mante</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Carandini</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The suppressive field of neurons in lateral geniculate nucleus</article-title>
          <source>J. Neurosci.</source>
          <volume>25</volume>
          <year>2005</year>
          <fpage>10844</fpage>
          <lpage>10856</lpage>
          <pub-id pub-id-type="pmid">16306397</pub-id>
        </element-citation>
      </ref>
      <ref id="bib12">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brown</surname>
              <given-names>S.P.</given-names>
            </name>
            <name>
              <surname>Masland</surname>
              <given-names>R.H.</given-names>
            </name>
          </person-group>
          <article-title>Spatial scale and cellular substrate of contrast adaptation by retinal ganglion cells</article-title>
          <source>Nat. Neurosci.</source>
          <volume>4</volume>
          <year>2001</year>
          <fpage>44</fpage>
          <lpage>51</lpage>
          <pub-id pub-id-type="pmid">11135644</pub-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carandini</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>17</volume>
          <year>1997</year>
          <fpage>8621</fpage>
          <lpage>8644</lpage>
          <pub-id pub-id-type="pmid">9334433</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carandini</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Senn</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>A synaptic explanation of suppression in visual cortex</article-title>
          <source>J. Neurosci.</source>
          <volume>22</volume>
          <year>2002</year>
          <fpage>10053</fpage>
          <lpage>10065</lpage>
          <pub-id pub-id-type="pmid">12427863</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chander</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Chichilnisky</surname>
              <given-names>E.J.</given-names>
            </name>
          </person-group>
          <article-title>Adaptation to temporal contrast in primate and salamander retina</article-title>
          <source>J. Neurosci.</source>
          <volume>21</volume>
          <year>2001</year>
          <fpage>9904</fpage>
          <lpage>9916</lpage>
          <pub-id pub-id-type="pmid">11739598</pub-id>
        </element-citation>
      </ref>
      <ref id="bib16">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chichilnisky</surname>
              <given-names>E.J.</given-names>
            </name>
          </person-group>
          <article-title>A simple white noise analysis of neuronal light responses</article-title>
          <source>Network</source>
          <volume>12</volume>
          <year>2001</year>
          <fpage>199</fpage>
          <lpage>213</lpage>
          <pub-id pub-id-type="pmid">11405422</pub-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chung</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Nelson</surname>
              <given-names>S.B.</given-names>
            </name>
          </person-group>
          <article-title>Short-term depression at thalamocortical synapses contributes to rapid adaptation of cortical sensory responses in vivo</article-title>
          <source>Neuron</source>
          <volume>34</volume>
          <year>2002</year>
          <fpage>437</fpage>
          <lpage>446</lpage>
          <pub-id pub-id-type="pmid">11988174</pub-id>
        </element-citation>
      </ref>
      <ref id="bib18">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dahmen</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Keating</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Nodal</surname>
              <given-names>F.R.</given-names>
            </name>
            <name>
              <surname>Schulz</surname>
              <given-names>A.L.</given-names>
            </name>
            <name>
              <surname>King</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Adaptation to stimulus statistics in the perception and neural representation of auditory space</article-title>
          <source>Neuron</source>
          <volume>66</volume>
          <year>2010</year>
          <fpage>937</fpage>
          <lpage>948</lpage>
          <pub-id pub-id-type="pmid">20620878</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>David</surname>
              <given-names>S.V.</given-names>
            </name>
            <name>
              <surname>Mesgarani</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Fritz</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Shamma</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>
          <source>J. Neurosci.</source>
          <volume>29</volume>
          <year>2009</year>
          <fpage>3374</fpage>
          <lpage>3386</lpage>
          <pub-id pub-id-type="pmid">19295144</pub-id>
        </element-citation>
      </ref>
      <ref id="bib20">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dean</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Harper</surname>
              <given-names>N.S.</given-names>
            </name>
            <name>
              <surname>McAlpine</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Neural population coding of sound level adapts to stimulus statistics</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <year>2005</year>
          <fpage>1684</fpage>
          <lpage>1689</lpage>
          <pub-id pub-id-type="pmid">16286934</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dean</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>B.L.</given-names>
            </name>
            <name>
              <surname>Harper</surname>
              <given-names>N.S.</given-names>
            </name>
            <name>
              <surname>McAlpine</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Rapid neural adaptation to sound level statistics</article-title>
          <source>J. Neurosci.</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>6430</fpage>
          <lpage>6438</lpage>
          <pub-id pub-id-type="pmid">18562614</pub-id>
        </element-citation>
      </ref>
      <ref id="bib22">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>deCharms</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Blake</surname>
              <given-names>D.T.</given-names>
            </name>
            <name>
              <surname>Merzenich</surname>
              <given-names>M.M.</given-names>
            </name>
          </person-group>
          <article-title>Optimizing sound features for cortical neurons</article-title>
          <source>Science</source>
          <volume>280</volume>
          <year>1998</year>
          <fpage>1439</fpage>
          <lpage>1443</lpage>
          <pub-id pub-id-type="pmid">9603734</pub-id>
        </element-citation>
      </ref>
      <ref id="bib23">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>DeWeese</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zador</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Asymmetric dynamics in optimal variance adaptation</article-title>
          <source>Neural Computation</source>
          <volume>10</volume>
          <year>1998</year>
          <fpage>1179</fpage>
          <lpage>1202</lpage>
        </element-citation>
      </ref>
      <ref id="bib24">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dobrunz</surname>
              <given-names>L.E.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>E.P.</given-names>
            </name>
            <name>
              <surname>Stevens</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <article-title>Very short-term plasticity in hippocampal synapses</article-title>
          <source>Proc. Natl. Acad. Sci. USA</source>
          <volume>94</volume>
          <year>1997</year>
          <fpage>14843</fpage>
          <lpage>14847</lpage>
          <pub-id pub-id-type="pmid">9405701</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Escabí</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Read</surname>
              <given-names>H.L.</given-names>
            </name>
            <name>
              <surname>Schreiner</surname>
              <given-names>C.E.</given-names>
            </name>
          </person-group>
          <article-title>Naturalistic auditory contrast improves spectrotemporal coding in the cat inferior colliculus</article-title>
          <source>J. Neurosci.</source>
          <volume>23</volume>
          <year>2003</year>
          <fpage>11489</fpage>
          <lpage>11504</lpage>
          <pub-id pub-id-type="pmid">14684853</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gill</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Woolley</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Fremouw</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Theunissen</surname>
              <given-names>F.E.</given-names>
            </name>
          </person-group>
          <article-title>Sound representation methods for spectro-temporal receptive field estimation</article-title>
          <source>J. Comput. Neurosci.</source>
          <volume>21</volume>
          <year>2006</year>
          <fpage>5</fpage>
          <lpage>20</lpage>
          <pub-id pub-id-type="pmid">16633939</pub-id>
        </element-citation>
      </ref>
      <ref id="bib27">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gourévitch</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Noreña</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shaw</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Eggermont</surname>
              <given-names>J.J.</given-names>
            </name>
          </person-group>
          <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent</article-title>
          <source>Cereb. Cortex</source>
          <volume>19</volume>
          <year>2009</year>
          <fpage>1448</fpage>
          <lpage>1461</lpage>
          <pub-id pub-id-type="pmid">18854580</pub-id>
        </element-citation>
      </ref>
      <ref id="bib28">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Heeger</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Normalization of cell responses in cat striate cortex</article-title>
          <source>Vis. Neurosci.</source>
          <volume>9</volume>
          <year>1992</year>
          <fpage>181</fpage>
          <lpage>197</lpage>
          <pub-id pub-id-type="pmid">1504027</pub-id>
        </element-citation>
      </ref>
      <ref id="bib29">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hosoya</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Baccus</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Meister</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic predictive coding by the retina</article-title>
          <source>Nature</source>
          <volume>436</volume>
          <year>2005</year>
          <fpage>71</fpage>
          <lpage>77</lpage>
          <pub-id pub-id-type="pmid">16001064</pub-id>
        </element-citation>
      </ref>
      <ref id="bib30">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Joris</surname>
              <given-names>P.X.</given-names>
            </name>
            <name>
              <surname>Yin</surname>
              <given-names>T.C.</given-names>
            </name>
          </person-group>
          <article-title>Responses to amplitude-modulated tones in the auditory nerve of the cat</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>91</volume>
          <year>1992</year>
          <fpage>215</fpage>
          <lpage>232</lpage>
          <pub-id pub-id-type="pmid">1737873</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kohn</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Visual adaptation: physiology, mechanisms, and functional benefits</article-title>
          <source>J. Neurophysiol.</source>
          <volume>97</volume>
          <year>2007</year>
          <fpage>3155</fpage>
          <lpage>3164</lpage>
          <pub-id pub-id-type="pmid">17344377</pub-id>
        </element-citation>
      </ref>
      <ref id="bib32">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kvale</surname>
              <given-names>M.N.</given-names>
            </name>
            <name>
              <surname>Schreiner</surname>
              <given-names>C.E.</given-names>
            </name>
          </person-group>
          <article-title>Short-term adaptation of auditory receptive fields to dynamic stimuli</article-title>
          <source>J. Neurophysiol.</source>
          <volume>91</volume>
          <year>2004</year>
          <fpage>604</fpage>
          <lpage>612</lpage>
          <pub-id pub-id-type="pmid">14762146</pub-id>
        </element-citation>
      </ref>
      <ref id="bib33">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lewicki</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <article-title>Efficient coding of natural sounds</article-title>
          <source>Nat. Neurosci.</source>
          <volume>5</volume>
          <year>2002</year>
          <fpage>356</fpage>
          <lpage>363</lpage>
          <pub-id pub-id-type="pmid">11896400</pub-id>
        </element-citation>
      </ref>
      <ref id="bib34">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Malone</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Scott</surname>
              <given-names>B.H.</given-names>
            </name>
            <name>
              <surname>Semple</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic amplitude coding in the auditory cortex of awake rhesus macaques</article-title>
          <source>J. Neurophysiol.</source>
          <volume>98</volume>
          <year>2007</year>
          <fpage>1451</fpage>
          <lpage>1474</lpage>
          <pub-id pub-id-type="pmid">17615123</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mante</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Frazor</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Bonin</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Geisler</surname>
              <given-names>W.S.</given-names>
            </name>
            <name>
              <surname>Carandini</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Independence of luminance and contrast in natural scenes and in the early visual system</article-title>
          <source>Nat. Neurosci.</source>
          <volume>8</volume>
          <year>2005</year>
          <fpage>1690</fpage>
          <lpage>1697</lpage>
          <pub-id pub-id-type="pmid">16286933</pub-id>
        </element-citation>
      </ref>
      <ref id="bib36">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>B.M.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>E.D.</given-names>
            </name>
          </person-group>
          <article-title>Contrast enhancement improves the representation of /epsilon/-like vowels in the hearing-impaired auditory nerve</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>106</volume>
          <year>1999</year>
          <fpage>2693</fpage>
          <lpage>2708</lpage>
          <pub-id pub-id-type="pmid">10573886</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nagel</surname>
              <given-names>K.I.</given-names>
            </name>
            <name>
              <surname>Doupe</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Temporal processing and adaptation in the songbird auditory forebrain</article-title>
          <source>Neuron</source>
          <volume>51</volume>
          <year>2006</year>
          <fpage>845</fpage>
          <lpage>859</lpage>
          <pub-id pub-id-type="pmid">16982428</pub-id>
        </element-citation>
      </ref>
      <ref id="bib38">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Reiss</surname>
              <given-names>L.A.J.</given-names>
            </name>
            <name>
              <surname>Bandyopadhyay</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>E.D.</given-names>
            </name>
          </person-group>
          <article-title>Effects of stimulus spectral contrast on receptive fields of dorsal cochlear nucleus neurons</article-title>
          <source>J. Neurophysiol.</source>
          <volume>98</volume>
          <year>2007</year>
          <fpage>2133</fpage>
          <lpage>2143</lpage>
          <pub-id pub-id-type="pmid">17671102</pub-id>
        </element-citation>
      </ref>
      <ref id="bib39">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Sahani</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Linden</surname>
              <given-names>J.F.</given-names>
            </name>
          </person-group>
          <chapter-title>Evidence optimization techniques for estimating stimulus-response functions</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Becker</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Thrun</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Obermayer</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <source>Advances in neural information processing systems 15</source>
          <year>2003</year>
          <publisher-name>MIT</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
          <fpage>317</fpage>
          <lpage>324</lpage>
        </element-citation>
      </ref>
      <ref id="bib40">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Sahani</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Linden</surname>
              <given-names>J.F.</given-names>
            </name>
          </person-group>
          <chapter-title>How linear are auditory cortical responses?</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Becker</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Thrun</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Obermayer</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <source>Advances in neural information processing systems 15</source>
          <year>2003</year>
          <publisher-name>MIT</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
          <fpage>125</fpage>
          <lpage>132</lpage>
        </element-citation>
      </ref>
      <ref id="bib41">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schnupp</surname>
              <given-names>J.W.H.</given-names>
            </name>
            <name>
              <surname>Mrsic-Flogel</surname>
              <given-names>T.D.</given-names>
            </name>
            <name>
              <surname>King</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Linear processing of spatial cues in primary auditory cortex</article-title>
          <source>Nature</source>
          <volume>414</volume>
          <year>2001</year>
          <fpage>200</fpage>
          <lpage>204</lpage>
          <pub-id pub-id-type="pmid">11700557</pub-id>
        </element-citation>
      </ref>
      <ref id="bib42">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schwartz</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Simoncelli</surname>
              <given-names>E.P.</given-names>
            </name>
          </person-group>
          <article-title>Natural signal statistics and sensory gain control</article-title>
          <source>Nat. Neurosci.</source>
          <volume>4</volume>
          <year>2001</year>
          <fpage>819</fpage>
          <lpage>825</lpage>
          <pub-id pub-id-type="pmid">11477428</pub-id>
        </element-citation>
      </ref>
      <ref id="bib43">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shapley</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Victor</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>The effect of contrast on the transfer properties of cat retinal ganglion cells</article-title>
          <source>J. Physiol.</source>
          <volume>285</volume>
          <year>1978</year>
          <fpage>275</fpage>
          <lpage>298</lpage>
          <pub-id pub-id-type="pmid">745079</pub-id>
        </element-citation>
      </ref>
      <ref id="bib44">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Simoncelli</surname>
              <given-names>E.P.</given-names>
            </name>
            <name>
              <surname>Paninski</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Pillow</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <chapter-title>Characterization of neural responses with stochastic stimuli</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Gazzaniga</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <source>The Cognitive Neurosciences III</source>
          <year>2004</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>Cambridge, MA</publisher-loc>
          <fpage>327</fpage>
          <lpage>338</lpage>
        </element-citation>
      </ref>
      <ref id="bib45">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Singh</surname>
              <given-names>N.C.</given-names>
            </name>
            <name>
              <surname>Theunissen</surname>
              <given-names>F.E.</given-names>
            </name>
          </person-group>
          <article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          <year>2003</year>
          <fpage>3394</fpage>
          <lpage>3411</lpage>
          <pub-id pub-id-type="pmid">14714819</pub-id>
        </element-citation>
      </ref>
      <ref id="bib46">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Steeneken</surname>
              <given-names>H.J.M.</given-names>
            </name>
            <name>
              <surname>Houtgast</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>A physical method for measuring speech-transmission quality</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>67</volume>
          <year>1980</year>
          <fpage>318</fpage>
          <lpage>326</lpage>
          <pub-id pub-id-type="pmid">7354199</pub-id>
        </element-citation>
      </ref>
      <ref id="bib47">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stratford</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Tarczy-Hornoch</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>K.A.C.</given-names>
            </name>
            <name>
              <surname>Bannister</surname>
              <given-names>N.J.</given-names>
            </name>
            <name>
              <surname>Jack</surname>
              <given-names>J.J.B.</given-names>
            </name>
          </person-group>
          <article-title>Excitatory synaptic inputs to spiny stellate cells in cat visual cortex</article-title>
          <source>Nature</source>
          <volume>382</volume>
          <year>1996</year>
          <fpage>258</fpage>
          <lpage>261</lpage>
          <pub-id pub-id-type="pmid">8717041</pub-id>
        </element-citation>
      </ref>
      <ref id="bib48">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>van Veen</surname>
              <given-names>T.M.</given-names>
            </name>
            <name>
              <surname>Houtgast</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Spectral sharpness and vowel dissimilarity</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>77</volume>
          <year>1985</year>
          <fpage>628</fpage>
          <lpage>634</lpage>
          <pub-id pub-id-type="pmid">3973234</pub-id>
        </element-citation>
      </ref>
      <ref id="bib49">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vinje</surname>
              <given-names>W.E.</given-names>
            </name>
            <name>
              <surname>Gallant</surname>
              <given-names>J.L.</given-names>
            </name>
          </person-group>
          <article-title>Natural stimulation of the nonclassical receptive field increases information transmission efficiency in V1</article-title>
          <source>J. Neurosci.</source>
          <volume>22</volume>
          <year>2002</year>
          <fpage>2904</fpage>
          <lpage>2915</lpage>
          <pub-id pub-id-type="pmid">11923455</pub-id>
        </element-citation>
      </ref>
      <ref id="bib50">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watkins</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual compensation for effects of reverberation in speech identification</article-title>
          <source>J. Acoust. Soc. Am.</source>
          <volume>118</volume>
          <year>2005</year>
          <fpage>249</fpage>
          <lpage>262</lpage>
          <pub-id pub-id-type="pmid">16119347</pub-id>
        </element-citation>
      </ref>
      <ref id="bib51">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watkins</surname>
              <given-names>P.V.</given-names>
            </name>
            <name>
              <surname>Barbour</surname>
              <given-names>D.L.</given-names>
            </name>
          </person-group>
          <article-title>Specialized neuronal adaptation for preserving input sensitivity</article-title>
          <source>Nat. Neurosci.</source>
          <volume>11</volume>
          <year>2008</year>
          <fpage>1259</fpage>
          <lpage>1261</lpage>
          <pub-id pub-id-type="pmid">18820690</pub-id>
        </element-citation>
      </ref>
      <ref id="bib52">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watkins</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Makin</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual compensation for reverberation in speech identification: Effects of single-band, multiple-band and wideband noise contexts</article-title>
          <source>Acta Acustica United with Acustica</source>
          <volume>93</volume>
          <year>2007</year>
          <fpage>403</fpage>
          <lpage>410</lpage>
        </element-citation>
      </ref>
      <ref id="bib53">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wehr</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zador</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Synaptic mechanisms of forward suppression in rat auditory cortex</article-title>
          <source>Neuron</source>
          <volume>47</volume>
          <year>2005</year>
          <fpage>437</fpage>
          <lpage>445</lpage>
          <pub-id pub-id-type="pmid">16055066</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="app2" sec-type="supplementary-material">
      <title>Supplemental Information</title>
      <p>
        <supplementary-material content-type="local-data" id="mmc1">
          <caption>
            <title>Document S1. Four Tables, Five Figures, and Supplemental Experimental Procedures</title>
          </caption>
          <media xlink:href="mmc1.pdf" mimetype="application" mime-subtype="pdf"/>
        </supplementary-material>
      </p>
    </sec>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was supported by the Wellcome Trust through a Principal Research Fellowship to A.J.K. (WT076508AIA) and by Merton College, Oxford through a Domus A three-year studentship to N.C.R. We are grateful to Sandra Tolnai, Jennifer Bizley, and Kerry Walker for assistance with data collection. We also would like to thank Fernando Nodal, Douglas Hartley, Amal Isaiah, and Bashir Ahmed for their helpful contributions to the surgical preparations.</p>
    </ack>
  </back>
  <floats-group>
    <fig id="fig1">
      <label>Figure 1</label>
      <caption>
        <p>Stimulus Paradigm</p>
        <p>(A–C) Dynamic random chord (DRC) sequences with different spectrotemporal contrasts. The elements of each sequence are chords of pure tones, whose levels are randomly chosen from the distributions in (D).</p>
        <p>(D) Tone level distributions for the DRC sequences in (A)–(C). These all have the same mean level <italic>μ<sub>L</sub></italic>, but different widths. The blue line corresponds to the low-contrast (<italic>σ<sub>L</sub></italic>) DRC (A); the green line is the medium-contrast DRC (B); the red is the high-contrast DRC (C).</p>
        <p>(E and F) The widths of the level distribution determine both the spectral and the temporal contrast of the individual sequences, as shown by the temporal profiles of a pure tone at a fixed frequency for the three sequences in (E) and the spectral profiles of a chord at a fixed time for the three sequences in (F).</p>
        <p>(G) We characterized the relationship between stimulus and neuronal response using a linear-nonlinear model. The sound input is treated as a spectrogram, <bold>X</bold>; the (normalized) receptive field <bold>v</bold> acts as a linear filter on <bold>X</bold>, extracting the relevant features of the sound via the dot product <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M68" altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. The output of the linear filter is (optionally) matched to the output spike rate through a nonlinearity that captures features such as thresholding. We parameterized these nonlinearities as sigmoids. See also <xref rid="app2" ref-type="sec">Tables S1 and S2</xref> and <xref rid="app2" ref-type="sec">Figure S1</xref>.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Figure 2</label>
      <caption>
        <p>Effect of Stimulus Contrast on Tuning</p>
        <p>(A and B) Example units show the same spectrotemporal selectivity in the receptive fields (STRFs) estimated from the three contrast conditions. Red denotes components of the stimuli that excite the unit, blue denotes components that inhibit. As the color scale is uniform across the plots, it is clear that the dominant variation across the conditions lies in the magnitude of the drive to the unit: this is stronger (the cortex appears to “listen harder”) under low-contrast than under high-contrast stimulus conditions.</p>
        <p>(C–E) Best frequency (C) does not vary systematically with stimulus contrast across units. Tuning bandwidth (D) shows a small, significant broadening at low contrast. In almost all units, the gain of the STRF (E) increases as contrast decreases. STRF properties under low-contrast stimulation are shown as blue circles, under medium contrast as green crosses. Filled dark blue circles and dark green pluses indicate data in these two same conditions from the awake recordings.</p>
        <p>(F) The linear STRFs fitted from DRCs with different contrasts are sufficiently similar in tuning properties that, once adjusted for differences in STRF gain, they predict responses across stimulus conditions on average 96.5% as well as they do within their own conditions. Thus, most of the contrast dependence of STRFs is captured by a change in gain. Red crosses indicate data from the awake recordings. See also <xref rid="app2" ref-type="sec">Table S3</xref>.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Figure 3</label>
      <caption>
        <p>Output Nonlinearities for Two Example Units Show Gain Rescaling as a Function of Stimulus Contrast</p>
        <p>(A) For each unit, we fitted a single linear STRF, then calculated a separate output nonlinearity for each contrast condition. The abscissa denotes the output of the linear STRF, <inline-formula><alternatives><textual-form specific-use="jats-markup"><bold>X</bold>⋅<bold>v</bold></textual-form><mml:math id="M69" altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>; the ordinate is the predicted spike rate.</p>
        <p>(B) The differences between the nonlinearities were quantified by the linear transform required to convert the high-contrast nonlinearity into each of the medium- and low-contrast nonlinearities. Solid curves show the original sigmoids for the unit shown in (A); dashed lines show the result of the transformation of the high-contrast (red) curve into the low-contrast (blue) and medium-contrast (green) curves. The parameters for the high-to-low transform for this unit were <italic>G</italic> = 2.9, Δ<italic>x</italic> = 17.6%, Δ<italic>y</italic> = 8.9%; the high-to-medium transform parameters were <italic>G</italic> = 1.5, Δ<italic>x</italic> = 2.0%, Δ<italic>y</italic> = −0.6%.</p>
        <p>(C and D) Nonlinearities for a second example unit; panels equivalent to (A) and (B). Parameters for these transforms were <italic>G</italic> = 1.5, Δ<italic>x</italic> = −27.6%, Δ<italic>y</italic> = 2.4% (high-to-low) and <italic>G</italic> = 1.2, Δ<italic>x</italic> = −3.8%, Δ<italic>y</italic> = 8.5% (high-to-medium). See also <xref rid="app2" ref-type="sec">Figure S2</xref>.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Figure 4</label>
      <caption>
        <p>Output Gain Is Inversely Related to Stimulus Contrast</p>
        <p>(A) Histogram of gain (relative to the reference condition) under low- (blue) and medium-contrast (green) conditions, for n = 315 units. Colored dashed lines are population medians. Red dashed line indicates <italic>G</italic> = 1, i.e., no scaling of the nonlinearity.</p>
        <p>(B) As in (A), for changes in x-offset. Positive values denote rightward shifts in nonlinearities.</p>
        <p>(C) As in (A), for changes in y-offset. Positive values denote upward shifts in nonlinearities.</p>
        <p>(D) For both the high-to-low-contrast (blue) and the high-to-medium-contrast (green) transformations, changes in gain (abscissa) and x-offset (ordinate) were positively correlated across the population of units. Shaded regions show the (bootstrapped) 99% confidence intervals about the mean regression line (solid).</p>
        <p>(E) The population median gain over a wide range of contrasts was well modeled by a standard gain normalization function, <xref rid="fd2" ref-type="disp-formula">Equation 2</xref>. Gray bars indicate 99% confidence intervals on the median, via bootstrapping. See also <xref rid="app2" ref-type="sec">Figure S3</xref>.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Figure 5</label>
      <caption>
        <p>Contrast Gain Control Is Modulated by <italic>μ<sub>L</sub></italic> Only at Low Mean Levels</p>
        <p>(A) Sigmoid nonlinearities were fitted to units' responses to a range of DRCs with different contrast and <italic>μ<sub>L</sub></italic> statistics and compared with a reference curve. Population median gain factors are plotted against contrast, with different symbols/colors for each mean level. Colored lines show independent fits of the model in <xref rid="fig4" ref-type="fig">Figure 4</xref>E.</p>
        <p>(B) As in (A), for x-offset.</p>
        <p>(C) As in (A), for y-offset.</p>
        <p>(D) Values of <italic>b</italic> fitted to the model given in <xref rid="fd8" ref-type="disp-formula">Equation 8</xref>, as shown in (A). These measure the relative sensitivity of neural gain to the stimulus contrast, as a function of mean level. At mean levels ≥35 dB SPL, <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M70" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is relatively independent of <italic>μ<sub>L</sub></italic>, while it becomes sensitive to <italic>μ<sub>L</sub></italic> at lower mean levels. Solid line denotes an exponential fit to <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>b</italic>(μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M71" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>(E) Illustration of the full model <inline-formula><alternatives><textual-form specific-use="jats-markup"><italic>G</italic>(σ<sub><italic>L</italic></sub>, μ<sub><italic>L</italic></sub>)</textual-form><mml:math id="M72" altimg="si4.gif" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for gain normalization (colored surface). A contour plot of this surface is projected below. Colored dots on the contour plot show the population median data used to constrain the model, from (A). Their position is a function of both <italic>σ<sub>L</sub></italic> and <italic>μ<sub>L</sub></italic>; their color denotes the median measured gain in these stimulus conditions; vertical arrows denote the residual between the measured gain and that described by the model. See also <xref rid="app2" ref-type="sec">Figure S4</xref>.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig6">
      <label>Figure 6</label>
      <caption>
        <p>Responses to Fixed Sounds Are Modulated by the Spectrotemporal Contrast of their Context</p>
        <p>(A) During each electrode penetration, the STRF of a representative unit was used as a basis for a test sound. This was inserted at random times into special DRCs in which stimulus contrast switched every 1 s between low (<italic>σ<sub>L</sub></italic> = 2.9 dB, <italic>c =</italic> 33%) and high contrast (<italic>σ<sub>L</sub></italic> = 8.7 dB, <italic>c =</italic> 92%). The test sound itself was identical within each stimulus regime; only the contrast of its context differed.</p>
        <p>(B) Mean response to the test sound for an example unit, when presented in high-contrast (top row) or low-contrast context (bottom row). Columns delineate responses by the time since the last switch in context at which the test sounds were presented.</p>
        <p>(C) Response to the test sound for the unit in (B), averaged within each contrast context over all postswitch delays from 150–800 ms.</p>
        <p>(D) Peak responses to the test sound across n = 63 units, during the low- and high-contrast contexts. Red dashed line shows expected response relationship if contrast-context was irrelevant. Green circle indicates the unit in (B) and (C). Shaded region shows the confidence intervals as in <xref rid="fig4" ref-type="fig">Figure 4</xref>D.</p>
        <p>(E) Peak response for unit in (B) and (C) as a function of the time after context switch at which the test sound was presented. Solid lines show exponential fits to these data, with time constant <italic>τ<sub>L→H</sub></italic> = 62 ms after an increase and <italic>τ<sub>H→L</sub></italic> = 85 ms after a decrease in the contrast of the context.</p>
        <p>(F) Time constants for context adaptation, as in (E), for 18 units for which both <italic>τ<sub>L→H</sub></italic> and <italic>τ<sub>H→L</sub></italic> could be reliably estimated. Data are plotted both as a scatter plot and as marginal histograms of <italic>τ<sub>L→H</sub></italic> (red) and <italic>τ<sub>H→L</sub></italic> (blue). Green circle denotes unit in (B), (C), and (E). See also <xref rid="app2" ref-type="sec">Figure S5</xref>.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig7">
      <label>Figure 7</label>
      <caption>
        <p>Gain Is Affected by the Contrast of Stimuli Lying both Within and Outside the Tuning of a Unit</p>
        <p>(A) During each electrode penetration, the STRF of a representative unit was mapped and the BF determined. A 0.5–1.2 octave band centered around the BF was designated the test and the remainder the mask. The contrast within these (<italic>σ<sub>test</sub></italic>, <italic>σ<sub>mask</sub></italic>) was independently varied. The example stimuli shown here were used for a unit with a BF of 9 kHz.</p>
        <p>(B–E) Relative gain from varying either <italic>σ<sub>test</sub></italic> or <italic>σ<sub>mask</sub></italic>, with the other kept constant. Color grids above each plot illustrate which stimulus conditions from (A) are being compared; the red box with the white dot is the reference curve used to calculate the transform.</p>
        <p>(F) Population median gain for 24 units with their responsive frequency range lying within the test (dots with dashed lines). Error bars denote 99% confidence interval on the median. Contrast within the test is a stronger determinant of the gain than that in the mask. Solid lines show the fit of <xref rid="fd3" ref-type="disp-formula">Equation 3</xref> to these data. See also <xref rid="app2" ref-type="sec">Table S4</xref>.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
  </floats-group>
</article>