<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuropsychologia</journal-id>
      <journal-title>Neuropsychologia</journal-title>
      <issn pub-type="ppub">0028-3932</issn>
      <issn pub-type="epub">1873-3514</issn>
      <publisher>
        <publisher-name>Pergamon Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2383989</article-id>
      <article-id pub-id-type="pmid">16797614</article-id>
      <article-id pub-id-type="publisher-id">NSY2294</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.04.022</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Event-related brain potential correlates of emotional face processing</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Eimer</surname>
            <given-names>Martin</given-names>
          </name>
          <email>m.eimer@bbk.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Holmes</surname>
            <given-names>Amanda</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line><sup>a</sup>Department of Psychology, Birkbeck College, University of London, Malet Street, London WC1E 7HX, UK</addr-line>
      </aff>
      <aff id="aff2">
        <addr-line><sup>b</sup>School of Human and Life Sciences, Roehampton University, London, UK</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author. Tel.: +44 207 6316312; fax: +44 207 6316312. <email>m.eimer@bbk.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <year>2007</year>
      </pub-date>
      <volume>45</volume>
      <issue>1</issue>
      <fpage>15</fpage>
      <lpage>31</lpage>
      <history/>
      <permissions>
        <copyright-statement>Â© 2007 Elsevier Ltd.</copyright-statement>
        <copyright-year>2006</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</p>
        </license>
      </permissions>
      <abstract>
        <title>Abstract</title>
        <p>Results from recent event-related brain potential (ERP) studies investigating brain processes involved in the detection and analysis of emotional facial expression are reviewed. In all experiments, emotional faces were found to trigger an increased ERP positivity relative to neutral faces. The onset of this emotional expression effect was remarkably early, ranging from 120 to 180 ms post-stimulus in different experiments where faces were either presented at fixation or laterally, and with or without non-face distractor stimuli. While broadly distributed positive deflections beyond 250 ms post-stimulus have been found in previous studies for non-face stimuli, the early frontocentrally distributed phase of this emotional positivity is most likely face-specific. Similar emotional expression effects were found for six basic emotions, suggesting that these effects are not primarily generated within neural structures specialised for the automatic detection of specific emotions. Expression effects were eliminated when attention was directed away from the location of peripherally presented emotional faces, indicating that they are not linked to pre-attentive emotional processing. When foveal faces were unattended, expression effects were attenuated, but not completely eliminated. It is suggested that these ERP correlates of emotional face processing reflect activity within a neocortical system where representations of emotional content are generated in a task-dependent fashion for the adaptive intentional control of behaviour. Given the early onset of the emotion-specific effects reviewed here, it is likely that this system is activated in parallel with the ongoing evaluation of emotional content in the amygdala and related subcortical brain circuits.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Face processing</kwd>
        <kwd>Emotion</kwd>
        <kwd>Emotional facial expression</kwd>
        <kwd>Event-related brain potentials</kwd>
        <kwd>Cognitive affective neuroscience</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec>
      <label>1</label>
      <title>Introduction</title>
      <p>The investigation of emotional states, their neural correlates, and their role for the regulation of cognition and action is now one of the most active research areas in cognitive neuroscience (see <xref rid="bib2 bib26" ref-type="bibr">Adolphs, 2003; Dolan, 2002</xref>, for reviews). On the most general level, emotional states are evolutionary adaptations that are critically involved in the regulation of basic survival mechanisms, and in the control of behaviour in complex environments (<xref rid="bib22" ref-type="bibr">Damasio, 1999</xref>). A number of complementary methods, such as single cell recordings, functional brain imaging, or neuropsychological investigations of focal brain damage have been used to identify brain structures that are involved in the perception and analysis of emotionally significant information, mediate bodily emotional responses, and control social cognition and behaviour.</p>
      <p>Many recent studies have investigated the neural network underlying emotional processing by measuring brain responses to emotionally salient stimuli. Differences in brain responses to stimuli that vary in their emotional content have been interpreted as evidence for functional specialisation among neural processes responsible for the processing of emotional information. Such studies have revealed a complex interconnected network of brain structures responsible for the analysis of emotional events. This network includes higher order sensory cortices, where perceptual representations of emotionally relevant stimuli are formed, and the amygdala, orbitofrontal cortex, and ventral striatum, where such sensory representations appear to be classified in terms of their emotional significance. It also includes paralimbic and higher cortical areas such as somatosensory cortex, anterior cingulate, and medial prefrontal cortex, where conscious representations of emotional states are generated, which can be used in the strategic control of behaviour in complex social situations, and in the planning of future goals and actions (see <xref rid="bib2" ref-type="bibr">Adolphs, 2003</xref>, for more details).</p>
      <p>Emotional facial expressions are particularly salient stimuli for conveying important nonverbal communications to other species members, and, in humans, are immediate indicators of affective dispositions in other people. Because of this paramount emotional significance of facial expression, numerous recent functional imaging, lesion, and single-cell recording studies have used emotional faces to identify neural substrates of emotional processing. These studies have found that brain areas generally involved in the processing of emotional information (see above) are also activated during the processing of facial emotion. The initial perceptual analysis of faces takes place in inferior occipital cortex (‘occipital face area’; see <xref rid="bib86" ref-type="bibr">Rossion et al., 2003</xref>) and in the middle fusiform gyrus for structural properties of faces which determine face identity (<xref rid="bib42" ref-type="bibr">Hoffman &amp; Haxby, 2000</xref>; for reviews, see <xref rid="bib41" ref-type="bibr">Haxby, Hoffman, &amp; Gobbini, 2000</xref>; <xref rid="bib37" ref-type="bibr">Gobbini &amp; Haxby, 2006</xref>, this issue). The superior temporal sulcus is involved in the processing of dynamic aspects of faces, such as facial expression, eye and mouth movements (<xref rid="bib4" ref-type="bibr">Allison, Puce, &amp; McCarthy, 2000</xref>; see also <xref rid="bib81" ref-type="bibr">Puce, Epling, Thompson, &amp; Carrick, 2006</xref>, this issue). A rapid evaluation of the emotional and motivational significance of facial expression appears to be mediated by the amygdala and orbitofrontal cortex, while structures such as the anterior cingulate, prefrontal cortex and somatosensory areas are linked to the conscious representation of emotional facial expression for the strategic control of thought and action, as well as to the production of concomitant feeling states (see <xref rid="bib2" ref-type="bibr">Adolphs, 2003</xref>, for more details).</p>
      <p>In summary, recent neuroscientific investigations of emotional processing have uncovered components of a complex network for the detection and analysis of emotionally significant information. Since most of these recent studies have used fMRI measures, which are based on relatively slow hemodynamic brain responses to emotional stimuli, information about the time course of emotional processing has been relatively scarce. The availability of detailed temporal information is necessary to obtain a more comprehensive picture of the functional properties of the emotional brain. Thus, fMRI measures need to be complemented with methods that provide insights into temporal parameters of emotional processing, such as event-related brain potential (ERP) or magnetoencephalographic (MEG) measures.</p>
      <p>This paper reviews a series of recent studies in our lab that have used ERP measures to investigate the processes involved in the detection and analysis of emotional facial expression. In Section <xref rid="sec1" ref-type="sec">2</xref>, we will introduce ERP correlates of emotional face processing by discussing differential ERP responses to fearful versus neutral faces. Section <xref rid="sec2" ref-type="sec">3</xref> will review ERP modulations triggered by other basic emotional expressions. In Section <xref rid="sec3" ref-type="sec">4</xref>, we will present ERP results that support the hypothesis that the structural encoding of faces and the detection of their emotional expression represent parallel and independent processes. Section <xref rid="sec4" ref-type="sec">5</xref> will discuss the impact of selective attention on ERP responses elicited by emotional facial expression, and Section <xref rid="sec5" ref-type="sec">6</xref> will briefly review recent findings concerning the impact of the spatial frequency content on such emotional expression effects. Overall, the studies reviewed in this paper will demonstrate that ERPs represent a useful tool to study the time course and the functional properties of emotional face processing stages, such as their automaticity, specificity, and sensitivity to attentional states. Perhaps most importantly, our studies have shown that although selective brain responses to emotional faces, as measured with ERPs, are triggered at very short latencies, they are strongly dependent on attention. This suggests that they are not directly linked to the initial automatic detection of emotional content mediated by the amygdala and related structures, but rather to subsequent, cognitively penetrable stages of emotional processing.</p>
    </sec>
    <sec id="sec1">
      <label>2</label>
      <title>ERP correlates of emotional face processing: fearful faces</title>
      <p>The basic question addressed in our initial study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>) was when and how the difference between emotional and neutral facial expressions would be reflected in ERP waveforms. We recorded ERPs while participants viewed photographs of single fearful faces, neutral faces, or houses, which were presented at the centre of a computer screen. As in all other studies reported below, fearful and neutral faces were taken from a standard set of pictures of facial affect (<xref rid="bib32" ref-type="bibr">Ekman &amp; Friesen, 1976</xref>). Participants’ task was to detect infrequent immediate repetitions of identical stimuli across successive trials. Half of all fearful and neutral faces were presented in their standard upright orientation, while the other half was presented upside-down. Because face inversion disrupts not only face identification, but also to some degree the recognition of emotional facial expression (<xref rid="bib24" ref-type="bibr">de Gelder, Teunisse, &amp; Benson, 1997</xref>; <xref rid="bib89" ref-type="bibr">Searcy &amp; Bartlett, 1996</xref>), we expected ERP modulations indicative of the detection and processing of facial expression to be attenuated and possibly also delayed in response to inverted relative to upright faces.</p>
      <p><xref rid="fig1" ref-type="fig">Fig. 1</xref> shows ERPs triggered in response to fearful faces and neutral faces, for faces presented in their usual upright orientation (top panel), and for inverted faces (bottom panel). An enhanced positivity was present for ERPs to fearful relative to neutral faces, and this difference started remarkably early. For upright faces, significant differences between fearful and neutral faces started 120 ms after stimulus onset (<xref rid="fig1" ref-type="fig">Fig. 1</xref>, top panel). When faces were presented upside-down (<xref rid="fig1" ref-type="fig">Fig. 1</xref>, bottom), the onset of this enhanced positivity for fearful as compared to neutral faces was delayed. The time course and scalp topography of these emotional expression effects is further illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref>, which shows ERP scalp distribution maps for mean difference amplitudes, obtained by subtracting ERP waveforms in response to neutral faces from ERPs triggered by fearful faces within six successive post-stimulus latency windows. In these maps, enhanced positivities for fearful relative to neutral faces are shown in red colours, while blue colours indicate that amplitude differences were small or absent. Emotional positivities for upright fearful faces (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, top panel) consisted of an early frontocentrally distributed effect (triggered between 110 and 200 ms after stimulus onset), and a more broadly distributed effect that started at about 250 ms post-stimulus, and remained present throughout the 1000 ms analysis interval. Emotional expression effects triggered by upside-down faces were substantially delayed and also attenuated (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, bottom panel). They only emerged beyond 150 ms post-stimulus, and disappeared beyond 700 ms.</p>
      <p>These ERP results suggest that emotional facial expression is analysed rapidly and can affect cortical processing at very short latencies (i.e., within about 120 ms after stimulus onset; see also <xref rid="bib8" ref-type="bibr">Ashley, Vuilleumier, &amp; Swick, 2003</xref>; <xref rid="bib94" ref-type="bibr">Vuilleumier &amp; Pourtois, 2006</xref>, this issue, for similar findings). One might of course argue that the early ERP differences shown in <xref rid="fig1 fig2" ref-type="fig">Figs. 1 and 2</xref> are not directly related to emotional facial expression processing, but could instead be caused by systematic differences in low-level visual features of fearful versus neutral faces. However, the fact that face inversion, which preserves all low-level visual features, but makes the recognition of facial expression more difficult, resulted in an attenuation and a delay of these emotional expression effects, makes this alternative interpretation unlikely. It appears much more plausible to assume that the impact of face inversion on the latency and amplitude of ERP emotional expression effects directly reflects the impairment of emotion detection and recognition produced by face inversion.</p>
      <p>The scalp distribution maps shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref> suggest that the processing of emotional facial expression, as reflected by ERP waveforms, might consist of two distinct stages. The early frontocentrally distributed positivity for fearful as compared to neutral faces could be linked to an initial rapid detection of facial expression in prefrontal areas involved in the detection of emotionally significant stimuli. In line with this assumption, <xref rid="bib51" ref-type="bibr">Kawasaki et al. (2001)</xref> have measured differential responses of single neurons in right ventral prefrontal cortex in response to emotionally neutral versus aversive stimuli at latencies comparable to the onset latencies of early emotional expression effects shown in <xref rid="fig1 fig2" ref-type="fig">Figs. 1 and 2</xref>. In contrast, the sustained and more broadly distributed positivity obtained for fearful faces beyond 250 ms post-stimulus might reflect subsequent higher level stages of emotional face processing, such as the conscious evaluation of emotional content. Similar sustained positive ERP deflections have been observed in previous ERP studies in response to emotionally salient non-face stimuli (<xref rid="bib21" ref-type="bibr">Cuthbert, Schupp, Bradley, Birbaumer, &amp; Lang, 2000</xref>; <xref rid="bib25" ref-type="bibr">Diedrich, Naumann, Maier, &amp; Becker, 1997</xref>; <xref rid="bib52" ref-type="bibr">Keil et al., 2002</xref>), thus suggesting that these longer latency effects are not face-specific, but can also be elicited by other kinds of emotional material.</p>
    </sec>
    <sec id="sec2">
      <label>3</label>
      <title>ERP correlates of emotional face processing: other emotional expressions</title>
      <p>In our initial study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>), we only studied the effects of fear on ERP waveforms. Fearful faces were chosen because they are known to modulate neocortical regions via the amygdala (<xref rid="bib6" ref-type="bibr">Amaral &amp; Price, 1984</xref>; <xref rid="bib92" ref-type="bibr">Vuilleumier, Armony, Driver, &amp; Dolan, 2001</xref>; see also <xref rid="bib38" ref-type="bibr">Graham, Devinsky, &amp; LaBar, 2006</xref>, this issue). However, there is now substantial evidence for the existence of neural systems that are specialised for processing distinct emotions. For example, the amygdala appears to be specifically sensitive to facial expressions of fear, while insula and basal ganglia have been linked to the processing of facial expressions of disgust (see <xref rid="bib1" ref-type="bibr">Adolphs, 2002</xref>, for a more detailed review). If the detection and analysis of different facial emotional expressions was mediated by distinct brain processes, this might also be reflected in systematic differences in the modulatory effects of these expressions on ERP waveforms.</p>
      <p>To investigate whether different emotional facial expressions give rise to distinct modulations of ERP waveforms, or whether similar emotional expression effects can be observed for all basic emotional expressions, we conducted an experiment where ERP responses elicited by six basic emotional facial expressions (anger, disgust, fear, happiness, sadness, and surprise, see <xref rid="bib32" ref-type="bibr">Ekman &amp; Friesen, 1976</xref>) were directly compared (<xref rid="bib31" ref-type="bibr">Eimer, Holmes, &amp; McGlone, 2003</xref>). In each block, faces were either neutral or emotional (with emotional expression varied between blocks). In contrast to our first study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>), where faces were presented at fixation, we now delivered pairs of identical faces to the left and right of fixation together with a pair of vertical lines close to fixation (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>, top). Participants had to decide on each trial whether the expression of the face pair was emotional or neutral. This procedure was chosen to investigate effects of spatial attention on the processing of emotional facial expression by comparing ERPs elicited when emotional and neutral faces were task-relevant to ERPs recorded in another part of the same experiment where faces were irrelevant, and attention was directed to the line stimuli instead (see Section <xref rid="sec4" ref-type="sec">5</xref>).</p>
      <p><xref rid="fig3" ref-type="fig">Fig. 3</xref> shows ERPs in response to task-relevant emotional and neutral faces elicited at frontal midline electrode Fz, separately for experimental blocks containing angry, disgusted, happy, and surprised faces. Emotional expression effects were very similar across different facial expressions. An enhanced positivity for emotional as compared to neutral faces started about 180 ms after stimulus onset, and a sustained emotional positivity was present throughout the 1000 ms recording epoch. These effects were elicited in a very similar fashion for all six emotions studied, and scalp topographies were statistically indistinguishable across emotions.<xref rid="fn1" ref-type="fn">1</xref> It is notable that the onset of emotional expression effects shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref> was slightly delayed relative to the onset latencies observed in our earlier study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>), where frontal differences between ERPs to upright fearful and neutral faces were already present at 120 ms post-stimulus (see <xref rid="fig1 fig2" ref-type="fig">Figs. 1 and 2</xref>). This difference is most likely due to the fact that face stimuli were now presented peripherally, rather than centrally, and were accompanied by potentially competing non-face stimuli (vertical lines) close to fixation (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>, top).</p>
      <p>The similarity in the onset latencies of ERP emotional expression effects for all six basic emotional expressions suggests that emotionally relevant information delivered by facial expression is available to neocortical processes within less then 200 ms after stimulus onset, and at approximately the same time for all basic emotional expressions. The observation that all six emotional facial expressions were also very similar in terms of the magnitude and duration of their effects on ERP waveforms relative to neutral faces, which was confirmed by statistical analyses (see <xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>, for details), appears to be at odds with the hypothesis that distinct neural sub-systems specialise in the processing of specific emotions (<xref rid="bib1" ref-type="bibr">Adolphs, 2002</xref>). If this was the case, one might have expected systematic differences between ERP emotional expression effects elicited by different facial expressions. While many neuroimaging studies have shown emotion-specific activation patterns of brain regions such as the amygdala or insula (<xref rid="bib3" ref-type="bibr">Adolphs, Tranel, &amp; Damasio, 2003</xref>; <xref rid="bib14" ref-type="bibr">Breiter et al., 1996</xref>; <xref rid="bib18" ref-type="bibr">Calder, Keane, Manes, Antoun, &amp; Young, 2000</xref>; <xref rid="bib19" ref-type="bibr">Calder, Lawrence, &amp; Young, 2001</xref>; <xref rid="bib62 bib74 bib75" ref-type="bibr">Morris et al., 1996; Phillips et al., 1997, 1998</xref>; <xref rid="bib90" ref-type="bibr">Sprengelmeyer, Rausch, Eysel, &amp; Przuntek, 1998</xref>; <xref rid="bib97" ref-type="bibr">Whalen et al., 2001</xref>), fMRI measures are insensitive to the time scale of such effects. Thus, it is possible that some of these effects occur substantially later than the early ERP modulations found in our studies. Initial evidence for this assumption comes from recent intracranial recordings of ERPs to facial expressions (<xref rid="bib53" ref-type="bibr">Krolak-Salmon, Henaff, Vighetto, Betrand, &amp; Maugiere, 2004</xref>). In this study, fear-specific amygdala responses were observed at latencies of 200 ms and beyond, that is, well after the early fear-specific ERP modulations described above. In addition, relatively few fMRI studies to date have pointed to differential activation within surface neocortical structures (where effects of emotional expression on ERPs are likely to be generated). It is thus possible that early stages in the processing of emotionally relevant information, subserved by limbic structures or the basal ganglia, and neocortical emotional processing stages differ in terms of their specificity.</p>
      <p>It has to be acknowledged that these tentative interpretations are primarily based on the results of a single ERP study, where systematic differences in ERP responses to specific facial expressions were conspicuously absent (<xref rid="bib31" ref-type="bibr">Eimer, Holmes, &amp; McGlone, 2003</xref>). One could argue that this negative result may be primarily due to methodological factors. For example, the same neutral face stimuli were presented in all blocks, whereas the expression of emotional faces changed across blocks. This could have resulted in different rates of habituation for emotional versus neutral faces, regardless of emotional expression (see <xref rid="bib20" ref-type="bibr">Carretie, Hinojosa, &amp; Mercado, 2003</xref>, for ERP correlates of habituation to emotional stimuli). However, the fact that the emotional expression effects observed in this experiment were qualitatively very similar to the effects observed in our other studies where emotional and neutral faces were equiprobable makes this interpretation somewhat unlikely. Alternatively, it could be argued that subtle topographical differences in the impact of emotional facial expression on electrical brain responses may only be detectable when combining high-density EEG or MEG recordings and source localization analyses. In fact, several recent studies have reported systematically different ERP modulations in response to different emotional expressions (e.g., <xref rid="bib9" ref-type="bibr">Batty &amp; Taylor, 2003</xref>; <xref rid="bib76" ref-type="bibr">Pourtois, Grandjean, Sander, &amp; Vuilleumier, 2004</xref>). In light of these results, it is clear that the question whether or not different emotional facial expressions give rise to specific ERP effects is far from settled, and that further systematic studies of electrophysiological correlates of emotional face processing are needed to find a definitive answer.</p>
    </sec>
    <sec id="sec3">
      <label>4</label>
      <title>Structural encoding and facial expression processing are independent and parallel processes</title>
      <p>Evidence from neuropsychology strongly suggests that the processing of facial identity and facial expression are subserved by dissociable neural substrates, in line with the model of face processing proposed by <xref rid="bib16" ref-type="bibr">Bruce and Young (1986)</xref>. Focal damage to selective brain regions can leave some patients with a deficiency in recognising faces, and yet spare the ability to read facial expressions of emotion (<xref rid="bib33" ref-type="bibr">Etcoff, 1984</xref>; <xref rid="bib78" ref-type="bibr">Posamentier &amp; Abdi, 2003</xref>; <xref rid="bib91" ref-type="bibr">Tranel &amp; Damasio, 1988</xref>; <xref rid="bib100" ref-type="bibr">Young, Newcombe, de Haan, Small, &amp; Hay, 1993</xref>). On the other hand, some patients are impaired in their ability to read emotional cues from faces, but have no difficulty in identifying people (<xref rid="bib48" ref-type="bibr">Hornak, Rolls, &amp; Wade, 1996</xref>). Informed by such double dissociations, models of face processing such as those proposed by <xref rid="bib16" ref-type="bibr">Bruce and Young (1986)</xref> and by <xref rid="bib41" ref-type="bibr">Haxby et al. (2000)</xref> have incorporated the assumption that the detection and analysis of facial emotional expression and the structural encoding of facial features for face recognition are implemented by separable, independent, and parallel processes.</p>
      <p>The ERP studies reviewed so far (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>; <xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>) have yielded further findings that are relevant to this hypothesis that the perceptual structural encoding and subsequent recognition of faces and the detection and analysis of emotional facial expression are independent. <xref rid="fig4" ref-type="fig">Fig. 4</xref> (bottom) shows the face-specific N170 component, as observed in our initial study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>) at lateral temporal electrodes T5/6 in response to fearful and neutral faces. Numerous ERP studies have demonstrated that this component is triggered reliably by faces at lateral posterior electrodes at about 170 ms post-stimulus, but not by other types of objects. The N170 component is assumed to reflect the pre-categorical perceptual encoding of faces in face-specific ventral visual areas, which provides structural representations that are utilized by subsequent face recognition stages (<xref rid="bib10" ref-type="bibr">Bentin, Allison, Puce, Perez, &amp; McCarthy, 1996</xref>; <xref rid="bib28 bib29" ref-type="bibr">Eimer, 1998, 2000</xref>).</p>
      <p>As can be seen from <xref rid="fig4" ref-type="fig">Fig. 4</xref> (bottom), the N170 was not at all sensitive to facial emotional expression, as no systematic differences in N170 amplitudes or latencies were observed for fearful as compared to neutral faces. This was confirmed in another study (<xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>), where the N170 component was found to be unaffected by the presence versus absence of any of the six basic emotional expressions. These findings suggest that the structural encoding of faces, as reflected by the N170, is insensitive to information derived from emotional facial expression.<xref rid="fn2" ref-type="fn">2</xref> It is interesting to note in this context that several fMRI studies (<xref rid="bib61 bib92" ref-type="bibr">Morris et al., 1998; Vuilleumier et al., 2001</xref>) have found that activity within face-specific fusiform areas is modulated by emotional facial expression. The fact that the N170 is insensitive to emotional expression could indicate that this component reflects face processing at some other anatomical stage than fusiform gyrus. In fact, there is now evidence from source localization studies (e.g., <xref rid="bib50" ref-type="bibr">Itier &amp; Taylor, 2004</xref>) that the N170 may at least in part be generated in more lateral temporal regions such as the superior temporal sulcus. Alternatively, the N170 might be triggered during an early expression-independent face processing stage located within the fusiform face area, which is too transient to be picked up reliably with hemodynamic measures, but is followed at longer latencies by a more sustained selective processing of facial expression in fusiform gyrus. In this context, it is interesting to note that intracranial recordings from ventral and lateral occipitotemporal and temporal regions have identified a sequence of face-specific potentials, starting with the N200 (<xref rid="bib5" ref-type="bibr">Allison, Puce, Spencer, &amp; McCarthy, 1999</xref>), and have found that only longer latency components are affected by affect, familiarity, and priming (<xref rid="bib80" ref-type="bibr">Puce, Allison, &amp; McCarthy, 1999</xref>).</p>
      <p>To illustrate that structural encoding and emotional face processing, as reflected by ERP measures, represent separable stages, <xref rid="fig4" ref-type="fig">Fig. 4</xref> contrasts ERPs observed in our initial study (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>) in response to fearful and neutral faces at lateral posterior electrodes (where the N170 component was found to be insensitive to facial expression, bottom panel) with ERPs recorded at the same time at lateral frontocentral electrodes, where emotional expression effects were clearly present at and even before 170 ms post-stimulus. This pattern of results, which was replicated in our other studies (<xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>; <xref rid="bib46" ref-type="bibr">Holmes, Vuilleumier, &amp; Eimer, 2003</xref>), strongly suggests that the rapid detection of emotional facial expression within anterior brain regions occurs independently and in parallel with the construction of a detailed perceptual representation of faces within face-specific posterior ventral areas. They provide new evidence for the existence of functionally separable and parallel brain processes involved in the structural encoding of faces and in the processing of emotional facial expression (see also <xref rid="bib69" ref-type="bibr">Parry, Young, Saul, &amp; Moss, 1991</xref>, for further neuropsychological evidence for dissociable impairments in face processing after brain injury).</p>
    </sec>
    <sec id="sec4">
      <label>5</label>
      <title>The impact of attention on the processing of emotional facial expression</title>
      <p>It is often assumed that affectively salient stimuli such as emotional facial expressions are detected pre-attentively, and attract attention automatically (see <xref rid="bib68" ref-type="bibr">Palermo &amp; Rhodes, 2006</xref>, this issue, for detailed discussion). Strong attentional biases towards emotional stimuli have indeed been found in behavioural studies for visual search tasks (<xref rid="bib27" ref-type="bibr">Eastwood, Smilek, &amp; Merikle, 2001</xref>; <xref rid="bib35" ref-type="bibr">Fox et al., 2000</xref>; <xref rid="bib39" ref-type="bibr">Hansen &amp; Hansen, 1988</xref>; <xref rid="bib65" ref-type="bibr">Öhman, Flykt, &amp; Esteves, 2001</xref>; <xref rid="bib66" ref-type="bibr">Öhman, Lundqvist, &amp; Esteves, 2001</xref>), or dot probe detection tasks (<xref rid="bib43" ref-type="bibr">Holmes, Green, &amp; Vuilleumier, 2005</xref>; <xref rid="bib45" ref-type="bibr">Holmes, Richards, &amp; Green, 2006</xref>; <xref rid="bib59" ref-type="bibr">Mogg &amp; Bradley, 1999</xref>; <xref rid="bib60" ref-type="bibr">Mogg et al., 2000</xref>). However, recent brain imaging studies have yielded conflicting findings with respect to the influence of attention on the processing of affective material. On the one hand, amygdala responses to fearful faces in humans appear to be unaffected by spatial attention (<xref rid="bib92" ref-type="bibr">Vuilleumier et al., 2001</xref>), and amygdala activations triggered by highly arousing emotional scenes are not modulated by a secondary task (<xref rid="bib54" ref-type="bibr">Lane, Chua, &amp; Dolan, 1999</xref>). In addition, neglect and extinction patients are more likely to detect emotionally significant relative to neutral pictures when these are presented in the affected visual hemifield (<xref rid="bib95 bib96" ref-type="bibr">Vuilleumier &amp; Schwartz, 2001a, 2001b</xref>). These results suggest that emotional stimuli can capture attention automatically. However, other recent fMRI studies have found attentional modulations of amygdala responses to fearful or happy facial expressions (<xref rid="bib72" ref-type="bibr">Pessoa, Kastner, &amp; Ungerleider, 2002</xref>; <xref rid="bib73" ref-type="bibr">Pessoa, McKenna, Gutierrez, &amp; Ungerleider, 2002</xref>), as well as increased responses to attended versus unattended fearful faces in the anterior temporal pole and anterior cingulate gyrus (<xref rid="bib92" ref-type="bibr">Vuilleumier et al., 2001</xref>).</p>
      <p>We investigated the role of attention in the processing of emotional facial expression by studying whether and how directing attention towards or away from emotional faces would affect any emotion-induced modulations of ERP waveforms. In one study (<xref rid="bib46" ref-type="bibr">Holmes et al., 2003</xref>), we recorded ERPs in response to stimulus arrays that consisted of two faces and two houses arranged in horizontal and vertical pairs (see <xref rid="fig5" ref-type="fig">Fig. 5</xref>, top). The location of the face and house pairs (vertical versus horizontal) and the emotional expression of the face pair (fearful versus neutral) was varied randomly across trials. Participants had to direct their attention either to the two vertical or to the two horizontal locations in order to detect infrequent target events (two identical faces or two identical houses at these attended locations). Stimuli at the two other locations could be ignored. Task-relevant locations changed randomly across trials, and were indicated by two boxes presented at the start of each trial.</p>
      <p><xref rid="fig5" ref-type="fig">Fig. 5</xref> shows ERPs triggered in response to stimulus arrays containing either fearful or neutral faces, separately for trials where faces were presented at cued (attended) positions (faces-cued trials), and for trials where houses were presented at cued locations, while faces were task-irrelevant and could therefore be ignored (houses-cued trials). When faces were attended, the results obtained in our previous studies (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>; <xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>) were basically replicated. Fearful faces triggered an enhanced positivity relative to neutral faces, with an early frontocentral effect and a subsequent more broadly distributed sustained emotional positivity. Surprisingly, these emotional expression effects were completely eliminated on trials where faces were presented at unattended locations (<xref rid="fig5" ref-type="fig">Fig. 5</xref>, houses-cued trials). Here, no statistically significant modulations of ERPs in response to arrays containing fearful versus neutral faces were obtained at all. This finding that emotion-specific ERP modulations are strongly dependent on spatial attention challenges the hypothesis that the detection and processing of emotional facial expression occurs pre-attentively, and suggests that the processes reflected by ERP modulations sensitive to emotional facial expression are gated by spatial attention.</p>
      <p>In order to confirm and extend this surprising finding that ERP modulations triggered by emotional faces are contingent upon faces being attended, we investigated the impact of directing attention towards or away from faces for all six basic facial expressions. This was done in the study (<xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>) already introduced in Section <xref rid="sec2" ref-type="sec">3</xref>, where stimulus arrays consisted of pairs of identical peripheral faces that were presented together with a central pair of vertical lines (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, top). Facial expression was either neutral, or angry, disgusted, fearful, happy, sad, or surprised, with emotional expression varied across blocks. To assess the impact of spatial attention on the processing of emotional facial expression, we compared two different tasks where attention was either directed towards or away from the face stimuli. In the Emotion task described in Section <xref rid="sec2" ref-type="sec">3</xref>, faces were attended, since participants were instructed to judge their emotional expression. In the Lines task, attention was directed away from these faces, as participants had to report whether the two vertical lines were identical or differed in length.</p>
      <p><xref rid="fig6" ref-type="fig">Fig. 6</xref> shows ERPs triggered at frontal recording sites in response to emotional faces (collapsed across all six emotional facial expressions) and neutral faces in the Emotion task where faces were attended and in the Lines task where attention was directed away from these faces. In the Emotion task, emotional faces elicited an enhanced positivity starting at about 160 ms post-stimulus (see also Section <xref rid="sec2" ref-type="sec">3</xref> and <xref rid="fig3" ref-type="fig">Fig. 3</xref>), similar to the results from our other ERP studies (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>; <xref rid="bib46" ref-type="bibr">Holmes et al., 2003</xref>). In marked contrast, emotional expression effects were completely eliminated in the Lines task (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, bottom). When attention was directed away from face stimuli towards the perceptually difficult central line discrimination task, the presence of emotional versus neutral faces had no effect whatsoever on ERP waveforms, and this was the case for each of the six basic emotions studied (see <xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>, for more details).</p>
      <p>In the light of these findings that emotional expression effects on ERP waveforms were completely eliminated when attention was directed away from laterally presented emotional faces to other task-relevant locations, we next wanted to find out whether attention would have a similar impact on emotional face processing even when faces are located at fixation. With emotional faces presented within foveal vision, we expected to find little if any modulatory effects of attention on emotional expression effects. This was tested in another ERP study (<xref rid="bib44" ref-type="bibr">Holmes, Kiss, &amp; Eimer, 2006</xref>), where single faces (either fearful or neutral) were presented foveally at fixation, and were flanked by a pair of vertical lines that were either identical or different in length (see <xref rid="fig7" ref-type="fig">Fig. 7</xref>, top). In one half of the experiment, faces were attended, since participants had to detect immediate repetitions of the same face stimulus on successive trials. In the other experimental half, they had to detect immediate repetitions of an identical line pair on successive trials, and faces could be entirely ignored.</p>
      <p><xref rid="fig7" ref-type="fig">Fig. 7</xref> shows grand-averaged ERP waveforms obtained from ten participants in response to fearful and neutral faces at midline electrodes Fz and Cz when attention was directed to central faces (Faces task, top) or to lateral lines (Lines task, bottom). Similar to the results obtained before, fearful faces again triggered an enhanced positivity relative to neutral faces when faces were attended, and this effect started at about 150 ms post-stimulus. In contrast to our findings for lateral faces, these emotional expression effects were not entirely eliminated when attention was directed to the lateral lines. As can be seen from <xref rid="fig7" ref-type="fig">Fig. 7</xref>, the early phase of this effect triggered between 150 and 200 ms post-stimulus was clearly preserved even when instructions required participants to ignore foveal faces, and statistical analyses revealed that a significantly enhanced positivity to fearful faces was present regardless of attention instructions. In contrast, longer latency emotional expression effects, which were present when faces were attended, were strongly attenuated and failed to reach statistical significance in the Lines task where participants were instructed to ignore faces, and to judge lateral lines instead.</p>
      <p>These observations suggest that there are important differences in the impact of attention on cortical stages of emotional expression processing of foveal and peripheral faces. When faces are presented at fixation, an initial rapid detection of their emotional expression (as reflected by early emotional expression effects) takes place irrespective of attentional task instructions. In contrast, no ERP evidence for emotional expression processing can be found when peripherally presented faces are unattended. However, and equally importantly, it appears that subsequent stages in emotional face processing are under full strategic control, and are therefore only activated when attentional task instructions require observers to process these faces, irrespective of whether they are presented foveally or in the periphery of the visual field.</p>
      <p>The ERP studies presented in this section have demonstrated that emotion-specific ERP modulations are strongly dependent on spatial attention. The observation that both short-latency as well as sustained longer latency ERP emotional expression effects are completely eliminated when emotional faces are presented at lateral positions and outside of the current focus of attention is clearly at odds with the hypothesis that emotional facial expression is always fully processed, regardless of other current task demands. It should be noted that our observation that ERP modulations sensitive to emotional facial expression are gated by spatial attention contrasts markedly with fMRI results showing that amygdala responses to fearful faces and other emotionally salient stimuli are unaffected by attention (<xref rid="bib7" ref-type="bibr">Anderson, Christoff, Panitz, De Rosa, &amp; Gabrieli, 2003</xref>; <xref rid="bib54 bib92" ref-type="bibr">Lane et al., 1999; Vuilleumier et al., 2001</xref>; see also <xref rid="bib67" ref-type="bibr">Öhman &amp; Mineka, 2001</xref>, for a description of a module for fear elicitation that is cognitively impenetrable and activated automatically). Recent functional imaging studies have even demonstrated fear-specific amygdala activation during binocular suppression (<xref rid="bib70" ref-type="bibr">Pasley, Mayes, &amp; Schultz, 2004</xref>; <xref rid="bib98" ref-type="bibr">Williams, Morris, McGlone, Abbot, &amp; Mattingley, 2004</xref>), which was interpreted as evidence for a direct subcortical pathway to the amygdala.</p>
      <p>The striking differences between these results and the ERP findings discussed in this section suggest that frontal neocortical and limbic systems involved in the analysis of emotional events might differ with respect to their functional properties. Rapid amygdala responses may be triggered by attended as well as unattended emotional stimuli (although these responses may still be modulated by selective attention; see <xref rid="bib72 bib73" ref-type="bibr">Pessoa et al., 2002a, 2002b</xref>). In contrast, neocortical stages of emotional processing (as reflected by the ERP effects discussed here) appear to be much more dependent on focal attention. At these stages, emotionally salient events such as emotional faces may not have a unique status with respect to their immunity to attentional capacity limitations. When attention is already actively engaged elsewhere, the cortical processing of emotional facial expressions may therefore be similarly impaired as the processing of other types of perceptual objects.</p>
    </sec>
    <sec id="sec5">
      <label>6</label>
      <title>The impact of spatial frequency on emotional expression analysis</title>
      <p>One distinctive feature of brain structures sensitive to emotionally relevant information such as the amygdala, superior colliculus and pulvinar is that they appear to be preferentially activated by low spatial frequency (LSF), but not high spatial frequency (HSF) representations of fearful faces (<xref rid="bib93" ref-type="bibr">Vuilleumier, Armony, Driver, &amp; Dolan, 2003</xref>; <xref rid="bib99" ref-type="bibr">Winston, Vuilleumier, &amp; Dolan, 2004</xref>). This observation is consistent with anatomical evidence that these brain areas receive substantial magnocellular inputs (<xref rid="bib11" ref-type="bibr">Berson, 1988</xref>; <xref rid="bib57" ref-type="bibr">Leventhal, Rodieck, &amp; Dreher, 1985</xref>; <xref rid="bib88" ref-type="bibr">Schiller, Malpeli, &amp; Schein, 1979</xref>), possibly as part of a phylogenetically old route specialised for the rapid processing of fear-related stimuli (<xref rid="bib56" ref-type="bibr">Le Doux, 1996</xref>; <xref rid="bib63" ref-type="bibr">Morris, Öhman, &amp; Dolan, 1999</xref>). In contrast, parvocellular channels, which are more responsive to HSF stimuli, provide input to ventral visual cortex, but not subcortical areas, and are crucial for the detailed processing of shape and colour on which object and face recognition are based (<xref rid="bib15" ref-type="bibr">Breitmeyer, 1992</xref>; <xref rid="bib58" ref-type="bibr">Livingstone &amp; Hubel, 1988</xref>). A recent behavioural study conducted in our lab (<xref rid="bib43" ref-type="bibr">Holmes et al., 2005a</xref>) has also revealed that rapid attentional responses to fearful versus neutral faces are driven by LSF rather than HSF information, consistent with the suggested role of amygdala in the mediation of attention towards emotional stimuli (<xref rid="bib61 bib92" ref-type="bibr">Morris et al., 1998; Vuilleumier et al., 2001</xref>).</p>
      <p>Given the assumed preference of amygdala and connected structures for LSF information, driven by magnocellular afferents, we have recently conducted a study (<xref rid="bib47" ref-type="bibr">Holmes, Winston, &amp; Eimer, 2005</xref>) to investigate whether effects of emotional facial expression on ERP waveforms would show a similar selectivity. ERPs were recorded while participants viewed photographs of centrally presented faces with fearful or neutral expressions, houses, or chairs. Their task was to detect and respond to infrequently presented target stimuli (chairs). <xref rid="fig8" ref-type="fig">Fig. 8</xref> (top) shows examples of the different types of face stimuli used in this study. Broad spatial frequency (BSF) stimuli were unfiltered, LSF stimuli were low-pass filtered to retain only frequencies below 6 cycles per image (2 cycles/degree of visual angle), while HSF stimuli were high-pass filtered to retain only frequencies above 26 cycles per image (4 cycles/degree of visual angle). To preclude confounds due to differences between these stimulus categories in terms of their brightness or contrast, all stimuli were normalized for their luminance and average spectral energy.</p>
      <p><xref rid="fig8" ref-type="fig">Fig. 8</xref> shows ERPs elicited at midline electrodes Fz and Cz in the first 400 ms after stimulus onset in response to fearful and neutral faces, separately for BSF faces (left panel), HSF faces (middle panel), and LSF faces (right panel). As expected, emotional expression had a strong effect on ERPs elicited by BSF faces. Confirming previous findings, an enhanced and statistically reliable positivity for fearful relative to neutral faces started at about 150 ms post-stimulus. In contrast, there was no clear evidence for differential ERP responses to fearful versus neutral faces in response to HSF and LSF faces (see <xref rid="fig8" ref-type="fig">Fig. 8</xref>, middle and right panels). The absence of systematic emotional expression effects for these filtered faces was also confirmed by statistical analyses. If LSF cues were more important than HSF cues in producing ERP modulations to fearful facial expressions, one would have expected to find stronger emotional expression effects for LSF as compared to HSF faces, with effects for LSF faces possibly even similar in magnitude to expression effects observed for unfiltered BSF faces. In fact, ERP responses to LSF faces were entirely unaffected by emotional expression. Given that emotional processes in amygdala and related brain regions have been found to be selectively driven by LSF signals (<xref rid="bib93 bib99" ref-type="bibr">Vuilleumier et al., 2003; Winston et al., 2004</xref>), the absence of any reliable ERP effects of facial expression for LSF faces again suggests that these ERP responses do not directly reflect activity in these regions, but are instead produced by functionally distinct neocortical brain systems.</p>
    </sec>
    <sec>
      <label>7</label>
      <title>Conclusions</title>
      <p>In the studies reviewed in this paper, ERPs were measured in response to emotional and neutral faces. We investigated the onset, time course, and topographic distribution of brain responses to emotional faces in order to learn more about functional properties of emotional face processing. These studies have revealed robust and replicable differential ERP responses to emotional versus neutral faces. In all experiments reviewed in this paper, emotional faces triggered an increased positivity relative to neutral faces. The onset of this emotional expression effect was remarkably early, ranging from 120 ms post-stimulus when faces were presented at fixation and no competing non-face stimuli were simultaneously present (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>) to 180 ms post-stimulus when emotional faces were presented at peripheral locations together with other stimuli close to fixation (<xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>). While we assume that factors such as the retinal position of faces and the presence versus absence of potentially competing non-face stimuli in the display are largely responsible for such onset latency differences, the possibility remains that other cognitive factors might determine the onset of these effects. It is unlikely that the presence of an explicit emotion task plays an important role, given that very early emotional expression effects were observed under conditions where participants had to detect the immediate repetitions of face as well as non-face stimuli, and emotional expression was entirely irrelevant (<xref rid="bib30" ref-type="bibr">Eimer &amp; Holmes, 2002</xref>). The intriguing possibility that the onset of these effects might also vary as a function of participants’ trait or state anxiety (see <xref rid="bib12" ref-type="bibr">Bishop, Duncan, &amp; Lawrence, 2004</xref>; <xref rid="bib34" ref-type="bibr">Fox, 2002</xref>, for recent behavioural and neuroimaging evidence for an impact of anxiety on emotional processing) will be investigated in future studies.</p>
      <p>The initial phase of the emotional expression effects observed in the studies reviewed here showed a frontocentral scalp distribution, while its later phase beyond 250 ms post-stimulus was more broadly distributed (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>), thus strongly suggesting that different neural generators are activated during early and later stages of this emotional positivity. While similar broadly distributed longer latency positivities have been reported in previous ERP studies for emotionally salient non-face stimuli (<xref rid="bib21 bib25 bib52" ref-type="bibr">Cuthbert et al., 2000; Diedrich et al., 1997; Keil et al., 2002</xref>), differential ERP modulations at latencies below 200 ms have not been found with other types of emotional material, thus suggesting that such rapid effects might be specific for emotional faces (see <xref rid="bib8" ref-type="bibr">Ashley et al., 2003</xref>, for similar early ERP effects of emotional facial expression).</p>
      <p>The short onset latency of emotional expression effects observed in the ERP studies reviewed in this paper might suggest that the early phase of these effects reflects the rapid pre-attentive automatic assessment of the emotional content of faces, as implemented by structures such as the amygdala. One obvious objection against this hypothesis is that it is highly unlikely that the effects of emotional expression on ERP waveforms reviewed in this paper are generated in the amygdala, given its deep position and its electrically closed nuclear structure of clustered neurons (unlike the regular alignment of neurons in layers of the neocortex). Of course, even though amygdala activations themselves are unlikely to result in measurable ERP responses at the scalp surface, rapid automatic amygdala activations triggered by emotional faces might still be relayed directly to neocortical areas (<xref rid="bib61" ref-type="bibr">Morris et al., 1998</xref>), where they could be picked up via ERPs. It is conceivable that the early emotional expression effects observed in our ERP studies reflect activity within a neural network involved in the rapid automatic classification of emotional faces, which includes limbic structures as well as interconnected neocortical regions. However, several other findings from our ERP studies provide strong evidence against such a hypothesis. First, we found that ERP emotional expression effects were triggered at comparable latencies, and showed similar amplitudes and scalp topographies for all six basic emotions (<xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref>). Although clearly preliminary (see the cautionary comments in Section <xref rid="sec2" ref-type="sec">3</xref>), this finding contrasts markedly with the emotion-specificity of the neural structures assumed to be involved in the rapid automatic evaluation of emotional content. Several studies have found a disproportionate activation of the amygdala in response to facial expressions of fear (<xref rid="bib14 bib62 bib75 bib97" ref-type="bibr">Breiter et al., 1996; Morris et al., 1996; Phillips et al., 1998; Whalen et al., 2001</xref>). Insula and basal ganglia seem to be particularly involved in processing facial expressions of disgust (<xref rid="bib3 bib18 bib19 bib74 bib75 bib90" ref-type="bibr">Adolphs et al., 2003; Calder et al., 2000, 2001; Phillips et al., 1997, 1998; Sprengelmeyer et al., 1998</xref>), and prefrontal areas appear to be specifically implicated in the recognition of angry faces (<xref rid="bib13" ref-type="bibr">Blair, Morris, Frith, Perrett, &amp; Dolan, 1999</xref>; <xref rid="bib40" ref-type="bibr">Harmer, Thilo, Rothwell, &amp; Goodwin, 2001</xref>). Second, we found that ERP responses to emotional faces are not selectively driven by low spatial frequency information (<xref rid="bib47" ref-type="bibr">Holmes et al., 2005b</xref>). Again, this observation contrasts with previous observations for structures subserving the automatic classification of emotional input, such as the amygdala, which has been found to be preferentially activated by LSF signals (<xref rid="bib93 bib99" ref-type="bibr">Vuilleumier et al., 2003; Winston et al., 2004</xref>). And finally, fear-specific amygdala activation appears to start only at latencies of 200 ms (<xref rid="bib53" ref-type="bibr">Krolak-Salmon et al., 2004</xref>), and thus considerably later than the early emotional expression effects observed in our studies. This observation casts further doubt on the hypothesis that rapid amygdala signals are responsible for these ERP effects.</p>
      <p>The most important evidence against the hypothesis that ERP modulations sensitive to emotional facial expression are generated during the initial automatic classification of emotional content comes from our finding that spatial attention had a strong modulatory effect on these modulations. When faces were presented foveally, early emotional expression effects (but not longer latency effects) were triggered independently of the current focus of attention. However, and most importantly, even these early effects were completely eliminated when attention was directed away from the location of peripheral emotional faces towards another perceptual task (<xref rid="bib31 bib46" ref-type="bibr">Eimer et al., 2003; Holmes et al., 2003</xref>). This observation is clearly at odds with the idea that early emotional expression effects reflect the pre-attentive registration of facial expression. Recent fMRI evidence suggests that amygdala responses to fearful faces are unaffected by attention (<xref rid="bib54 bib92" ref-type="bibr">Lane et al., 1999; Vuilleumier et al., 2001</xref>), indicating that the amygdala is part of a network involved in the pre-attentive automatic detection of emotional content. The strong dependence of ERP emotional expression effects on spatial attention demonstrated in our studies implies that the processes responsible for the generation of these effects are functionally distinct from this pre-attentive detection network. One could speculate that this remarkable effect of attention on emotional expression processing, as reflected by the absence of any differential ERP effects for unattended emotional faces, might be mediated by control structures in orbitofrontal cortex. Orbitofrontal regulatory processes can suppress responses to emotional stimuli in the amygdala as well as in higher-order emotion areas (<xref rid="bib23" ref-type="bibr">Davidson, 2002</xref>; <xref rid="bib36" ref-type="bibr">Freedman, Black, Ebert, &amp; Binns, 1998</xref>; <xref rid="bib83" ref-type="bibr">Rolls, 1996</xref>). Orbitofrontal cortex has also been implicated in monitoring and restricting affective impulses through feedback mechanisms (<xref rid="bib84" ref-type="bibr">Rolls, 1999</xref>; see also <xref rid="bib85" ref-type="bibr">Rolls, 2006</xref>, this issue), and has been posited as a key structure in the reallocation of attention when emotional faces are task irrelevant (<xref rid="bib92" ref-type="bibr">Vuilleumier et al., 2001</xref>).</p>
      <p>It is conceivable that the absence of early emotional expression effects in response to unattended peripheral emotional faces found in our previous studies (<xref rid="bib31 bib46" ref-type="bibr">Eimer et al., 2003; Holmes et al., 2003</xref>) may be due to the fact that observers were unable to identify facial expressions when attention was directed elsewhere. Although face identification performance was excellent when peripheral faces were attended, the possibility that observers are unaware of emotional expressions when attention is diverted has not yet been explicitly addressed. Links between attention, early emotional expression effects, and the presence versus absence of conscious awareness of facial expressions will need to be systematically investigated in future studies.</p>
      <p>It should also be stressed that amygdala activations in response to emotional stimuli do not always and exclusively represent a rapid and automatic classification of these stimuli. Attentional modulations of amygdala responses to fearful or happy facial expressions have in fact been observed (<xref rid="bib72 bib73" ref-type="bibr">Pessoa et al., 2002a, 2002b</xref>), and modulations of amygdala activation were also found as a function of top–down control processes involved in the intentional regulation or reinterpretation of affective information (<xref rid="bib64" ref-type="bibr">Ochsner, Bunge, Gross, &amp; Gabrielli, 2002</xref>; <xref rid="bib87" ref-type="bibr">Schaefer et al., 2002</xref>). These findings suggest that the amygdala may also play an important role during later processing stages where the processing of emotional information is under attentional control and conscious representations of emotional content are generated.</p>
      <p>Overall, our findings that ERP modulations in response to emotional faces were triggered in a very similar fashion for all basic facial expressions, were not selectively driven by low spatial frequency information, but were strongly modulated by attention all suggest that these effects are elicited during stages in the processing of emotional information that are located beyond the initial rapid and automatic classification of emotional content. The outcome of an initial rapid and automatic appraisal of emotional stimuli will be fed into higher necortical stages of emotional processing, where the evaluation of emotional material is likely to continue in parallel with ongoing emotion evaluation in amygdala and related brain circuits. We suggest that emotional expression effects, as reflected by ERP waveforms in response to emotional faces, reflect processes at this later neocortical stage in the processing of emotional information.</p>
      <p>At present, it would be premature to speculate in more detail about specific cortical regions where the ERP effects reviewed in this paper might be generated, although regions such as anterior cingulate, somatosensory cortex, or medial prefrontal cortical areas seem plausible candidates. For example, <xref rid="bib92" ref-type="bibr">Vuilleumier, Armony, Driver, and Dolan (2001)</xref> have identified a dorsal region of the anterior cingulate, which showed greater activation when emotional faces were attended, analogous to our finding that ERP effects of emotional expression are strongly affected by attention. The dorsal subdivision of the anterior cingulate has been implied in functions such as attentional control, error and response conflict monitoring (<xref rid="bib17" ref-type="bibr">Bush, Luu, &amp; Posner, 2000</xref>; <xref rid="bib71" ref-type="bibr">Paus, Koski, Caramanos, &amp; Westbury, 1998</xref>; <xref rid="bib79" ref-type="bibr">Posner &amp; Rothbart, 1998</xref>), but also as a potential locus of emotional awareness (<xref rid="bib55" ref-type="bibr">Lane, Reiman, Axelrod, Holmes, &amp; Schwartz, 1998</xref>), consistent with evidence that this region participates directly in the affective component of personally experienced (<xref rid="bib82" ref-type="bibr">Rainville, Duncan, Price, Carrier, &amp; Bushnell, 1997</xref>) or observed (<xref rid="bib49" ref-type="bibr">Hutchison, Davis, Lozano, Tasker, &amp; Dostrovsky, 1999</xref>) pain.</p>
      <p>The analysis of emotional facial expression is based on a complex neural network, and includes both a rapid, obligatory, and pre-attentive classification of emotional content (implemented within the amygdala, orbitofrontal cortex, and ventral striatum), and the subsequent in-depth analysis of emotional faces in higher order necortical emotion areas (including somatosensory cortex, anterior cingulate, and medial prefrontal cortices). In spite of the fact that ERP effects of emotional facial expression are triggered at very short latencies, they are likely to reflect processes that form part of the second, higher level and attention-dependent emotional processing system, where representations of emotional content are generated in a strategic and task-dependent fashion for the adaptive intentional control of behaviour. Further studies will have to investigate to what extent effects of emotional facial expression on ERP waveforms, such as reviewed here, might represent the initial stages of higher level emotional processes, which may not just be involved in the analysis of emotionally relevant sensory stimuli, but perhaps also in the representation of subjective emotional states.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgements</title>
      <p>This research has been supported by a grant from the Biotechnology and Biological Sciences Research Council (BBSRC), UK. M.E. holds a Royal Society-Wolfson Research Merit Award. The authors thank two anonymous reviewers for helpful comments.</p>
    </ack>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p>Emotional expression effects for fearful and disgusted faces, which are not shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, were also similar to and statistically indistinguishable from the effects observed for the other emotions (see <xref rid="bib31" ref-type="bibr">Eimer et al., 2003</xref> for more details).</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p>It should be noted that in contrast to the findings reported here, some other studies have reported effects of emotional facial expression on early posterior ERP component, such as the P1 and N170 (e.g., <xref rid="bib9" ref-type="bibr">Batty &amp; Taylor, 2003</xref>), or even the earlier C1 component which is assumed to be generated in primary visual cortex (<xref rid="bib76 bib77" ref-type="bibr">Pourtois et al., 2004, 2005</xref>), thus suggesting that under certain experimental conditions, emotional facial expression may be able to modulate early stages of perceptual processing in sensory-specific visual areas.</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adolphs</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Neural systems for recognizing emotion</article-title>
          <source>Current Opinion in Neurobiology</source>
          <year>2002</year>
          <volume>12</volume>
          <fpage>169</fpage>
          <lpage>178</lpage>
          <pub-id pub-id-type="pmid">12015233</pub-id>
        </citation>
      </ref>
      <ref id="bib2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adolphs</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Cognitive neuroscience of human social behaviour</article-title>
          <source>Nature Reviews Neuroscience</source>
          <year>2003</year>
          <volume>4</volume>
          <fpage>165</fpage>
          <lpage>178</lpage>
        </citation>
      </ref>
      <ref id="bib3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Adolphs</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Tranel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable neural systems for recognizing emotions</article-title>
          <source>Brain and Cognition</source>
          <year>2003</year>
          <volume>52</volume>
          <fpage>61</fpage>
          <lpage>69</lpage>
          <pub-id pub-id-type="pmid">12812805</pub-id>
        </citation>
      </ref>
      <ref id="bib4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Allison</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Social perception from visual cues: Role of the STS region</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year>2000</year>
          <volume>4</volume>
          <fpage>267</fpage>
          <lpage>278</lpage>
          <pub-id pub-id-type="pmid">10859571</pub-id>
        </citation>
      </ref>
      <ref id="bib5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Allison</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Spencer</surname>
              <given-names>D.D.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological studies of human face perception. I. Potentials generated in occipitotemporal cortex by face and non-face stimuli</article-title>
          <source>Cerebral Cortex</source>
          <year>1999</year>
          <volume>9</volume>
          <fpage>415</fpage>
          <lpage>430</lpage>
          <pub-id pub-id-type="pmid">10450888</pub-id>
        </citation>
      </ref>
      <ref id="bib6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Amaral</surname>
              <given-names>D.G.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>J.L.</given-names>
            </name>
          </person-group>
          <article-title>Amygdalo-cortical projections in the monkey (Macaca fasicularis)</article-title>
          <source>Journal of Comparative Neurology</source>
          <year>1984</year>
          <volume>230</volume>
          <fpage>465</fpage>
          <lpage>496</lpage>
          <pub-id pub-id-type="pmid">6520247</pub-id>
        </citation>
      </ref>
      <ref id="bib7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>A.K.</given-names>
            </name>
            <name>
              <surname>Christoff</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Panitz</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>De Rosa</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Gabrieli</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of the automatic processing of threat signals</article-title>
          <source>Journal of Neuroscience</source>
          <year>2003</year>
          <volume>23</volume>
          <fpage>5627</fpage>
          <lpage>5633</lpage>
          <pub-id pub-id-type="pmid">12843265</pub-id>
        </citation>
      </ref>
      <ref id="bib8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ashley</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Swick</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Time course and specificity of event-related potentials to emotional expressions</article-title>
          <source>Neuroreport</source>
          <year>2003</year>
          <volume>15</volume>
          <fpage>211</fpage>
          <lpage>216</lpage>
          <pub-id pub-id-type="pmid">15106860</pub-id>
        </citation>
      </ref>
      <ref id="bib9">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Batty</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Early processing of the six basic facial emotional expressions</article-title>
          <source>Cognitive Brain Research</source>
          <year>2003</year>
          <volume>17</volume>
          <fpage>613</fpage>
          <lpage>620</lpage>
          <pub-id pub-id-type="pmid">14561449</pub-id>
        </citation>
      </ref>
      <ref id="bib10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bentin</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Allison</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Perez</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological studies of face perception in humans</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <year>1996</year>
          <volume>8</volume>
          <fpage>551</fpage>
          <lpage>565</lpage>
        </citation>
      </ref>
      <ref id="bib11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Berson</surname>
              <given-names>D.M.</given-names>
            </name>
          </person-group>
          <article-title>Retinal and cortical inputs to cat superior colliculus: Composition, convergence and laminar specificity</article-title>
          <source>Progressive Brain Research</source>
          <year>1988</year>
          <volume>75</volume>
          <fpage>17</fpage>
          <lpage>26</lpage>
        </citation>
      </ref>
      <ref id="bib12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bishop</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Duncan</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lawrence</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>State anxiety modulation of the amygdala response to unattended threat-related stimuli</article-title>
          <source>Journal of Neuroscience</source>
          <year>2004</year>
          <volume>24</volume>
          <fpage>10364</fpage>
          <lpage>10368</lpage>
          <pub-id pub-id-type="pmid">15548650</pub-id>
        </citation>
      </ref>
      <ref id="bib13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Blair</surname>
              <given-names>R.J.R.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable neural responses to facial expressions of sadness and anger</article-title>
          <source>Brain</source>
          <year>1999</year>
          <volume>122</volume>
          <fpage>883</fpage>
          <lpage>893</lpage>
          <pub-id pub-id-type="pmid">10355673</pub-id>
        </citation>
      </ref>
      <ref id="bib14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Breiter</surname>
              <given-names>H.C.</given-names>
            </name>
            <name>
              <surname>Etcoff</surname>
              <given-names>N.L.</given-names>
            </name>
            <name>
              <surname>Whalen</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Kennedy</surname>
              <given-names>W.A.</given-names>
            </name>
            <name>
              <surname>Rauch</surname>
              <given-names>S.L.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
          </person-group>
          <article-title>Response and habituation of the human amygdala during visual processing of facial expression</article-title>
          <source>Neuron</source>
          <year>1996</year>
          <volume>17</volume>
          <fpage>875</fpage>
          <lpage>887</lpage>
          <pub-id pub-id-type="pmid">8938120</pub-id>
        </citation>
      </ref>
      <ref id="bib15">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Breitmeyer</surname>
              <given-names>B.G.</given-names>
            </name>
          </person-group>
          <article-title>Parallel processing in human vision: History, review, and critique</article-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Brannan</surname>
              <given-names>J.R.</given-names>
            </name>
          </person-group>
          <source>Applications of parallel processing of vision</source>
          <year>1992</year>
          <publisher-name>North-Holland</publisher-name>
          <publisher-loc>Amsterdam</publisher-loc>
          <fpage>37</fpage>
          <lpage>86</lpage>
        </citation>
      </ref>
      <ref id="bib16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Understanding face recognition</article-title>
          <source>British Journal of Psychology</source>
          <year>1986</year>
          <volume>77</volume>
          <fpage>305</fpage>
          <lpage>327</lpage>
          <pub-id pub-id-type="pmid">3756376</pub-id>
        </citation>
      </ref>
      <ref id="bib17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bush</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Luu</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Posner</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>Cognitive and emotional influences in anterior cingulate cortex</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year>2000</year>
          <volume>4</volume>
          <fpage>215</fpage>
          <lpage>222</lpage>
          <pub-id pub-id-type="pmid">10827444</pub-id>
        </citation>
      </ref>
      <ref id="bib18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Keane</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Manes</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Antoun</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Impaired recognition and experience of disgust following brain injury</article-title>
          <source>Nature Neuroscience</source>
          <year>2000</year>
          <volume>3</volume>
          <fpage>1077</fpage>
          <lpage>1078</lpage>
        </citation>
      </ref>
      <ref id="bib19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Lawrence</surname>
              <given-names>A.D.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Neuropsychology of fear and loathing</article-title>
          <source>Nature Reviews Neuroscience</source>
          <year>2001</year>
          <volume>2</volume>
          <fpage>352</fpage>
          <lpage>363</lpage>
        </citation>
      </ref>
      <ref id="bib20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carretie</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Hinojosa</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Mercado</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Cerebral patterns of attentional habituation to emotional visual stimuli</article-title>
          <source>Psychophysiology</source>
          <year>2003</year>
          <volume>40</volume>
          <fpage>381</fpage>
          <lpage>388</lpage>
          <pub-id pub-id-type="pmid">12946112</pub-id>
        </citation>
      </ref>
      <ref id="bib21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cuthbert</surname>
              <given-names>B.N.</given-names>
            </name>
            <name>
              <surname>Schupp</surname>
              <given-names>H.T.</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Birbaumer</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>P.J.</given-names>
            </name>
          </person-group>
          <article-title>Brain potentials in affective picture processing: Covariation with autonomic arousal and affective report</article-title>
          <source>Biological Psychology</source>
          <year>2000</year>
          <volume>52</volume>
          <fpage>95</fpage>
          <lpage>111</lpage>
          <pub-id pub-id-type="pmid">10699350</pub-id>
        </citation>
      </ref>
      <ref id="bib22">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
          </person-group>
          <article-title>The feeling of what happens: Body and emotion in the making of consciousness</article-title>
          <year>1999</year>
          <publisher-name>Harcourt Brace</publisher-name>
          <publisher-loc>New York</publisher-loc>
        </citation>
      </ref>
      <ref id="bib23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Davidson</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Anxiety and affective style: Role of prefrontal cortex and amygdala</article-title>
          <source>Biological Psychiatry</source>
          <year>2002</year>
          <volume>51</volume>
          <fpage>68</fpage>
          <lpage>80</lpage>
          <pub-id pub-id-type="pmid">11801232</pub-id>
        </citation>
      </ref>
      <ref id="bib24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>de Gelder</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Teunisse</surname>
              <given-names>J.-P.</given-names>
            </name>
            <name>
              <surname>Benson</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Categorical perception of facial expressions: Categories and their internal structure</article-title>
          <source>Cognition and Emotion</source>
          <year>1997</year>
          <volume>11</volume>
          <fpage>1</fpage>
          <lpage>23</lpage>
        </citation>
      </ref>
      <ref id="bib25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Diedrich</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Naumann</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Maier</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Becker</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>A frontal slow wave in the ERP associated with emotional slides</article-title>
          <source>Journal of Psychophysiology</source>
          <year>1997</year>
          <volume>11</volume>
          <fpage>71</fpage>
          <lpage>84</lpage>
        </citation>
      </ref>
      <ref id="bib26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Emotion, cognition, and behavior</article-title>
          <source>Science</source>
          <year>2002</year>
          <volume>298</volume>
          <fpage>1191</fpage>
          <lpage>1194</lpage>
          <pub-id pub-id-type="pmid">12424363</pub-id>
        </citation>
      </ref>
      <ref id="bib27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eastwood</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Smilek</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Merikle</surname>
              <given-names>P.M.</given-names>
            </name>
          </person-group>
          <article-title>Differential attentional guidance by unattended faces expressing positive and negative emotion</article-title>
          <source>Perception and Psychophysics</source>
          <year>2001</year>
          <volume>63</volume>
          <fpage>1004</fpage>
          <lpage>1013</lpage>
          <pub-id pub-id-type="pmid">11578045</pub-id>
        </citation>
      </ref>
      <ref id="bib28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Does the face-specific N170 component reflect the activity of a specialized eye detector?</article-title>
          <source>Neuroreport</source>
          <year>1998</year>
          <volume>9</volume>
          <fpage>2945</fpage>
          <lpage>2948</lpage>
          <pub-id pub-id-type="pmid">9804295</pub-id>
        </citation>
      </ref>
      <ref id="bib29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The face-specific N170 component reflects late stages in the structural encoding of faces</article-title>
          <source>Neuroreport</source>
          <year>2000</year>
          <volume>11</volume>
          <fpage>2319</fpage>
          <lpage>2324</lpage>
          <pub-id pub-id-type="pmid">10923693</pub-id>
        </citation>
      </ref>
      <ref id="bib30">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>An ERP study on the time course of emotional face processing</article-title>
          <source>Neuroreport</source>
          <year>2002</year>
          <volume>13</volume>
          <fpage>427</fpage>
          <lpage>431</lpage>
          <pub-id pub-id-type="pmid">11930154</pub-id>
        </citation>
      </ref>
      <ref id="bib31">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>McGlone</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>The role of spatial attention in the processing of facial expression: An ERP study of rapid brain responses to six basic emotions</article-title>
          <source>Cognitive, Affective, and Behavioral Neuroscience</source>
          <year>2003</year>
          <volume>3</volume>
          <fpage>97</fpage>
          <lpage>110</lpage>
        </citation>
      </ref>
      <ref id="bib32">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ekman</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Friesen</surname>
              <given-names>W.V.</given-names>
            </name>
          </person-group>
          <article-title>Pictures of facial affect</article-title>
          <year>1976</year>
          <publisher-name>Consulting Psychologists Press</publisher-name>
          <publisher-loc>Palo Alto, CA</publisher-loc>
        </citation>
      </ref>
      <ref id="bib33">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Etcoff</surname>
              <given-names>N.L.</given-names>
            </name>
          </person-group>
          <article-title>Selective attention to facial identity and facial emotion</article-title>
          <source>Neuropsychologia</source>
          <year>1984</year>
          <volume>22</volume>
          <fpage>281</fpage>
          <lpage>295</lpage>
          <pub-id pub-id-type="pmid">6462422</pub-id>
        </citation>
      </ref>
      <ref id="bib34">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fox</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Processing emotional facial expressions: The role of anxiety and awareness</article-title>
          <source>Cognitive, Affective, and Behavioral Neuroscience</source>
          <year>2002</year>
          <volume>2</volume>
          <fpage>52</fpage>
          <lpage>63</lpage>
        </citation>
      </ref>
      <ref id="bib35">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fox</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Lester</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Russo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bowles</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Pichler</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Dutton</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Facial expressions of emotion: Are angry faces detected more efficiently?</article-title>
          <source>Cognition and Emotion</source>
          <year>2000</year>
          <volume>14</volume>
          <fpage>61</fpage>
          <lpage>92</lpage>
          <pub-id pub-id-type="pmid">17401453</pub-id>
        </citation>
      </ref>
      <ref id="bib36">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Freedman</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Black</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ebert</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Binns</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Orbitofrontal function, object alternation and perseveration</article-title>
          <source>Cerebral Cortex</source>
          <year>1998</year>
          <volume>8</volume>
          <fpage>18</fpage>
          <lpage>27</lpage>
          <pub-id pub-id-type="pmid">9510382</pub-id>
        </citation>
      </ref>
      <ref id="bib37">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gobbini</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
          </person-group>
          <article-title>Neural systems for recognition of familiar faces</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
          <comment>(this issue)</comment>
        </citation>
      </ref>
      <ref id="bib38">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Graham</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Devinsky</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>LaBar</surname>
              <given-names>K.S.</given-names>
            </name>
          </person-group>
          <article-title>Quantifying deficits in the perception of fear and anger in morphed facial expressions after bilateral amygdala damage</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
          <comment>(this issue)</comment>
        </citation>
      </ref>
      <ref id="bib39">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hansen</surname>
              <given-names>C.H.</given-names>
            </name>
            <name>
              <surname>Hansen</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <article-title>Finding the face in the crowd: An anger superiority effect</article-title>
          <source>Journal of Personality and Social Psychology</source>
          <year>1988</year>
          <volume>54</volume>
          <fpage>917</fpage>
          <lpage>924</lpage>
          <pub-id pub-id-type="pmid">3397866</pub-id>
        </citation>
      </ref>
      <ref id="bib40">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Harmer</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Thilo</surname>
              <given-names>K.V.</given-names>
            </name>
            <name>
              <surname>Rothwell</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Goodwin</surname>
              <given-names>G.M.</given-names>
            </name>
          </person-group>
          <article-title>Transcranial magnetic stimulation of medial-frontal cortex impairs the processing of angry facial expressions</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>17</fpage>
          <lpage>18</lpage>
        </citation>
      </ref>
      <ref id="bib41">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Hoffman</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>I.M.</given-names>
            </name>
          </person-group>
          <article-title>The distributed human neural system for face perception</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year>2000</year>
          <volume>4</volume>
          <fpage>223</fpage>
          <lpage>233</lpage>
          <pub-id pub-id-type="pmid">10827445</pub-id>
        </citation>
      </ref>
      <ref id="bib42">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hoffman</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
          </person-group>
          <article-title>Distinct representations of eye gaze and identity in the distributed human neural system for face perception</article-title>
          <source>Nature Neuroscience</source>
          <year>2000</year>
          <volume>3</volume>
          <fpage>80</fpage>
          <lpage>84</lpage>
        </citation>
      </ref>
      <ref id="bib43">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Green</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>The involvement of distinct visual channels in rapid attention towards fearful facial expressions</article-title>
          <source>Cognition and Emotion</source>
          <year>2005</year>
          <volume>19</volume>
          <fpage>899</fpage>
          <lpage>922</lpage>
        </citation>
      </ref>
      <ref id="bib44">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kiss</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Attention modulates the processing of emotional expression triggered by foveal faces</article-title>
          <source>Neuroscience Letters</source>
          <year>2006</year>
          <volume>394</volume>
          <fpage>48</fpage>
          <lpage>52</lpage>
          <pub-id pub-id-type="pmid">16257119</pub-id>
        </citation>
      </ref>
      <ref id="bib45">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Richards</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Green</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Anxiety and sensitivity to eye gaze in emotional faces</article-title>
          <source>Brain and Cognition</source>
          <year>2006</year>
          <volume>60</volume>
          <fpage>282</fpage>
          <lpage>294</lpage>
          <pub-id pub-id-type="pmid">16510226</pub-id>
        </citation>
      </ref>
      <ref id="bib46">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The processing of emotional facial expression is gated by spatial attention: Evidence from event-related brain potentials</article-title>
          <source>Cognitive Brain Research</source>
          <year>2003</year>
          <volume>16</volume>
          <fpage>174</fpage>
          <lpage>184</lpage>
          <pub-id pub-id-type="pmid">12668225</pub-id>
        </citation>
      </ref>
      <ref id="bib47">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Winston</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Eimer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The role of spatial frequency information for ERP components sensitive to faces and emotional facial expression</article-title>
          <source>Cognitive Brain Research</source>
          <year>2005</year>
          <volume>25</volume>
          <fpage>508</fpage>
          <lpage>520</lpage>
          <pub-id pub-id-type="pmid">16168629</pub-id>
        </citation>
      </ref>
      <ref id="bib48">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hornak</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rolls</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Wade</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Face and voice expression identification in patients with emotional and behavioural changes following ventral frontal lobe damage</article-title>
          <source>Neuropsychologia</source>
          <year>1996</year>
          <volume>34</volume>
          <fpage>247</fpage>
          <lpage>261</lpage>
          <pub-id pub-id-type="pmid">8657356</pub-id>
        </citation>
      </ref>
      <ref id="bib49">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hutchison</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Davis</surname>
              <given-names>K.D.</given-names>
            </name>
            <name>
              <surname>Lozano</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Tasker</surname>
              <given-names>R.R.</given-names>
            </name>
            <name>
              <surname>Dostrovsky</surname>
              <given-names>J.O.</given-names>
            </name>
          </person-group>
          <article-title>Pain-related neurons in the human cingulate cortex</article-title>
          <source>Nature Neuroscience</source>
          <year>1999</year>
          <volume>2</volume>
          <fpage>403</fpage>
          <lpage>405</lpage>
        </citation>
      </ref>
      <ref id="bib50">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Itier</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Taylor</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Source analysis of the N170 to faces and objects</article-title>
          <source>Neuroreport</source>
          <year>2004</year>
          <volume>15</volume>
          <fpage>1261</fpage>
          <lpage>1265</lpage>
          <pub-id pub-id-type="pmid">15167545</pub-id>
        </citation>
      </ref>
      <ref id="bib51">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kawasaki</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Kaufman</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Granner</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bakken</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Single-neuron responses to emotional visual stimuli recorded in human ventral prefrontal cortex</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>15</fpage>
          <lpage>16</lpage>
        </citation>
      </ref>
      <ref id="bib52">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Keil</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Hauk</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Rockstroh</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Elbert</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>P.J.</given-names>
            </name>
          </person-group>
          <article-title>Large-scale neural correlates of affective picture processing</article-title>
          <source>Psychophysiology</source>
          <year>2002</year>
          <volume>39</volume>
          <fpage>641</fpage>
          <lpage>649</lpage>
          <pub-id pub-id-type="pmid">12236331</pub-id>
        </citation>
      </ref>
      <ref id="bib53">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Krolak-Salmon</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Henaff</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Vighetto</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Betrand</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Maugiere</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: A depth electrode ERP study in human</article-title>
          <source>Neuron</source>
          <year>2004</year>
          <volume>42</volume>
          <fpage>665</fpage>
          <lpage>676</lpage>
          <pub-id pub-id-type="pmid">15157426</pub-id>
        </citation>
      </ref>
      <ref id="bib54">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lane</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Chua</surname>
              <given-names>P.M.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Common effects of emotional valence, arousal and attention on neural activation during visual processing of pictures</article-title>
          <source>Neuropsychologia</source>
          <year>1999</year>
          <volume>37</volume>
          <fpage>989</fpage>
          <lpage>997</lpage>
          <pub-id pub-id-type="pmid">10468363</pub-id>
        </citation>
      </ref>
      <ref id="bib55">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lane</surname>
              <given-names>R.D.</given-names>
            </name>
            <name>
              <surname>Reiman</surname>
              <given-names>E.M.</given-names>
            </name>
            <name>
              <surname>Axelrod</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>G.E.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of levels of emotional awareness: Evidence of an interaction between emotion and attention in anterior cingulated cortex</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <year>1998</year>
          <volume>10</volume>
          <fpage>525</fpage>
          <lpage>535</lpage>
          <pub-id pub-id-type="pmid">9712681</pub-id>
        </citation>
      </ref>
      <ref id="bib56">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Le Doux</surname>
              <given-names>J.E.</given-names>
            </name>
          </person-group>
          <article-title>The emotional brain</article-title>
          <year>1996</year>
          <publisher-name>Simon and Schuster</publisher-name>
          <publisher-loc>New York</publisher-loc>
        </citation>
      </ref>
      <ref id="bib57">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leventhal</surname>
              <given-names>A.G.</given-names>
            </name>
            <name>
              <surname>Rodieck</surname>
              <given-names>R.W.</given-names>
            </name>
            <name>
              <surname>Dreher</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Central projections of cat retinal ganglion cells</article-title>
          <source>Journal of Comparative Neurology</source>
          <year>1985</year>
          <volume>237</volume>
          <fpage>216</fpage>
          <lpage>226</lpage>
          <pub-id pub-id-type="pmid">4031122</pub-id>
        </citation>
      </ref>
      <ref id="bib58">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Livingstone</surname>
              <given-names>M.S.</given-names>
            </name>
            <name>
              <surname>Hubel</surname>
              <given-names>D.H.</given-names>
            </name>
          </person-group>
          <article-title>Segregation of form, color, movement, and depth: Anatomy, physiology, and perception</article-title>
          <source>Science</source>
          <year>1988</year>
          <volume>240</volume>
          <fpage>740</fpage>
          <lpage>749</lpage>
          <pub-id pub-id-type="pmid">3283936</pub-id>
        </citation>
      </ref>
      <ref id="bib59">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mogg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>B.P.</given-names>
            </name>
          </person-group>
          <article-title>Orienting of attention to threatening facial expressions presented under conditions of restricted awareness</article-title>
          <source>Cognition and Emotion</source>
          <year>1999</year>
          <volume>13</volume>
          <fpage>713</fpage>
          <lpage>740</lpage>
        </citation>
      </ref>
      <ref id="bib60">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mogg</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>McNamara</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Powys</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Rawlinson</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Seiffer</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bradley</surname>
              <given-names>B.P.</given-names>
            </name>
          </person-group>
          <article-title>Selective attention to threat: A test of two cognitive models of anxiety</article-title>
          <source>Cognition and Emotion</source>
          <year>2000</year>
          <volume>14</volume>
          <fpage>375</fpage>
          <lpage>399</lpage>
        </citation>
      </ref>
      <ref id="bib61">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morris</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Buechel</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>A neuromodulatory role for the human amygdala in processing emotional facial expressions</article-title>
          <source>Brain</source>
          <year>1998</year>
          <volume>121</volume>
          <fpage>47</fpage>
          <lpage>57</lpage>
          <pub-id pub-id-type="pmid">9549487</pub-id>
        </citation>
      </ref>
      <ref id="bib62">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morris</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Rowland</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>A differential neural response in the human amygdala to fearful and happy facial expressions</article-title>
          <source>Nature</source>
          <year>1996</year>
          <volume>383</volume>
          <fpage>812</fpage>
          <lpage>815</lpage>
          <pub-id pub-id-type="pmid">8893004</pub-id>
        </citation>
      </ref>
      <ref id="bib63">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morris</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Öhman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>A subcortical pathway to the right amygdala mediating “unseen” fear</article-title>
          <source>Proceedings of the National Academy of Sciences</source>
          <year>1999</year>
          <volume>96</volume>
          <fpage>1680</fpage>
          <lpage>1685</lpage>
        </citation>
      </ref>
      <ref id="bib64">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ochsner</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Bunge</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Gross</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Gabrielli</surname>
              <given-names>J.D.E.</given-names>
            </name>
          </person-group>
          <article-title>Rethinking feelings: An fMRI study of the cognitive regulation of emotion</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <year>2002</year>
          <volume>14</volume>
          <fpage>1215</fpage>
          <lpage>1229</lpage>
          <pub-id pub-id-type="pmid">12495527</pub-id>
        </citation>
      </ref>
      <ref id="bib65">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Öhman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Flykt</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Esteves</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Emotion drives attention: Detecting the snake in the grass</article-title>
          <source>Journal of Experimental Psychology: General</source>
          <year>2001</year>
          <volume>130</volume>
          <fpage>466</fpage>
          <lpage>478</lpage>
          <pub-id pub-id-type="pmid">11561921</pub-id>
        </citation>
      </ref>
      <ref id="bib66">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Öhman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lundqvist</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Esteves</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>The face in the crowd revisited: A threat advantage with schematic stimuli</article-title>
          <source>Journal of Personality and Social Psychology</source>
          <year>2001</year>
          <volume>80</volume>
          <fpage>381</fpage>
          <lpage>396</lpage>
          <pub-id pub-id-type="pmid">11300573</pub-id>
        </citation>
      </ref>
      <ref id="bib67">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Öhman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mineka</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Fears, phobias, and preparedness: Toward an evolved module of fear and fear learning</article-title>
          <source>Psychological Review</source>
          <year>2001</year>
          <volume>108</volume>
          <fpage>483</fpage>
          <lpage>522</lpage>
          <pub-id pub-id-type="pmid">11488376</pub-id>
        </citation>
      </ref>
      <ref id="bib68">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Palermo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rhodes</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Are you always on my mind? A review of how face perception and attention interact</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
          <comment>(this issue)</comment>
        </citation>
      </ref>
      <ref id="bib69">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Parry</surname>
              <given-names>F.M.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Saul</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Moss</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Dissociable face processing impairments after brain injury</article-title>
          <source>Journal of Clinical and Experimental Neuropsychology</source>
          <year>1991</year>
          <volume>13</volume>
          <fpage>545</fpage>
          <lpage>558</lpage>
          <pub-id pub-id-type="pmid">1918285</pub-id>
        </citation>
      </ref>
      <ref id="bib70">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pasley</surname>
              <given-names>B.N.</given-names>
            </name>
            <name>
              <surname>Mayes</surname>
              <given-names>L.C.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>R.T.</given-names>
            </name>
          </person-group>
          <article-title>Subcortical discrimination of unperceived objects during binocular rivalry</article-title>
          <source>Neuron</source>
          <year>2004</year>
          <volume>42</volume>
          <fpage>163</fpage>
          <lpage>172</lpage>
          <pub-id pub-id-type="pmid">15066273</pub-id>
        </citation>
      </ref>
      <ref id="bib71">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Paus</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Koski</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Caramanos</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Westbury</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Regional differences in the effects of task difficulty and motor output on blood flow response in the human anterior cingulate cortex: A review of 107 PET activation studies</article-title>
          <source>Neuroreport</source>
          <year>1998</year>
          <volume>9</volume>
          <fpage>37</fpage>
          <lpage>47</lpage>
          <pub-id pub-id-type="pmid">9592044</pub-id>
        </citation>
      </ref>
      <ref id="bib72">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pessoa</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Kastner</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Ungerleider</surname>
              <given-names>L.G.</given-names>
            </name>
          </person-group>
          <article-title>Attentional control of the processing of neutral and emotional stimuli</article-title>
          <source>Cognitive Brain Research</source>
          <year>2002</year>
          <volume>15</volume>
          <fpage>31</fpage>
          <lpage>45</lpage>
          <pub-id pub-id-type="pmid">12433381</pub-id>
        </citation>
      </ref>
      <ref id="bib73">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pessoa</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>McKenna</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gutierrez</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ungerleider</surname>
              <given-names>L.G.</given-names>
            </name>
          </person-group>
          <article-title>Neural processing of emotional faces requires attention</article-title>
          <source>Proceedings of the National Academy of Science USA</source>
          <year>2002</year>
          <volume>99</volume>
          <fpage>11458</fpage>
          <lpage>11463</lpage>
        </citation>
      </ref>
      <ref id="bib74">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Phillips</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Senior</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Brammer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Andrew</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>A specific neural substrate for perceiving facial expressions of disgust</article-title>
          <source>Nature</source>
          <year>1997</year>
          <volume>389</volume>
          <fpage>495</fpage>
          <lpage>498</lpage>
          <pub-id pub-id-type="pmid">9333238</pub-id>
        </citation>
      </ref>
      <ref id="bib75">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Phillips</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Scott</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Andrew</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Giampietro</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Neural responses to facial and vocal expressions of fear and disgust</article-title>
          <source>Proceedings of the Royal Society London Series B</source>
          <year>1998</year>
          <volume>265</volume>
          <fpage>1809</fpage>
          <lpage>1817</lpage>
        </citation>
      </ref>
      <ref id="bib76">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pourtois</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Grandjean</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Sander</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological correlates of rapid spatial orienting towards fearful faces</article-title>
          <source>Cerebral Cortex</source>
          <year>2004</year>
          <volume>14</volume>
          <fpage>619</fpage>
          <lpage>633</lpage>
          <pub-id pub-id-type="pmid">15054077</pub-id>
        </citation>
      </ref>
      <ref id="bib77">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pourtois</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Thut</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Grave de Peralta</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Michel</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Two electrophysiological stages of spatial orienting towards fearful faces: Early temporo-parietal activation preceding gain control in extrastriate visual cortex</article-title>
          <source>NeuroImage</source>
          <year>2005</year>
          <volume>26</volume>
          <fpage>149</fpage>
          <lpage>163</lpage>
          <pub-id pub-id-type="pmid">15862215</pub-id>
        </citation>
      </ref>
      <ref id="bib78">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Posamentier</surname>
              <given-names>M.T.</given-names>
            </name>
            <name>
              <surname>Abdi</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Processing faces and facial expressions</article-title>
          <source>Neuropsychology Review</source>
          <year>2003</year>
          <volume>13</volume>
          <fpage>113</fpage>
          <lpage>143</lpage>
          <pub-id pub-id-type="pmid">14584908</pub-id>
        </citation>
      </ref>
      <ref id="bib79">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Posner</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Rothbart</surname>
              <given-names>M.K.</given-names>
            </name>
          </person-group>
          <article-title>Attention, self regulation and consciousness</article-title>
          <source>Philosophical Transactions Royal Society London Series B</source>
          <year>1998</year>
          <volume>353</volume>
          <fpage>1915</fpage>
          <lpage>1927</lpage>
        </citation>
      </ref>
      <ref id="bib80">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Allison</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological studies of human face perception. III. Effects of top–down processing on face-specific potentials</article-title>
          <source>Cerebral Cortex</source>
          <year>1999</year>
          <volume>9</volume>
          <fpage>445</fpage>
          <lpage>458</lpage>
          <pub-id pub-id-type="pmid">10450890</pub-id>
        </citation>
      </ref>
      <ref id="bib81">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Puce</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Epling</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Thompson</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Carrick</surname>
              <given-names>O.K.</given-names>
            </name>
          </person-group>
          <article-title>Neural responses elicited to face motion and vocalization pairings</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
          <comment>(this issue)</comment>
        </citation>
      </ref>
      <ref id="bib82">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rainville</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Duncan</surname>
              <given-names>G.H.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>D.D.</given-names>
            </name>
            <name>
              <surname>Carrier</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Bushnell</surname>
              <given-names>M.C.</given-names>
            </name>
          </person-group>
          <article-title>Pain affect encoded in human anterior cingulate but not somatosensory cortex</article-title>
          <source>Science</source>
          <year>1997</year>
          <volume>277</volume>
          <fpage>968</fpage>
          <lpage>971</lpage>
          <pub-id pub-id-type="pmid">9252330</pub-id>
        </citation>
      </ref>
      <ref id="bib83">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rolls</surname>
              <given-names>E.T.</given-names>
            </name>
          </person-group>
          <article-title>The orbitofrontal cortex</article-title>
          <source>Philosophical Transactions Royal Society London B</source>
          <year>1996</year>
          <volume>351</volume>
          <fpage>1433</fpage>
          <lpage>1443</lpage>
        </citation>
      </ref>
      <ref id="bib84">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Rolls</surname>
              <given-names>E.T.</given-names>
            </name>
          </person-group>
          <article-title>The brain and emotion</article-title>
          <year>1999</year>
          <publisher-name>Oxford University Press</publisher-name>
          <publisher-loc>Oxford</publisher-loc>
        </citation>
      </ref>
      <ref id="bib85">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rolls</surname>
              <given-names>E.T.</given-names>
            </name>
          </person-group>
          <article-title>The representation of information about faces in the temporal and frontal lobes</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
          <comment>(this issue)</comment>
        </citation>
      </ref>
      <ref id="bib86">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Caldara</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Seghier</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Schuller</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Lazeyras</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Mayer</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>A network of occipito-temporal face-sensitive areas besides the right middle fusiform gyrus is necessary for normal face processing</article-title>
          <source>Brain</source>
          <year>2003</year>
          <volume>126</volume>
          <fpage>2381</fpage>
          <lpage>2395</lpage>
          <pub-id pub-id-type="pmid">12876150</pub-id>
        </citation>
      </ref>
      <ref id="bib87">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schaefer</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Jackson</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Davidson</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Aguirre</surname>
              <given-names>G.K.</given-names>
            </name>
            <name>
              <surname>Kimberg</surname>
              <given-names>D.Y.</given-names>
            </name>
            <name>
              <surname>Thompson-Schill</surname>
              <given-names>S.L.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of amygdala activity by the conscious regulation of negative emotion</article-title>
          <source>Journal of Cognitive Neuroscience</source>
          <year>2002</year>
          <volume>14</volume>
          <fpage>913</fpage>
          <lpage>921</lpage>
          <pub-id pub-id-type="pmid">12191458</pub-id>
        </citation>
      </ref>
      <ref id="bib88">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schiller</surname>
              <given-names>P.H.</given-names>
            </name>
            <name>
              <surname>Malpeli</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Schein</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>Composition of geniculostriate input to superior colliculus of the rhesus monkey</article-title>
          <source>Journal of Neurophysiology</source>
          <year>1979</year>
          <volume>42</volume>
          <fpage>1124</fpage>
          <lpage>1133</lpage>
          <pub-id pub-id-type="pmid">113508</pub-id>
        </citation>
      </ref>
      <ref id="bib89">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Searcy</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Bartlett</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Inversion and processing of component and spatial-relational information in faces</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <year>1996</year>
          <volume>22</volume>
          <fpage>904</fpage>
          <lpage>915</lpage>
          <pub-id pub-id-type="pmid">8756958</pub-id>
        </citation>
      </ref>
      <ref id="bib90">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sprengelmeyer</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rausch</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Eysel</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Przuntek</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Neural structures associated with recognition of facial expressions of basic emotions</article-title>
          <source>Proceedings for the Royal Society London Series B</source>
          <year>1998</year>
          <volume>265</volume>
          <fpage>1927</fpage>
          <lpage>1931</lpage>
        </citation>
      </ref>
      <ref id="bib91">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tranel</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Damasio</surname>
              <given-names>A.R.</given-names>
            </name>
          </person-group>
          <article-title>Nonconscious face recognition in patients with face agnosia</article-title>
          <source>Behavioural Brain Research</source>
          <year>1988</year>
          <volume>30</volume>
          <fpage>235</fpage>
          <lpage>249</lpage>
          <pub-id pub-id-type="pmid">3178995</pub-id>
        </citation>
      </ref>
      <ref id="bib92">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Armony</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Effects of attention and emotion on face processing in the human brain: An event-related fMRI study</article-title>
          <source>Neuron</source>
          <year>2001</year>
          <volume>30</volume>
          <fpage>829</fpage>
          <lpage>841</lpage>
          <pub-id pub-id-type="pmid">11430815</pub-id>
        </citation>
      </ref>
      <ref id="bib93">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Armony</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Distinct spatial frequency sensitivities for processing faces and emotional expressions</article-title>
          <source>Nature Neuroscience</source>
          <year>2003</year>
          <volume>6</volume>
          <fpage>624</fpage>
          <lpage>631</lpage>
        </citation>
      </ref>
      <ref id="bib94">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Pourtois</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Distributed and interactive brain mechanisms during emotion face perception: Evidence from functional neuroimaging</article-title>
          <source>Neuropsychologia</source>
          <year>2006</year>
        </citation>
      </ref>
      <ref id="bib95">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Emotional expressions capture attention</article-title>
          <source>Neurology</source>
          <year>2001</year>
          <volume>56</volume>
          <fpage>153</fpage>
          <lpage>158</lpage>
          <pub-id pub-id-type="pmid">11160948</pub-id>
        </citation>
      </ref>
      <ref id="bib96">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Schwartz</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Beware and be aware: Capture of spatial attention by fear-related stimuli in neglect</article-title>
          <source>Neuroreport</source>
          <year>2001</year>
          <volume>12</volume>
          <fpage>1119</fpage>
          <lpage>1122</lpage>
          <pub-id pub-id-type="pmid">11338176</pub-id>
        </citation>
      </ref>
      <ref id="bib97">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Whalen</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Shin</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>McInerney</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Fischer</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Wright</surname>
              <given-names>C.I.</given-names>
            </name>
            <name>
              <surname>Rauch</surname>
              <given-names>S.L.</given-names>
            </name>
          </person-group>
          <article-title>A functional MRI study of human amygdala responses to facial expressions of fear versus anger</article-title>
          <source>Emotion</source>
          <year>2001</year>
          <volume>1</volume>
          <fpage>70</fpage>
          <lpage>83</lpage>
          <pub-id pub-id-type="pmid">12894812</pub-id>
        </citation>
      </ref>
      <ref id="bib98">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Williams</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>McGlone</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Abbot</surname>
              <given-names>D.F.</given-names>
            </name>
            <name>
              <surname>Mattingley</surname>
              <given-names>J.B.</given-names>
            </name>
          </person-group>
          <article-title>Amygdala responses to fearful and happy facial expressions under conditions of binocular suppression</article-title>
          <source>Journal of Neuroscience</source>
          <year>2004</year>
          <volume>24</volume>
          <fpage>2898</fpage>
          <lpage>2904</lpage>
          <pub-id pub-id-type="pmid">15044528</pub-id>
        </citation>
      </ref>
      <ref id="bib99">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Winston</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Effects of low spatial frequency components of fearful faces on fusiform cortex activity</article-title>
          <source>Current Biology</source>
          <year>2004</year>
          <volume>13</volume>
          <fpage>1824</fpage>
          <lpage>1829</lpage>
          <pub-id pub-id-type="pmid">14561410</pub-id>
        </citation>
      </ref>
      <ref id="bib100">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Newcombe</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>de Haan</surname>
              <given-names>E.H.</given-names>
            </name>
            <name>
              <surname>Small</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hay</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Face perception after brain injury. Selective impairments affecting identity and expression</article-title>
          <source>Brain</source>
          <year>1993</year>
          <volume>116</volume>
          <fpage>941</fpage>
          <lpage>959</lpage>
          <pub-id pub-id-type="pmid">8353717</pub-id>
        </citation>
      </ref>
    </ref-list>
  </back>
  <floats-wrap>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>Grand-averaged ERP waveforms in response to fearful faces (solid lines) and neutral faces (dashed lines), displayed separately for upright faces (top panel) and inverted faces (bottom panel). Data from <xref rid="bib30" ref-type="bibr">Eimer and Holmes (2002)</xref>.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>Topographical maps showing scalp distributions of emotional expression effects for upright faces (top) and inverted faces (bottom), obtained by subtracting ERPs to neutral faces from ERPs to fearful faces within six successive post-stimulus latency windows. Red colours indicate an enhanced positivity for fearful relative to neutral faces, while blue colours indicate small or absent amplitude differences. Data from <xref rid="bib30" ref-type="bibr">Eimer and Holmes (2002)</xref>.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p><italic>Top:</italic> Stimulus setup used in the <xref rid="bib31" ref-type="bibr">Eimer et al. (2003)</xref> study. <italic>Bottom:</italic> Grand-averaged ERP waveforms elicited at midline electrode Fz in response to stimulus arrays containing neutral faces (dashed lines) or emotional faces (solid lines). ERPs are shown separately for blocks containing angry, disgusted, happy, and surprised faces. Data from <xref rid="bib31" ref-type="bibr">Eimer et al. (2003)</xref>.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>Grand-averaged ERPs in response to fearful faces (solid lines) and neutral faces (dashed lines) at lateral frontocentral electrodes (FC5/6, top panel) and at lateral temporal electrodes (T5/6, bottom panel). Data from <xref rid="bib30" ref-type="bibr">Eimer and Holmes (2002)</xref>.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Fig. 5</label>
      <caption>
        <p><italic>Top:</italic> Stimulus setup used in the <xref rid="bib46" ref-type="bibr">Holmes et al. (2003)</xref> study. <italic>Bottom:</italic> Grand-averaged ERP waveforms elicited at midline electrode Fz at lateral frontal electrodes F3/4 in response to stimulus arrays containing fearful faces (solid lines) or neutral faces (dashed lines), shown separately for trials where faces were presented at attended locations (faces-cued trials), and for trials where houses were presented at attended locations and faces were unattended (houses-cued trials). Data from <xref rid="bib46" ref-type="bibr">Holmes et al. (2003)</xref>.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig6">
      <label>Fig. 6</label>
      <caption>
        <p><italic>Top:</italic> Stimulus setup used in the <xref rid="bib31" ref-type="bibr">Eimer et al. (2003)</xref> study. <italic>Bottom:</italic> Grand-averaged ERP waveforms elicited at midline electrode Fz at lateral frontal electrodes F3/4 in response to stimulus arrays containing emotional faces (solid lines) or neutral faces (dashed lines), shown separately for blocks where faces were task-relevant and therefore attended (Emotion Task), and for blocks where lines were task-relevant and faces were unattended (Lines Task). Data from <xref rid="bib31" ref-type="bibr">Eimer et al. (2003)</xref>.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig7">
      <label>Fig. 7</label>
      <caption>
        <p><italic>Top:</italic> Stimulus setup used in our study of the impact of selective attention on the processing of foveal emotional faces. <italic>Bottom:</italic> Grand-averaged ERP waveforms elicited at midline electrodes Fz and Cz in response to stimulus arrays containing emotional faces (solid lines) or neutral faces (dashed lines), shown separately for blocks where faces were task-relevant and therefore attended (Emotion Task), and for blocks where lines were task-relevant and faces were unattended (Lines Task). Data from <xref rid="bib44" ref-type="bibr">Holmes et al. (2006a)</xref>.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <fig id="fig8">
      <label>Fig. 8</label>
      <caption>
        <p>Grand-averaged ERP waveforms elicited at midline electrodes Fz and Cz in response to fearful faces (solid lines) and neutral faces (dashed lines), shown separately for broadband (BSF) faces (left), high spatial frequency (HSF) faces (middle), and low spatial frequency (LSF) faces (right). Data from <xref rid="bib47" ref-type="bibr">Holmes et al. (2005b)</xref>.</p>
      </caption>
      <graphic xlink:href="gr8"/>
    </fig>
  </floats-wrap>
</article>