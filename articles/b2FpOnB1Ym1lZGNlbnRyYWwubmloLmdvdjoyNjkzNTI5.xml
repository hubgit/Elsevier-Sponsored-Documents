<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Brain Res</journal-id>
      <journal-title>Brain Research</journal-title>
      <issn pub-type="ppub">0006-8993</issn>
      <issn pub-type="epub">1872-6240</issn>
      <publisher>
        <publisher-name>Elsevier/North-Holland Biomedical Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2693529</article-id>
      <article-id pub-id-type="pmid">18789907</article-id>
      <article-id pub-id-type="publisher-id">BRES38466</article-id>
      <article-id pub-id-type="doi">10.1016/j.brainres.2008.08.037</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Report</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>The influence of colour and sound on neuronal activation during visual object naming</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Hocking</surname>
            <given-names>Julia</given-names>
          </name>
          <email>julia.hocking@cmr.uq.edu.au</email>
          <email>http://www.fmrilab.net</email>
          <email>julia.hocking@gmail.com</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Price</surname>
            <given-names>Cathy J.</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line><sup>a</sup>Centre for Magnetic Resonance, The University of Queensland, Brisbane, Australia</addr-line>
      </aff>
      <aff id="aff2">
        <addr-line><sup>b</sup>Wellcome Trust Centre for Neuroimaging, UCL, London, UK</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author. Centre for Magnetic Resonance The University of Queensland, St Lucia, Queensland, Australia, 4072. Fax: + 61 7 3365 3833. <email>julia.hocking@cmr.uq.edu.au</email><email>http://www.fmrilab.net</email><email>julia.hocking@gmail.com</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <day>19</day>
        <month>11</month>
        <year>2008</year>
      </pub-date>
      <volume>1241</volume>
      <issue>1</issue>
      <fpage>92</fpage>
      <lpage>102</lpage>
      <history>
        <date date-type="accepted">
          <day>10</day>
          <month>8</month>
          <year>2008</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2008 Elsevier B.V.</copyright-statement>
        <copyright-year>2008</copyright-year>
        <copyright-holder>Elsevier B.V.</copyright-holder>
        <license>
          <p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</p>
        </license>
      </permissions>
      <abstract>
        <title>Abstract</title>
        <p>This paper investigates how neuronal activation for naming photographs of objects is influenced by the addition of appropriate colour or sound. Behaviourally, both colour and sound are known to facilitate object recognition from visual form. However, previous functional imaging studies have shown inconsistent effects. For example, the addition of appropriate colour has been shown to reduce antero-medial temporal activation whereas the addition of sound has been shown to increase posterior superior temporal activation. Here we compared the effect of adding colour or sound cues in the same experiment. We found that the addition of either the appropriate colour or sound increased activation for naming photographs of objects in bilateral occipital regions and the right anterior fusiform. Moreover, the addition of colour reduced left antero-medial temporal activation but this effect was not observed for the addition of object sound. We propose that activation in bilateral occipital and right fusiform areas precedes the integration of visual form with either its colour or associated sound. In contrast, left antero-medial temporal activation is reduced because object recognition is facilitated after colour and form have been integrated.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Object naming</kwd>
        <kwd>Perceptual</kwd>
        <kwd>Conceptual</kwd>
        <kwd>Integration</kwd>
        <kwd>Audiovisual</kwd>
        <kwd>Crossmodal</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec>
      <label>1</label>
      <title>Introduction</title>
      <p>It is well documented that visual object processing proceeds in a hierarchy of stages with early sensory input activating primary visual occipital cortices and later stages of visual processing progressing anteriorly along ventral aspects of the occipito-temporal lobes (for a review see <xref rid="bib20" ref-type="bibr">Grill-Spector, 2003</xref>). Although a similar hierarchical model to visual processing has been proposed for auditory objects (<xref rid="bib13 bib34 bib46" ref-type="bibr">Clarke et al., 2000; Maeder et al., 2001; Rauschecker and Tian, 2000</xref>), it is not entirely clear how multimodal perceptual inputs are integrated into an amodal conceptual representation. In this paper we investigate how visual object naming is influenced by the addition of appropriate colour or sound.</p>
      <p>Behaviourally, object naming is facilitated when congruent perceptual cues are increased. This has been shown within the visual modality when objects are appropriately coloured (<xref rid="bib26 bib35 bib44 bib45" ref-type="bibr">Humphrey et al., 1994; Mapelli and Behrmann, 1997; Ostergaard and Davidoff, 1985; Price and Humphreys, 1989</xref>) and across modality for audiovisual speech processing (<xref rid="bib23 bib51" ref-type="bibr">Hershenson, 1962; Summerfield, 1992</xref>) and audiovisual nonverbal processing (<xref rid="bib19 bib32 bib53" ref-type="bibr">Giard and Perronet, 1999; Laurienti et al., 2003; Teder-Sälejärvi et al., 2005</xref>). Additional perceptual cues are particularly advantageous when an object has multiple structurally similar neighbours. For example, 4-legged animals or round fruits have many structurally and semantically similar neighbours that compete for selection (<xref rid="bib27 bib29 bib28 bib39" ref-type="bibr">Humphreys et al., 1995; Joseph and Gathers, 2003; Joseph and Proffitt, 1996; McRae et al., 1999</xref>). By increasing perceptual cues, for instance the provision of appropriate colour, competition is reduced and response times are facilitated.</p>
      <p>Functional neuroimaging studies have associated the perceptual facilitation with differential neuronal responses. For example, <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref> reported a relative decrease in activation in bilateral anterior temporal cortices and a right posterior middle temporal region for appropriately coloured pictures of objects compared to black and white pictures of the same stimuli. In contrast combined auditory and visual information has been shown to increase activation in a network of regions, including the posterior superior temporal sulcus (pSTS; e.g. <xref rid="bib4 bib22" ref-type="bibr">Beauchamp et al., 2004; Hein et al., 2007</xref>) and the antero-medial temporal lobe (e.g. <xref rid="bib52" ref-type="bibr">Taylor et al., 2006</xref>).</p>
      <p>The current literature therefore suggests that as the number and type of perceptual cues are increased, neuronal activation 1) increases in response to the presentation of crossmodal relative to uni-modal inputs, and 2) decreases when additional perceptual cues (e.g. form and colour) are presented within a modality. These contrasting patterns of activation could either be due to task differences (passive viewing versus naming) or the level of processing (perceptual or semantic) at which multimodal inputs are integrated within versus across modality. At the perceptual level, it has already been established that sensory processing in one modality can influence activation in another modality, for example, responses in auditory cortices to visual stimuli (<xref rid="bib43 bib57" ref-type="bibr">Nyberg et al., 2000; Wheeler et al., 2000</xref>), and responses in visual cortices to auditory stimuli (<xref rid="bib6" ref-type="bibr">Bookheimer et al., 1998</xref>). At the semantic processing level, functional imaging has shown that both visual and auditory inputs access a shared semantic system (<xref rid="bib6 bib7 bib50 bib54" ref-type="bibr">Bookheimer et al., 1998; Booth et al., 2002; Spitsyna et al., 2006; Thierry and Price, 2006</xref>).</p>
      <p>The functional imaging study reported here investigates the influence of both colour and sound on object naming in the same group of participants. Colour–form integration was investigated by comparing appropriately coloured objects to their black and white counterparts and to coloured squares. Likewise, sound–form integration was investigated by comparing photographs of objects with their corresponding sounds to photographs only and sounds only. This experimental design (see <xref rid="fig1" ref-type="fig">Fig. 1</xref> for details) enables the identification of regions where object naming activation is modulated by increased perceptual cues (1) independent of whether the additional perceptual cue is within or between modality (e.g. form and colour versus form and sound); and (2) dependent on whether the additional perceptual cue is within or between modality. Moreover, we can distinguish between the different levels at which colour or sound may influence neuronal patterns of activation. For example, if activation for two inputs (i.e. [form with colour] or [form with sound]) is higher than the average of each input alone (i.e. [form only plus colour only] or [form only plus sound only]), then the inputs must be influencing one another prior to or during the integration process. In contrast, if activation for two inputs is less than the average of each input alone, then the effect must be occurring after integration when two inputs have become one object. In addition to a whole brain analysis, previous studies provide us with a priori functional–anatomical hypotheses in two regions of interest. First, we expected to see decreased activation for colour–form integration in the bilateral medial anterior temporal and right posterior middle temporal regions reported by <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. Second, we expected increased activation for sound–form integration in the left posterior superior temporal cortex (<xref rid="bib4" ref-type="bibr">Beauchamp et al., 2004</xref>).</p>
    </sec>
    <sec>
      <label>2</label>
      <title>Results</title>
      <sec>
        <label>2.1</label>
        <title>Behavioural results</title>
        <p>Means and standard deviations are shown in <xref rid="tbl1" ref-type="table">Table 1</xref>. For the colour-form integration, pairwise <italic>t</italic>-tests between conditions revealed that response latencies for object naming were facilitated with the presence of colour (<italic>t</italic> = 2.519, <italic>p</italic> &lt; 0.015) and also significantly faster when naming colour patches relative to naming both black and white pictures (<italic>t</italic> = 8.801, <italic>p</italic> &lt; 0.0005) and colour pictures (<italic>t</italic> = 6.122, <italic>p</italic> &lt; 0.0005). For audiovisual integration, object naming latencies were neither facilitated nor inhibited when both sound and form information were simultaneously presented (<italic>t</italic> = 0.044, <italic>p</italic> = 0.965) although naming objects from their sound only was significantly slower than either form only (<italic>t</italic> = 13.062, <italic>p</italic> &lt; 0.0005) or form with sound (<italic>t</italic> = 15.10, <italic>p</italic> &lt; 0.0005). This effect for auditory naming is consistent with previous studies and may be due to the presentation duration of auditory relative to visual stimuli. Auditory recognition may not occur until stimulus presentation (up to 1500 ms) is complete, whereas picture presentation is complete at stimulus onset.</p>
      </sec>
      <sec>
        <label>2.2</label>
        <title>Functional imaging results</title>
        <sec>
          <label>2.2.1</label>
          <title>Whole brain analysis</title>
          <p>The main effect of additional perceptual cues (within and across modalities) was identified by comparing activation for the [form with colour; CF1] plus [form with sound; SF2] conditions to the corresponding [form only; F1, F2], [colour only; C1] and [sound only; S2] conditions. Activation was identified in bilateral occipital lobes and the right anterior fusiform (see <xref rid="fig2" ref-type="fig">Fig. 2</xref> and <xref rid="tbl2" ref-type="table">Table 2</xref>). There was no significant decreased activation and no significant difference between the addition of colour or the addition of sound (relative to their corresponding components). As expected, the main effect of visual versus auditory inputs yielded activation predominantly in visual and auditory regions respectively (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>).</p>
        </sec>
        <sec>
          <label>2.2.2</label>
          <title>Regions of interest</title>
          <p>For the [form with colour; FC1] condition relative to [form; F1] only and [colour; C1] only conditions, we expected decreased activation in bilateral antero-medial temporal cortex centred around [− 26, 0,− 20] and [30, 8,− 24] as well as in the right posterior temporal cortex [64,− 56, 0] as reported by <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. This prediction was confirmed in the left medial anterior temporal region at [− 24, 8,− 30]; <italic>Z</italic> = 3.4; <italic>p</italic> = 0.023 after small volume correction, see <xref rid="fig4" ref-type="fig">Fig. 4</xref>. There was no corresponding effect in the right hemisphere regions or in any of the regions for the [form with sound; SF2] relative to [form only; F2] and [sound only; S2] conditions. Moreover, the difference in the effect of adding colour versus sound was confirmed by a significant interaction in the left medial anterior temporal region [− 22, 8,− 28, <italic>Z</italic> = 3.6; <italic>p</italic> &lt; 0.05 following small volume correction].</p>
          <p>For the [form with sound; SF2] condition relative to [form; F2] only and [sound; S2] only conditions, we expected increased activation in the left posterior superior temporal cortex centred around [+/− 50,− 56, 4 in MNI space] from [− 50,− 55, 7] in Talairach and Tournoux space as reported by <xref rid="bib4" ref-type="bibr">Beauchamp et al. (2004)</xref>. This effect was not significant in our data (<italic>p</italic> &gt; 0.05, uncorrected in a sphere of 10 mm radius centred on [+/− 50,− 56, 4]).</p>
        </sec>
      </sec>
    </sec>
    <sec>
      <label>3</label>
      <title>Discussion</title>
      <p>This experiment was designed to investigate the influence of increased perceptual information (colour or sound) on naming objects from their visual form. The results highlight two key findings. Firstly, independent of whether increased perceptual information was provided by uni-modal visual stimuli that were appropriately coloured, or by the combination of crossmodal audiovisual perceptual inputs, an enhanced response was observed in bilateral occipital cortices and the right anterior fusiform gyrus. The bilateral occipital regions are well established uni-modal visual association areas and, as such, correspond to areas involved in visual perception. Examination of the effect sizes across all conditions suggests that, like the bilateral occipital regions, the right anterior fusiform region is also driven by visual form processing. Specifically, activation was higher for form only than either sound only or colour only and there was no significant difference between sound only or colour only as one might expect if the area was involved in semantic processing. Nevertheless, the influence that colour and sound had on form processing indicates that these regions are also influenced by other perceptual inputs. This may explain why previous studies have associated the right anterior fusiform with amodal processing (<xref rid="bib36 bib54 bib56" ref-type="bibr">Martin, 2007; Thierry and Price, 2006; Vuilleumier et al., 2002</xref>).</p>
      <p>Secondly, the addition of colour but not the addition of sound reduced activation in a left antero-medial temporal region, as previously reported by <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. This region has been strongly linked to semantic processing by neuropsychological studies of patients with semantic dementia and herpes simplex virus encephalitis (<xref rid="bib1 bib8 bib14 bib30 bib41" ref-type="bibr">Barbarotto et al., 1996; Brambati et al., 2006; Davies et al., 2004; Kapur et al., 1994; Noppeney et al., 2007</xref>). Our data therefore suggest that the addition of colour decreased the demands on semantic processes in the left antero-medial temporal cortex, consistent with the faster naming times that we observed for the [form with colour] condition compared to form only condition (see <xref rid="tbl1" ref-type="table">Table 1</xref>). This apparent “facilitation” contrasts to the effect of additional colour in posterior cortices where activation increased in areas associated with both visual perception and amodal semantics. We now discuss each of these regional effects in turn.</p>
      <sec>
        <label>3.1</label>
        <title>The effect of colour and sound in posterior occipital regions</title>
        <p>The posterior occipital activations associated with additional perceptual cues (colour or sound) are in well established visual processing areas (see <xref rid="bib20" ref-type="bibr">Grill-Spector, 2003</xref> for a review). Indeed, as shown in <xref rid="tbl2" ref-type="table">Table 2</xref>, bilateral occipital activation was most significant when object form was compared to no object form (colour only or sound only). Nevertheless, our results show that activation in these visual processing regions is modulated by the addition of both colour and sound relative to the individual components of form, colour or sound alone. The effect of combining form and colour on occipital activation is predicted on the basis of previous studies (<xref rid="bib40 bib58" ref-type="bibr">Moore and Price, 1999; Zeki and Marini, 1998</xref>). Critically, however, the occipital areas we observe, after colour naming has been subtracted out, are at least 20 mm posterior to the areas associated with colour processing only (<xref rid="bib2 bib16 bib21 bib25 bib38 bib42 bib47 bib59" ref-type="bibr">Bartels and Zeki, 2000; Dojat et al., 2006; Hadjikhani et al., 1998; Howard et al., 1998; McKeefry and Zeki, 1997; Nunn et al., 2002; Sakai et al., 1995; Zeki et al., 1991</xref>). This suggests that increased posterior occipital activation for the combined [form and colour] condition occurs at an early visual processing stage. Indeed, it is known that the extraction of information about an object's colour occurs early in visual analysis (<xref rid="bib11" ref-type="bibr">Cant and Goodale, 2007</xref>) and that binding of visual attributes is subsequent to stimulus processing itself (<xref rid="bib3" ref-type="bibr">Bartels and Zeki, 2006</xref>).</p>
        <p>Increased posterior occipital activation for the combined form and sound condition is more surprising. However, other studies have also demonstrated modulation of visual areas by auditory inputs. For instance, <xref rid="bib6" ref-type="bibr">Bookheimer et al. (1998)</xref> directly compared the semantic network involved in uni-modal auditory and uni-modal visual naming. Employing the same design as a visual object processing study (<xref rid="bib5" ref-type="bibr">Bookheimer et al., 1995</xref>), subjects were scanned during an auditory semantic task whilst blindfolded, thus ensuring no external visual stimulation. In addition to brain regions typically associated with language processing (bilateral superior temporal, left inferior frontal, including Broca's and Wernicke's areas), activation was also observed in bilateral primary visual cortex, consistent with their previous study on visual object processing. They interpreted this result in terms of the influence from top–down semantic to sensory processing which may facilitate activation of semantic representations through an automatic evocation of visual images consequent to auditory processing. Despite these previous findings, the increased occipital activation that we observe in our study for combined auditory and visual inputs remains surprising because there is no need to evoke visual imagery when the relevant visual inputs are already present. Our study therefore suggests that auditory object processing automatically activates visual areas irrespective of whether visual processing is required or not.</p>
        <p>In our behavioural study, there was no evidence that naming times were facilitated by the combination of form and sound. Moreover, facilitation is usually associated with reduced rather than increased activation. These observations lead us to propose that the effect of combined form and sound information in the posterior occipital regions reflects increased perceptual processing rather than processing related to an integrated percept. A possible explanation for this effect is that the additional perceptual information increased attention to the visual input thereby enhancing visual form processing. However, there are two points to note here. First the task was kept constant across all conditions to ensure that subjects attended to and identified all stimuli. Second, the response times were faster for stimuli with form and colour than form only suggesting that less attention was required to name the stimulus when colour was present. In summary, we have located the brain regions where additional perceptual cues (either colour or sound) enhance activation in visual cortices. Although further studies are required to elucidate the precise mechanisms, we propose that the influence of colour and sound occurs prior to the integration of multimodal inputs into a single object representation.</p>
      </sec>
      <sec>
        <label>3.2</label>
        <title>The effect of colour and sound in the right anterior fusiform</title>
        <p>In contrast to the posterior occipital regions where activation is associated with early visual processing, the right anterior fusiform has been linked to amodal semantic processing in a number of previous studies. For example, using a repetition priming paradigm, <xref rid="bib56" ref-type="bibr">Vuilleumier et al. (2002)</xref> showed a repetition decrease in the anterior fusiform (bilaterally) for repetition of real but not nonsense pictures of objects. <xref rid="bib37" ref-type="bibr">Martin et al. (1996)</xref> reported the same anterior fusiform region (also bilateral) for naming real objects relative to non-objects and <xref rid="bib49" ref-type="bibr">Simmons et al. (2007)</xref> reported bilateral anterior fusiform activation for retrieving object colour from object names. In the auditory modality, <xref rid="bib55" ref-type="bibr">von Kriegstein et al. (2006)</xref> demonstrated that familiar voice and face recognition activate the right anterior fusiform, and <xref rid="bib54" ref-type="bibr">Thierry and Price (2006)</xref> associated the same right anterior fusiform region with amodal conceptual processing of both object sounds and action videos.</p>
        <p>The novel finding in the current study is that right anterior fusiform region shows an additive effect when both auditory and visual object inputs are presented simultaneously relative to when auditory and visual inputs are presented independently. There are two possible explanations. One is that increased right fusiform activation reflects the integration of visual and auditory inputs but we think this is unlikely because the advantage of combined inputs was not super-additive relative to form only, sound only or colour only. Furthermore, there was no evidence from the behavioural data that form and sound had been integrated. Indeed, the pattern of response in this fusiform region was strikingly similar to that observed in the bilateral occipital areas, suggesting that activation was driven more by perceptual inputs than by subsequent semantic processes (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>). Our preferred explanation, therefore, is that right fusiform activation (like bilateral occipital activation) reflects processing prior to the integration of perceptual cues.</p>
        <p>Although category effects have been reported in the fusiform gyri, it is worth noting that the effects observed here do not correspond to regions associated with category selective responses. For example, the right fusiform region activated here is more lateral and anterior to that reported for living &gt; non-living items by <xref rid="bib12" ref-type="bibr">Chao et al. (1999)</xref>. It is not surprising then that no interaction between category and level of perceptual information was observed in this region (see <xref rid="sec1" ref-type="sec">Section 4.5</xref>).</p>
      </sec>
      <sec>
        <label>3.3</label>
        <title>The effect of colour and sound in the left antero-medial temporal cortex</title>
        <p>The left antero-medial temporal cortex was the only region where we detected reduced activation in the presence of additional perceptual cues, but even here the effect was only identified in the colour-form condition not the sound-form condition. Reduced left antero-medial temporal activation for the addition of appropriate colour cues has previously been reported by <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref> where it was interpreted in terms of a reduction in the number of competing responses within the semantic system. Our finding that response times were facilitated by the addition of colour (see <xref rid="tbl1" ref-type="table">Table 1</xref>) is consistent with this explanation. Using the same logic – that faster response times and less activation reflect facilitation – our data also demonstrate that the addition of sound did not facilitate object identification because, when form and sound were combined, there was no difference in response times relative to the form only condition and no decreased left antero-medial temporal activation (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>). The most likely explanation is that an object's sound takes longer to process than both form and colour information (see <xref rid="tbl1" ref-type="table">Table 1</xref>), therefore there was no advantage of sound when object naming can proceed on the basis of form alone. This does not exclude the possibility that sound would have a more facilitatory influence if the objects were difficult to recognize on the basis of form alone.</p>
        <p>The observation that the addition of appropriate colour facilitated picture naming and reduced left medial anterior temporal activation is consistent with <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. However, we did not observe decreased activation for coloured relative to black and white pictures in the right anterior or posterior temporal regions that were also reported for this contrast in <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. This inconsistency can be explained by differences in the type of stimuli used. Moore and Price used outline drawings while we used high-resolution photographs. The facilitatory effect of colour on perceptual identification will therefore have been greater in <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref>. Indeed, Moore and Price highlight the perceptual role of the right anterior and posterior temporal regions because activation in these areas was higher for drawings of meaningless non-objects than drawings of familiar objects. In contrast, in the left medial anterior temporal region, Moore and Price found greater activation for drawings of objects (particularly fruit) than drawings of meaningless non-objects. Thus, our observation of reduced activation in the left anterior temporal cortex is consistent with the impact of colour on semantic processing but our use of high-resolution photographs may have eliminated the facilitatory effect of colour on perceptual identification.</p>
      </sec>
      <sec>
        <label>3.4</label>
        <title>The absence of an effect of colour and sound in left pSTS</title>
        <p>Given the association of pSTS with crossmodal audiovisual processing (for reviews see <xref rid="bib9 bib10 bib31" ref-type="bibr">Calvert, 2001; Calvert and Lewis, 2004; King and Calvert, 2001</xref>) it is perhaps surprising that we did not observe increased pSTS activation during the form with sound condition. As discussed above, the most likely explanation is that the object naming task that we used here did not require the integration of form and sound. Rather, naming was possible from the visual input alone, without recourse to the auditory signal. This is consistent with recent evidence demonstrating that superior temporal activation during audiovisual integration is confounded by a range of methodological difficulties (<xref rid="bib24" ref-type="bibr">Hocking and Price, 2008</xref>).</p>
      </sec>
      <sec>
        <label>3.5</label>
        <title>Summary</title>
        <p>To summarize, during a visual object naming task, the addition of colour or sound increased activation in early visual (bilateral occipital) areas as well as areas previously associated with semantic processing (right anterior fusiform). In addition, left antero-medial temporal activation was decreased for combined form/colour inputs but no areas of decreased activation were observed for the combination of visual and sound inputs. This follows the behavioural data where response times were facilitated for the combination of colour and form but not for the combination of sound and form. Increased activation in the occipital and fusiform regions for additional perceptual cues suggests that these effects might be arising prior to the perceptual integration. In contrast, decreased activation in the left antero-medial temporal cortex is likely to occur after form and colour have been integrated.</p>
      </sec>
    </sec>
    <sec sec-type="methods">
      <label>4</label>
      <title>Experimental procedures</title>
      <sec>
        <label>4.1</label>
        <title>Subjects</title>
        <p>15 subjects (14 males, 1 female, age range 20–65, mean age 32.7) participated in a total of 12 × 90 s PET scans. All were right handed native English speakers with normal or corrected to normal vision. All had normal neurological and audiological status. The study was approved by the joint ethics committee of the Institute of Neurology and University College London Hospital, London, UK. This includes the stipulation that females of child-bearing age cannot be subjected to injection of the radioactive isotope used in PET.</p>
      </sec>
      <sec>
        <label>4.2</label>
        <title>Experimental design and stimuli</title>
        <p>We chose to use positron emission tomography (PET) to maximize our chances of detecting anterior temporal lobe activations in areas that are susceptible to inhomogeneities in fMRI and for consistency with the <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref> study. There were 12 PET scans. Three conditions were designed to identify the effect of form (F) and colour (C), with two scans per condition. These were:<list list-type="simple"><list-item><label>(1)</label><p>Colour photos of objects with a characteristic colour (CF1)</p></list-item><list-item><label>(2)</label><p>Black and white versions of condition 1 (F1)</p></list-item><list-item><label>(3)</label><p>Solid colour patches (C1)</p></list-item></list></p>
        <p>The remaining three conditions (two scans per condition) were used to investigate the integration of form (F) and sound (S):<list list-type="simple"><list-item><label>(4)</label><p>Black and white photos of objects and animals with their characteristic sounds (SF2)</p></list-item><list-item><label>(5)</label><p>Black and white photographs from condition 4 (F2)</p></list-item><list-item><label>(6)</label><p>Sounds from condition 4 (S2)</p></list-item></list></p>
        <p>In all conditions, subjects were instructed to articulate their response silently, moving their lips without generating any sounds. The lip movements enabled us to monitor accuracy of response, while the silent responses aimed to minimize auditory processing of the spoken response.</p>
        <sec>
          <label>4.2.1</label>
          <title>Stimuli</title>
          <p>For the conditions investigating the integration of form and colour, stimuli consisted of 48 objects with a prototypical colour (24 manmade and 24 fruits and vegetables) and 12 solid colour patches. The manmade and natural objects were presented in different scans, with 12 items in the CF1 condition and the other 12 in the F1 condition. The same 12 colour patches were repeated twice in the two C1 scans. The form and sound integration conditions consisted of 36 animals and 36 manmade objects all with strongly associated sounds, see <xref rid="app1" ref-type="sec">Appendix</xref>. As in the colour conditions, there were 12 stimuli of the same category per scan, no object was repeated within subject and stimulus set was counterbalanced across subjects.</p>
          <p>Photographs were obtained from the Hemara Photo Objects CD collection and object sounds were downloaded from the internet, with the majority obtained from the website <ext-link xlink:href="http://www.sounddogs.com" ext-link-type="uri">www.sounddogs.com</ext-link>. Sounds were converted to mono and were 1500 ms in length. The 12 colour patches were created using Corel Photo-paint v.11, and all visual stimuli were equated as far as possible for size (∼ 8 cm × 8 cm). See <xref rid="app1" ref-type="sec">Appendix</xref> for a complete list and <xref rid="fig1" ref-type="fig">Fig. 1</xref> for examples of each trial type.</p>
          <p>To reduce sensory and attention differences between conditions, both visual and auditory stimuli were presented on every trial in every condition. Thus, in the uni-modal auditory condition (S2) each object sound was simultaneously presented with an unrecognizable scrambled photograph (using the “scatter pixel” function in Corel Photo-paint v.11), and in uni-modal visual conditions (CF1, F1, C1, and F2) each visual stimulus was simultaneously presented with an unrecognizable scrambled object sound. Meaningless auditory stimuli were created by converting the object sounds using a Fast Fourier Transform to scramble their frequency. Examples of the stimuli can be seen in <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
          <p>Stimuli were presented on a 43 cm monitor suspended from a movable gantry at a distance of approximately 50 cm from the subject. Sounds were presented through two speakers situated behind the subject. Stimulus presentation was controlled with COGENT software (<ext-link xlink:href="http://www.vislab.ucl.ac.uk" ext-link-type="uri">www.vislab.ucl.ac.uk</ext-link>). Prior to being scanned, all subjects were familiarized with all stimuli, to ensure that they were equally familiar with the pictures and sounds. Immediately prior to each scan, an instruction was presented on the monitor to indicate what sort of stimuli needed to be named (animal, fruit, manmade object or colour). For each trial, an audiovisual stimulus was presented for 1500 ms, followed by a fixation cross for 2500 ms, giving an inter-stimulus interval of 4000 ms and a total activation block length of 48 s. Although this would be considered to be long for an fMRI study, 48 s is considered optimum for PET (<xref rid="bib48" ref-type="bibr">Silbersweig et al., 1993</xref>).</p>
        </sec>
      </sec>
      <sec>
        <label>4.3</label>
        <title>Behavioural study</title>
        <p>As it was only possible to record accuracy but not response latencies in the scanner, an additional behavioural study was run with a separate group of 24 subjects (age range: 24–55, mean age 32.2) to investigate differences in naming latencies for each condition. These subjects received the same instructions and the same 12 conditions as the subjects in the PET study, and were instructed to name the stimuli out loud as quickly and as accurately as possible. Stimulus presentation was delivered on a laptop computer, using the same presentation software as during scanning, in a private testing room, with only the subject and an experimenter present. Response latencies were recorded with a voice activated relay system from stimulus to response onset.</p>
      </sec>
      <sec>
        <label>4.4</label>
        <title>Data acquisition</title>
        <p>All subjects underwent 12 PET relative perfusion scans at the Wellcome Trust Centre for Neuroimaging, London, UK. Scans were obtained using a Siemens/CPS ECAT Exact HR+ (model 962) head scanner (Siemens/CTI, Knoxville, TN, USA) with a total field view of 15 cm. The head of each subject was located in the centre of the PET camera by means of a helmet attached with Velcro to the scanner bed in order to minimize movement within and between each scan. They received a 20 s intravenous bolus of H<sub>2</sub><sup>15</sup>O at a concentration of 55 MBq/ml and a flow rate of 10 ml/min through a forearm venous cannula. For each scan, approximately 10–15 mCi of H<sub>2</sub><sup>15</sup>O in 3 m of normal saline was flushed into the subject over 20 s, at a rate of 10 ml/min by an automatic pump. After a 30 s background scan, head counts peaked 30–40 s later (depending on the individuals' circulation time). Data acquisition time lasted 90 s, with an interval of 9 min between successive H<sub>2</sub><sup>15</sup>O administrations. The assimilated radioactivity counts accumulated over the 90 s acquisition period were corrected for background noise and were used as an index of regional cerebral blood flow (rCBF).</p>
        <p>Attenuation was corrected for by performing a transmission scan at the beginning of each study with an exposed <sup>68</sup>Ge/<sup>68</sup>Ga external source. Images were reconstructed in 3D filtered back projection (Hanning filter, cut off frequency 0.5 Hz), giving a transaxial resolution of 8.5 mm full width at half maximum. The reconstructed images contained 128 × 128 pixels, each 2.05 × 2.05 × 2.00 mm in size. To ensure normal neurological status a T1-weighted structural MRI was also obtained for each participant with a Siemens Magnetom Vision 1.5T scanner (Siemens, Erlangen, Germany).</p>
      </sec>
      <sec id="sec1">
        <label>4.5</label>
        <title>Data transformation</title>
        <p>After realignment and spatial normalization of each scan to a reference PET template (<xref rid="bib17" ref-type="bibr">Friston et al., 1995a</xref>) that conformed to the standard MNI space, all images were smoothed with a Gaussian kernel of 10 mm FWHM. Statistical analysis involved Analysis of Covariance (ANCOVA) with subject effects modelled and global activity included as a subject specific covariate. The condition and subject effects were estimated according to the general linear model at each voxel (<xref rid="bib18" ref-type="bibr">Friston et al., 1995b</xref>). The resulting set of voxel values constitutes a SPM of the <italic>t</italic> statistic (SPMt), the values of which were transformed to the unit normal distribution (SPMZ).</p>
        <p>In a preliminary analysis that modelled living and non-living object categories separately, the effects of additional perceptual information did not interact with category. The results reported in this paper are therefore based on an analysis that summed over the effect of object category. Nevertheless, we note here that in addition to the results reported in this paper, we also observed a highly significant effect of object category in the left posterior middle temporal cortex. As reported in many previous studies (e.g. <xref rid="bib15 bib33" ref-type="bibr">Devlin et al., 2002; Lewis et al., 2005</xref>), left posterior middle temporal activation was higher when the stimuli were manmade objects than living entities (animals, fruits and vegetables).</p>
        <p>In the analysis of 6 conditions, we identified where activation was increased or decreased with the addition of colour and sound using the following contrasts:<list list-type="simple"><list-item><label>(1)</label><p>Positive main effect of additional perceptual cues = [CF1+SF2 &gt; C1+F1+S2+F2] and negative main effect of additional perceptual cues = [CF1+SF2 &lt; C1+F1+S2+F2]</p></list-item><list-item><label>(2)</label><p>Interaction of additional perceptual cues with sensory modality:<list list-type="simple"><list-item><label>a.</label><p>Increased for addition of colour/decreased for addition of sound = [CF1 &gt; C1 + F1] − [SF2 &gt; S2 + F2]</p></list-item><list-item><label>b.</label><p>Increased for addition of sound or decreased for addition of colour = [SF2 &gt; S2 + F2] − [CF1 &gt; C1 + F1]</p></list-item></list></p></list-item><list-item><label>(3)</label><p>Simple main effects of:<list list-type="simple"><list-item><label>a.</label><p>increased for additional colour = [CF1 &gt; C1 + F1]</p></list-item><list-item><label>b.</label><p>decreased additional colour = [CF1 &lt; C1 + F1]</p></list-item><list-item><label>c.</label><p>increased for additional sound = [SF2 &gt; S2 + F2]</p></list-item><list-item><label>d.</label><p>decreased for additional sound = [SF2 &lt; S2 + F2]</p></list-item></list></p></list-item></list></p>
        <p>We report only those effects that reach a threshold of <italic>p</italic> &lt; 0.05, family wise error corrected for multiple comparisons either across the whole brain or in two regions of interest (ROIs) based on previous literature. The first ROI was taken from the <xref rid="bib40" ref-type="bibr">Moore and Price (1999)</xref> study, where facilitation was observed for coloured relative to black and white natural objects in the antero-medial temporal cortices at the co-ordinates [− 26, 0,− 20] and [30, 8,− 24] and the right posterior temporal cortex centred around [64,− 56, 0]. The second ROI was the pSTS region associated with enhanced activation during audiovisual integration. It was centred on the peak co-ordinates reported in <xref rid="bib4" ref-type="bibr">Beauchamp et al. (2004)</xref> at [− 50,− 55, 7] for nonverbal audiovisual integration. These co-ordinates were converted from Talairach and Tournoux stereotactic space into the nearest estimated co-ordinates in MNI space [+/− 50,− 56, 4] using the algorithm developed by Matthew Brett (<ext-link xlink:href="http://www.mrc-cbu.cam.ac.uk/Imaging" ext-link-type="uri">http://www.mrc-cbu.cam.ac.uk/Imaging</ext-link>). Within our two ROIs, the search volume was a sphere of 10 mm radius.</p>
      </sec>
    </sec>
    <sec id="app1">
      <label>Appendix</label>
      <title>Stimulus list</title>
      <p>
        <table-wrap position="anchor" id="N0x19d4330N0x2ee7240">
          <table frame="hsides" rules="groups">
            <tbody>
              <tr>
                <td colspan="6" valign="top">
                  <italic>Manmade object with a prototypical colour</italic>
                </td>
              </tr>
              <tr>
                <td valign="top">Ambulance</td>
                <td valign="top">Battery</td>
                <td valign="top">Fire engine</td>
                <td valign="top">Lego</td>
                <td valign="top">Ring</td>
                <td valign="top">Tennis ball</td>
              </tr>
              <tr>
                <td valign="top">Baseball bat</td>
                <td valign="top">Brick</td>
                <td valign="top">Fire extinguisher</td>
                <td valign="top">Lipstick</td>
                <td valign="top">Rolling pin</td>
                <td valign="top">Traffic cone</td>
              </tr>
              <tr>
                <td valign="top">Basket</td>
                <td valign="top">Coin</td>
                <td valign="top">Flag</td>
                <td valign="top">Postbox</td>
                <td valign="top">Taxi</td>
                <td valign="top">Traffic light</td>
              </tr>
              <tr>
                <td valign="top">Basketball</td>
                <td valign="top">London bus</td>
                <td valign="top">Land rover</td>
                <td valign="top">Red wine bottle</td>
                <td valign="top">Telephone box</td>
                <td valign="top">Wooden spoon</td>
              </tr>
              <tr>
                <td colspan="6" valign="top">
                  <italic>Natural objects with a prototypical colour</italic>
                </td>
              </tr>
              <tr>
                <td valign="top">Apple</td>
                <td valign="top">Carrot</td>
                <td valign="top">Garlic</td>
                <td valign="top">Melon</td>
                <td valign="top">Peach</td>
                <td valign="top">Potato</td>
              </tr>
              <tr>
                <td valign="top">Banana</td>
                <td valign="top">Coconut</td>
                <td valign="top">Leek</td>
                <td valign="top">Mushroom</td>
                <td valign="top">Pear</td>
                <td valign="top">Raspberry</td>
              </tr>
              <tr>
                <td valign="top">Bean</td>
                <td valign="top">Corn</td>
                <td valign="top">Lemon</td>
                <td valign="top">Onion</td>
                <td valign="top">Pepper</td>
                <td valign="top">Strawberry</td>
              </tr>
              <tr>
                <td valign="top">Broccoli</td>
                <td valign="top">Courgette</td>
                <td valign="top">Lettuce</td>
                <td valign="top">Orange</td>
                <td valign="top">Pineapple</td>
                <td valign="top">Tomato</td>
              </tr>
              <tr>
                <td colspan="6" valign="top">
                  <italic>Manmade objects with a prototypical object sound</italic>
                </td>
              </tr>
              <tr>
                <td valign="top">Accordion</td>
                <td valign="top">Clarinet</td>
                <td valign="top">Door</td>
                <td valign="top">Guitar</td>
                <td valign="top">Phone</td>
                <td valign="top">Toilet</td>
              </tr>
              <tr>
                <td valign="top">Bell</td>
                <td valign="top">Clock</td>
                <td valign="top">Doorbell</td>
                <td valign="top">Gun</td>
                <td valign="top">Piano</td>
                <td valign="top">Toothbrush</td>
              </tr>
              <tr>
                <td valign="top">Bicycle bell</td>
                <td valign="top">Coin</td>
                <td valign="top">Drum</td>
                <td valign="top">Hammer</td>
                <td valign="top">Plane</td>
                <td valign="top">Train</td>
              </tr>
              <tr>
                <td valign="top">Bongos'</td>
                <td valign="top">Cork</td>
                <td valign="top">Fire engine</td>
                <td valign="top">Harp</td>
                <td valign="top">Razor</td>
                <td valign="top">Trumpet</td>
              </tr>
              <tr>
                <td valign="top">Camera</td>
                <td valign="top">Cymbals</td>
                <td valign="top">Flute</td>
                <td valign="top">Lawnmower</td>
                <td valign="top">Saw</td>
                <td valign="top">Whistle</td>
              </tr>
              <tr>
                <td valign="top">Can</td>
                <td valign="top">Dice</td>
                <td valign="top">Gong</td>
                <td valign="top">Match</td>
                <td valign="top">Tap</td>
                <td valign="top">Zip</td>
              </tr>
              <tr>
                <td colspan="6" valign="top">
                  <italic>Natural objects with a prototypical sound</italic>
                </td>
              </tr>
              <tr>
                <td valign="top">Baby (crying)</td>
                <td valign="top">Cow</td>
                <td valign="top">Donkey</td>
                <td valign="top">Goose</td>
                <td valign="top">Parrot</td>
                <td valign="top">Sheep</td>
              </tr>
              <tr>
                <td valign="top">Baby (laughing)</td>
                <td valign="top">Cricket</td>
                <td valign="top">Duck</td>
                <td valign="top">Horse</td>
                <td valign="top">Pig</td>
                <td valign="top">Snake</td>
              </tr>
              <tr>
                <td valign="top">Bee</td>
                <td valign="top">Crow</td>
                <td valign="top">Elephant</td>
                <td valign="top">Horse</td>
                <td valign="top">Rattlesnake</td>
                <td valign="top">Sparrow</td>
              </tr>
              <tr>
                <td valign="top">Cat</td>
                <td valign="top">Cuckoo</td>
                <td valign="top">Fly</td>
                <td valign="top">Lion</td>
                <td valign="top">Rooster</td>
                <td valign="top">Whale</td>
              </tr>
              <tr>
                <td valign="top">Cat</td>
                <td valign="top">Dog (barking)</td>
                <td valign="top">Frog</td>
                <td valign="top">Mosquito</td>
                <td valign="top">Seagull</td>
                <td valign="top">Wolf</td>
              </tr>
              <tr>
                <td valign="top">Chicken</td>
                <td valign="top">Dog (yapping)</td>
                <td valign="top">Goat</td>
                <td valign="top">Owl</td>
                <td valign="top">Seal</td>
                <td valign="top">Wood pigeon</td>
              </tr>
              <tr>
                <td colspan="6" valign="top">
                  <italic>Colours</italic>
                </td>
              </tr>
              <tr>
                <td valign="top">Black</td>
                <td valign="top">Brown</td>
                <td valign="top">Green</td>
                <td valign="top">Orange</td>
                <td valign="top">Purple</td>
                <td valign="top">White</td>
              </tr>
              <tr>
                <td valign="top">Blue</td>
                <td valign="top">Cream</td>
                <td valign="top">Grey</td>
                <td valign="top">Pink</td>
                <td valign="top">Red</td>
                <td valign="top">Yellow</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>This work was funded by the Wellcome Trust. We would like to thank all the subjects who participated in these studies, and the FIL Functional Technologies Team for support acquiring the data.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Barbarotto</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Capitani</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Laiacona</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Naming deficit in herpes simplex encephalitis</article-title>
          <source>Acta Neurol. Scand.</source>
          <year>1996</year>
          <volume>93</volume>
          <fpage>272</fpage>
          <lpage>280</lpage>
          <pub-id pub-id-type="pmid">8739438</pub-id>
        </citation>
      </ref>
      <ref id="bib2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bartels</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The architecture of the colour centre in the human visual brain: new results and a review</article-title>
          <source>Eur. J. Neurosci.</source>
          <year>2000</year>
          <volume>12</volume>
          <fpage>172</fpage>
          <lpage>193</lpage>
          <pub-id pub-id-type="pmid">10651872</pub-id>
        </citation>
      </ref>
      <ref id="bib3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bartels</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The temporal order of binding visual attributes</article-title>
          <source>Vis. Res.</source>
          <year>2006</year>
          <volume>46</volume>
          <fpage>2280</fpage>
          <lpage>2286</lpage>
          <pub-id pub-id-type="pmid">16387344</pub-id>
        </citation>
      </ref>
      <ref id="bib4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beauchamp</surname>
              <given-names>M.S.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Argall</surname>
              <given-names>B.D.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Integration of auditory and visual information about objects in superior temporal sulcus</article-title>
          <source>Neuron</source>
          <year>2004</year>
          <volume>41</volume>
          <fpage>809</fpage>
          <lpage>823</lpage>
          <pub-id pub-id-type="pmid">15003179</pub-id>
        </citation>
      </ref>
      <ref id="bib5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bookheimer</surname>
              <given-names>S.Y.</given-names>
            </name>
            <name>
              <surname>Zeffiro</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Blaxton</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Gaillard</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Theodore</surname>
              <given-names>W.H.</given-names>
            </name>
          </person-group>
          <article-title>Regional cerebral blood flow during object naming and word reading</article-title>
          <source>Hum. Brain. Mapp<italic>.</italic></source>
          <year>1995</year>
          <volume>3</volume>
          <fpage>93</fpage>
          <lpage>106</lpage>
        </citation>
      </ref>
      <ref id="bib6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bookheimer</surname>
              <given-names>S.Y.</given-names>
            </name>
            <name>
              <surname>Zeffiro</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Blaxton</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Gaillard</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Malow</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Theodore</surname>
              <given-names>W.H.</given-names>
            </name>
          </person-group>
          <article-title>Regional cerebral blood flow during auditory responsive naming: evidence for cross-modality neural activation</article-title>
          <source>Neuroreport</source>
          <year>1998</year>
          <volume>9</volume>
          <fpage>2409</fpage>
          <lpage>2413</lpage>
          <pub-id pub-id-type="pmid">9694237</pub-id>
        </citation>
      </ref>
      <ref id="bib7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Booth</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Burman</surname>
              <given-names>D.D.</given-names>
            </name>
            <name>
              <surname>Meyer</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Gitelman</surname>
              <given-names>D.R.</given-names>
            </name>
            <name>
              <surname>Parrish</surname>
              <given-names>T.B.</given-names>
            </name>
            <name>
              <surname>Mesulam</surname>
              <given-names>M.M.</given-names>
            </name>
          </person-group>
          <article-title>Modality independence of word comprehension</article-title>
          <source>Hum. Brain. Mapp.</source>
          <year>2002</year>
          <volume>16</volume>
          <fpage>251</fpage>
          <lpage>261</lpage>
          <pub-id pub-id-type="pmid">12112766</pub-id>
        </citation>
      </ref>
      <ref id="bib8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brambati</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Myers</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Wilson</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rankin</surname>
              <given-names>K.P.</given-names>
            </name>
            <name>
              <surname>Allison</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Rosen</surname>
              <given-names>H.J.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>B.L.</given-names>
            </name>
            <name>
              <surname>Gorno-Tempini</surname>
              <given-names>M.L.</given-names>
            </name>
          </person-group>
          <article-title>The anatomy of category-specific object naming in neurodegenerative diseases</article-title>
          <source>J. Cogn. Neurosci.</source>
          <year>2006</year>
          <volume>18</volume>
          <fpage>1644</fpage>
          <lpage>1653</lpage>
          <pub-id pub-id-type="pmid">17014369</pub-id>
        </citation>
      </ref>
      <ref id="bib9">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calvert</surname>
              <given-names>G.A.</given-names>
            </name>
          </person-group>
          <article-title>Crossmodal processing in the human brain: insights from functional neuroimaging studies</article-title>
          <source>Cereb. Cortex</source>
          <year>2001</year>
          <volume>11</volume>
          <fpage>1110</fpage>
          <lpage>1123</lpage>
          <pub-id pub-id-type="pmid">11709482</pub-id>
        </citation>
      </ref>
      <ref id="bib10">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Calvert</surname>
              <given-names>G.A.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>J.W.</given-names>
            </name>
          </person-group>
          <article-title>Hemodynamic studies of audiovisual interactions</article-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Calvert</surname>
              <given-names>G.A.</given-names>
            </name>
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Stein</surname>
              <given-names>B.E.</given-names>
            </name>
          </person-group>
          <source>The Handbook of Multisensory Processes</source>
          <year>2004</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>London</publisher-loc>
          <fpage>203</fpage>
          <lpage>233</lpage>
        </citation>
      </ref>
      <ref id="bib11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cant</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
          </person-group>
          <article-title>Attention to form or surface properties modulates different regions of human occipitotemporal cortex</article-title>
          <source>Cereb. Cortex</source>
          <year>2007</year>
          <volume>17</volume>
          <fpage>713</fpage>
          <lpage>731</lpage>
          <pub-id pub-id-type="pmid">16648452</pub-id>
        </citation>
      </ref>
      <ref id="bib12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chao</surname>
              <given-names>L.L.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects</article-title>
          <source>Nat. Neurosci.</source>
          <year>1999</year>
          <volume>2</volume>
          <fpage>913</fpage>
          <lpage>919</lpage>
          <pub-id pub-id-type="pmid">10491613</pub-id>
        </citation>
      </ref>
      <ref id="bib13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Clarke</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bellmann</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Meuli</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Assal</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Steck</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Auditory agnosia and auditory spatial deficits following left hemispheric lesions: evidence for distinct processing pathways</article-title>
          <source>Neuropsychologia</source>
          <year>2000</year>
          <volume>38</volume>
          <fpage>797</fpage>
          <lpage>807</lpage>
          <pub-id pub-id-type="pmid">10689055</pub-id>
        </citation>
      </ref>
      <ref id="bib14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Davies</surname>
              <given-names>R.R.</given-names>
            </name>
            <name>
              <surname>Graham</surname>
              <given-names>K.S.</given-names>
            </name>
            <name>
              <surname>Xuereb</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>G.B.</given-names>
            </name>
            <name>
              <surname>Hodges</surname>
              <given-names>J.R.</given-names>
            </name>
          </person-group>
          <article-title>The human perirhinal cortex and semantic memory</article-title>
          <source>Eur. J. Neurosci.</source>
          <year>2004</year>
          <volume>20</volume>
          <fpage>2441</fpage>
          <lpage>2446</lpage>
          <pub-id pub-id-type="pmid">15525284</pub-id>
        </citation>
      </ref>
      <ref id="bib15">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Devlin</surname>
              <given-names>J.T.</given-names>
            </name>
            <name>
              <surname>Moore</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Mummery</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Gorno-Tempini</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Phillips</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Noppeney</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Anatomic constraints on cognitive theories of category specificity</article-title>
          <source>Neuroimage</source>
          <year>2002</year>
          <volume>15</volume>
          <fpage>675</fpage>
          <lpage>685</lpage>
          <pub-id pub-id-type="pmid">11848710</pub-id>
        </citation>
      </ref>
      <ref id="bib16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dojat</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Piettre</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Delon-Martin</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Pachot-Clouard</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Segebarth</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Knoblauch</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Global integration of local color differences in transparency perception: an fMRI study</article-title>
          <source>Vis. Neurosci.</source>
          <year>2006</year>
          <volume>23</volume>
          <fpage>357</fpage>
          <lpage>364</lpage>
          <pub-id pub-id-type="pmid">16961967</pub-id>
        </citation>
      </ref>
      <ref id="bib17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Ashburner</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Heather</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
          </person-group>
          <article-title>Spatial registration and normalization of images</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>1995</year>
          <volume>3</volume>
          <fpage>165</fpage>
          <lpage>189</lpage>
        </citation>
      </ref>
      <ref id="bib18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Worsley</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.J.</given-names>
            </name>
          </person-group>
          <article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>1995</year>
          <volume>2</volume>
          <fpage>189</fpage>
          <lpage>210</lpage>
        </citation>
      </ref>
      <ref id="bib19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Giard</surname>
              <given-names>M.H.</given-names>
            </name>
            <name>
              <surname>Peronnet</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Auditory-visual integration during multimodal object recognition in humans: a behavioral and electrophysiological study</article-title>
          <source>J. Cogn. Neurosci.</source>
          <year>1999</year>
          <volume>11</volume>
          <fpage>473</fpage>
          <lpage>490</lpage>
          <pub-id pub-id-type="pmid">10511637</pub-id>
        </citation>
      </ref>
      <ref id="bib20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grill-Spector</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>The neural basis of object perception</article-title>
          <source>Curr. Opin. Neurobiol.</source>
          <year>2003</year>
          <volume>13</volume>
          <fpage>159</fpage>
          <lpage>166</lpage>
          <pub-id pub-id-type="pmid">12744968</pub-id>
        </citation>
      </ref>
      <ref id="bib21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hadjikhani</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>A.K.</given-names>
            </name>
            <name>
              <surname>Dale</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Cavanagh</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Tootell</surname>
              <given-names>R.B.</given-names>
            </name>
          </person-group>
          <article-title>Retinotopy and color sensitivity in human visual cortical area V8</article-title>
          <source>Nat. Neurosci.</source>
          <year>1998</year>
          <volume>1</volume>
          <fpage>235</fpage>
          <lpage>241</lpage>
          <pub-id pub-id-type="pmid">10195149</pub-id>
        </citation>
      </ref>
      <ref id="bib22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hein</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Doehrmann</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Muller</surname>
              <given-names>N.G.</given-names>
            </name>
            <name>
              <surname>Kaiser</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Muckli</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Naumer</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Object familiarity and semantic congruency modulate responses in cortical audiovisual integration areas</article-title>
          <source>J. Neurosci.</source>
          <year>2007</year>
          <volume>27</volume>
          <fpage>7881</fpage>
          <lpage>7887</lpage>
          <pub-id pub-id-type="pmid">17652579</pub-id>
        </citation>
      </ref>
      <ref id="bib23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hershenson</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Reaction time as a measure of intersensory facilitation</article-title>
          <source>J. Exp. Psychol.</source>
          <year>1962</year>
          <volume>63</volume>
          <fpage>289</fpage>
          <lpage>293</lpage>
          <pub-id pub-id-type="pmid">13906889</pub-id>
        </citation>
      </ref>
      <ref id="bib24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hocking</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>The role of the posterior superior temporal sulcus in audiovisual processing</article-title>
          <source>Cereb Cortex</source>
          <year>2008</year>
          <comment>epub ahead of print</comment>
        </citation>
      </ref>
      <ref id="bib25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Howard</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Ffytche</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Barnes</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>McKeefry</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Ha</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Woodruff</surname>
              <given-names>P.W.</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Simmons</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>David</surname>
              <given-names>A.S.</given-names>
            </name>
            <name>
              <surname>Brammer</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The functional anatomy of imagining and perceiving colour</article-title>
          <source>Neuroreport</source>
          <year>1998</year>
          <volume>9</volume>
          <fpage>1019</fpage>
          <lpage>1023</lpage>
          <pub-id pub-id-type="pmid">9601660</pub-id>
        </citation>
      </ref>
      <ref id="bib26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Humphrey</surname>
              <given-names>G.K.</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Jakobson</surname>
              <given-names>L.S.</given-names>
            </name>
            <name>
              <surname>Servos</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>The role of surface information in object recognition: studies of a visual form agnosic and normal subjects</article-title>
          <source>Perception</source>
          <year>1994</year>
          <volume>23</volume>
          <fpage>1457</fpage>
          <lpage>1481</lpage>
          <pub-id pub-id-type="pmid">7792135</pub-id>
        </citation>
      </ref>
      <ref id="bib27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Humphreys</surname>
              <given-names>G.W.</given-names>
            </name>
            <name>
              <surname>Lamote</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Lloyd-Jones</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>An interactive activation approach to object processing: effects of structural similarity, name frequency, and task in normality and pathology</article-title>
          <source>Memory</source>
          <year>1995</year>
          <volume>3</volume>
          <fpage>535</fpage>
          <lpage>586</lpage>
          <pub-id pub-id-type="pmid">8574877</pub-id>
        </citation>
      </ref>
      <ref id="bib28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Joseph</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Proffitt</surname>
              <given-names>D.R.</given-names>
            </name>
          </person-group>
          <article-title>Semantic versus perceptual influences of color in object recognition</article-title>
          <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
          <year>1996</year>
          <volume>22</volume>
          <fpage>407</fpage>
          <lpage>429</lpage>
          <pub-id pub-id-type="pmid">8901343</pub-id>
        </citation>
      </ref>
      <ref id="bib29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Joseph</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Gathers</surname>
              <given-names>A.D.</given-names>
            </name>
          </person-group>
          <article-title>Effects of structural similarity on neural substrates for object recognition</article-title>
          <source>Cogn. Affect. Behav. Neurosci.</source>
          <year>2003</year>
          <volume>3</volume>
          <fpage>1</fpage>
          <lpage>16</lpage>
          <pub-id pub-id-type="pmid">12822594</pub-id>
        </citation>
      </ref>
      <ref id="bib30">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kapur</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Ellison</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Parkin</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Hunkin</surname>
              <given-names>N.M.</given-names>
            </name>
            <name>
              <surname>Burrows</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Sampson</surname>
              <given-names>S.A.</given-names>
            </name>
            <name>
              <surname>Morrison</surname>
              <given-names>E.A.</given-names>
            </name>
          </person-group>
          <article-title>Bilateral temporal lobe pathology with sparing of medial temporal lobe structures: lesion profile and pattern of memory disorder</article-title>
          <source>Neuropsychologia</source>
          <year>1994</year>
          <volume>32</volume>
          <fpage>23</fpage>
          <lpage>38</lpage>
          <pub-id pub-id-type="pmid">8818152</pub-id>
        </citation>
      </ref>
      <ref id="bib31">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>King</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Calvert</surname>
              <given-names>G.A.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory integration: perceptual grouping by eye and ear</article-title>
          <source>Curr. Biol.</source>
          <year>2001</year>
          <volume>11</volume>
          <fpage>R322</fpage>
          <lpage>325</lpage>
          <pub-id pub-id-type="pmid">11369224</pub-id>
        </citation>
      </ref>
      <ref id="bib32">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Laurienti</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Wallace</surname>
              <given-names>M.T.</given-names>
            </name>
            <name>
              <surname>Maldjian</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Susi</surname>
              <given-names>C.M.</given-names>
            </name>
            <name>
              <surname>Stein</surname>
              <given-names>B.E.</given-names>
            </name>
            <name>
              <surname>Burdette</surname>
              <given-names>J.H.</given-names>
            </name>
          </person-group>
          <article-title>Cross-modal sensory processing in the anterior cingulate and medial prefrontal cortices</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>2003</year>
          <volume>19</volume>
          <fpage>213</fpage>
          <lpage>223</lpage>
          <pub-id pub-id-type="pmid">12874776</pub-id>
        </citation>
      </ref>
      <ref id="bib33">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lewis</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Brefczynski</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Phinney</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Janik</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>DeYoe</surname>
              <given-names>E.A.</given-names>
            </name>
          </person-group>
          <article-title>Distinct cortical pathways for processing tool versus animal sounds</article-title>
          <source>J. Neurosci.</source>
          <year>2005</year>
          <volume>25</volume>
          <fpage>5148</fpage>
          <lpage>5158</lpage>
          <pub-id pub-id-type="pmid">15917455</pub-id>
        </citation>
      </ref>
      <ref id="bib34">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maeder</surname>
              <given-names>P.P.</given-names>
            </name>
            <name>
              <surname>Meuli</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Adriani</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bellmann</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fornari</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Thiran</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Pittet</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Clarke</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Distinct pathways involved in sound recognition and localization: a human fMRI study</article-title>
          <source>Neuroimage</source>
          <year>2001</year>
          <volume>14</volume>
          <fpage>802</fpage>
          <lpage>816</lpage>
          <pub-id pub-id-type="pmid">11554799</pub-id>
        </citation>
      </ref>
      <ref id="bib35">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mapelli</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>The role of color in object recognition: evidence from visual agnosia</article-title>
          <source>Neurocase</source>
          <year>1997</year>
          <volume>3</volume>
          <fpage>237</fpage>
          <lpage>247</lpage>
        </citation>
      </ref>
      <ref id="bib36">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The representation of object concepts in the brain</article-title>
          <source>Annu. Rev. Psychol.</source>
          <year>2007</year>
          <volume>58</volume>
          <fpage>25</fpage>
          <lpage>45</lpage>
          <pub-id pub-id-type="pmid">16968210</pub-id>
        </citation>
      </ref>
      <ref id="bib37">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Wiggs</surname>
              <given-names>C.L.</given-names>
            </name>
            <name>
              <surname>Ungerleider</surname>
              <given-names>L.G.</given-names>
            </name>
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of category-specific knowledge</article-title>
          <source>Nature</source>
          <year>1996</year>
          <volume>379</volume>
          <fpage>649</fpage>
          <lpage>652</lpage>
          <pub-id pub-id-type="pmid">8628399</pub-id>
        </citation>
      </ref>
      <ref id="bib38">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McKeefry</surname>
              <given-names>D.J.</given-names>
            </name>
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The position and topography of the human colour centre as revealed by functional magnetic resonance imaging</article-title>
          <source>Brain</source>
          <year>1997</year>
          <volume>120</volume>
          <issue>Pt 12</issue>
          <fpage>2229</fpage>
          <lpage>2242</lpage>
          <pub-id pub-id-type="pmid">9448578</pub-id>
        </citation>
      </ref>
      <ref id="bib39">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McRae</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Cree</surname>
              <given-names>G.S.</given-names>
            </name>
            <name>
              <surname>Westmacott</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>de Sa</surname>
              <given-names>V.R.</given-names>
            </name>
          </person-group>
          <article-title>Further evidence for feature correlations in semantic memory</article-title>
          <source>Can. J. Exp. Psychol.</source>
          <year>1999</year>
          <volume>53</volume>
          <fpage>360</fpage>
          <lpage>373</lpage>
          <pub-id pub-id-type="pmid">10646207</pub-id>
        </citation>
      </ref>
      <ref id="bib40">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Moore</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>A functional neuroimaging study of the variables that generate category-specific object processing differences</article-title>
          <source>Brain</source>
          <year>1999</year>
          <volume>122</volume>
          <fpage>943</fpage>
          <lpage>962</lpage>
          <pub-id pub-id-type="pmid">10355678</pub-id>
        </citation>
      </ref>
      <ref id="bib41">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Noppeney</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Patterson</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Tyler</surname>
              <given-names>L.K.</given-names>
            </name>
            <name>
              <surname>Moss</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Stamatakis</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Bright</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Mummery</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Temporal lobe lesions and semantic impairment: a comparison of herpes simplex virus encephalitis and semantic dementia</article-title>
          <source>Brain</source>
          <year>2007</year>
          <volume>130</volume>
          <fpage>1138</fpage>
          <lpage>1147</lpage>
          <pub-id pub-id-type="pmid">17251241</pub-id>
        </citation>
      </ref>
      <ref id="bib42">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nunn</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Gregory</surname>
              <given-names>L.J.</given-names>
            </name>
            <name>
              <surname>Brammer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Parslow</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Morgan</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Morris</surname>
              <given-names>R.G.</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Baron-Cohen</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Gray</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Functional magnetic resonance imaging of synesthesia: activation of V4/V8 by spoken words</article-title>
          <source>Nat. Neurosci.</source>
          <year>2002</year>
          <volume>5</volume>
          <fpage>371</fpage>
          <lpage>375</lpage>
          <pub-id pub-id-type="pmid">11914723</pub-id>
        </citation>
      </ref>
      <ref id="bib43">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nyberg</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Habib</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>McIntosh</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Tulving</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Reactivation of encoding-related brain activity during memory retrieval</article-title>
          <source>Proc. Natl. Acad. Sci. U. S. A.</source>
          <year>2000</year>
          <volume>97</volume>
          <fpage>11120</fpage>
          <lpage>11124</lpage>
          <pub-id pub-id-type="pmid">11005878</pub-id>
        </citation>
      </ref>
      <ref id="bib44">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ostergaard</surname>
              <given-names>A.L.</given-names>
            </name>
            <name>
              <surname>Davidoff</surname>
              <given-names>J.B.</given-names>
            </name>
          </person-group>
          <article-title>Some effects of color on naming and recognition of objects</article-title>
          <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
          <year>1985</year>
          <volume>11</volume>
          <fpage>579</fpage>
          <lpage>587</lpage>
          <pub-id pub-id-type="pmid">3160817</pub-id>
        </citation>
      </ref>
      <ref id="bib45">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Humphreys</surname>
              <given-names>G.W.</given-names>
            </name>
          </person-group>
          <article-title>The effects of surface detail on object categorization and naming</article-title>
          <source>Q. J. Exp. Psychol. A</source>
          <year>1989</year>
          <volume>41</volume>
          <fpage>797</fpage>
          <lpage>827</lpage>
          <pub-id pub-id-type="pmid">2587799</pub-id>
        </citation>
      </ref>
      <ref id="bib46">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rauschecker</surname>
              <given-names>J.P.</given-names>
            </name>
            <name>
              <surname>Tian</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Mechanisms and streams for processing of “what” and “where” in auditory cortex</article-title>
          <source>Proc. Natl. Acad. Sci. U. S. A.</source>
          <year>2000</year>
          <volume>97</volume>
          <fpage>11800</fpage>
          <lpage>11806</lpage>
          <pub-id pub-id-type="pmid">11050212</pub-id>
        </citation>
      </ref>
      <ref id="bib47">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sakai</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Watanabe</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Onodera</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Uchida</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Kato</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Yamamoto</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Koizumi</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Miyashita</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Functional mapping of the human colour centre with echo-planar magnetic resonance imaging</article-title>
          <source>Proc. Biol. Sci.</source>
          <year>1995</year>
          <volume>261</volume>
          <fpage>89</fpage>
          <lpage>98</lpage>
          <pub-id pub-id-type="pmid">7644550</pub-id>
        </citation>
      </ref>
      <ref id="bib48">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Silbersweig</surname>
              <given-names>D.A.</given-names>
            </name>
            <name>
              <surname>Stern</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Cahill</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Schnorr</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Grootoonk</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Spinks</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Detection of thirty-second cognitive activations in single subjects with positron emission tomography: a new low-dose H2(15)O regional cerebral blood flow three-dimensional imaging technique</article-title>
          <source>J. Cereb. Blood Flow Metab.</source>
          <year>1993</year>
          <volume>13</volume>
          <fpage>617</fpage>
          <lpage>629</lpage>
          <pub-id pub-id-type="pmid">8314915</pub-id>
        </citation>
      </ref>
      <ref id="bib49">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Simmons</surname>
              <given-names>W.K.</given-names>
            </name>
            <name>
              <surname>Ramjee</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Beauchamp</surname>
              <given-names>M.S.</given-names>
            </name>
            <name>
              <surname>McRae</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Barsalou</surname>
              <given-names>L.W.</given-names>
            </name>
          </person-group>
          <article-title>A common neural substrate for perceiving and knowing about color</article-title>
          <source>Neuropsychologia</source>
          <year>2007</year>
          <volume>45</volume>
          <fpage>2802</fpage>
          <lpage>2810</lpage>
          <pub-id pub-id-type="pmid">17575989</pub-id>
        </citation>
      </ref>
      <ref id="bib50">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Spitsyna</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Warren</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Scott</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Turkheimer</surname>
              <given-names>F.E.</given-names>
            </name>
            <name>
              <surname>Wise</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Converging language streams in the human temporal lobe</article-title>
          <source>J. Neurosci.</source>
          <year>2006</year>
          <volume>26</volume>
          <fpage>7328</fpage>
          <lpage>7336</lpage>
          <pub-id pub-id-type="pmid">16837579</pub-id>
        </citation>
      </ref>
      <ref id="bib51">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Summerfield</surname>
              <given-names>Q.</given-names>
            </name>
          </person-group>
          <article-title>Lipreading and audio-visual speech perception</article-title>
          <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source>
          <year>1992</year>
          <volume>335</volume>
          <fpage>71</fpage>
          <lpage>78</lpage>
          <pub-id pub-id-type="pmid">1348140</pub-id>
        </citation>
      </ref>
      <ref id="bib52">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Taylor</surname>
              <given-names>K.I.</given-names>
            </name>
            <name>
              <surname>Moss</surname>
              <given-names>H.E.</given-names>
            </name>
            <name>
              <surname>Stamatakis</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Tyler</surname>
              <given-names>L.K.</given-names>
            </name>
          </person-group>
          <article-title>Binding crossmodal object features in perirhinal cortex</article-title>
          <source>Proc. Natl. Acad. Sci. U.S.A</source>
          <year>2006</year>
          <volume>103</volume>
          <fpage>8239</fpage>
          <lpage>8244</lpage>
          <pub-id pub-id-type="pmid">16702554</pub-id>
        </citation>
      </ref>
      <ref id="bib53">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Teder-Sälejärvi</surname>
              <given-names>W.A.</given-names>
            </name>
            <name>
              <surname>Di Russo</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>McDonald</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Hillyard</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Effects of spatial congruity on audio-visual multimodal integration</article-title>
          <source>J. Cogn. Neurosci.</source>
          <year>2005</year>
          <volume>17</volume>
          <fpage>1396</fpage>
          <lpage>1409</lpage>
          <pub-id pub-id-type="pmid">16197693</pub-id>
        </citation>
      </ref>
      <ref id="bib54">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thierry</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C.J.</given-names>
            </name>
          </person-group>
          <article-title>Dissociating verbal and nonverbal conceptual processing in the human brain</article-title>
          <source>J. Cogn. Neurosci.</source>
          <year>2006</year>
          <volume>18</volume>
          <fpage>1018</fpage>
          <lpage>1028</lpage>
          <pub-id pub-id-type="pmid">16839307</pub-id>
        </citation>
      </ref>
      <ref id="bib55">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>von Kriegstein</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kleinschmidt</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Giraud</surname>
              <given-names>A.L.</given-names>
            </name>
          </person-group>
          <article-title>Voice recognition and cross-modal responses to familiar speakers' voices in prosopagnosia</article-title>
          <source>Cereb. Cortex</source>
          <year>2006</year>
          <volume>16</volume>
          <fpage>1314</fpage>
          <lpage>1322</lpage>
          <pub-id pub-id-type="pmid">16280461</pub-id>
        </citation>
      </ref>
      <ref id="bib56">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vuilleumier</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Henson</surname>
              <given-names>R.N.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Multiple levels of visual object constancy revealed by event-related fMRI of repetition priming</article-title>
          <source>Nat. Neurosci.</source>
          <year>2002</year>
          <volume>5</volume>
          <fpage>491</fpage>
          <lpage>499</lpage>
          <pub-id pub-id-type="pmid">11967545</pub-id>
        </citation>
      </ref>
      <ref id="bib57">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wheeler</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Petersen</surname>
              <given-names>S.E.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
          </person-group>
          <article-title>Memory's echo: vivid remembering reactivates sensory-specific cortex</article-title>
          <source>Proc. Natl. Acad. Sci. U. S. A.</source>
          <year>2000</year>
          <volume>97</volume>
          <fpage>11125</fpage>
          <lpage>11129</lpage>
          <pub-id pub-id-type="pmid">11005879</pub-id>
        </citation>
      </ref>
      <ref id="bib58">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Marini</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Three cortical stages of colour processing in the human brain</article-title>
          <source>Brain</source>
          <year>1998</year>
          <volume>121</volume>
          <fpage>1669</fpage>
          <lpage>1685</lpage>
          <pub-id pub-id-type="pmid">9762956</pub-id>
        </citation>
      </ref>
      <ref id="bib59">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Watson</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Lueck</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
            <name>
              <surname>Kennard</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>R.S.</given-names>
            </name>
          </person-group>
          <article-title>A direct demonstration of functional specialization in human visual cortex</article-title>
          <source>J. Neurosci.</source>
          <year>1991</year>
          <volume>11</volume>
          <fpage>641</fpage>
          <lpage>649</lpage>
          <pub-id pub-id-type="pmid">2002358</pub-id>
        </citation>
      </ref>
    </ref-list>
  </back>
  <floats-wrap>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>Example of a single stimulus trial for each of the six conditions. Visual stimuli were pictures of objects, colour patches or scrambled images. Auditory stimuli were object sounds or scrambled sounds, depicted here as the 1.5 s auditory sound envelope. Key: C = colour; F = form; S = sound; 1 = part of form and colour conditions; 2 = part of form and sound conditions.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>Main effect of increased perceptual input. (a) Activation increases for the addition of either colour or sound, rendered at <italic>p</italic> &lt; 0.001 uncorrected on an averaged T1 axial slice of the standardized brain at <italic>Z</italic> = − 16. (b) Design matrix showing contrast weights [2− 1− 1 2− 1− 1]. Plots show mean-centred relative effect sizes at the peak co-ordinates of significant activations in left and right occipital and right anterior fusiform (see also <xref rid="tbl2" ref-type="table">Table 2</xref>). For Key see <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p>Main effect of visual versus auditory input. Activation increases for conditions involving (a) visual only &gt; auditory only inputs i.e. contrast weights of [1 1 1 0 1− 4] and (b) auditory only &gt; visual only inputs i.e. contrast weights of [− 1− 1− 1 0− 1 4]. Activation rendered at <italic>p</italic> &lt; 0.001 uncorrected on the SPM standard surface model of an averaged brain, with a minimum cluster size of 10 voxels.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>Interaction in antero-medial temporal lobe. (a) Activation in antero-medial temporal ROI, rendered on an averaged T1 section at <italic>Z</italic> = − 28. (b) Design matrix showing contrast weights [− 2 1 1 2− 1− 1] (c) Plot of mean-centred relative effect sizes for all conditions showing least activation for the combination of form and colour [− 22, 8,− 28]. For Key see <xref rid="fig2" ref-type="fig">Fig. 2</xref>. In addition the plot suggests a non-significant trend for higher activation in F1 then F2. This may be due to category differences because the natural stimuli in F1 were pictures of fruit and vegetables whereas the natural stimuli in F2 were pictures of animals (see <xref rid="app1" ref-type="sec">Appendix</xref> for details). Critically however, all reported comparisons are within study and within category, therefore the difference does not alter the conclusions drawn.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <table-wrap position="float" id="tbl1">
      <label>Table 1</label>
      <caption>
        <p>Naming latencies (mean and standard deviation) for behavioural experiment</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th valign="top">Naming condition</th>
            <th valign="top">Mean (ms)</th>
            <th valign="top">SD (ms)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top">CF1</td>
            <td valign="top" align="char">932</td>
            <td valign="top" align="char">99</td>
          </tr>
          <tr>
            <td valign="top">F1</td>
            <td valign="top" align="char">966</td>
            <td valign="top" align="char">105</td>
          </tr>
          <tr>
            <td valign="top">C1</td>
            <td valign="top" align="char">799</td>
            <td valign="top" align="char">114</td>
          </tr>
          <tr>
            <td valign="top">SF2</td>
            <td valign="top" align="char">960</td>
            <td valign="top" align="char">130</td>
          </tr>
          <tr>
            <td valign="top">F2</td>
            <td valign="top" align="char">961</td>
            <td valign="top" align="char">162</td>
          </tr>
          <tr>
            <td valign="top">S2</td>
            <td valign="top" align="char">1556</td>
            <td valign="top" align="char">273</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Key: C = colour; F = form; S = sound; 1 = vision only; 2 = audiovisual.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="tbl2">
      <?landscape?>
      <label>Table 2</label>
      <caption>
        <p>Regional activation for main effect of increased perceptual input</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th colspan="4" valign="top">Main effects<hr/></th>
            <th colspan="4" valign="top"><italic>Z</italic>-scores for individual contracts<hr/></th>
          </tr>
          <tr>
            <th valign="top">Anatomical region</th>
            <th valign="top">Peak cluster</th>
            <th valign="top"><italic>Z</italic>-score (CF1&gt;C1+F1) +(SF2&gt;S2+F2)</th>
            <th valign="top">Number of voxels</th>
            <th valign="top">CF1&gt;C1</th>
            <th valign="top">CF1&gt;F1</th>
            <th valign="top">SF2&gt;S2</th>
            <th valign="top">SF2&gt;F2</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top">R inf/mid occipital</td>
            <td valign="top"><bold>34,</bold> − <bold>98,</bold> − <bold>4</bold></td>
            <td valign="top">6.1</td>
            <td valign="top">740</td>
            <td valign="top">5.4</td>
            <td valign="top">2.9</td>
            <td valign="top">5.3</td>
            <td valign="top">1.7</td>
          </tr>
          <tr>
            <td valign="top"/>
            <td valign="top"><italic>30,</italic> − <italic>90,</italic> − <italic>10</italic></td>
            <td valign="top">4.8</td>
            <td valign="top"/>
            <td valign="top">4.0</td>
            <td valign="top">1.6</td>
            <td valign="top">5.1</td>
            <td valign="top">2.8</td>
          </tr>
          <tr>
            <td valign="top">L inf/mid occipital</td>
            <td valign="top">− <bold>32,</bold> − <bold>92,</bold> − <bold>18</bold></td>
            <td valign="top">5.1</td>
            <td valign="top">581</td>
            <td valign="top">5.5</td>
            <td valign="top">2.7</td>
            <td valign="top">3.9</td>
            <td valign="top">1.8</td>
          </tr>
          <tr>
            <td valign="top">R ant fusiform</td>
            <td valign="top"><bold>42,</bold> − <bold>40,</bold> − <bold>14</bold></td>
            <td valign="top">4.2</td>
            <td valign="top">239</td>
            <td valign="top">2.8</td>
            <td valign="top">1.8</td>
            <td valign="top">3.8</td>
            <td valign="top">2.3</td>
          </tr>
          <tr>
            <td valign="top"/>
            <td valign="top"><italic>36</italic> − <italic>34</italic> − <italic>12</italic></td>
            <td valign="top">3.2</td>
            <td valign="top"/>
            <td valign="top">2.2</td>
            <td valign="top">3.5</td>
            <td valign="top">1.6</td>
            <td valign="top">1.6</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Table 2, columns 1–4, shows the anatomical regions, MNI co-ordinates (centre of peak cluster shown in bold) and corresponding <italic>Z</italic>-scores for the main effect of increased perceptual cues across input type. Columns 5–8 show the <italic>Z</italic>-scores for the individual linear contrasts.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </floats-wrap>
</article>