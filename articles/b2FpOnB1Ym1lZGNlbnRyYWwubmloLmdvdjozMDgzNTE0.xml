<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuropsychologia</journal-id>
      <journal-title-group>
        <journal-title>Neuropsychologia</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0028-3932</issn>
      <issn pub-type="epub">1873-3514</issn>
      <publisher>
        <publisher-name>Pergamon Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">3083514</article-id>
      <article-id pub-id-type="pmid">21333662</article-id>
      <article-id pub-id-type="publisher-id">NSY4019</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.02.021</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Impaired holistic coding of facial expression and facial identity in congenital prosopagnosia</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Palermo</surname>
            <given-names>Romina</given-names>
          </name>
          <email>Romina.Palermo@anu.edu.au</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff0005" ref-type="aff">b</xref>
          <xref rid="aff0010" ref-type="aff">c</xref>
          <xref rid="cor0005" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Willis</surname>
            <given-names>Megan L.</given-names>
          </name>
          <xref rid="aff0010" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Rivolta</surname>
            <given-names>Davide</given-names>
          </name>
          <xref rid="aff0010" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>McKone</surname>
            <given-names>Elinor</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff0005" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Wilson</surname>
            <given-names>C. Ellie</given-names>
          </name>
          <xref rid="aff0010" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Calder</surname>
            <given-names>Andrew J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff0015" ref-type="aff">d</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>a</label>ARC Centre of Excellence in Cognition and its Disorders (CCD)</aff>
      <aff id="aff0005"><label>b</label>Department of Psychology, Australian National University, Canberra, ACT 0200, Australia</aff>
      <aff id="aff0010"><label>c</label>Macquarie Centre for Cognitive Science (MACCS), Macquarie University, Sydney, NSW 2109, Australia</aff>
      <aff id="aff0015"><label>d</label>MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, England, United Kingdom</aff>
      <author-notes>
        <corresp id="cor0005"><label>⁎</label>Corresponding author at: Department of Psychology, The Australian National University, ACT 0200, Australia. Tel.: +61 2 6125 5545; fax: +61 2 6125 0499. <email>Romina.Palermo@anu.edu.au</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <month>4</month>
        <year>2011</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="ppub"/>. -->
      <pub-date pub-type="ppub">
        <month>4</month>
        <year>2011</year>
      </pub-date>
      <volume>49</volume>
      <issue>5</issue>
      <fpage>1226</fpage>
      <lpage>1235</lpage>
      <history>
        <date date-type="received">
          <day>23</day>
          <month>9</month>
          <year>2010</year>
        </date>
        <date date-type="rev-recd">
          <day>8</day>
          <month>2</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>10</day>
          <month>2</month>
          <year>2011</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2011 Elsevier Ltd.</copyright-statement>
        <copyright-year>2011</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <license-p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract abstract-type="graphical">
        <title>Research highlights</title>
        <p>► Congenital prosopagnosics show weak holistic coding of expression and identity. ► Normal expression recognition can result from compensatory strategies. ► There may be a common stage of holistic coding for expression and identity. ► Holistic coding of identity is functionally involved in face identification ability.</p>
      </abstract>
      <abstract>
        <p>We test 12 individuals with congenital prosopagnosia (CP), who replicate a common pattern of showing severe difficulty in recognising facial identity in conjunction with normal recognition of facial expressions (both basic and ‘social’). Strength of holistic processing was examined using standard expression composite and identity composite tasks. Compared to age- and sex-matched controls, group analyses demonstrated that CPs showed weaker holistic processing, for both expression and identity information. Implications are (a) normal expression recognition in CP can derive from compensatory strategies (e.g., over-reliance on non-holistic cues to expression); (b) the split between processing of expression and identity information may take place after a common stage of holistic processing; and (c) contrary to a recent claim, holistic processing of identity is functionally involved in face identification ability.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Face perception</kwd>
        <kwd>Identity</kwd>
        <kwd>Expression</kwd>
        <kwd>Emotion</kwd>
        <kwd>Holistic processing</kwd>
        <kwd>Prosopagnosia</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec0005">
      <label>1</label>
      <title>Introduction</title>
      <p>People with congenital prosopagnosia (CP; also referred to as developmental prosopagnosia) have severe, life-long deficits recognising the identity of familiar people from their faces despite intact low-level vision and general cognitive abilities (<xref rid="bib0025 bib0160" ref-type="bibr">Behrmann &amp; Avidan, 2005; Lee, Duchaine, Wilson, &amp; Nakayama, 2010</xref>). As many as 2.5% of the educated population can be classified as a CP (<xref rid="bib0035 bib0130" ref-type="bibr">Bowles et al., 2009; Kennerknecht et al., 2006</xref>), and some of these cases run in families (<xref rid="bib0060 bib0100 bib0160 bib0250" ref-type="bibr">Duchaine, Germine, &amp; Nakayama, 2007; Grueter et al., 2007; Lee et al., 2010; Schmalzl, Palermo, &amp; Coltheart, 2008</xref>). Face recognition deficits in CP appear to be associated with smaller anterior fusiform volumes (<xref rid="bib0030" ref-type="bibr">Behrmann, Avidan, Gao, &amp; Black, 2007</xref>), reduced grey matter volume in brain regions that respond to faces, such as the mid-fusiform gyrus (<xref rid="bib0090" ref-type="bibr">Garrido et al., 2009</xref>), and compromised white matter tracts in occipito-temporal cortex (<xref rid="bib0265" ref-type="bibr">Thomas et al., 2009</xref>).</p>
      <p>Despite profound impairments in facial identity recognition, many, although not all, CPs are adept at labelling the basic facial expressions of happiness, anger, disgust, fear, sadness and surprise (<xref rid="bib0140 bib0190 bib0250" ref-type="bibr">Kress &amp; Daum, 2003; Nunn, Postma, &amp; Pearson, 2001; Schmalzl et al., 2008</xref>), even when the display of these basic expressions is subtle and difficult to categorise (<xref rid="bib0075 bib0110" ref-type="bibr">Duchaine, Parker, &amp; Nakayama, 2003; Humphreys, Avidan, &amp; Behrmann, 2007</xref>). CPs are also typically able to recognise subtle social emotions conveyed by the eyes, such as playfulness and regret (<xref rid="bib0075 bib0060 bib0160" ref-type="bibr">Duchaine et al., 2003, 2007; Lee et al., 2010</xref>). In the present study we test 12 CPs showing this pattern of impaired identity recognition with no discernable deficit in facial expression recognition, and examine the strength of holistic processing for face expression information (in all 12 participants) and face identity information (in a subset of nine participants), in order to address three theoretical questions regarding the role of holistic processing in their patterns of face processing abilities.</p>
      <p>Holistic processing, defined as the “simultaneous perception of multiple features of an individual face, that are integrated into a single global representation” (<xref rid="bib0235" ref-type="bibr">Rossion, 2008</xref>, p. 275), is a core perceptual mechanism in the processing of faces. The most widely accepted measure of holistic processing is the composite effect. Assessing holistic coding of identity typically involves participants identifying the top (or bottom) half of a face paired with the bottom (or top) half of another person's face. The composite effect is the robust finding that participants are slower, and less accurate, when the face halves are vertically <italic>aligned</italic> (forming the illusion of a new face) compared to when they are spatially <italic>unaligned</italic> so they do not resemble a whole face (e.g., <xref rid="bib0175 bib0290" ref-type="bibr">McKone, 2008; Young, Hellawell, &amp; Hay, 1987</xref>; e.g., <xref rid="fig0005" ref-type="fig">Fig. 1</xref>a). In the expression version, participants judge the expression on one half of the face (e.g., anger) while trying to ignore an inconsistent expression on the other half (e.g., happiness) (<xref rid="bib0050 bib0055 bib0275" ref-type="bibr">Calder &amp; Jansen, 2005; Calder, Young, Keane, &amp; Dean, 2000; White, 2000</xref>; e.g., <xref rid="fig0005" ref-type="fig">Fig. 1</xref>b). Composite effects for both types of information occur for upright faces (where identity and expression recognition is typically also good) but not inverted faces (where recognition is poorer).</p>
      <p>The first question we address in the current study is whether the normal levels of expression recognition ability in our CPs derive from normal use of perceptual mechanisms, as opposed to reliance on other compensatory strategies. Patient H.J.A., who acquired prosopagnosia at age 61 following a stroke, demonstrated a relatively normal ability to recognise facial expressions despite displaying no expression composite effect, implying the use of compensatory strategies (perhaps a reliance on local part cues) (<xref rid="bib0020" ref-type="bibr">Baudouin &amp; Humphreys, 2006</xref>). This implies that there is no guarantee that normal expression recognition ability in CP is achieved via the same perceptual mechanisms used by typically developing adults. Here we test whether our CPs may rely less on holistic processing (and therefore more on other contributory mechanisms) than controls.</p>
      <p>The second question concerns the stage of processing from which the dissociation between identity and expression recognition derives. Common theories place the point of split between processing of identity and expression information quite early in perceptual/cognitive processing, with the split occurring before the stage of view-independent ‘structural descriptions’ in the cognitive model of <xref rid="bib0040" ref-type="bibr">Bruce and Young (1986)</xref>, and before processing in the lateral fusiform gyrus (identity) and superior temporal sulcus (expression) in the anatomical model of <xref rid="bib0105" ref-type="bibr">Haxby, Hoffman, and Gobbini (2000)</xref>. However, <xref rid="bib0310" ref-type="bibr">Calder and Young's (2005)</xref> review argued that much of the evidence for an early split was not as strong as often assumed. Here, we address the question of whether a split has occurred by the perceptual stage of holistic processing. We consider two models. In the first (Model A, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>), there are two distinct types of holistic coding, one for coding expression and another for coding information about identity. In support of this model, <xref rid="bib0055" ref-type="bibr">Calder et al. (2000)</xref> found that participants could selectively attend to holistic information specific to identity or expression (i.e., participants took no longer to judge the facial expression of a composite whether they were composed of the same or different identity and vice versa), suggesting that holistic coding of identity and expression were independent. However, as this data can also be modelled within a single multi-dimensional system, there may not be an absolute dissociation between the composite effect for expression and identity (Calder and Young, 2005). Alternatively then, there could be a common stage of holistic coding, which feeds into both expression and identity recognition (Model B, <xref rid="fig0010" ref-type="fig">Fig. 2</xref>). In support of this model, <xref rid="bib0050" ref-type="bibr">Calder and Jansen (2005)</xref> note that composite effects for both identity and expression are sensitive to inversion but not photographic negative, suggesting a common level of perceptual processing.</p>
      <p>In the current study, we assess whether holistic expression and identity processing go together, or dissociate, in our CPs. Model A (two separate holistic processing stages) would be supported if a dissociation is revealed, that is, if one form of holistic processing is impaired, while the other is intact. Given that the CPs had impaired recognition of identity but not expression, such a dissociation would most likely take the form of the CPs showing a weak identity composite effect relative to controls but a normal strength expression composite effect. Alternatively, Model B (one combined holistic processing stage) would predict that the status of holistic processing of expression should match that of identity (i.e., either both impaired, or both intact). For example, if CPs showed weak composite effects for identity information, then Model B would also predict weak composite effects for expression information <italic>despite</italic> the CPs’ intact recognition of expressions.</p>
      <p>The third question concerns identity processing only, and asks whether holistic processing of identity information is functionally related to face recognition ability. A recent paper with typically developing adults demonstrated large individual differences in the strength of the identity composite effect but found no correlation between these differences and face recognition ability (<xref rid="bib0135" ref-type="bibr">Konar, Bennett, &amp; Sekuler, 2010</xref>). However, face recognition ability was assessed with simultaneous or immediate sequential matching tasks (where the stimuli included hair), and such tasks have been shown to be more closely associated with general object processing than face memory skills (e.g., the Glasgow Face Matching Task, GFMT; <xref rid="bib0045" ref-type="bibr">Burton, White, &amp; McNeill, 2010</xref>). None of the CPs tested in our lab are impaired on the GFMT whereas they all show significant impairments on tests involving a memory component, such as the Cambridge Face Memory Test (CFMT) (unpublished data). In the current study we used our group-based comparison of differences in identity recognition ability (i.e., CPs vs. controls). If holistic processing is not functionally involved in recognition, then there should be no difference in the strength of the identity composite effect between the CP and control groups. On the other hand, if holistic coding contributes to face identity recognition, then the identity composite effect should be weaker in CPs than in controls.</p>
      <p>To summarise, we confirmed impaired face identity with intact facial expression recognition in a group of 12 individuals. We then report the first group study of holistic coding of both expression and identity in CP.</p>
    </sec>
    <sec sec-type="methods" id="sec0010">
      <label>2</label>
      <title>Methods and results</title>
      <sec id="sec0015">
        <label>2.1</label>
        <title>Participants</title>
        <sec id="sec0020">
          <label>2.1.1</label>
          <title>Congenital prosopagnosics</title>
          <p>The CP group comprised 12 people (4 males) who reported severe everyday face recognition difficulties and performed poorly on tests of facial identity recognition. Most contacted us via our prosopagnosia register: <ext-link ext-link-type="uri" xlink:href="http://www.maccs.mq.edu.au/research/projects/prosopagnosia/">http://www.maccs.mq.edu.au/research/projects/prosopagnosia/</ext-link>. They were aged between 20 and 60 years (<italic>M</italic> = 40.58, <italic>SD</italic> = 13.00) when facial identity recognition, low-level vision and IQ were assessed. They reported normal or corrected-to-normal vision and demonstrated normal range contrast sensitivity when measured with the <italic>Functional Acuity Contrast Test</italic> (FACT, Vision Sciences Research Corporation, 2002)<xref rid="fn0005" ref-type="fn">1</xref> and colour perception as assessed with the <italic>Ishihara Test for Colour Blindness</italic> (<xref rid="bib0115" ref-type="bibr">Ishihara, 1925</xref>). Performance on the length, size, orientation and picture naming (long version) subtests of the <italic>Birmingham Object Recognition Battery</italic> (BORB) (<xref rid="bib0225" ref-type="bibr">Riddoch &amp; Humphreys, 1993</xref>) confirmed intact basic-level object recognition in all prosopagnosics. IQ, as measured with the <italic>Raven Colored Progressive Matrices</italic> (<xref rid="bib0205" ref-type="bibr">Raven, Raven, &amp; Court, 1998</xref>) was also within the normal range for all prosopagnosics. None of the prosopagnosics reported any psychiatric or neurological problems.</p>
          <p>The presence of prosopagnosia – that is, the inability to reliably recognise facial identity – was determined using two tests of face memory and one of face perception. As can be seen in <xref rid="fig0015" ref-type="fig">Fig. 3</xref>, the individuals in the prosopagnosic group performed poorly on these tests, and performed at least two standard deviations (SDs) below control norms on one or more tests. The <italic>MACCS Famous Face Test 2008</italic> (MFFT-08) assesses memory for famous faces that have generally been repeatedly seen over relatively long time periods (Palermo, Rivolta, Wilson, &amp; Jeffery, in preparation). It contains 20 people famous to Australians and 20 that are not. On each trial: (a) a <italic>face</italic> is presented and participants judge whether it is familiar or not, (b) for the famous faces, they are asked to identify the <italic>face</italic> by providing its name or other specific autobiographical information, then (c) the famous person's <italic>name</italic> and relevant autobiographical information are presented, and participants report whether the famous <italic>person</italic> was actually known to them (any that are unknown are excluded from further analyses). The score on the MFFT-08 is the percentage of correctly recognised <italic>faces</italic> of <italic>known</italic> famous people. A sample of 39 control participants (26 females) aged between 19 and 72 years (<italic>M</italic> = 45.69, <italic>SD</italic> = 16.08) correctly recognised 74.17% (<italic>SD</italic> = 19.09) of known faces (Palermo et al., in preparation). Age-appropriate <italic>z</italic>-scores based on these control data were calculated for each prosopagnosic and vary from −0.95 to −4.39 (see <xref rid="fig0015" ref-type="fig">Fig. 3</xref>).</p>
          <p>The <italic>Cambridge Face Memory Test</italic> (CFMT, <xref rid="bib0070" ref-type="bibr">Duchaine &amp; Nakayama, 2006</xref>) assesses face learning and memory. Participants learn six individuals (each from three different viewpoints), and then recognize the previously seen faces when shown in novel views and/or degraded by noise. Total scores on the upright CFMT were transformed to age-adjusted <italic>z</italic>-scores (using age-based norms reported in <xref rid="bib0035" ref-type="bibr">Bowles et al., 2009</xref>), with the prosopagnosics scoring between −1.39 and −2.83 below the Australian sample (<xref rid="fig0015" ref-type="fig">Fig. 3</xref>).<xref rid="fn0010" ref-type="fn">2</xref></p>
          <p>The <italic>Cambridge Face Perception Test</italic> (CFPT, <xref rid="bib0060" ref-type="bibr">Duchaine et al., 2007</xref>) requires participants to order a series of morphed faces in order of their likeness to a target face. <italic>Z</italic>-scores for upright faces, calculated using the age- and sex-based norms in <xref rid="bib0035" ref-type="bibr">Bowles et al. (2009)</xref>, ranged from 0.53 to −3.34 (<xref rid="fig0015" ref-type="fig">Fig. 3</xref>).<xref rid="fn0015" ref-type="fn">3</xref></p>
          <p>All 12 prosopagnosics completed the tests of facial expression recognition and the expression composite effect, which were administered between 6 and 24 months after the identity tests (thus they were aged between 22 and 61 years; <italic>M</italic> = 41.67, <italic>SD</italic> = 12.87). Nine (<italic>M</italic> = 42.56, <italic>SD</italic> = 14.52) also completed the identity composite test (F37-8, F37-9, and F30-1 did not).</p>
          <p>Some of these participants are also referred to in <xref rid="bib0035 bib0320" ref-type="bibr">Bowles et al. (2009); Rivolta, Palermo, Schmalzl, and Coltheart (in press)</xref>, and Palermo et al. (in preparation).</p>
        </sec>
        <sec id="sec0025">
          <label>2.1.2</label>
          <title>Controls</title>
          <p>For the three facial expression recognition tests, the expression composite effect and the CFMT, our controls comprised 17 participants without known brain injury (7 males), who were aged between 19 and 60 years (<italic>M</italic> = 38.94, <italic>SD</italic> = 14.42). They did not differ in age from the prosopagnosics, <italic>t</italic> &lt; 1. (Note that we initially tested 21 control participants; however four were excluded, one for a CFMT <italic>z</italic>-score of −1.84, one for scoring below the ‘normal range’ cutoff given in the manual for the Ekman 60 Faces Test, and two for scoring below normal range cutoff values on both the Ekman 60 Faces and the Emotion Hexagon Test).</p>
          <p>The identity composite effect was completed by a different group of control participants; <italic>n</italic> = 30 (7 males), aged between 23 and 62 years (<italic>M</italic> = 34.20, <italic>SD</italic> = 10.09). Once again, age did not differ from the prosopagnosics, <italic>t</italic>(37) = 1.96, <italic>p</italic> &gt; .05.</p>
        </sec>
      </sec>
      <sec id="sec0030">
        <label>2.2</label>
        <title>Tests of facial expression recognition and social cognition</title>
        <p>Recognition of basic and social expressions was assessed with three tests, following standard procedures. Results showed completely normal expression recognition in the CP group relative to the 17 controls (<xref rid="tbl0005" ref-type="table">Table 1</xref>).</p>
        <p>The <italic>Ekman 60 Faces</italic> (<xref rid="bib0295" ref-type="bibr">Young, Perrett, Calder, Sprengelmeyer, &amp; Ekman, 2002</xref>) contains grayscale photographs of 10 individuals, each displaying one of six high-intensity prototypical basic emotions. Faces are presented, in random order, for 5 s each, and participants choose which emotion term (anger, disgust, fear, happiness, sadness, and surprise) best describes the facial expression shown. The number of correct responses out of 60 was computed. The mean performance of the group of prosopagnosics did not differ to that of our controls, <italic>t</italic> &lt; 1 (<xref rid="tbl0005" ref-type="table">Table 1</xref>). Importantly, this lack of difference cannot be attributed to a ceiling effect on the task (mean control accuracy was approximately 86%). We also confirmed that none of the individual prosopagnosics scored below cut-off scores that indicate the boundary between normal-range and impaired performance based on a large-N control sample as provided in the manual (i.e., 45 for ages 20–40, 43 for ages 41–60 and 41 for those aged 61–70 years).</p>
        <p>The <italic>Emotion Hexagon</italic> Test (<xref rid="bib0295" ref-type="bibr">Young et al., 2002</xref>) consists of stimuli of graded difficulty, created by blending between two maximally confusable prototypical expressions (e.g., 90% happiness, 10% surprise; 70%, happiness, 30% surprise; 50% happiness, 50% surprise; 70% happiness, 30% surprise; 10% happiness, 90% surprise). Each of the thirty morphed faces is shown once in each of 5 blocks, for 5 s, in random order. Participants choose which emotion term (anger, disgust, fear, happiness, sadness, and surprise) best describes the facial expression. Total correct score out of 120 was computed. The prosopagnosic and control groups did not differ, <italic>t</italic> &lt; 1 (<xref rid="tbl0005" ref-type="table">Table 1</xref>), although note performance was close to ceiling on this task (control mean = 95%). We also compared individuals to large-N sample cut-offs in the manual (94 for ages 20–40, 92 for ages 41–60 and 90 for those aged 61–70 years). None of the prosopagnosics scored below cut-off.</p>
        <p>The <italic>Reading the Mind in the Eyes</italic> (Revised) test (<xref rid="bib0010" ref-type="bibr">Baron-Cohen, Wheelwright, Hill, Raste, &amp; Plumb, 2001</xref>) contains the eye-region of 36 faces displaying social emotions (e.g., flirtatious, pensive, sceptical). Participants are presented with four terms for each set of eyes and circle which word best describes what the person in the photograph was thinking or feeling. A page of word definitions is provided for reference. Adults with autism are impaired on this test, suggesting that this test taps subtle impairments in social intelligence (<xref rid="bib0010" ref-type="bibr">Baron-Cohen, Wheelwright, Hill, et al.</xref>). In the present study, the prosopagnosic and control groups did not differ, <italic>t</italic>(27) = 1.32, <italic>p</italic> &gt; .2 (<xref rid="tbl0005" ref-type="table">Table 1</xref>), with no ceiling effect (control mean = 87%) and in fact a small trend for the CP group to be <italic>better</italic> than controls. We further confirmed intact social expression perception in our CPs via comparison to published norms for a large-N sample from the general population (<italic>n</italic> = 122, mean age = 46.5 years, <italic>SD</italic> = 16.9; <xref rid="bib0010" ref-type="bibr">Baron-Cohen, Wheelwright, Hill, et al.</xref>): the large-N mean was 26.2 (<italic>SD</italic> = 3.6), and the lowest score here for a prosopagnosic was 25.</p>
        <p>Participants also completed the <italic>Autism Spectrum Quotient</italic> (AQ) questionnaire (<xref rid="bib0015" ref-type="bibr">Baron-Cohen, Wheelwright, Skinner, &amp; Clubley, 2001</xref>). None of the prosopagnosics scored 32 or above, which is indicative of an autism spectrum disorder (<xref rid="bib0015" ref-type="bibr">Baron-Cohen, Wheelwright, Skinner, et al.</xref>), and there was no difference between the prosopagnosics and controls, <italic>t</italic>(16.51, adjusted for unequal variance) = 1.40, <italic>p</italic> &gt; .18 (<xref rid="tbl0005" ref-type="table">Table 1</xref>). This is consistent with other recent work showing that CP can be clearly distinct from autism in both adults (<xref rid="bib0065" ref-type="bibr">Duchaine, Murray, Turner, White, &amp; Garrido, 2009</xref>) and children (<xref rid="bib0285" ref-type="bibr">Wilson, Palermo, Schmalzl, &amp; Brock, 2010</xref>).</p>
      </sec>
      <sec id="sec0035">
        <label>2.3</label>
        <title>Expression composite test</title>
        <p>Each face displayed a composite of two emotions, one on the top half and a different one on the bottom half (e.g., fear on the top together with happiness on the bottom, see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>b). This test was essentially the same as that of <xref rid="bib0055" ref-type="bibr">Calder et al. (2000, Experiment 1)</xref>, but with a different set of stimuli (because Calder et al. used the Ekman and Friesen Pictures of Facial Affect that were also contained in the Ekman 60 Faces Test that participants in our study had already completed). As in Calder et al., only expressions well recognised from the specific half were employed in that half: for the top half of the face emotions used were anger, fear, sadness; and for the bottom half of the face emotions used were happiness, disgust, surprise, of the same individual.</p>
        <sec id="sec0040">
          <label>2.3.1</label>
          <title>Stimuli</title>
          <p>The original whole faces (later used to make the composite stimuli) were grayscale photographs of four Caucasian individuals (two females), each displaying an angry, disgusted, fearful, sad, happy and surprised expression. The faces were sourced from the NimStim Face Stimulus Set (Models # 7 and 8) (<xref rid="bib0270" ref-type="bibr">Tottenham et al., 2009</xref>) and the Karolinska Directed Emotional Faces database (KDEF, Models # M09 and M17) (<xref rid="bib0170" ref-type="bibr">Lundqvist et al., 1998</xref>). A pilot study (<italic>n</italic> = 13) confirmed that the whole face expressions were well recognised (average recognition accuracy was 86.86%). Each of these faces was divided in half along the bridge of the nose to create the composite images. The pilot study also verified that participants were able to accurately recognise anger, fear, and sadness from the top halves presented alone (<italic>M</italic> = 80.45%) and happiness, disgust, and surprise from the bottom halves presented alone (<italic>M</italic> = 86.54%).</p>
          <p><italic>Aligned</italic> face composites were created by combining the top of an expression well-recognised from the top half of the face (i.e., anger, fear, sadness) with the bottom of an expression well-recognised from the bottom (i.e., happiness, disgust, surprise) of the same individual (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref>b). All nine possible combinations were formed for each of the four individuals, for a total of 36 aligned composites; there were thus, for example, 12 “happy”-target aligned trials, 4 where the happy expression was combined with anger on the top, 4 where happy was combined with fear on the top, and 4 where happy was combined with sadness. <italic>Unaligned</italic> composites were created by horizontally misaligning the top and bottom halves of the stimuli that were used to create the aligned composites so that the middle of the nose in the top segment was aligned with the edge of the face in the bottom segment. For half of the stimuli the top segment was shifted to the left of the bottom segment, while for the other half the top segment was shifted to the right. As neither the top nor bottom half of the unaligned images were centred on the screen, we therefore presented half of the aligned composites in the same position as the left segment of the aligned composites and half in the same position as the right segment of the unaligned composites.</p>
        </sec>
        <sec id="sec0045">
          <label>2.3.2</label>
          <title>Procedure</title>
          <p>The experiment commenced with a block of trials in which participants categorised the facial expression of each of the four <italic>whole</italic> faces posing each of the six facial expressions (24 trials) by pressing one of six labelled keys (anger, happiness, sadness, fear, surprise, disgust). This was then followed by one of two blocks: in one block participants were required to classify the facial expression depicted in the <italic>top</italic> half of the aligned and unaligned composites (as either anger, fear or sadness) via a key press, whereas in the other block, they were asked to classify the <italic>bottom</italic> half (as either happiness, surprise or disgust). Within each block, each aligned and unaligned composite was presented once, in a random order, for a total of 72 trials per block. Block order was counterbalanced between participants. Prior to commencing each block, participants classified an isolated top (or bottom) half of each individual displaying each expression (12 trials), and then 10 practice trials with the face halves combined into composites (half aligned, half unaligned). Each trial began with a fixation cross for 500 ms, followed by a 500 ms blank interval, and then the composite was presented until a response was made. An inter-trial-interval of 1000 ms preceded the commencement of the following trial. Participants were asked to respond as quickly and accurately as possible. Stimulus presentation was controlled by SuperLab (Cedrus Corp.) on a MacBook Pro with a 15-in. monitor, at a viewing distance of approximately 50 cm. Aligned composites were approximately 3.5 cm × 5.5 cm (4 × 6.5 degrees of visual angle) and unaligned were 5 cm × 5.5 cm (5.5 × 6.5 degrees of visual angle).</p>
        </sec>
        <sec id="sec0050">
          <label>2.3.3</label>
          <title>Results</title>
          <p>Given the high accuracy rates on both our composite tasks, our analyses focus on response times (RTs) (percentage accuracy for the expression composite task is displayed in <xref rid="tbl0010" ref-type="table">Table 2</xref>). Analysed RTs were for correct trials, excluding responses 3 SDs greater than the mean for each condition. Mean RTs were calculated for aligned and unaligned composites, for expressions judged from either the top (anger, fear, sadness) or the bottom (happiness, disgust, surprise) face half. Results (<xref rid="fig0020 fig0025" ref-type="fig">Figs. 4 and 5</xref>) showed a weaker expression composite effect in the CP group than in controls, particularly for top-half expression judgements, with even controls showing quite a small composite effect for bottom-half judgements. Supporting statistics were as follows.</p>
          <p>A Group (prosopagnosics, controls) × Alignment (aligned, unaligned) × Half (top, bottom) ANOVA revealed main effects of Half, <italic>F</italic>(1,27) = 95.39, <italic>p</italic> &lt; .001, <inline-formula><mml:math id="M1" altimg="si1.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.78</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:math></inline-formula> and Alignment, <italic>F</italic>(1,27) = 35.12, <italic>p</italic> &lt; .001, <inline-formula><mml:math id="M2" altimg="si2.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:math></inline-formula> moderated by an Alignment × Half interaction, <italic>F</italic>(1,27) = 12.54, <italic>p</italic> &lt; .001, <inline-formula><mml:math id="M3" altimg="si3.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext>.32.</mml:mtext></mml:mrow></mml:math></inline-formula> The interaction reflected a larger composite effect for top (aligned: <italic>M</italic> = 2244, SE = 134; unaligned: <italic>M</italic> = 1856, SE = 106) than bottom (aligned: <italic>M</italic> = 1324, SE = 72; unaligned: <italic>M</italic> = 1183, SE = 59) halves, although composite effects for both halves were statistically significant, <italic>t</italic>'s &gt; 5.27, <italic>p</italic>'s &lt; .001. The Group × Alignment × Half interaction approached significance, <italic>F</italic>(1,27) = 3.78, <italic>p</italic> = .06, <inline-formula><mml:math id="M4" altimg="si4.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.12</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:math></inline-formula> and most importantly, the Group × Alignment interaction was significant, <italic>F</italic>(1,27) = 4.33, <italic>p</italic> &lt; .05, <inline-formula><mml:math id="M5" altimg="si5.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn><mml:mtext>.</mml:mtext></mml:mrow></mml:math></inline-formula> Composite effects were evident for both groups, but significantly larger for controls, (aligned: <italic>M</italic> = 1897, SE = 123; unaligned: <italic>M</italic> = 1539, SE = 97), <italic>t</italic>(16) = 6.55, <italic>p</italic> &lt; .001, than prosopagnosics (aligned: <italic>M</italic> = 1671, SE = 147; unaligned: <italic>M</italic> = 1499, SE = 116), <italic>t</italic>(11) = 2.35, <italic>p</italic> &lt; .04 (see <xref rid="fig0020" ref-type="fig">Fig. 4</xref>).</p>
          <p>We also calculated the magnitude of the expression composite effect for each individual participant. To normalize for differences in baseline performance these were calculated as the relative difference in performance across conditions [(aligned − unaligned)/(aligned + misaligned)] (see <xref rid="bib0200" ref-type="bibr">Ramon, Busigny, &amp; Rossion, 2010</xref> for a similar procedure with an acquired prosopagnosic P.S.). Given these data were skewed we used a non-parametric test suited to small sample sizes, the Kolmogorov–Smirnov <italic>Z</italic> (<xref rid="bib0085" ref-type="bibr">Field, 2009</xref>). The magnitude of the composite effect for expressions displayed by the top half of the face was significantly weaker for prosopagnosics than controls, <italic>z</italic> = 1.43, <italic>p</italic> &lt; .04, <italic>r</italic> = .27 (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>). There was no significant difference between the prosopagnosic and control groups for expressions displayed by the bottom half, <italic>z</italic> = .79, <italic>p</italic> = .55, <italic>r</italic> = .15.<xref rid="fn0020" ref-type="fn">4</xref></p>
          <p>In sum, the group of CPs clearly show a composite effect for expression. However, the magnitude of the composite effect was significantly reduced for CPs compared to controls.</p>
        </sec>
      </sec>
      <sec id="sec0055">
        <label>2.4</label>
        <title>Identity composite test</title>
        <sec id="sec0060">
          <label>2.4.1</label>
          <title>Stimuli and procedure</title>
          <p>The identity composite effect stimuli were created by <xref rid="bib0155" ref-type="bibr">Le Grand, Mondloch, Maurer, and Brent (2004)</xref>, who split photographs of unexpressive grayscale faces horizontally across the middle of the nose into top and bottom halves. The halves were recombined into different individuals that were <italic>aligned</italic> into an intact face, and spatially <italic>unaligned</italic>, with the top half of each face shifted to the left. The procedure was very similar to <xref rid="bib0155 bib0150" ref-type="bibr">Le Grand et al. (2004, 2006)</xref>. In brief, on each trial two face composites were sequentially presented (200 ms, with a 300 ms inter-stimulus interval) and participants judged whether the top halves were the same or different identity (the bottom halves were always different). A block of aligned composites (48 trials; half same top halves and half different top halves, randomly intermixed) was followed by a block of unaligned composites (also 48 trials) (note that block order does not affect performance, <xref rid="bib0155" ref-type="bibr">Le Grand et al., 2004</xref>). Four practice trials were presented prior to each block. Participants were asked to respond as quickly and accurately as possible. Stimulus presentation was controlled using SuperLab (Cedrus Corp.) on a Dell PC (19-in. monitor) or a MacBook Pro (15-in. monitor) from a distance of approximately 50 cm. Aligned composites were approximately 5 cm × 7.5 cm (5.5 × 8.5 degrees of visual angle) and unaligned were 8.5 cm × 7.5 cm (9.5 × 8.5 degrees of visual angle).</p>
          <p>[Note that there has been recent discussion in the literature (e.g., <xref rid="bib0210" ref-type="bibr">Richler, Gauthier, Wenger, &amp; Palmeri, 2008</xref>) about whether the traditional same-different version of the composite task, as used here, might tap a response bias to say “same” rather than the perceptual composite illusion. We chose to use the traditional version rather than the Gauthier-lab version involving additional conditions (e.g., <xref rid="bib0210 bib0315 bib0215" ref-type="bibr">Richler et al., 2008, 2011, in press</xref>) for several reasons. (a) A recent ERP study using the traditional conditions and monitoring for same-different changes as the behavioural task showed the composite effect was present early in visual processing (i.e., on the N170); this demonstrates a perceptual rather than decisional locus (<xref rid="bib0145" ref-type="bibr">Kuefner, Jacques, Prieto, &amp; Rossion, 2010</xref>). (b) The particular <xref rid="bib0155" ref-type="bibr">Le Grand et al. (2004)</xref> stimulus set we used here has been confirmed to show the expected pattern of a large traditional composite effect upright in combination with no composite effect at all for the same faces inverted (<xref rid="bib0185" ref-type="bibr">Mondloch &amp; Maurer, 2008</xref>); this demonstrates that the composite effect (misaligned − aligned difference for same trials) does not reflect a generalised bias to say ‘same’ more often to aligned trials. Also, (c) the Gauthier-lab version produces a large “composite effect” (i.e., congruency effect) for <italic>inverted</italic> faces (<xref rid="bib0315" ref-type="bibr">Richler et al., 2011</xref>), despite the lack of any perceptual illusion of integration of the two halves inverted (e.g., <xref rid="bib0290" ref-type="bibr">Young et al., 1987</xref>).]</p>
        </sec>
        <sec id="sec0065">
          <label>2.4.2</label>
          <title>Results</title>
          <p>Mean RTs (for correct trials, excluding responses 3 SDs greater than the mean for each condition) were calculated for aligned and unaligned composites, for trials where the identities were the same, and ones where they were different. As is general practice, only the <italic>same</italic> trials were used to test for the presence of the composite effect (c.f., <xref rid="bib0155 bib0230" ref-type="bibr">Le Grand et al., 2004; Robbins &amp; McKone, 2007</xref>) (mean RTs for different trials and percent accuracy for same and different trials are shown in <xref rid="tbl0015" ref-type="table">Table 3</xref>). A Group (prosopagnosics, controls) × Alignment (aligned, unaligned) ANOVA showed a composite effect, with slower RTs in the aligned (<italic>M</italic> = 960, SE = 39) than the unaligned (<italic>M</italic> = 767, SE = 26) condition, <italic>F</italic>(1,37) = 43.93, <italic>p</italic> &lt; .0001, <inline-formula><mml:math id="M6" altimg="si6.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn></mml:mrow></mml:math></inline-formula> (see <xref rid="fig0030" ref-type="fig">Fig. 6</xref>). There was no Group × Alignment interaction, <italic>F</italic>(1,37) = 1.06, <italic>p</italic> &gt; .3. However, the most important result of the ANOVA was a marginal main effect of Group <italic>F</italic>(1,37) = 2.86, <italic>p</italic> = .099, <inline-formula><mml:math id="M7" altimg="si7.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.07</mml:mn><mml:mtext>,</mml:mtext></mml:mrow></mml:math></inline-formula> with prosopagnosics slower than controls, and an <italic>a priori</italic> comparison of the unaligned “baseline” condition showed that the prosopagnosics were significantly slower for unaligned trials than controls, <italic>t</italic>(37) = 2.50, <italic>p</italic> &lt; .02. This means that the comparison of composite effects via the interaction in the ANOVA on raw scores is invalid, because it fails to take into account that controls, having a faster baseline RT, have theoretically <italic>less</italic> room to show a composite effect than CPs yet show a trend on the raw scores to showing a <italic>larger</italic> composite effect than CPs.</p>
          <p>Thus, as for the expression composite effect, the baseline-adjusted magnitude of the identity composite effect was calculated [(aligned − unaligned)/(aligned + misaligned)]. On this measure, the magnitude of the identity composite effect was significantly weaker for prosopagnosics than controls, <italic>z</italic> = 1.37, <italic>p</italic> &lt; .05, <italic>r</italic> = .15 (<xref rid="fig0035" ref-type="fig">Fig. 7</xref>). We also note that the baseline-adjusted composite effect was significant (i.e., greater than zero), for both controls, <italic>t</italic>(29) = 9.43, <italic>p</italic> &lt; .001 and CPs, <italic>t</italic>(8) = 3.21, <italic>p</italic> &lt; .02.</p>
          <p>We also briefly examined the correlation, within the group of CPs (<italic>n</italic> = 9), between the size of their identity composite effect and the size of their expression composite effect for the top-half (both using baseline-adjusted scores). We used a non-parametric test, Kendall's tau (<italic>τ</italic>), which assesses the probability that the data are in the same order for the two variables, and has a range between −1 to 1 (<xref rid="bib0255" ref-type="bibr">StatSoft Inc, 2010</xref>). This correlation was small (although positive) and non-significant, <italic>τ</italic> = .17, <italic>p</italic> = .27, 1-tailed. Note, however, that we would not wish to rule out an association between these variables, given the low power with the small sample size. (Unfortunately, we were unable to conduct similar correlational analyses with the controls, because those who completed the identity composite task did not complete the other task.)</p>
          <p>In sum, the results for identity are very similar to those for expression. That is, the identity composite effect for CPs is evident, but weaker.</p>
        </sec>
      </sec>
    </sec>
    <sec id="sec0070">
      <label>3</label>
      <title>Discussion</title>
      <p>None of the 12 CPs we assessed was impaired on any of the three tests of basic and social facial expression recognition. These objective test scores agree with the CPs’ subjective reports of their everyday experience: all reported difficulty recognising facial identity (e.g., difficulty following films due to confusion about tracking the characters) but none reported difficulty recognising facial expression. Intact expression with impaired identity recognition is consistent with other studies (e.g., <xref rid="bib0075 bib0110" ref-type="bibr">Duchaine et al., 2003; Humphreys et al., 2007</xref>), suggesting that this pattern may be common in CP. Note that we cannot rule out a subtle deficit in expression recognition emerging in CPs had they been tested on speeded expression recognition tasks. Importantly, however, the dissociation between expression and identity observed here cannot be attributed to differences in stimulus presentation duration. The expression tasks (Emotion Hexagon, Ekman 60, Reading the Mind in the Eyes) use long (&gt;5 s) or unlimited presentation duration of faces. However, this is also true of the identity recognition tests used to diagnose the prosopagnosia: all our CPs were impaired either on a Famous Faces Test (unlimited stimulus duration) and/or the CFMT (6 s to learn each person; unlimited presentation duration at test). Thus, it is unlikely that a generic strategy which is easier to implement with long stimulus durations (e.g., sequential feature-by-feature analysis), can account for the dissociation between expression and identity recognition.</p>
      <p>Our first question was to determine whether normal levels of facial expression recognition in our CPs were obtained via the use of normal perceptual mechanisms. Although our CPs did show holistic coding for expression, it was weaker than that seen for controls. This group of CPs also demonstrated normal facial expression recognition despite their weak holistic coding. Thus, they must be relying upon compensatory mechanisms that are either atypical (i.e., not used at all by controls) or typical but used to different degrees by controls (i.e., heavier use of non-holistic mechanisms in CP). This latter idea is plausible because there may be multiple effective expression recognition mechanisms (which may be less the case for identity recognition), some of which involve holistic coding but others which may involve focusing on single facial features (such as an upturned mouth for happiness; <xref rid="bib0080" ref-type="bibr">Ellison &amp; Massaro, 1997</xref>) and/or “embodied cognition”, involving internal simulation of the emotion in somatosensory brain regions (<xref rid="bib0195" ref-type="bibr">Pitcher, Garrido, Walsh, &amp; Duchaine, 2008</xref>). CPs could be using a subset of these other strategies, but relying on them more heavily than controls. Regardless of the precise mechanism relied upon by CPs, weak holistic coding implies that CPs were not recognising facial expressions in the same manner as controls.</p>
      <p>The second question addressed by the current study was the locus of the dissociation between identity and expression recognition. The pattern of results for holistic coding of identity and expression were similar: CPs showed holistic coding, but it was weaker than in controls for both facial attributes. This result supports Model B (<xref rid="fig0010" ref-type="fig">Fig. 2</xref>), in which there is an initial holistic processing stage that is common to both identity and expression. This stage of general holistic coding may be very early, with recent evidence for identity composite effects as early as 170 ms after stimulus onset (i.e., the face-sensitive N170 event-related potential, <xref rid="bib0120 bib0125 bib0165" ref-type="bibr">Jacques &amp; Rossion, 2009, 2010; Letourneau &amp; Mitchell, 2008</xref>). This early general holistic processing stage may also encompass other facial attributes in addition to identity and expression, given that composite effects are also seen for judgements of sex and attractiveness (<xref rid="bib0005 bib0020 bib0300" ref-type="bibr">Abbas &amp; Duchaine, 2008; Baudouin &amp; Humphreys, 2006; Zhao &amp; Hayward, 2010</xref>).</p>
      <p>The third question we examined was whether holistic processing for identity is functionally related to face identification ability. Consistent with proposals that holistic coding contributes to face recognition, we found that the identity composite effect was weaker in CPs (who by definition are very poor at recognising face identity) than in controls (who we confirmed were normal at recognising face identity). Weak holistic coding of identity is also seen in other groups of individuals with developmental disorders affecting face perception. A group of 12 individuals who were deprived of early patterned visual input by bilateral congenital cataracts for 3–6 months after birth displayed a significantly smaller composite effect when assessed with essentially the same composite test as used here (<xref rid="bib0155" ref-type="bibr">Le Grand et al., 2004</xref>). Group studies of adolescents with autism, a neurodevelopmental disorder in which individuals often display face identity and expression recognition impairments (<xref rid="bib0245 bib0285" ref-type="bibr">Sasson, 2006; Wilson et al., 2010</xref>), also reveal impaired holistic coding, as measured with the composite effect (<xref rid="bib0095 bib0260" ref-type="bibr">Gauthier, Klaiman, &amp; Schultz, 2009; Teunisse &amp; de Gelder, 2003</xref>). Our claim that holistic coding contributes to identity recognition is not supported by <xref rid="bib0135" ref-type="bibr">Konar et al.’s (2010)</xref> study of individual differences across the normal population. However, as noted earlier, associations may have been masked by the use of a face matching, rather than recognition memory, task. <xref rid="bib0215" ref-type="bibr">Richler et al. (in press)</xref> did not observe a relationship between face recognition ability on the CFMT and strength of the identity composite effect assessed via the traditional same-different version of the composite task (but note that <italic>n</italic> = 34). They did find a relationship between CFMT scores and the Gauthier-lab version (‘congruency effect’; but see earlier note for discussion of limitations of this version). As such, the present study is the first to show a relationship between face recognition ability and strength of the standard composite effect. This leaves open the possibility that the relationship only becomes apparent with a wide range of CFMT scores (available when including CPs) and is either absent or more difficult to observe in the smaller range afforded by the normal population.</p>
      <p>We note that the holistic processing deficits seen in our study of CPs are milder than those reported in acquired prosopagnosia. In acquired prosopagnosia, case studies have reported a complete lack of holistic coding, for both expression (Case H.J.A., <xref rid="bib0020" ref-type="bibr">Baudouin &amp; Humphreys, 2006</xref>) and identity (Case P.S., <xref rid="bib0200" ref-type="bibr">Ramon et al., 2010</xref>). The difference in results may be related to severity of prosopagnosia. That is, the acquired prosopagnosics tested to date recognise few if any faces (H.J.A. and P.S. identified less than 1% of famous faces, <xref rid="bib0020 bib0240" ref-type="bibr">Baudouin &amp; Humphreys, 2006; Rossion et al., 2003</xref>), and display negligible levels of holistic coding, while CPs who can typically recognise a modest proportion of faces (e.g., the CPs in our present study recognised 33% of famous faces on average), have weak but not completely absent holistic coding. Our finding of weak, but not absent, holistic coding in CP may be consistent with suggestions that CPs are at the lower end of a continuum with normals, of both holistic processing, and of face identity recognition abilities (see <xref rid="bib0035" ref-type="bibr">Bowles et al., 2009</xref> for discussion).</p>
      <p>It is also important to note that we do not wish to argue that weak holistic coding is the only, or even primary, deficit in CP. First, our CPs did show holistic coding, albeit weaker than controls on average. Second, <xref rid="fig0025 fig0035" ref-type="fig">Figs. 5 and 7</xref> suggest there may be heterogeneity between individuals: some individual CPs in the current study appear to display normal levels of holistic coding of expression or identity. For identity, this has also been reported in previous studies (<xref rid="bib0150 bib0250" ref-type="bibr">Le Grand et al., 2006; Schmalzl et al., 2008</xref>), although we note that composite findings from <italic>individual</italic> participants cannot necessarily be taken as reliable from a single composite test, given that the internal reliability of this task is generally not high (e.g., split-half reliability = .65 in <xref rid="bib0305" ref-type="bibr">Zhu et al., 2010</xref>), and thus evidence of normal holistic processing in individual CPs would thus ideally require confirmation from two or more versions of an identity (or expression) composite task.</p>
      <p>To summarise, our CPs as a group displayed normal facial expression recognition, together with impaired facial identity recognition, and weakened holistic processing of both expression and identity. The expression findings suggest an increased use of compensatory non-holistic strategies for expression recognition. The identity findings support a view that holistic coding is functionally involved in face identification. Finally, the findings involving expression and identity in concert, are consistent with a model proposing a general, early, holistic coding stage for multiple facial attributes.</p>
    </sec>
    <sec id="sec0075">
      <title>Funding sources</title>
      <p>This research was supported by funding from Macquarie University and the Australian National University [RP], Australian Research Council's <italic>Discovery Projects</italic> funding scheme (project numbers: DP110100850) [EM and RP] and DP0984558 [EM]) and the MRC (grant code 513111 MC_US_A060_0017 [AJC]).</p>
      <p>These funding sources played no role in study design; in the collection, analysis, and interpretation of data; in the writing of the report; or in the decision to submit the paper for publication.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib0005">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abbas</surname>
              <given-names>Z.-A.</given-names>
            </name>
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>The role of holistic processing in judgments of facial attractiveness</article-title>
          <source>Perception</source>
          <volume>37</volume>
          <year>2008</year>
          <fpage>1187</fpage>
          <lpage>1196</lpage>
          <pub-id pub-id-type="pmid">18853555</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0010">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baron-Cohen</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Wheelwright</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Hill</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Raste</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Plumb</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>The ‘Reading the Mind in the Eyes’ Test Revised Version: A study with normal adults, and adults with Asperger Syndrome or High-Functioning Autism</article-title>
          <source>Journal of Child Psychiatry and Psychiatry</source>
          <volume>42</volume>
          <year>2001</year>
          <fpage>241</fpage>
          <lpage>252</lpage>
        </element-citation>
      </ref>
      <ref id="bib0015">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baron-Cohen</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Wheelwright</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Skinner</surname>
              <given-names>R.J.M.</given-names>
            </name>
            <name>
              <surname>Clubley</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>The Autism Spectrum Quotient (AQ): Evidence from Asperger syndrome/high functioning autism, males and females, scientists and mathematicians</article-title>
          <source>Journal of Autism and Developmental Disorders</source>
          <volume>31</volume>
          <year>2001</year>
          <fpage>5</fpage>
          <lpage>17</lpage>
          <pub-id pub-id-type="pmid">11439754</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0020">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baudouin</surname>
              <given-names>J.-Y.</given-names>
            </name>
            <name>
              <surname>Humphreys</surname>
              <given-names>G.W.</given-names>
            </name>
          </person-group>
          <article-title>Compensatory strategies in processing facial emotions: Evidence from prosopagnosia</article-title>
          <source>Neuropsychologia</source>
          <volume>44</volume>
          <year>2006</year>
          <fpage>1361</fpage>
          <lpage>1369</lpage>
          <pub-id pub-id-type="pmid">16513146</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0025">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Congenital prosopagnosia: Face-blind from birth</article-title>
          <source>Trends in Cognitive Sciences</source>
          <volume>9</volume>
          <year>2005</year>
          <fpage>180</fpage>
          <lpage>187</lpage>
          <pub-id pub-id-type="pmid">15808500</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0030">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Black</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Structural imaging reveals anatomical alterations in inferotemporal cortex in congenital prosopagnosia</article-title>
          <source>Cerebral Cortex</source>
          <volume>17</volume>
          <year>2007</year>
          <fpage>2354</fpage>
          <lpage>2363</lpage>
          <pub-id pub-id-type="pmid">17218483</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0035">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bowles</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>McKone</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Dawel</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Palermo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Schmalzl</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Diagnosing prosopagnosia: Effects of ageing, sex, and participant-stimulus ethnic match on the Cambridge Face Memory Test and Cambridge Face Perception Test</article-title>
          <source>Cognitive Neuropsychology</source>
          <volume>26</volume>
          <year>2009</year>
          <fpage>423</fpage>
          <lpage>455</lpage>
          <pub-id pub-id-type="pmid">19921582</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0040">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bruce</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Understanding face recognition</article-title>
          <source>British Journal of Psychology</source>
          <volume>77</volume>
          <year>1986</year>
          <fpage>305</fpage>
          <lpage>327</lpage>
          <pub-id pub-id-type="pmid">3756376</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0045">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Burton</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>McNeill</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The Glasgow Face Matching Test</article-title>
          <source>Behavior Research Methods</source>
          <volume>42</volume>
          <year>2010</year>
          <fpage>286</fpage>
          <lpage>291</lpage>
          <pub-id pub-id-type="pmid">20160307</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0050">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Jansen</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Configural coding of facial expressions: The impact of inversion and photographic negative</article-title>
          <source>Visual Cognition</source>
          <volume>12</volume>
          <year>2005</year>
          <fpage>495</fpage>
          <lpage>518</lpage>
        </element-citation>
      </ref>
      <ref id="bib0310">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
          </person-group>
          <article-title>Understanding the recognition of facial identity and facial expression</article-title>
          <source>Nature Reviews Neuroscience</source>
          <volume>6</volume>
          <year>2005</year>
          <fpage>641</fpage>
          <lpage>651</lpage>
        </element-citation>
      </ref>
      <ref id="bib0055">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Keane</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dean</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Configural information in facial expression perception</article-title>
          <source>Journal of Experimental Psychology: Human Perception &amp; Performance</source>
          <volume>26</volume>
          <year>2000</year>
          <fpage>527</fpage>
          <lpage>551</lpage>
          <pub-id pub-id-type="pmid">10811161</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0060">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Germine</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Family resemblance: Ten family members with prosopagnosia and within-class object agnosia</article-title>
          <source>Cognitive Neuropsychology</source>
          <volume>24</volume>
          <year>2007</year>
          <fpage>419</fpage>
          <lpage>430</lpage>
          <pub-id pub-id-type="pmid">18416499</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0065">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Murray</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Garrido</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Normal social cognition in developmental prosopagnosia</article-title>
          <source>Cognitive Neuropsychology</source>
          <volume>26</volume>
          <year>2009</year>
          <fpage>620</fpage>
          <lpage>634</lpage>
          <pub-id pub-id-type="pmid">20191404</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0070">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>The Cambridge Face Memory Test: Results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants</article-title>
          <source>Neuropsychologia</source>
          <volume>44</volume>
          <year>2006</year>
          <fpage>576</fpage>
          <lpage>585</lpage>
          <pub-id pub-id-type="pmid">16169565</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0075">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Parker</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Normal emotion recognition in a prosopagnosic</article-title>
          <source>Perception</source>
          <volume>32</volume>
          <year>2003</year>
          <fpage>827</fpage>
          <lpage>838</lpage>
          <pub-id pub-id-type="pmid">12974568</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0080">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ellison</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Massaro</surname>
              <given-names>D.W.</given-names>
            </name>
          </person-group>
          <article-title>Featural evaluation, integration, and judgment of facial affect</article-title>
          <source>Journal of Experimental Psychology. Human Perception and performance</source>
          <volume>23</volume>
          <issue>1</issue>
          <year>1997</year>
          <fpage>213</fpage>
          <lpage>226</lpage>
          <pub-id pub-id-type="pmid">9090153</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0085">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Field</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Discovering statistics using SPSS</chapter-title>
          <edition>3rd ed.</edition>
          <year>2009</year>
          <publisher-name>Sage</publisher-name>
          <publisher-loc>London</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib0090">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Garrido</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Furl</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Draganski</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Weiskopf</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Stevens</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>G.C.-Y.</given-names>
            </name>
          </person-group>
          <article-title>Voxel-based morphometry reveals reduced grey matter volume in the temporal cortex of developmental prosopagnosics</article-title>
          <source>Brain</source>
          <volume>132</volume>
          <year>2009</year>
          <fpage>3443</fpage>
          <lpage>3455</lpage>
          <pub-id pub-id-type="pmid">19887506</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0095">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gauthier</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Klaiman</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Schultz</surname>
              <given-names>R.T.</given-names>
            </name>
          </person-group>
          <article-title>Face composite effects reveal abnormal face processing in Autism spectrum disorders</article-title>
          <source>Vision Research</source>
          <volume>49</volume>
          <year>2009</year>
          <fpage>470</fpage>
          <lpage>478</lpage>
          <pub-id pub-id-type="pmid">19135077</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grueter</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Grueter</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Bell</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Horst</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Laskowski</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Sperling</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Hereditary prosopagnosia: The first case series</article-title>
          <source>Cortex</source>
          <volume>43</volume>
          <year>2007</year>
          <fpage>734</fpage>
          <lpage>749</lpage>
          <pub-id pub-id-type="pmid">17710825</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haxby</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Hoffman</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>M.I.</given-names>
            </name>
          </person-group>
          <article-title>The distributed human neural system for face perception</article-title>
          <source>Trends in Cognitive Sciences</source>
          <volume>4</volume>
          <year>2000</year>
          <fpage>223</fpage>
          <lpage>233</lpage>
          <pub-id pub-id-type="pmid">10827445</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0110">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Humphreys</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A detailed investigation of facial expression processing in congenital prosopagnosia as compared to acquired prosopagnosia</article-title>
          <source>Experimental Brain Research</source>
          <volume>176</volume>
          <year>2007</year>
          <fpage>356</fpage>
          <lpage>373</lpage>
        </element-citation>
      </ref>
      <ref id="bib0115">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ishihara</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <chapter-title>Tests for color-blindness</chapter-title>
          <edition>5th ed.</edition>
          <year>1925</year>
          <publisher-name>Kanehara</publisher-name>
          <publisher-loc>Tokyo</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib0120">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jacques</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>The initial representation of individual faces in the right occipito-temporal cortex is holistic: Electrophysiological evidence from the composite face illusion</article-title>
          <source>Journal of Vision</source>
          <volume>9</volume>
          <year>2009</year>
          <comment>8.1-16</comment>
        </element-citation>
      </ref>
      <ref id="bib0125">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jacques</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Misaligning face halves increases and delays the N170 specifically for upright faces: Implications for the nature of early face representations</article-title>
          <source>Brain Research</source>
          <year>2010</year>
          <fpage>1</fpage>
          <lpage>45</lpage>
        </element-citation>
      </ref>
      <ref id="bib0130">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kennerknecht</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Grueter</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Welling</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Wentzek</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Horst</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Edwards</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>First report of prevalence of non-syndromic hereditary prosopagnosia (HPA)</article-title>
          <source>American Journal of Medical Genetics Part A</source>
          <volume>140A</volume>
          <year>2006</year>
          <fpage>1617</fpage>
          <lpage>1622</lpage>
          <pub-id pub-id-type="pmid">16817175</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0135">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Konar</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Bennett</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Sekuler</surname>
              <given-names>A.B.</given-names>
            </name>
          </person-group>
          <article-title>Holistic processing is not correlated with face-identification accuracy</article-title>
          <source>Psychological Science</source>
          <volume>21</volume>
          <issue>1</issue>
          <year>2010</year>
          <fpage>38</fpage>
          <lpage>43</lpage>
          <pub-id pub-id-type="pmid">20424020</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0140">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kress</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Daum</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Developmental prosopagnosia: A review</article-title>
          <source>Behavioural Neurology</source>
          <volume>14</volume>
          <year>2003</year>
          <fpage>109</fpage>
          <lpage>121</lpage>
          <pub-id pub-id-type="pmid">14757987</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0145">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kuefner</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Jacques</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Prieto</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Electrophysiological correlates of the composite face illusion: Disentangling perceptual and decisional components of holistic face processing in the human brain</article-title>
          <source>Brain and Cognition</source>
          <volume>74</volume>
          <year>2010</year>
          <fpage>225</fpage>
          <lpage>238</lpage>
          <pub-id pub-id-type="pmid">20851511</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0150">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Le Grand</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Cooper</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Mondloch</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>T.L.</given-names>
            </name>
            <name>
              <surname>Sagiv</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>de Gelder</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>What aspects of face processing are impaired in developmental prosopagnosia?</article-title>
          <source>Brain and Cognition</source>
          <volume>61</volume>
          <year>2006</year>
          <fpage>139</fpage>
          <lpage>158</lpage>
          <pub-id pub-id-type="pmid">16466839</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0155">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Le Grand</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Mondloch</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Maurer</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Brent</surname>
              <given-names>H.P.</given-names>
            </name>
          </person-group>
          <article-title>Impairment in holistic face processing following early visual deprivation</article-title>
          <source>Psychological Science</source>
          <volume>15</volume>
          <year>2004</year>
          <fpage>762</fpage>
          <lpage>768</lpage>
          <pub-id pub-id-type="pmid">15482448</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0160">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Wilson</surname>
              <given-names>H.R.</given-names>
            </name>
            <name>
              <surname>Nakayama</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Three cases of developmental prosopagnosia from one family: Detailed neuropsychological and psychophysical investigation of face processing</article-title>
          <source>Cortex</source>
          <volume>46</volume>
          <year>2010</year>
          <fpage>949</fpage>
          <lpage>964</lpage>
          <pub-id pub-id-type="pmid">19726036</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0165">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Letourneau</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Mitchell</surname>
              <given-names>T.V.</given-names>
            </name>
          </person-group>
          <article-title>Behavioral and ERP measures of holistic face processing in a composite task</article-title>
          <source>Brain and Cognition</source>
          <volume>67</volume>
          <year>2008</year>
          <fpage>234</fpage>
          <lpage>245</lpage>
          <pub-id pub-id-type="pmid">18336979</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0170">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Lundqvist</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Flykt</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Öhman</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>The Karolinska Directed Emotional Faces—KDEF</chapter-title>
          <year>1998</year>
          <publisher-name>CD ROM from Department of Clinical Neuroscience, Psychology Section, Karolinska Institutet</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib0175">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McKone</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Holistic processing for faces operates over a wide range of sizes but is strongest at identification rather than conversational distances</article-title>
          <source>Vision Research</source>
          <volume>49</volume>
          <year>2008</year>
          <fpage>268</fpage>
          <lpage>283</lpage>
          <pub-id pub-id-type="pmid">19022276</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0185">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mondloch</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Maurer</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>The effect of face orientation on holistic processing</article-title>
          <source>Perception</source>
          <volume>37</volume>
          <year>2008</year>
          <fpage>1175</fpage>
          <lpage>1186</lpage>
          <pub-id pub-id-type="pmid">18853554</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0190">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nunn</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Postma</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Pearson</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Developmental prosopagnosia: Should it be taken at face value?</article-title>
          <source>Neurocase</source>
          <volume>7</volume>
          <year>2001</year>
          <fpage>15</fpage>
          <lpage>27</lpage>
          <pub-id pub-id-type="pmid">11239073</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0195">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pitcher</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Garrido</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Walsh</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Duchaine</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Transcranial magnetic stimulation disrupts the perception and embodiment of facial expressions</article-title>
          <source>Journal of Neuroscience</source>
          <volume>28</volume>
          <year>2008</year>
          <fpage>8929</fpage>
          <lpage>8933</lpage>
          <pub-id pub-id-type="pmid">18768686</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0200">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ramon</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Busigny</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Impaired holistic processing of unfamiliar individual faces in acquired prosopagnosia</article-title>
          <source>Neuropsychologia</source>
          <volume>48</volume>
          <year>2010</year>
          <fpage>933</fpage>
          <lpage>944</lpage>
          <pub-id pub-id-type="pmid">19944710</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0205">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Raven</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Raven</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Court</surname>
              <given-names>J.H.</given-names>
            </name>
          </person-group>
          <chapter-title>Manual for Raven's Progressive Matrices and Vocabulary Scales</chapter-title>
          <year>1998</year>
          <publisher-name>Harcourt Assessment</publisher-name>
          <publisher-loc>San Antonio, TX, USA</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib0210">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Richler</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Gauthier</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Wenger</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Palmeri</surname>
              <given-names>T.J.</given-names>
            </name>
          </person-group>
          <article-title>Holistic processing of faces: Perceptual and decisional components</article-title>
          <source>Journal of Experimental Psychology: Learning Memory and Cognition</source>
          <volume>34</volume>
          <year>2008</year>
          <fpage>328</fpage>
          <lpage>342</lpage>
        </element-citation>
      </ref>
      <ref id="bib0215">
        <mixed-citation publication-type="other">Richler, J.J., Cheung, O.S., &amp; Gauthier, I. Holistic processing predicts face recognition. <italic>Psychological Science</italic>, in press.</mixed-citation>
      </ref>
      <ref id="bib0315">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Richler</surname>
              <given-names>J.J.</given-names>
            </name>
            <name>
              <surname>Mack</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Palmeri</surname>
              <given-names>T.J.</given-names>
            </name>
            <name>
              <surname>Gauthier</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Inverted faces are (eventually) processed holistically</article-title>
          <source>Vision Research</source>
          <volume>51</volume>
          <year>2011</year>
          <fpage>333</fpage>
          <lpage>342</lpage>
          <pub-id pub-id-type="pmid">21130798</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0225">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Riddoch</surname>
              <given-names>M.J.</given-names>
            </name>
            <name>
              <surname>Humphreys</surname>
              <given-names>G.W.</given-names>
            </name>
          </person-group>
          <chapter-title>BORB: The Birmingham Object Recognition Battery</chapter-title>
          <year>1993</year>
          <publisher-name>Lawrence Erlbaum Associates</publisher-name>
          <publisher-loc>Hove, UK</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib0320">
        <mixed-citation publication-type="other">Rivolta, D., Palermo, R., Schmalzl, L., &amp; Coltheart, M. Covert face recognition in congenital prosopagnosia: A group study. Cortex, in press.</mixed-citation>
      </ref>
      <ref id="bib0230">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Robbins</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>McKone</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>No face-like processing for objects-of-expertise in three behavioural tasks</article-title>
          <source>Cognition</source>
          <volume>103</volume>
          <year>2007</year>
          <fpage>34</fpage>
          <lpage>79</lpage>
          <pub-id pub-id-type="pmid">16616910</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0235">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Picture-plane inversion leads to qualitative changes of face perception</article-title>
          <source>Acta Psychologia</source>
          <volume>128</volume>
          <year>2008</year>
          <fpage>274</fpage>
          <lpage>289</lpage>
        </element-citation>
      </ref>
      <ref id="bib0240">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rossion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Caldara</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Seghier</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Schuller</surname>
              <given-names>A.-M.</given-names>
            </name>
            <name>
              <surname>Lazeyras</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Mayer</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>A network of occipito-temporal face-sensitive areas besides the right middle fusiform gyrus is necessary for normal face processing</article-title>
          <source>Brain</source>
          <volume>126</volume>
          <year>2003</year>
          <fpage>2381</fpage>
          <lpage>2395</lpage>
          <pub-id pub-id-type="pmid">12876150</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0245">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sasson</surname>
              <given-names>N.J.</given-names>
            </name>
          </person-group>
          <article-title>The development of face processing in autism</article-title>
          <source>Journal of Autism and Developmental Disorders</source>
          <volume>36</volume>
          <year>2006</year>
          <fpage>381</fpage>
          <lpage>394</lpage>
          <pub-id pub-id-type="pmid">16572261</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0250">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schmalzl</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Palermo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Coltheart</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Cognitive heterogeneity in genetically-based prosopagnosia: A family study</article-title>
          <source>Journal of Neuropsychology</source>
          <volume>2</volume>
          <year>2008</year>
          <comment>99-17</comment>
        </element-citation>
      </ref>
      <ref id="bib0255">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>StatSoft, Inc.</surname>
            </name>
          </person-group>
          <chapter-title>Electronic Statistics Textbook</chapter-title>
          <year>2010</year>
          <publisher-name>StatSoft.</publisher-name>
          <publisher-loc>Tulsa, OK</publisher-loc>
          <comment>WEB: <ext-link ext-link-type="uri" xlink:href="http://www.statsoft.com/textbook/">http://www.statsoft.com/textbook/</ext-link></comment>
        </element-citation>
      </ref>
      <ref id="bib0260">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Teunisse</surname>
              <given-names>J.-P.</given-names>
            </name>
            <name>
              <surname>de Gelder</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Face processing in adolescents with autistic disorder: The inversion and composite effects</article-title>
          <source>Brain and Cognition</source>
          <volume>52</volume>
          <year>2003</year>
          <fpage>285</fpage>
          <lpage>294</lpage>
          <pub-id pub-id-type="pmid">12907173</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0265">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thomas</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Avidan</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Humphreys</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Jung</surname>
              <given-names>K.-J.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Behrmann</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Reduced structural connectivity in ventral visual cortex in congenital prosopagnosia</article-title>
          <source>Nature Neuroscience</source>
          <volume>12</volume>
          <year>2009</year>
          <fpage>29</fpage>
          <lpage>31</lpage>
        </element-citation>
      </ref>
      <ref id="bib0270">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tottenham</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Tanaka</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Leon</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>McCarry</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Nurse</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hare</surname>
              <given-names>T.A.</given-names>
            </name>
          </person-group>
          <article-title>The NimStim set of facial expressions: Judgments from untrained research participants</article-title>
          <source>Psychiatry Research</source>
          <volume>168</volume>
          <year>2009</year>
          <fpage>242</fpage>
          <lpage>249</lpage>
          <pub-id pub-id-type="pmid">19564050</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0275">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>White</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Parts and wholes in expression recognition</article-title>
          <source>Cognition and Emotion</source>
          <volume>14</volume>
          <year>2000</year>
          <fpage>39</fpage>
          <lpage>60</lpage>
        </element-citation>
      </ref>
      <ref id="bib0280">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wilmer</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Germine</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Chabris</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Chatterjee</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Loken</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Human face recognition ability is specific and highly heritable</article-title>
          <source>Proceedings of the National Academy of Sciences of the United States of America</source>
          <volume>107</volume>
          <year>2010</year>
          <fpage>5238</fpage>
          <lpage>5241</lpage>
          <pub-id pub-id-type="pmid">20176944</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0285">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wilson</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Palermo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Schmalzl</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Brock</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Specificity of impaired facial identity recognition in children with suspected developmental prosopagnosia</article-title>
          <source>Cognitive Neuropsychology</source>
          <volume>27</volume>
          <year>2010</year>
          <fpage>1</fpage>
          <lpage>30</lpage>
          <pub-id pub-id-type="pmid">20812057</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0290">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Hellawell</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Hay</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Configural information in face perception</article-title>
          <source>Perception</source>
          <volume>16</volume>
          <year>1987</year>
          <fpage>747</fpage>
          <lpage>759</lpage>
          <pub-id pub-id-type="pmid">3454432</pub-id>
        </element-citation>
      </ref>
      <ref id="bib0295">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Young</surname>
              <given-names>A.W.</given-names>
            </name>
            <name>
              <surname>Perrett</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Calder</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Sprengelmeyer</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ekman</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <chapter-title>Facial expressions of emotion: Stimuli and tests (FEEST) [computer software].</chapter-title>
          <year>2002</year>
          <publisher-name>Thames Valley Test Company</publisher-name>
          <publisher-loc>Bury St Edmunds, England</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib0300">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhao</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hayward</surname>
              <given-names>W.G.</given-names>
            </name>
          </person-group>
          <article-title>Holistic processing underlies gender judgments of faces</article-title>
          <source>Attention, Perception &amp; Psychophysics</source>
          <volume>72</volume>
          <year>2010</year>
          <fpage>591</fpage>
          <lpage>596</lpage>
        </element-citation>
      </ref>
      <ref id="bib0305">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Tian</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Zhen</surname>
              <given-names>Z.</given-names>
            </name>
          </person-group>
          <article-title>Heritability of the specific cognitive ability of face perception</article-title>
          <source>Current Biology</source>
          <volume>20</volume>
          <year>2010</year>
          <fpage>137</fpage>
          <lpage>142</lpage>
          <pub-id pub-id-type="pmid">20060296</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <ack>
      <title>Acknowledgements</title>
      <p>We thank Daphne Maurer and the McMaster Visual Development Lab for providing the composite faces used in the identity composite effect. Development of the MacBrain Face Stimulus Set was overseen by Nim Tottenham and supported by the John D. and Catherine T. MacArthur Foundation Research Network on Early Experience and Brain Development. Please contact Nim Tottenham at tott0006@tc.umn.edu for more information concerning the stimulus set.</p>
    </ack>
    <fn-group>
      <fn id="fn0005">
        <label>1</label>
        <p>The FACT was not administered to F47-8 and M57.</p>
      </fn>
      <fn id="fn0010">
        <label>2</label>
        <p>The CFMT <italic>z</italic>-score (−1.39) for F30-1 likely overestimates her face recognition skills as it was the second time she completed the test (the initial score six weeks prior was not recorded due to computer malfunction) and controls, on average, improve 6.3 percentage points when re-tested approximately 6 months later (<xref rid="bib0280" ref-type="bibr">Wilmer et al., 2010</xref>).</p>
      </fn>
      <fn id="fn0015">
        <label>3</label>
        <p>For the four CPs with normal-looking CFPT performance (F23-4, M53-5, M20-2, M60-1), holistic coding strength was not consistently greater, or lower, than that of the other prosopagnosics. Thus, we opted to include all 12 CPs whose performance we assessed, on the basis that they are representative of the typical CP population.</p>
      </fn>
      <fn id="fn0020">
        <label>4</label>
        <p>Given that happy faces are typically recognized more accurately/rapidly than other expressions, we also analysed the bottom-half-target condition leaving out the happy-target trials. The results did not change: there was still no difference in baseline adjusted composite effect scores for CPs and controls, <italic>z</italic> = .57, <italic>p</italic> = .90.</p>
      </fn>
    </fn-group>
  </back>
  <floats-group>
    <fig id="fig0005">
      <label>Fig. 1</label>
      <caption>
        <p>(a) <italic>Identity composite task</italic>. Pairs of faces were shown sequentially and participants judged whether the top halves of the faces were either the “same” or “different”. In this example the top halves were the “same” in both the unaligned (left) and aligned (right) pairs. The bottom halves were always of a different individual to the top individual. Reprinted with kind permission from <xref rid="bib0155" ref-type="bibr">Le Grand et al. (2004)</xref>. (b) <italic>Expression Composite task</italic>. Examples of unaligned (left) and aligned (right) composite expressions in which participants judged the expression from either the (i) top (fear) or (ii) bottom (disgusted) halves of the face. The other half of the face was always of a different expression. Face images are from the KDEF (<xref rid="bib0170" ref-type="bibr">Lundqvist et al., 1998</xref>).</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig0010">
      <label>Fig. 2</label>
      <caption>
        <p>Models of holistic processing in identity and expression processing. In Model A, there are two separate holistic processing stages, one for expression and one for identity. In Model B, there is a holistic coding stage that is common to both expression and identity processing. Face image is from the KDEF (<xref rid="bib0170" ref-type="bibr">Lundqvist et al., 1998</xref>).</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig0015">
      <label>Fig. 3</label>
      <caption>
        <p><italic>Z</italic>-scores of the 12 prosopagnosics on three tests of facial identity recognition, the MACCS Famous Face Test-08 (MFFT-08, Palermo et al., in preparation), the Cambridge Face Memory Test (CFMT, <xref rid="bib0070" ref-type="bibr">Duchaine &amp; Nakayama, 2006</xref>) and the Cambridge Face Perception Test (CFPT, <xref rid="bib0060" ref-type="bibr">Duchaine et al., 2007</xref>). The prosopagnosics are labelled by sex and their age at completing the identity, and then expression, tests.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig0020">
      <label>Fig. 4</label>
      <caption>
        <p>Mean RTs for the aligned vs. unaligned condition for controls and prosopagnosics, for expressions recognised from the top (anger, fear, sadness) and bottom (happiness, surprise, disgust) of a composite. Standard error bars are shown (adjusted for within-subject comparisons).</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig0025">
      <label>Fig. 5</label>
      <caption>
        <p>Normalised RT scores for expressions recognised from the top (anger, fear, sadness) and bottom (happiness, surprise, disgust) of a composite for each control and prosopagnosic. Means and SEMs displayed for each group.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig0030">
      <label>Fig. 6</label>
      <caption>
        <p>Mean RT for the aligned vs. unaligned condition for controls and prosopagnosics on the <italic>same</italic>-identity composite effect trials. Standard error bars are shown (adjusted for within-subject comparisons).</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig0035">
      <label>Fig. 7</label>
      <caption>
        <p>Normalised RT scores for the identity composite for each control and prosopagnosic. Means and SEMs displayed for each group.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <table-wrap id="tbl0005" position="float">
      <label>Table 1</label>
      <caption>
        <p>Scores on the <italic>Ekman 60 Faces</italic> and <italic>Emotion Hexagon</italic> tests (<xref rid="bib0295" ref-type="bibr">Young et al., 2002</xref>), the <italic>Reading the Mind in the Eyes</italic> test (<xref rid="bib0010 bib0015" ref-type="bibr">Baron-Cohen et al., 2001</xref>), and the <italic>Autism Spectrum Quotient</italic> (AQ) (<xref rid="bib0010 bib0015" ref-type="bibr">1</xref>) for each of the prosopagnosics, and means and standard deviations for the prosopagnosic (<italic>n</italic> = 12) and control (n = 17) groups.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th align="left">Ekman 60 Faces (/60)</th>
            <th align="left">Emotion Hexagon (/120)</th>
            <th align="left">Reading the Mind in the Eyes (/36)</th>
            <th align="left">Autism Spectrum Quotient (AQ)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="5" align="left">
              <italic>Prosopagnosics</italic>
            </td>
          </tr>
          <tr>
            <td align="left">F23-4</td>
            <td align="char">55</td>
            <td align="char">119</td>
            <td align="char">33</td>
            <td align="char">16</td>
          </tr>
          <tr>
            <td align="left">F30-1</td>
            <td align="char">53</td>
            <td align="char">120</td>
            <td align="char">28</td>
            <td align="char">11</td>
          </tr>
          <tr>
            <td align="left">F33</td>
            <td align="char">51</td>
            <td align="char">120</td>
            <td align="char">31</td>
            <td align="char">11</td>
          </tr>
          <tr>
            <td align="left">F37-8</td>
            <td align="char">52</td>
            <td align="char">115</td>
            <td align="char">28</td>
            <td align="char">3</td>
          </tr>
          <tr>
            <td align="left">F37-9</td>
            <td align="char">50</td>
            <td align="char">115</td>
            <td align="char">32</td>
            <td align="char">11</td>
          </tr>
          <tr>
            <td align="left">F40-1</td>
            <td align="char">53</td>
            <td align="char">112</td>
            <td align="char">28</td>
            <td align="char">14</td>
          </tr>
          <tr>
            <td align="left">F47-8</td>
            <td align="char">55</td>
            <td align="char">113</td>
            <td align="char">27</td>
            <td align="char">30</td>
          </tr>
          <tr>
            <td align="left">F50-1</td>
            <td align="char">52</td>
            <td align="char">111</td>
            <td align="char">29</td>
            <td align="char">22</td>
          </tr>
          <tr>
            <td align="left">M20-2</td>
            <td align="char">54</td>
            <td align="char">110</td>
            <td align="char">25</td>
            <td align="char">23</td>
          </tr>
          <tr>
            <td align="left">M53-5</td>
            <td align="char">49</td>
            <td align="char">102</td>
            <td align="char">29</td>
            <td align="char">22</td>
          </tr>
          <tr>
            <td align="left">M57</td>
            <td align="char">49</td>
            <td align="char">111</td>
            <td align="char">28</td>
            <td align="char">20</td>
          </tr>
          <tr>
            <td align="left">M60-1</td>
            <td align="char">58</td>
            <td align="char">118</td>
            <td align="char">33</td>
            <td align="char">28</td>
          </tr>
          <tr>
            <td align="left">Mean (SD) (<italic>n</italic> = 12)</td>
            <td align="char">52.58 (2.68)</td>
            <td align="char">113.83 (5.20)</td>
            <td align="char">29.25 (2.49)</td>
            <td align="char">17.58 (7.95)</td>
          </tr>
          <tr>
            <td align="left"><italic>Controls</italic> (<italic>n</italic> = 17)</td>
            <td/>
            <td/>
            <td/>
            <td/>
          </tr>
          <tr>
            <td align="left">Mean (SD)</td>
            <td align="char">52.00 (4.03)</td>
            <td align="char">114.29 (3.41)</td>
            <td align="char">27.94 (2.73)</td>
            <td align="char">14.00 (4.74)</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="tbl0010" position="float">
      <label>Table 2</label>
      <caption>
        <p>Percent accuracy for the aligned vs. unaligned conditions for controls and prosopagnosics, for expressions recognised from the top (anger, fear, sadness) and bottom (happiness, surprise, disgust) of a composite (standard errors, adjusted for within-subject comparisons in parentheses).</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th colspan="2" align="left">Top<hr/></th>
            <th colspan="2" align="left">Bottom<hr/></th>
          </tr>
          <tr>
            <th/>
            <th align="left">Aligned</th>
            <th align="left">Unaligned</th>
            <th align="left">Aligned</th>
            <th align="left">Unaligned</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Controls</td>
            <td align="char">85.65 (1.38)</td>
            <td align="char">87.82 (1.38)</td>
            <td align="char">92.35 (1.46)</td>
            <td align="char">95.35 (1.46)</td>
          </tr>
          <tr>
            <td align="left">Prosopagnosics</td>
            <td align="char">82.83 (2.56)</td>
            <td align="char">84.25 (2.56)</td>
            <td align="char">96.33 (1.12)</td>
            <td align="char">96.92 (1.12)</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="tbl0015" position="float">
      <label>Table 3</label>
      <caption>
        <p>Percent accuracy for <italic>same</italic>-identity trials and percent accuracy and mean RTs for <italic>different</italic>-identity trials (standard errors, adjusted for within-subject comparisons in parentheses).</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th colspan="2" align="left"><italic>Same</italic>-identity trials<hr/></th>
            <th colspan="4" align="left"><italic>Different</italic>-identity trials<hr/></th>
          </tr>
          <tr>
            <th/>
            <th colspan="2" align="left">Percent accuracy<hr/></th>
            <th colspan="2" align="left">Percent accuracy<hr/></th>
            <th colspan="2" align="left">Mean RTs (ms)<xref rid="tblfn0005" ref-type="table-fn">a</xref><hr/></th>
          </tr>
          <tr>
            <th/>
            <th align="left">Aligned</th>
            <th align="left">Unaligned</th>
            <th align="left">Aligned</th>
            <th align="left">Unaligned</th>
            <th align="left">Aligned</th>
            <th align="left">Unaligned</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Controls</td>
            <td align="char">80.97 (2.74)</td>
            <td align="char">91.37 (2.74)</td>
            <td align="char">81.53 (2.98)</td>
            <td align="char">80.27 (2.98)</td>
            <td align="char">940 (27)</td>
            <td align="char">806 (27)</td>
          </tr>
          <tr>
            <td align="left">Prosopagnosics</td>
            <td align="char">80.56 (4.07)</td>
            <td align="char">92.60 (4.07)</td>
            <td align="char">80.56 (2.84)</td>
            <td align="char">79.63 (2.84)</td>
            <td align="char">1043 (45)</td>
            <td align="char">928 (45)</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn0005">
          <label>a</label>
          <p>One prosopagnosic (M53-5) was excluded as his mean RTs were consistently longer than the other participants: 2690 ms (aligned) and 5706 ms (unaligned).</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </floats-group>
</article>