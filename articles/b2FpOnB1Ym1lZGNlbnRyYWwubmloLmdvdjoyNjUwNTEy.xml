<article xmlns="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://dtd.nlm.nih.gov/2.0/xsd/archivearticle http://dtd.nlm.nih.gov/2.0/xsd/archivearticle.xsd" article-type="research-article">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neural Netw</journal-id>
      <journal-title>Neural Networks</journal-title>
      <issn pub-type="ppub">0893-6080</issn>
      <issn pub-type="epub">1879-2782</issn>
      <publisher>
        <publisher-name>Pergamon Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmc">2650512</article-id>
      <article-id pub-id-type="pmid">18835129</article-id>
      <article-id pub-id-type="publisher-id">NN2475</article-id>
      <article-id pub-id-type="doi">10.1016/j.neunet.2008.08.007</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Integrated Bayesian models of learning and decision making for saccadic eye movements<sup><xref ref-type="fn" rid="N0x1d53730N0x2a5be50">☆</xref></sup></article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Brodersen</surname>
            <given-names>Kay H.</given-names>
          </name>
          <email>kay.brodersen@gmx.net</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
          <xref rid="cor1" ref-type="corresp">⁎</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Penny</surname>
            <given-names>Will D.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Harrison</surname>
            <given-names>Lee M.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Daunizeau</surname>
            <given-names>Jean</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ruff</surname>
            <given-names>Christian C.</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Duzel</surname>
            <given-names>Emrah</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Friston</surname>
            <given-names>Karl J.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Stephan</surname>
            <given-names>Klaas E.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff4" ref-type="aff">d</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line><sup>a</sup>Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, 12 Queen Square, London WC1N 3BG, UK</addr-line>
      </aff>
      <aff id="aff2">
        <addr-line><sup>b</sup>Centre for Functional Magnetic Resonance Imaging of the Brain (FMRIB), John Radcliffe Hospital, University of Oxford, Oxford OX3 9DU, UK</addr-line>
      </aff>
      <aff id="aff3">
        <addr-line><sup>c</sup>Institute of Cognitive Neuroscience, University College London, 17 Queen Square, London WC1N 3AR, UK</addr-line>
      </aff>
      <aff id="aff4">
        <addr-line><sup>d</sup>Branco-Weiss-Laboratory, Institute for Empirical Research in Economics, University of Zurich, Switzerland</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><label>⁎</label>Corresponding author at: Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, 12 Queen Square, London WC1N 3BG, UK. <email>kay.brodersen@gmx.net</email></corresp>
      </author-notes>
      <pub-date pub-type="ppub">
        <month>11</month>
        <year>2008</year>
      </pub-date>
      <volume>21</volume>
      <issue>9</issue>
      <fpage>1247</fpage>
      <lpage>1260</lpage>
      <history>
        <date date-type="received">
          <day>7</day>
          <month>9</month>
          <year>2007</year>
        </date>
        <date date-type="rev-recd">
          <day>29</day>
          <month>8</month>
          <year>2008</year>
        </date>
        <date date-type="accepted">
          <day>31</day>
          <month>8</month>
          <year>2008</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2008 Elsevier Ltd.</copyright-statement>
        <copyright-year>2008</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license>
          <p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.elsevier.com/wps/find/authorsview.authors/supplementalterms1.0">certain conditions</ext-link>.</p>
        </license>
      </permissions>
      <abstract>
        <title>Abstract</title>
        <p>The neurophysiology of eye movements has been studied extensively, and several computational models have been proposed for decision-making processes that underlie the generation of eye movements towards a visual stimulus in a situation of uncertainty. One class of models, known as linear rise-to-threshold models, provides an economical, yet broadly applicable, explanation for the observed variability in the latency between the onset of a peripheral visual target and the saccade towards it. So far, however, these models do not account for the dynamics of learning across a sequence of stimuli, and they do not apply to situations in which subjects are exposed to events with conditional probabilities. In this methodological paper, we extend the class of linear rise-to-threshold models to address these limitations. Specifically, we reformulate previous models in terms of a generative, hierarchical model, by combining two separate sub-models that account for the interplay between learning of target locations across trials and the decision-making process within trials. We derive a maximum-likelihood scheme for parameter estimation as well as model comparison on the basis of log likelihood ratios. The utility of the integrated model is demonstrated by applying it to empirical saccade data acquired from three healthy subjects. Model comparison is used (i) to show that eye movements do not only reflect marginal but also conditional probabilities of target locations, and (ii) to reveal subject-specific learning profiles over trials. These individual learning profiles are sufficiently distinct that test samples can be successfully mapped onto the correct subject by a naïve Bayes classifier. Altogether, our approach extends the class of linear rise-to-threshold models of saccadic decision making, overcomes some of their previous limitations, and enables statistical inference both about learning of target locations across trials and the decision-making process within trials.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Saccades</kwd>
        <kwd>Decision making</kwd>
        <kwd>Reaction time</kwd>
        <kwd>Bayesian learning</kwd>
        <kwd>Model comparison</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <label>1</label>
      <title>Introduction</title>
      <p>In order to survive in a competitive, dynamic environment, animals must be able to integrate past experience with sensory evidence to infer the current state of the world and execute a behavioural response. Marked progress in our understanding of the neural basis of decision making has been achieved by focusing on sensory-driven decisions, such as the simple question of where to look next. Studying decision making in sensorimotor systems like the oculomotor system has the advantage that one can exploit a large body of neuroanatomical and neurophysiological knowledge that has been accumulated over the past decades. It seems conceivable that studying the neuronal mechanisms of visual-saccadic decision making could provide us with a blueprint of how the brain implements other sensorimotor decisions, or even deliver “a model for understanding decision making in general” (<xref rid="b14" ref-type="bibr">Glimcher, 2003</xref>).</p>
      <p>The decision processes that underlie rapid eye movements towards a target have been studied in a variety of experimental paradigms. One seminal series of studies is based on the <italic>random dot-motion</italic> task designed by Newsome and colleagues (<xref rid="b48" ref-type="bibr">Newsome &amp; Pare, 1988</xref>). In an initial fixed-duration version of this task, monkeys were trained to discriminate the motion direction of a set of moving dots with varying degrees of coherence, and indicate the perceived motion by a leftward or rightward saccade (<xref rid="b45 b46 b47 b67" ref-type="bibr">Newsome, 1997; Newsome, Britten, &amp; Movshon, 1989; Newsome, Britten, Salzman, &amp; Movshon, 1990; Salzman, Britten, &amp; Newsome, 1990</xref>). Subsequently, <xref rid="b71" ref-type="bibr">Shadlen, Britten, Newsome, and Movshon (1996)</xref> suggested a computational explanation of the neuronal mechanisms producing the resulting saccade and provided experimental verification of its key assumptions (<xref rid="b15 b28 b71 b74" ref-type="bibr">Gold &amp; Shadlen, 2000; Kim &amp; Shadlen, 1999; Shadlen et al., 1996; Shadlen &amp; Newsome, 2001</xref>). In particular, they identified a gradual rise of spiking activity in the lateral intraparietal (LIP) area integrating motion direction-specific signals from the middle temporal (MT) area (<xref rid="b73 b74" ref-type="bibr">Shadlen &amp; Newsome, 1996, 2001</xref>).</p>
      <p>Based on a reaction time version of the same task (<xref rid="b65" ref-type="bibr">Roitman &amp; Shadlen, 2002</xref>), Shadlen and colleagues advanced the hypothesis that rising activity before a saccade, which had also been observed in the frontal eye fields (FEF), represented the ratio of the log likelihoods that the two possible eye movements would be executed (<xref rid="b15 b16" ref-type="bibr">Gold &amp; Shadlen, 2000, 2001</xref>). Based on their decision-theoretic analysis, they suggested that log likelihood ratios might be used as “a natural currency for trading off sensory information, prior probability and expected value to form a perceptual decision” (<xref rid="b16" ref-type="bibr">Gold &amp; Shadlen, 2001</xref>).</p>
      <p>Another key series of studies was carried out by Hanes, Schall, and colleagues, who investigated an <italic>oddball</italic> task (as well as the <italic>countermanding</italic> paradigm; <xref rid="b19" ref-type="bibr">Hanes and Carpenter (1999)</xref>) to study how neural signals in the FEFs would finally trigger the initiation of saccades (<xref rid="b21 b22 b70 b82 b83" ref-type="bibr">Hanes &amp; Schall, 1996; Hanes, Thompson, &amp; Schall, 1995; Schall &amp; Thompson, 1999; Thompson, Bichot, &amp; Schall, 1997; Thompson, Hanes, Bichot, &amp; Schall, 1996</xref>). In their oddball task, monkeys were trained to indicate, by an eye movement, the location of the oddball within a circular arrangement of visual stimuli around a central fixation dot. They showed that FEF activity was consistent with psychophysical models about oddball reaction time tasks (<xref rid="b35 b55 b79 b80" ref-type="bibr">Luce, 1986; Ratcliff, 1978; Sternberg, 1969a, 1969b</xref>). Specifically, their findings supported the notion that the saccadic decision would be made as soon as gradually increasing neural activity in the FEFs had crossed a biophysical threshold (<xref rid="b20 b70" ref-type="bibr">Hanes, Patterson, &amp; Schall, 1998; Schall &amp; Thompson, 1999</xref>).</p>
      <p>Motivated by the question of why saccadic latencies displayed large variance in all of the above tasks, an even simpler reaction time paradigm was investigated by Carpenter and colleagues (<xref rid="b9 b63" ref-type="bibr">Carpenter &amp; Williams, 1995; Reddi &amp; Carpenter, 2000</xref>). In their <italic>saccade-to-target</italic> reaction time task, human subjects were asked to shift their gaze from a central fixation stimulus to an eccentric target as soon as it appeared on the screen. The critical manipulation was to vary the uncertainty about where the target would appear (<xref rid="b3 b4" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998</xref>). It was found that saccade latencies became shorter with increasing prior probability of the corresponding target location. Specifically, response speed was found to be proportional to the log prior probability of target location (<xref rid="b3 b4 b9" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998; Carpenter &amp; Williams, 1995</xref>).</p>
      <p>The behavioural and electrophysiological findings from all three paradigms described above are consistent with the notion of a saccade being elicited once some gradually rising neuronal activity crosses a biophysical threshold. This idea has been formalized in terms of various mechanisms known as <italic>rise-to-threshold</italic> accumulator models. These models aim to provide a computational abstraction of a biophysically conceivable mechanism that explains saccade latencies and their variability across trials (for reviews see <xref rid="b13 b14" ref-type="bibr">Glimcher (2001, 2003)</xref>, <xref rid="b16" ref-type="bibr">Gold and Shadlen (2001)</xref>, <xref rid="b52" ref-type="bibr">Platt (2002)</xref>, <xref rid="b59" ref-type="bibr">Ratcliff and Smith (2004)</xref>, <xref rid="b68 b69" ref-type="bibr">Schall (2001, 2003)</xref>, <xref rid="b77" ref-type="bibr">Smith and Ratcliff (2004)</xref> and <xref rid="b84" ref-type="bibr">Usher and McClelland (2001)</xref>).</p>
      <p>In the context of saccadic decision making with a fixed set of potential target locations, rise-to-threshold models assume that subjects maintain a set of hypotheses each of which corresponds to one such location (<xref rid="b9 b17 b41 b72" ref-type="bibr">Carpenter &amp; Williams, 1995; Gold &amp; Shadlen, 2002; McMillen &amp; Holmes, 2006; Shadlen &amp; Gold, 2004</xref>). As the stimulus appears, a measure of evidence for each of these hypotheses is continuously refined, implemented as a competition between alternative decision signals in the brain. At any given point in post-stimulus time, these decision signals might, for example, represent the posterior probabilities of the target hypotheses, as derived from the subject’s prior (<xref rid="b3 b4 b53" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998; Platt &amp; Glimcher, 1999</xref>) and the sensory evidence (i.e., the likelihood of the data) collected up to that point in time (<xref rid="b6 b9" ref-type="bibr">Carpenter, 2004; Carpenter &amp; Williams, 1995</xref>). As soon as one such signal reaches a preset threshold, a saccade is elicited towards the corresponding target. Depending on the way in which information is assumed to be accumulated over time, two specific types of rise-to-threshold model are often distinguished: random-walk models and linear rise-to-threshold models.</p>
      <p><italic>Random-walk</italic> or <italic>diffusion</italic> models are fundamentally based on a sequential probability ratio test that is being carried out continually (<xref rid="b55 b58 b59 b60 b85" ref-type="bibr">Ratcliff, 1978; Ratcliff &amp; Rouder, 1998; Ratcliff &amp; Smith, 2004; Ratcliff, Zandt, &amp; McKoon, 1999; Wald, 1945</xref>). In these models, each new incoming piece of sensory evidence either increases or decreases a single decision variable until it has drifted beyond a threshold associated with the saccadic movement towards a particular target. The decision variable represents the relative evidence for the two alternatives (<xref rid="b58" ref-type="bibr">Ratcliff &amp; Rouder, 1998</xref>). However, in the case of a simple saccade-to-target task in a high-contrast setting with highly salient targets, it has been questioned whether a random-walk process for target detection provides a sufficient explanation for the large variability in latencies (<xref rid="b6 b8 b61" ref-type="bibr">Carpenter, 2004; Carpenter &amp; Reddi, 2001; Reddi, 2001</xref>).</p>
      <p>In <italic>linear</italic> rise-to-threshold models, randomness is introduced as trial-by-trial changes in the otherwise constant rate of rise of the decision signal. This notion has been formalized by Carpenter in a model termed ‘LATER’ (linear approach to threshold with ergodic rate; <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref>, <xref rid="b32" ref-type="bibr">Leach and Carpenter (2001)</xref>, <xref rid="b62" ref-type="bibr">Reddi, Asrress, and Carpenter (2003)</xref>). Like other rise-to-threshold models, LATER proposes that a saccade towards a target is elicited as soon as a neural decision signal has reached a particular threshold. But unlike other rise-to-threshold models (e. g., <xref rid="b18" ref-type="bibr">Grice (1968)</xref> and <xref rid="b44" ref-type="bibr">Nazir and Jacobs (1991)</xref>), it assumes a fixed threshold and a linear increase whose rate is subject to variation <italic>across</italic> trials, yet fixed <italic>within</italic> a given trial (for a debate on the relationship between the two approaches see <xref rid="b8" ref-type="bibr">Carpenter and Reddi (2001)</xref>, <xref rid="b56" ref-type="bibr">Ratcliff (2001)</xref>, <xref rid="b84" ref-type="bibr">Usher and McClelland (2001)</xref>). The neurophysiological recordings by Schall and colleagues (<xref rid="b21 b70" ref-type="bibr">Hanes &amp; Schall, 1996; Schall &amp; Thompson, 1999</xref>) are consistent with these key assumptions of the LATER model: they had observed that the threshold for saccade release seemed to be constant, whereas the slope of the rise in activity varied considerably across trials (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>a).</p>
      <p>In their experiments on the saccade-to-target task, Carpenter and colleagues found that the observed saccadic latency was a function of the log probability of the corresponding target location: the more likely the target location, the shorter the latency (<xref rid="b9" ref-type="bibr">Carpenter &amp; Williams, 1995</xref>). LATER accounts for this relationship by assuming that the learned a priori target probabilities determine the baseline levels of the decision signals, but not their rates of rise (cf. biased choice theory by <xref rid="b34" ref-type="bibr">Luce (1963)</xref>). Carpenter and colleagues used LATER to produce remarkably accurate predictions of human latency distributions in the saccade-to-target task as well as variations of it (<xref rid="b2 b9 b32 b62 b63" ref-type="bibr">Asrress &amp; Carpenter, 2001; Carpenter &amp; Williams, 1995; Leach &amp; Carpenter, 2001; Reddi et al., 2003; Reddi &amp; Carpenter, 2000</xref>).</p>
      <p>A strength of the LATER model is the straightforward interpretability of its parameters. LATER has thus been used to relate various features of observed latency distributions to the putative underlying neurophysiological process (<xref rid="b1 b2 b7 b30 b32 b33 b39 b62 b75" ref-type="bibr">Anderson, 2008; Asrress &amp; Carpenter, 2001; Carpenter &amp; McDonald, 2007; Kurata &amp; Aizawa, 2004; Leach &amp; Carpenter, 2001; Loon, Hooge, Berg, &amp; den, 2002; Madelain, Champrenaut, &amp; Chauvin, 2007; Reddi et al., 2003; Sinha, Brown, &amp; Carpenter, 2006</xref>). Furthermore, various extensions have been proposed, such as arrangements of multiple LATER units in parallel (<xref rid="b6 b64" ref-type="bibr">Carpenter, 2004; Robinson, 1973</xref>), mixture models (<xref rid="b43" ref-type="bibr">Nakahara, Nakamura, &amp; Hikosaka, 2006</xref>), or the assumption that both the rate of rise and the baseline level of the decision signal are trial-by-trial random variables (<xref rid="b43" ref-type="bibr">Nakahara et al., 2006</xref>).</p>
      <p>However, the simplicity of this model limits its applicability in three ways. First, linear rise-to-threshold models like LATER have only been applied to saccade-to-target situations in which no learning took place: in previous studies, prior probabilities of target location were always fixed in a given experimental session, and subjects were initially given extensive training until their performance levelled off. During learning, by contrast, the baseline levels of the decision signals are expected to <italic>change</italic> across trials. Even though the notion of variable baseline levels has been discussed before (<xref rid="b13 b43" ref-type="bibr">Glimcher, 2001; Nakahara et al., 2006</xref>), no specific model has been put forward how they might evolve dynamically depending on the history of previous trials. Second, LATER only accounts for simple marginal probabilities, where the probability distribution of target locations is described by a single vector of probabilities. It does not account for higher-order contingencies, that is, situations in which the target location probability depends on the target location during the previous trial. Third, within the class of linear rise-to-threshold models, no generative model has been proposed so far that would allow for statistical inference about parameter estimates and for model comparison (e.g., with regard to the type of learning that occurs across trials).</p>
      <p>In this study, we propose a more general linear rise-to-threshold model for visual-saccadic decision making that overcomes the restrictions outlined above. First, we explicitly model how subjects’ priors are systematically altered by the sequence of stimuli observed so far. This approach makes it possible to investigate how learning dynamically shapes decision making about saccades. Second, our model is able to account for different forms of learning which can be evaluated by model comparison. In particular, this allows us to investigate whether subjects’ behaviour is not only driven by <italic>marginal</italic> but also by <italic>conditional</italic> probabilities. Third, based on computational considerations, we propose a specific parameterization of the model. This enables parameter estimation within a maximum likelihood scheme and the subsequent construction of a classifier that can be used to distinguish subjects with different learning profiles.</p>
    </sec>
    <sec sec-type="methods" id="sec2">
      <label>2</label>
      <title>Methods</title>
      <sec id="sec2.1">
        <label>2.1</label>
        <title>Task</title>
        <p>For the present study, subjects were engaged in a sequential reaction time task (SRTT) during which they had to elicit saccades towards a given target in quick succession. The predictability of the target location was modified between blocks to induce varying forms of learning. The degree to which subjects learned the underlying contingency of a particular block was measured by the latencies of their saccades, that is, the time between stimulus onset and the beginning of the saccade towards the stimulus.</p>
        <p>The specific setup adopted in this study was based on the saccade-to-target task proposed by <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref>. Subjects placed their heads on a chinrest in front of a computer screen in a dark, soundproof booth. At the beginning of a trial, they focused on a red fixation dot (hue 0<sup>∘</sup>, luminance 0.5) at the centre of a black screen. After a random waiting period between 500 and 1500 ms, a second red dot, the target, appeared on the screen, either located at 15<sup>∘</sup> to the left or to the right. Since the original fixation dot remained visible, this design represented an overlap task rather than a gap task (alternative types of waiting-period probability distribution are examined in <xref rid="b49" ref-type="bibr">Oswal, Ogden, and Carpenter (2007)</xref>). Subjects were asked to foveate the target as quickly as possible, but not at the cost of errors. After another 700 ms, both dots disappeared, and the screen remained blank for an inter-trial interval of 500 ms.</p>
        <p>Based on this design, <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref> investigated the effects of fixed state probabilities for the two target locations on saccadic reaction times. For example, prior to the actual experiment, subjects were trained extensively on a sequence of trials during which the target appeared on the left-hand side with a probability of 70%, and on the right-hand side with a probability of 30%.</p>
        <p>In our study, we extended this experimental design in two ways (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>). First, each block contained a comparatively small number of trials, and subjects were not trained on a particular setting before the beginning of data acquisition. In this way, data were acquired while learning was in progress. Experimental pilots showed that 150 trials allowed for the subjects’ performance to stabilize sufficiently. Second, in addition to modifying target probabilities across blocks, the probability <italic>structure</italic> underlying the sequence of target locations was varied.</p>
        <p>In a <italic>state-oriented block</italic>, as in previous experiments, the sequence of target locations was generated according to fixed state probabilities. They were specified as a vector <mml:math id="M1" altimg="si62.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>, <mml:math id="M2" altimg="si63.gif" display="inline" overflow="scroll"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:math>, where p and <mml:math id="M3" altimg="si65.gif" display="inline" overflow="scroll"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:math> denote the marginal probabilities of leftward and rightward targets, respectively.</p>
        <p>In a <italic>transition-oriented block</italic>, the probability distribution of the target location of the current trial was conditional on the target location of the previous trial. Thus, given a sequence of past trials, the probability distribution of the target on the next trial depended on the last item of the sequence, and only on this one. A sequence with this property is known as a first-order Markov chain, and the change from one trial to the next as a transition. The probability that the next target location is j, given that the current target location is i, is given by <mml:math id="M4" altimg="si68.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>. Thus, the sequence of target locations was specified by the transition matrix of its underlying Markov chain, <mml:math id="M5" altimg="si69.gif" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>, where <mml:math id="M6" altimg="si70.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math> and <mml:math id="M7" altimg="si71.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math> denote the probabilities of leftward and rightward targets, respectively, given that the target of the previous trial appeared at location i. The first target in the sequence was drawn from a uniform initial distribution <mml:math id="M8" altimg="si73.gif" display="inline" overflow="scroll"><mml:mi>π</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math>; that is, the sequence of target locations was initialized randomly, either with a leftward or with a rightward target. The example in <xref rid="tbl1" ref-type="table">Table 1</xref> shows a short sequence of trials generated from the transition matrix <disp-formula><mml:math id="M9" altimg="si74.gif" display="block" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.7</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.3</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.3</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.7</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
        <p>For each trial, the table shows the probability distribution vector from which the current target location is drawn. For the first trial, it is <mml:math id="M10" altimg="si75.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math>. In all subsequent trials, it is either the top or the bottom row of P, depending on whether the previous target location was ‘left’ (top row) or ‘right’ (bottom row). The example illustrates that, given a transition matrix with high diagonal probabilities (a ‘stable’ transition matrix), the target tends to stay where it was on the previous trial, and only occasionally switches to the other side.</p>
        <p>Finally, in a <italic>uniform block</italic>, target locations occurred on the left-hand side and the right-hand side with equal chance, rendering the sequence of targets maximally unpredictable. This block structure served as a control condition in which no statistical learning across trials should take place.</p>
        <p>In order to avoid drowsiness, which subjects in pilot experiments had displayed after 30 min of constant testing, a single experimental session was chosen to contain only 5 blocks. A break of 3 min between any two blocks was introduced to reduce the potential confound of learning effects carrying over from one block to another.</p>
        <p>In order to allow for a unified formalism, all blocks were specified in terms of a transition matrix P. The blocks for each session were chosen according to the scheme in <xref rid="tbxI" ref-type="boxed-text">Box I</xref>.</p>
        <p>Each session contained all five block types. Their order was randomized in each session, and the two alternative matrices underlying the state-oriented blocks were counterbalanced across subjects. In order to distinguish transition-oriented learning from simpler state-oriented learning, all transition-oriented blocks were designed in such a way that the states of the implied Markov chain, 1 and 2, had a uniform steady state distribution <mml:math id="M11" altimg="si78.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> (see <xref rid="b50" ref-type="bibr">Papoulis (1991)</xref>). Hence, in transition-oriented blocks, targets would, on average, appear equally often on either side, and no state-oriented learning should take place.</p>
        <p>Experimental data were collected from three healthy male right-handed authors of this article with normal vision aged between 23 and 40 years (KHB, KES, WDP; see <xref rid="tbl2" ref-type="table">Table 2</xref>). Eye movements were recorded at a sampling frequency of 120 Hz using an ASL 504 infrared remote optics eye tracker. Targets were presented on a 27 cm × 37 cm CRT screen at a viewing distance of 67 cm. Data acquisition and analysis were implemented using MATLAB, Cogent <xref rid="b66" ref-type="bibr">2000</xref>, and ILAB (<xref rid="b12" ref-type="bibr">Gitelman, 2002</xref>).</p>
        <p>Before extracting latencies from eye recordings, blinks were filtered by searching for invalid pupil size values. Pupil coordinates within a time window of 25 ms around the beginning and the end of a blink were removed. Saccades were then detected using a standard algorithm by <xref rid="b11" ref-type="bibr">Fischer, Biscaldi, and Otto (1993)</xref>: in the raw recorded eye coordinates we looked for an initial pupil velocity of 250<sup>∘</sup>/s and searched the consecutive 100 ms time window for a saccade of at least 10<sup>∘</sup> that resulted in a fixation of at least 100 ms. Any latencies below 10 ms or above 800 ms were interpreted as artifacts and removed, as were blocks with an overall recognition rate below 80%. Altogether, 15% of the recorded blocks were rejected, as were 4% of the trials from accepted blocks. For the remaining trials, we computed the latency between target onset and the beginning of the first detected saccade.</p>
        <p>In order to reduce the variance of latencies, each subject took part in many sessions with an overall number of more than 20 000 trials.</p>
      </sec>
      <sec id="sec2.2">
        <label>2.2</label>
        <title>Modelling</title>
        <p>Various models have been proposed over the past two decades to explain the variability in the latencies between the appearance of a target and the initiation of an eye movement towards it. In one class of models, a decision signal is assumed to rise at a linear rate until reaching a fixed threshold. The release of a saccade is then modelled as the final outcome of this linear rise-to-threshold mechanism (<xref rid="b9 b32 b62" ref-type="bibr">Carpenter &amp; Williams, 1995; Leach &amp; Carpenter, 2001; Reddi et al., 2003</xref>). This type of model can be extended in two ways: (i) within an individual trial, the linear rise to threshold can be parameterized and turned into a generative model; (ii) across trials, the dynamics of alternative forms of learning can be integrated into the model.</p>
        <p>The two levels can be formalized as hierarchically related <italic>intra-trial</italic> and <italic>inter-trial</italic> sub-models, respectively. They are described separately in the following sections. Put together, they predict saccade latencies on the basis of the sequence of target locations observed so far, as well as three model parameters.</p>
        <sec id="sec2.2.1">
          <label>2.2.1</label>
          <title>Intra-trial modelling</title>
          <p>We propose a generative intra-trial model that extends previous models of the relation between prior expectations about target location and saccadic onset times. It describes a computational abstraction of putative neurophysiological processes between target onset and the release of a saccade.</p>
          <p>Each trial has two potential outcomes: a target appears either on the left-hand side or on the right-hand side of the screen. Within each trial, we model a subject’s belief in these two outcomes at any given point of time as distinct decision signals S that evolve linearly over time t until one of them hits a threshold <mml:math id="M12" altimg="si82.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math>. At the beginning of a trial, both decision signals have specific initial values, with the signal of the ‘winning’ hypothesis defined to start at <mml:math id="M13" altimg="si83.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>. The initial level <mml:math id="M14" altimg="si84.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math> reflects the subject’s prior as provided by the inter-trial model described in Section <xref rid="sec2.2.2" ref-type="sec">2.2.2</xref>. As the stimulus appears at <mml:math id="M15" altimg="si85.gif" display="inline" overflow="scroll"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>, the two signals increase or decrease, respectively, representing the changing belief in the two hypotheses. As soon as one of them hits threshold, a saccade is released towards the corresponding target location at time τ. The rate at which the decision signals rise or fall varies over trials, accounting for the large variance of the resulting latency distribution (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>). </p>
          <p>The decision process can be parameterized by modelling subjects as Bayesian observers who collect evidence about the true state of the world and, combined with their prior expectations, accept one of two competing hypotheses about it (<xref rid="b29" ref-type="bibr">Knill &amp; Pouget, 2004</xref>). In this scheme, the initial level of the ‘winning’ decision signal, <mml:math id="M16" altimg="si87.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>, is associated with the subject’s prior, and the rate of rise is associated with the likelihood of the true hypothesis.</p>
          <p>Evidence from several studies provides support for this parameterization. For instance, based on psychophysical experiments in humans, <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref> plotted latencies on a reciprobit scale, in which normally distributed data approach a straight line. They found that a change in the marginal probabilities of the two target locations led to a reciprobit swivel. This change in slope is consistent with a change in the threshold height but not with a change in the mean rate of rise, which would cause a reciprobit shift (<xref rid="b75" ref-type="bibr">Sinha et al., 2006</xref>). Further support for the notion that priors determine the initial level of the decision signal rather than its rate of rise comes from neurophysiological experiments using a similar task to ours in monkeys (<xref rid="b3 b4 b57" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998; Ratcliff, Cherian, &amp; Segraves, 2003</xref>). These studies identified neurons in the superior colliculus whose firing rates just before target onset reflected the target probability but not target salience. Altogether, these human and primate studies provide a robust foundation for the assumption that the subjective prior systematically influences the initial level of the decision signal, <mml:math id="M17" altimg="si88.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>, before it starts to rise until hitting threshold.</p>
          <p>Let the two possible states of the world be denoted by <mml:math id="M18" altimg="si89.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace class="nbsp"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math>, corresponding to the target location being <mml:math id="M19" altimg="si90.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:math>, respectively, within the current trial k. The sensory evidence for the hypotheses <mml:math id="M20" altimg="si92.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math> is provided by time-continuous visual input. Assuming this supportive evidence to be processed in small, discrete timesteps, in a lossless fashion without any form of temporal filter (<xref rid="b36" ref-type="bibr">Ludwig, Gilchrist, McSorley, &amp; Baddeley, 2005</xref>), the evidence at time t is referred to as <mml:math id="M21" altimg="si94.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math>, and the accumulated evidence for one or another hypothesis up to time t is denoted by <mml:math id="M22" altimg="si96.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math>. Writing <mml:math id="M23" altimg="si97.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> for the probability density of the piece of evidence at time t, we make two simple assumptions. First, it is assumed that <mml:math id="M24" altimg="si99.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math>, that is, <mml:math id="M25" altimg="si100.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math> and <mml:math id="M26" altimg="si101.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math> are conditionally independent. This means that <mml:math id="M27" altimg="si102.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math>. Second, since sensory stimuli <mml:math id="M28" altimg="si103.gif" display="inline" overflow="scroll"><mml:mi>e</mml:mi><mml:mo>≔</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>…</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math> are equal throughout the duration of the trial, the likelihood term <mml:math id="M29" altimg="si104.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> is taken to be constant. It follows that <disp-formula id="fd1"><label>(1)</label><mml:math id="M30" altimg="si105.gif" display="block" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mo>⋯</mml:mo><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mo>⋯</mml:mo><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
          <p>Subjects are modelled as permanently testing a decision rule which determines whether they continue their observation—or accept one of the hypotheses. From a Bayesian learning perspective it is intuitive to consider, as a decision variable, the subjective posterior probability of each hypothesis, given the supporting evidence up to time t. In an iterative form, its dynamics can be written as <disp-formula id="fd2"><label>(2)</label><mml:math id="M31" altimg="si107.gif" display="block" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> illustrating how the prior probability <mml:math id="M32" altimg="si108.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> is turned into a posterior probability <mml:math id="M33" altimg="si109.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> as new evidence <mml:math id="M34" altimg="si110.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math> is processed. Using Bayes’ theorem and Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref>, we obtain the closed form <disp-formula id="fd3"><label>(3)</label><mml:math id="M35" altimg="si111.gif" display="block" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> in which the assumption of discretized time is no longer necessary. However, this quantity does not rise linearly over time. Therefore, as an alternative decision variable that can be constructed in the case of two possible target locations, we consider the log posterior ratio. Using <xref rid="fd2" ref-type="disp-formula">(2)</xref>, its iterative form can be written as <disp-formula id="fd4"><label>(4)</label><mml:math id="M36" altimg="si112.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>.</mml:mtext></mml:math></disp-formula> Using <xref rid="fd3" ref-type="disp-formula">(3)</xref>, the closed form is <disp-formula id="fd5"><label>(5)</label><mml:math id="M37" altimg="si113.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>×</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> which can be written in an analogous fashion for its counterpart <mml:math id="M38" altimg="si114.gif" display="inline" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math> by interchanging <mml:math id="M39" altimg="si115.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math> and <mml:math id="M40" altimg="si116.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math>. These log-odds are attractive candidates for computational models of neuronal processes of decision making because they (i) allow for optimal decision making and (ii) rise linearly over time, as shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref>a. It is assumed that a hypothesis is accepted when its decision variable reaches a fixed threshold. This yields a decision rule that is evaluated at each point of time t: <disp-formula id="fd6"><label>(6)</label><mml:math id="M41" altimg="si118.gif" display="block" overflow="scroll"><mml:mstyle mathvariant="normal"><mml:mi>accept</mml:mi></mml:mstyle><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>when</mml:mi></mml:mstyle><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>}</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>ϑ</mml:mi><mml:mtext>,</mml:mtext></mml:math></disp-formula> and otherwise neither is accepted. Note that equivalently optimal decision rules, although framed somewhat differently, have been proposed by previous authors. For example, in the case of a forced-choice task, <xref rid="b16" ref-type="bibr">Gold and Shadlen (2001)</xref> consider a decision rule that is based on the likelihood ratio of the two hypotheses: accept <mml:math id="M42" altimg="si119.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math> when <mml:math id="M43" altimg="si120.gif" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math>, and accept <mml:math id="M44" altimg="si121.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math> otherwise. This rule can be turned into a decision rule for our task by multiplying the right-hand side criterion by an additional factor c that introduces the necessary ‘temporal gap’ in which neither hypothesis is accepted. Equating <mml:math id="M45" altimg="si123.gif" display="inline" overflow="scroll"><mml:mi>ϑ</mml:mi><mml:mo>≡</mml:mo><mml:mo>ln</mml:mo><mml:mi>c</mml:mi></mml:math>, taking logarithms, and using Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref>, this modified rule can be rewritten as <disp-formula><mml:math id="M46" altimg="si124.gif" display="block" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow></mml:msup></mml:math></disp-formula><disp-formula><mml:math id="M47" altimg="si125.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mi>ϑ</mml:mi></mml:math></disp-formula><disp-formula id="fd7"><label>(7)</label><mml:math id="M48" altimg="si126.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>×</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mi>ϑ</mml:mi><mml:mtext>,</mml:mtext></mml:math></disp-formula> which is precisely the same rule as in <xref rid="fd6" ref-type="disp-formula">(6)</xref>. This means that the two approaches are decision-equivalent.</p>
          <p>Both the decision variable for the true hypothesis in <xref rid="fd7" ref-type="disp-formula">(7)</xref> and its counterpart for the alternative hypothesis start at specific initial levels that represent the subject’s prior, and then rise or fall, respectively, over time. This corresponds to the notion of the accumulation of supportive evidence for the two rival hypotheses. A saccade to the true target location is released at time τ when <disp-formula><mml:math id="M49" altimg="si128.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>ϑ</mml:mi></mml:math></disp-formula><disp-formula><mml:math id="M50" altimg="si129.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>×</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>ϑ</mml:mi></mml:math></disp-formula><disp-formula id="fd8"><label>(8)</label><mml:math id="M51" altimg="si130.gif" display="block" overflow="scroll"><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> where <mml:math id="M52" altimg="si131.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math> and <mml:math id="M53" altimg="si132.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace class="nbsp"/><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math> denote the true and the false target location of the current trial k, respectively.</p>
          <p>The likelihood term <mml:math id="M54" altimg="si134.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> can be thought of as a descriptor of a subject’s visual discrimination efficiency or processing capacity. The larger it is the more quickly will an observed sensory stimulus make the subject increase their posterior belief in the corresponding hypothesis, and the shorter the resulting saccade latency. One way of parameterizing this quantity is to assume arbitrary ‘evidence units’. With <disp-formula id="fd9"><label>(9)</label><mml:math id="M55" altimg="si135.gif" display="block" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mspace width="1em" class="quad"/><mml:mtext>and</mml:mtext><mml:mspace width="1em" class="quad"/><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></disp-formula> the supportive evidence per unit time for the true hypothesis is larger than the evidence for the false hypothesis, by an amount determined by a second model parameter <mml:math id="M56" altimg="si136.gif" display="inline" overflow="scroll"><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:math>.</p>
          <p>In addition to the parameters ϑ and ρ, we must account for the fact that, across trials, the rate of the decision signal varies (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>a). Previous experiments based on the same paradigm as in this study have found reciprocal latencies to conform to a Gaussian distribution (<xref rid="b9" ref-type="bibr">Carpenter &amp; Williams, 1995</xref>). Hence, in trial k, the rate of the assumed decision signal, <mml:math id="M57" altimg="si140.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math>, will have a Gaussian distribution as well, with <mml:math id="M58" altimg="si141.gif" display="inline" overflow="scroll"><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math> denoting the difference between the threshold <mml:math id="M59" altimg="si142.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math> and the initial level <mml:math id="M60" altimg="si143.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math> of the decision variable (see <xref rid="fig2" ref-type="fig">Fig. 2</xref>b). This introduces a third model parameter σ that describes the standard deviation of r. The parameterization of the intra-trial model is summarized in <xref rid="fig3" ref-type="fig">Fig. 3</xref>.</p>
        </sec>
        <sec id="sec2.2.2">
          <label>2.2.2</label>
          <title>Inter-trial modelling</title>
          <p>A central assumption of our model is that, at the beginning of each trial, the starting point of the decision signal associated with the true hypothesis corresponds to <mml:math id="M61" altimg="si146.gif" display="inline" overflow="scroll"><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math>, i.e. the log ratio of the prior probabilities of the correct and the incorrect hypothesis, see Eq. <xref rid="fd5" ref-type="disp-formula">(5)</xref>. The evolution of the prior probabilities <mml:math id="M62" altimg="si147.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> during a sequence of trials should reflect the learning of certain statistical properties of the target locations. In order to investigate what type of learning might happen during a sequence of trials <mml:math id="M63" altimg="si148.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>, we propose three different inter-trial models that formalize alternative learning hypotheses.</p>
          <sec id="sec2.2.2.1">
            <label>2.2.2.1</label>
            <title>The transition model</title>
            <p>In the first candidate inter-trial model, we assume that subjects act like ideal observers: while responding to the sequence of stimuli within a block, they continuously refine an estimate of the underlying Markov transition matrix (see <xref rid="b42" ref-type="bibr">Minka (2001)</xref>).</p>
            <p>Let <mml:math id="M64" altimg="si149.gif" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math> be a hidden homogeneous transition matrix with a uniform initial distribution <mml:math id="M65" altimg="si150.gif" display="inline" overflow="scroll"><mml:mi>π</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> underlying the sequence of target locations <mml:math id="M66" altimg="si151.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>. The states of the Markov chain, 1 and 2, encode leftward and rightward targets, respectively. Let <mml:math id="M67" altimg="si152.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math> denote the number of transitions <mml:math id="M68" altimg="si153.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>, for <mml:math id="M69" altimg="si154.gif" display="inline" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math>, that have occurred in the sequence of <mml:math id="M70" altimg="si155.gif" display="inline" overflow="scroll"><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math> trials observed so far. A maximum likelihood estimate of P could be obtained by maximizing the log likelihood function <disp-formula id="fd10"><label>(10)</label><mml:math id="M71" altimg="si157.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munderover><mml:mo>ln</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula> subject to <mml:math id="M72" altimg="si158.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math>. Using Lagrange’s method, the maximum likelihood estimates <mml:math id="M73" altimg="si159.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math> follow.</p>
            <p>For example, having observed the first six trials in <xref rid="tbl1" ref-type="table">Table 1</xref>, an ideal observer will have counted two ‘left→left’ transitions, one ‘left→right’ transition, and so forth. From this follows an estimated transition matrix <mml:math id="M74" altimg="si162.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.67</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.33</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math>. It is the matrix that makes the observed sequence of trials most likely.</p>
            <p>In this form, however, an individual matrix element <mml:math id="M75" altimg="si163.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow></mml:msubsup></mml:math> remains undefined as long as <mml:math id="M76" altimg="si164.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>. Instead, we assume an initial uniform prior of <mml:math id="M77" altimg="si165.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math> for all <mml:math id="M78" altimg="si166.gif" display="inline" overflow="scroll"><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math>, which can be thought of as an imaginary ‘prior observation count’ of 1 for each transition event (<xref rid="b42" ref-type="bibr">Minka, 2001</xref>). The posterior predictive distribution <mml:math id="M79" altimg="si167.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math> based on k trials then allows subsequent generative models to yield predictions for all trials. Specifically, at the beginning of trial k, subjects are assumed to have constructed the estimate <disp-formula id="fd11"><label>(11)</label><mml:math id="M80" altimg="si170.gif" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="1em" class="quad"/><mml:mstyle mathvariant="normal"><mml:mi>with</mml:mi></mml:mstyle><mml:mspace width="1em" class="quad"/><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>≔</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> such that <mml:math id="M81" altimg="si171.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:math> and <mml:math id="M82" altimg="si172.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:math>. Using this alternative formulation, the estimated transition matrix in the above example (<xref rid="tbl1" ref-type="table">Table 1</xref>) would be <mml:math id="M83" altimg="si173.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>6</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.6</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.4</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math>.</p>
            <p>Obtaining maximum likelihood estimates of the transition matrix elements in this way can equivalently be viewed as a Bayesian update scheme. By counting how often each type of transition has occurred so far, an ideal observer can estimate the joint probabilities <mml:math id="M84" altimg="si174.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>, from which estimates of the conditional probabilities <mml:math id="M85" altimg="si175.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> can be derived (see <xref rid="b23" ref-type="bibr">Harrison, Duggins, and Friston (2006)</xref>, for an example).</p>
            <p>The initial uniform matrix at the beginning of an experimental block corresponds to maximal uncertainty. As more and more trials are observed, the posterior of the transition matrix is refined and gradually approaches the true matrix.</p>
          </sec>
          <sec id="sec2.2.2.2">
            <label>2.2.2.2</label>
            <title>The state model</title>
            <p>The inter-trial model outlined so far is <italic>transition</italic>-oriented in that it assumes an observer who estimates a transition matrix underlying the sequence of stimuli. Alternatively, a <italic>state</italic>-oriented observer can be imagined who simply estimates a state probabilities vector <mml:math id="M86" altimg="si176.gif" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> by counting the frequencies <mml:math id="M87" altimg="si177.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math> of the two target locations while not paying attention to the transitions between them. At the beginning of trial <mml:math id="M88" altimg="si178.gif" display="inline" overflow="scroll"><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math>, in analogy to the Bayesian update scheme outlined above, this estimate is <disp-formula id="fd12"><label>(12)</label><mml:math id="M89" altimg="si179.gif" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="1em" class="quad"/><mml:mstyle mathvariant="normal"><mml:mi>with</mml:mi></mml:mstyle><mml:mspace width="1em" class="quad"/><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>≔</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math></disp-formula> such that <mml:math id="M90" altimg="si180.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>i</mml:mi></mml:math> for all <mml:math id="M91" altimg="si181.gif" display="inline" overflow="scroll"><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math>. Again, the initial prior is assumed to be uniform, <mml:math id="M92" altimg="si182.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math>.</p>
            <p>Having observed the first six trials of the above example (<xref rid="tbl1" ref-type="table">Table 1</xref>), a ‘state’ observer will have counted four ‘left’ trials and two ‘right’ trials. Using <xref rid="fd12" ref-type="disp-formula">(12)</xref>, an estimated state probabilities vector <mml:math id="M93" altimg="si183.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.63</mml:mn><mml:mo>,</mml:mo><mml:mn>0.38</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:msup></mml:math> follows. Using the same notation as in the transition model, this estimate can be written as <mml:math id="M94" altimg="si184.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>6</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.63</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.38</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.63</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.38</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math>.</p>
          </sec>
          <sec id="sec2.2.2.3">
            <label>2.2.2.3</label>
            <title>The uniform model</title>
            <p>The two alternative inter-trial models proposed so far account for different forms of learning, but they do not question whether learning occurs at all. Therefore, a third candidate model is proposed in which subjects are assumed to be entirely ignorant of the history of stimuli. In this <italic>uniform</italic> model, subjects maintain a uniform prior belief of <mml:math id="M95" altimg="si185.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math> in either target location throughout the experiment. Using the same notation as in the transition model, this prior can be written as a constant estimate <mml:math id="M96" altimg="si186.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.5</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:math>.</p>
            <p><xref rid="fig4" ref-type="fig">Fig. 4</xref> illustrates exemplary predictions generated by the alternative inter-trial models operating on alternative block structures. The individual diagrams show the extent to which the models are able to adapt to the transition matrix underlying the observed sequence of target locations. Crucially, the rate of convergence is highest when the model structure most closely matches the block structure. In particular, convergence takes longer when the true block structure is more complicated than the assumed one. For example, in the case of a uniform block, all three models eventually settle around 0. 5/0.5 predictions, but the ‘state’ model and the ‘transition’ model take longer to converge. Thus, we will be able to make use of measured reaction times from <italic>all</italic> blocks to find out which model explains a particular subject’s behaviour best (Section <xref rid="sec3.4" ref-type="sec">3.4</xref>).</p>
          </sec>
        </sec>
        <sec id="sec2.2.3">
          <label>2.2.3</label>
          <title>Model construction</title>
          <p>The two sub-models outlined above can now be integrated into an overall generative model with three free parameters.</p>
          <p>In our paradigm, reciprocal latencies have previously been observed to follow a normal distribution (<xref rid="b9" ref-type="bibr">Carpenter &amp; Williams, 1995</xref>). Thus, the rate of the rising decision signal can be modelled as a random variable <disp-formula id="fd13"><label>(13)</label><mml:math id="M97" altimg="si187.gif" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mtext>,</mml:mtext></mml:math></disp-formula> where <mml:math id="M98" altimg="si188.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math> and σ describe the mean and the standard deviation of the rate across trials. Using <mml:math id="M99" altimg="si190.gif" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:mi>S</mml:mi></mml:mrow></mml:mfrac></mml:math>, the reciprocal latency <mml:math id="M100" altimg="si191.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>≔</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math> can then be modelled as a random variable <disp-formula id="fd14"><label>(14)</label><mml:math id="M101" altimg="si192.gif" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
          <p>The difference <mml:math id="M102" altimg="si193.gif" display="inline" overflow="scroll"><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math> between the initial level <mml:math id="M103" altimg="si194.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math> of the decision signal and its threshold can be expressed in terms of a model parameter ϑ and the log prior ratio as derived in Section <xref rid="sec2.2.1" ref-type="sec">2.2.1</xref>: <disp-formula id="fd15"><label>(15)</label><mml:math id="M104" altimg="si196.gif" display="block" overflow="scroll"><mml:mstyle mathvariant="normal"><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
          <p>The mean rate of the decision signal was derived in <xref rid="fd5 fd9" ref-type="disp-formula">(5) and (9)</xref>: <disp-formula id="fd16"><label>(16)</label><mml:math id="M105" altimg="si197.gif" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
          <p>The variability of the rate across trials is described by the model parameter σ. The prior of the two hypotheses is given by the corresponding entry in the transition matrix, as estimated within the inter-trial model: <disp-formula id="fd17"><label>(17)</label><mml:math id="M106" altimg="si199.gif" display="block" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="1em" class="quad"/><mml:mtext>and</mml:mtext><mml:mspace width="1em" class="quad"/><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo accent="true">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
          <p>The overall probability distribution for reciprocal latencies, conditional on the model parameters, is then given by <disp-formula id="fd18"><label>(18)</label><mml:math id="M107" altimg="si200.gif" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula> Note that the overall model does not propose a single parameterized distribution Y, but a sequence of distributions <mml:math id="M108" altimg="si202.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>. This is because of its dependence on the output of the inter-trial model, <mml:math id="M109" altimg="si203.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math>, which in turn depends on the sequence of target locations <mml:math id="M110" altimg="si204.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> observed so far.</p>
        </sec>
      </sec>
      <sec id="sec2.3">
        <label>2.3</label>
        <title>Parameter estimation</title>
        <p>Each candidate model constructed in the preceding section proposes a particular distribution of reciprocal saccade latencies parameterized by a vector <mml:math id="M111" altimg="si205.gif" display="inline" overflow="scroll"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. <xref rid="fig3" ref-type="fig">Fig. 3</xref> indicates that the parameters are not perfectly independent in their effect on the resulting predictions. For example, an increase in predicted response speed can be obtained by either decreasing the threshold ϑ or by increasing the rate of the decision signal ρ. Note, however, that this also alters the dependence of reaction times on the subject’s priors, so the parameters are not completely interchangeable. Nevertheless, to avoid numerical identifiability problems during parameter estimation, we reparameterized the model such that the rate ρ is expressed as per unit threshold, i.e. <mml:math id="M112" altimg="si209.gif" display="inline" overflow="scroll"><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo><mml:mi>ρ</mml:mi><mml:mo>/</mml:mo><mml:mi>ϑ</mml:mi></mml:math>. Moreover, since the dispersion parameter σ must take a non-negative value, we used a log-transform. Thus, during numerical parameter estimation, the model was parameterized by <mml:math id="M113" altimg="si211.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>/</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mo>ln</mml:mo><mml:mi>σ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>.</p>
        <p>The maximum likelihood principle identifies those model parameters of the distributions of <mml:math id="M114" altimg="si212.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math> that are most likely to give rise to the data <mml:math id="M115" altimg="si213.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math>. An estimate <mml:math id="M116" altimg="si214.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>ϑ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:math> can be found by maximizing <disp-formula id="fd19"><label>(19)</label><mml:math id="M117" altimg="si215.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>ln</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>−</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mo>ln</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula> with respect to θ. The implementation can be simplified by omitting the term <mml:math id="M118" altimg="si217.gif" display="inline" overflow="scroll"><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>ln</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:math> which does not depend on the free parameters. Multiplying the expression by <mml:math id="M119" altimg="si218.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math>, the maximum likelihood estimate <mml:math id="M120" altimg="si219.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:math> is then found as the solution to a minimization problem with respect to ϑ, ρ, σ.</p>
      </sec>
    </sec>
    <sec id="sec3">
      <label>3</label>
      <title>Results</title>
      <sec id="sec3.1">
        <label>3.1</label>
        <title>Data analysis</title>
        <p>In order to validate our paradigm, we replicated two key results by <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref>. First, latencies varied considerably over trials. Across our 20 078 trials, we found an overall mean of <mml:math id="M121" altimg="si223.gif" display="inline" overflow="scroll"><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>262</mml:mn><mml:mspace class="nbsp"/><mml:mstyle mathvariant="normal"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:math> and a standard deviation of <mml:math id="M122" altimg="si224.gif" display="inline" overflow="scroll"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>65</mml:mn><mml:mspace class="nbsp"/><mml:mstyle mathvariant="normal"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:math>. Second, reciprocal latencies <mml:math id="M123" altimg="si225.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math>, with <mml:math id="M124" altimg="si226.gif" display="inline" overflow="scroll"><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>4.02</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mspace class="nbsp"/><mml:mstyle mathvariant="normal"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:math> and <mml:math id="M125" altimg="si227.gif" display="inline" overflow="scroll"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.67</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mspace class="nbsp"/><mml:mstyle mathvariant="normal"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant="normal"><mml:mi>s</mml:mi></mml:mstyle></mml:math>, closely approximated a normal distribution (see <xref rid="fig5" ref-type="fig">Fig. 5</xref>).</p>
        <p>Above and beyond these descriptive features, Carpenter and colleagues showed that latencies declined as the learned state probability of the corresponding target location increased (<xref rid="b3 b4 b9" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998; Carpenter &amp; Williams, 1995</xref>). Specifically, they found a significant negative linear relation between log prior probabilities and latencies. In our study, we replicated these results as well, finding a very similar negative linear relation between log state probabilities and latencies in our state-oriented blocks (<mml:math id="M126" altimg="si228.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:math>). We further extended this analysis to transition probabilities. Using a linear regression analysis, we found a significant relation (<mml:math id="M127" altimg="si229.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:math>) between reciprocal latencies and log transition probabilities (see <xref rid="fig6" ref-type="fig">Fig. 6</xref>). Even though this analysis neglects the dynamics of learning completely, it already indicates that human observers are sensitive to transition probabilities in visual input statistics. Yet formal model comparison will provide much stronger evidence for this claim.</p>
      </sec>
      <sec id="sec3.2">
        <label>3.2</label>
        <title>Parameter estimation</title>
        <p>In order to obtain maximum likelihood parameter estimates from Eq. <xref rid="fd19" ref-type="disp-formula">(19)</xref>, a gradient-descent scheme was run on the acquired data from all three subjects separately. The results are given in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
        <p>In order to visualize the dependence between conditional probabilities and latencies, and provide face validity for our parameter estimates, one of the subjects was engaged in an additional session consisting of 10 transition-oriented blocks with identical sequences initially generated from a <mml:math id="M128" altimg="si230.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.8</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0.2</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>0.8</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math> transition matrix. We fitted the model to the data and predicted the priors <mml:math id="M129" altimg="si231.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math> using the ‘transition’ model. <xref rid="fig7" ref-type="fig">Fig. 7</xref> shows how observed latencies develop over time and how this is reflected by model predictions.</p>
        <p>In order to give a qualitative comparison between the predictive power of the three competing inter-trial models, <xref rid="fig8" ref-type="fig">Fig. 8</xref> visualizes measured latencies versus model predictions. The individual diagrams show a marked separation between trials in which the target has just switched to the other side (crosses) and those in which it has not (dots). As expected from a subject that learns transition probabilities, switch trials lead to long latencies, i.e. short reciprocals; accordingly, crosses have low x-coordinates. Conversely, non-switch trials lead to short latencies, i.e. long reciprocals; accordingly, dots have high x-coordinates. Looking at the y-coordinates, the ‘transition’ model is the only model that predicts these two clusters of trials.</p>
      </sec>
      <sec id="sec3.3">
        <label>3.3</label>
        <title>Statistical classification</title>
        <p>The parameter estimates obtained for each subject are sufficiently distinct to demonstrate the use of a statistical classifier that maps an unseen test sample onto the correct class (<xref rid="b25" ref-type="bibr">Jain, Duin, &amp; Mao, 2000</xref>). Such a classifier could be used to (i) separate groups of individuals that exhibit similar learning profiles, or (ii) find out whether there are systematic differences between healthy subjects and patients.</p>
        <p>A class can be regarded as a discrete random variable C and the eye movement data as a vector of continuous random variables <mml:math id="M130" altimg="si236.gif" display="inline" overflow="scroll"><mml:mstyle mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> with observed realizations <mml:math id="M131" altimg="si237.gif" display="inline" overflow="scroll"><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math>. For illustration purposes, let the classes in <mml:math id="M132" altimg="si238.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> correspond to the three subjects themselves. Then, given a test sample of unseen saccade data y, the classifier is to return <disp-formula id="fd20"><label>(20)</label><mml:math id="M133" altimg="si240.gif" display="block" overflow="scroll"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>argmax</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi></mml:mrow></mml:munder><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula> Using Bayes’ theorem and the fact that saccade latencies <mml:math id="M134" altimg="si241.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math> are independently drawn from their respective underlying distributions, the right-hand side can be rewritten as <disp-formula id="fd21"><label>(21)</label><mml:math id="M135" altimg="si242.gif" display="block" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="fd22"><label>(22)</label><mml:math id="M136" altimg="si243.gif" display="block" overflow="scroll"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="fd23"><label>(23)</label><mml:math id="M137" altimg="si244.gif" display="block" overflow="scroll"><mml:mo>∝</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>.</mml:mtext></mml:math></disp-formula></p>
        <p>We based the classifier on the ‘transition’ model which showed a reasonable fit across all subjects, and trained it by finding maximum likelihood estimates of labelled training data from the three subjects (see <xref rid="tbl4" ref-type="table">Table 4</xref>). The unknown parameters of the distribution in Eq. <xref rid="fd18" ref-type="disp-formula">(18)</xref> were then replaced by these estimates, yielding approximations for the class-conditional probability densities <mml:math id="M138" altimg="si245.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. The priors were chosen to be flat, i.e. <mml:math id="M139" altimg="si246.gif" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi></mml:math>. In future applications, when particular classes are to be distinguished such as subgroups of a disease, the priors would be given by the unconditional frequencies of the different conditions.</p>
        <p><xref rid="tbl5" ref-type="table">Table 5</xref> shows the resulting joint probabilities <mml:math id="M140" altimg="si247.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mspace class="nbsp"/><mml:mi>∀</mml:mi><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi></mml:math> as determined by the classifier.</p>
        <p>The table shows that the classifier has assigned the test sample to the correct class in all cases.</p>
        <p><xref rid="fig4" ref-type="fig">Fig. 4</xref> provides some intuition as to what specific properties of a sequence of latencies allow the classifier to distinguish between different inter-trial models. In a transition-oriented block (left column in the figure), for instance, the ‘transition’ model predicts that log prior ratios fall into two groups: negative and positive ones (top-left diagram). Accordingly, saccadic latencies are expected to be separated into long-latency and short-latency saccades. The ‘state’ model, by contrast, predicts the convergence of log prior ratios around zero (mid-left diagram), and saccadic latencies are expected to display relatively low variability around their mean. Finally, the ‘uniform’ model predicts that log prior ratios remain fixed at zero.</p>
      </sec>
      <sec id="sec3.4">
        <label>3.4</label>
        <title>Model comparison</title>
        <p>The maximum likelihood approach discussed so far does not only yield a point estimate of the model parameters. It can also be used to compare the competing inter-trial models. The question of which model explains the observed data best can be posed explicitly by comparing <disp-formula id="fd24"><label>(24)</label><mml:math id="M141" altimg="si248.gif" display="block" overflow="scroll"><mml:mo>ln</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mo>ln</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mo>ln</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>D</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>KL</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mo>ln</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle mathvariant="normal"><mml:mi>const</mml:mi></mml:mstyle></mml:math></disp-formula> for each inter-trial model M, where we approximate the unknown parameter distribution <mml:math id="M142" altimg="si250.gif" display="inline" overflow="scroll"><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> by a Dirac-delta distribution at <mml:math id="M143" altimg="si251.gif" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup></mml:math>. The likelihood term evaluated at the maximum likelihood parameter estimate, <mml:math id="M144" altimg="si252.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>ˆ</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mstyle mathvariant="normal"><mml:mi>ML</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>, is an approximation to the model evidence, <mml:math id="M145" altimg="si253.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>M</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. When competing models do not differ with regard to their parameterization (as in our case, where model differences are restricted to the parameter-free function describing the ideal observer), these models can be compared using their likelihood ratio, which is an approximation to the model evidence ratio, or Bayes factor (see <xref rid="b27" ref-type="bibr">Kass and Raftery (1995)</xref>). Since the logarithm is a monotonic function, it is common practice, and usually more convenient, to compute and report the log likelihood ratio. Hence, differences between bar lengths in <xref rid="fig9" ref-type="fig">Fig. 9</xref> represent the log likelihood ratio between the associated models (note that differences between logs are mathematically equivalent to the log of the ratio).</p>
        <p>The negative log likelihood values of the competing inter-trial models fitted to different subsets of the data are given in <xref rid="fig9" ref-type="fig">Fig. 9</xref>. Each diagram is based on a particular subject and a particular type of block structure. Note that it is meaningless to compare absolute values between subjects since they depend on the mere number of trials a subject was engaged in. Instead, the likelihood value of each model must be interpreted in relation to the likelihood values of the other models from the same subject and block structure. Each diagram has been scaled individually so as to emphasize the full range between the lowest and the highest likelihood.</p>
        <p>The data show that model fit differences vary considerably across subjects. In subjects S-1 and S-2, there is very strong evidence for the ‘transition’ model compared to the ‘uniform’ and the ‘state’ model. In subject S-1, for example, the likelihood ratio between the ‘transition’ model and the ‘state’ model, each fitted to all blocks, is <mml:math id="M146" altimg="si254.gif" display="inline" overflow="scroll"><mml:mo>exp</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>23</mml:mn><mml:mspace width="0.16667em"/><mml:mn>053.79</mml:mn><mml:mo>−</mml:mo><mml:mn>22</mml:mn><mml:mspace width="0.16667em"/><mml:mn>964.11</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mn>8.9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>38</mml:mn></mml:mrow></mml:msup></mml:math>, that is, the ‘transition’ model is much more likely to underlie the observed data than the ‘state’ model. Similarly, it is <mml:math id="M147" altimg="si255.gif" display="inline" overflow="scroll"><mml:mo>exp</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>23</mml:mn><mml:mspace width="0.16667em"/><mml:mn>053.79</mml:mn><mml:mo>−</mml:mo><mml:mn>22</mml:mn><mml:mspace width="0.16667em"/><mml:mn>953.8</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mn>2.7</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>43</mml:mn></mml:mrow></mml:msup></mml:math> times more likely than the ‘uniform’ model. In subject S-3, by contrast, the ‘state’ model allows for the best fit. For this subject, the likelihood ratios are much smaller than in the other two subjects, but they still constitute strong evidence in favour of the ‘state’ model. For the experimental data presented here, there was always strong evidence for one particular model in each combination of subject and block type.</p>
        <p>The most salient result within the diagrams is that for each subject the same model is found to be optimal for all three data sets. The probability of this happening by chance is <mml:math id="M148" altimg="si256.gif" display="inline" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:mfrac></mml:math> within each subject, and therefore <mml:math id="M149" altimg="si257.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≈</mml:mo><mml:mn>0.001</mml:mn></mml:math> for the three subjects as a whole.</p>
      </sec>
    </sec>
    <sec id="sec4">
      <label>4</label>
      <title>Discussion</title>
      <p>In this article, we have extended the class of linear rise-to-threshold models of the relation between a priori probabilities of target location and saccadic latencies. These models are centered around the intuitive, and empirically supported, notion of a decision signal that rises over time until reaching a fixed threshold. We have presented a generative, hierarchical model that combines two separate sub-models for learning of target locations across trials and the decision-making process within a trial, respectively. This has enabled three lines of progress: (i) explicit modelling of how subjects’ priors change across trials as a function of stimulus history, which makes it possible to investigate how saccadic decision making is dynamically shaped by learning; (ii) a model parameterization, inspired by computational considerations, which enables maximum likelihood parameter estimation and the subsequent construction of classifiers for distinguishing subjects with different learning profiles; (iii) differentiation between specific forms of learning by model comparison, e.g., the question of whether saccades are more influenced by marginal or by conditional probabilities.</p>
      <p>The focus of this paper is a methodological one, and its primary goal is not to provide major novel neurobiological insights. Nevertheless, we acquired eye movement data from three healthy subjects performing a well-established and simple binary saccadic task. In order to make our results comparable to previous ones, we used the same paradigm as <xref rid="b9" ref-type="bibr">Carpenter and Williams (1995)</xref>. The aim of this empirical data analysis was to demonstrate the face validity of our modelling approach by showing that under realistic noise levels, as found in standard saccade measurements with infrared video technology, consistent and subject-specific learning profiles can be identified. Indeed, our analysis showed that (i) the behavioural pattern observed in each subject was consistent across all experimental sessions and that (ii) it was distinct from the patterns of the other subjects.</p>
      <p>The question that led to these findings was what sort of learning underlies changes of prior probabilities across trials in a particular subject. In our analyses of empirical data, we evaluated three different inter-trial learning models: a ‘state’ model (which learns the marginal probabilities of target locations), a ‘transition’ model (which learns the conditional probabilities of a transition matrix), and a ‘uniform’ model (representing the hypothesis that no learning takes place and prior probabilities therefore remain constant). Fitting the three alternative models to different subsets of the data shows that there is least evidence for the ‘uniform’ model in all cases. We can conclude from this that human observers do take into account the probabilistic structure underlying the sequence of trials. This finding was compatible with simple linear regression analyses of the relation between log prior probability ratios and reciprocal saccade latencies. In these analyses, we fully replicated the previous results by Carpenter and colleagues, who had reported a significant negative correlation between log prior marginal probabilities and reciprocal saccade latencies (<xref rid="b3 b4 b9" ref-type="bibr">Basso &amp; Wurtz, 1997, 1998; Carpenter &amp; Williams, 1995</xref>). In addition, we found a significant negative correlation between log prior transition probability ratios and reciprocal saccade latencies. This demonstrates that human observers are sensitive to conditional probabilities, not merely to the marginal probabilities, of target locations.</p>
      <p>A particularly interesting finding is that in each of our three subjects there was one model (the ‘transition’ model in subjects S-1 and S-2, and the ‘state’ model in subject S-3) that performed best for all data sets, independent of the hidden probability structure underlying the stimulus sequence. The probability of obtaining such a pattern by chance is very small (<mml:math id="M150" altimg="si258.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:math>). In addition, model comparison, on the basis of likelihood ratios, showed that in each condition the best model allowed for a much better fit than both other models. This suggests that each subject exhibited an inherent and individual learning profile, independent of the current block type. This notion is also confirmed by our classification results, in which all unknown test samples were mapped onto the correct subject.</p>
      <p>Although related modelling principles have been used in previous studies, these were implemented for rather different experimental paradigms. For example, <xref rid="b38" ref-type="bibr">Maddox (2002)</xref> has looked at a broad range of mathematical frameworks for optimal decision criterion learning in perceptual categorization tasks. In this type of experiment, subjects are asked to assign the correct category to a given stimulus, and a typical modelling approach is to assume that they aim to maximize expected reward. <xref rid="b76" ref-type="bibr">Smith, Wirth, Suzuki, and Brown (2007)</xref> consider a paradigm in which subjects are required to associate different cues with different actions. They propose a novel way of analysing such interleaved learning by means of a state-space model that provides a single framework for all associations to be learned. <xref rid="b10" ref-type="bibr">Corrado, Sugrue, Seung, and Newsome (2005)</xref> and <xref rid="b31" ref-type="bibr">Lau and Glimcher (2005)</xref> analyse sequential choice tasks with probabilistic reinforcers. They propose attractive candidate models that are capable of implementing the matching law described by <xref rid="b24" ref-type="bibr">Herrnstein (1961)</xref>. Finally, several alternative models for two-choice reaction time tasks were compared by <xref rid="b59" ref-type="bibr">Ratcliff and Smith (2004)</xref>, who showed that these models, even though based on very different assumptions, often led to similar predictions, at least for very simple tasks.</p>
      <p>The above studies describe powerful approaches for characterizing and analysing learning and choice behaviour for a variety of tasks. In this study, by contrast, we were considering a different type of decision task, and we were aiming for a different type of insight. In our paradigm, subjects were not asked to assign a given sample to one of several overlapping categories; decisions were not associated with a reward; and there were no probabilistic reinforcers. Instead, subjects were confronted with a target that was extremely easily detectable, there were only two alternative responses per trial, and no behavioural feedback (e.g., rewards) was given. Similarly, we were not aiming to model the cognitive state of subjects who are evaluating the potential outcome of alternative decisions, or who are learning to associate a cue with a particular action. Instead, we attempted to model subjects’ reaction times in response to an extremely simple stimulus, and how these reaction times depended on learned statistical distributions about stimulus properties.</p>
      <p>There are several potential lines of future research that could be based on the model presented in this paper. For example, an interesting extension would be to consider additional inter-trial models, e.g., differently parameterized ‘declining-memory’ models which represent forgetful observers, or observers that adapt their learning rate to the volatility of the environment (<xref rid="b5" ref-type="bibr">Behrens, Woolrich, Walton, &amp; Rushworth, 2007</xref>). Because of different numbers of parameters in such models, however, model comparison could no longer be pursued on the basis of log likelihood ratios. Instead, one would require an approach that takes into account both model fit and model complexity, e.g., Bayesian model selection based on the model evidence (<xref rid="b51" ref-type="bibr">Penny, Stephan, Mechelli, &amp; Friston, 2004</xref>). For example, different forms of online learning of the probability distribution from which a sequence of events is drawn have been used in the context of modelling SRTT neuroimaging data (<xref rid="b23 b81" ref-type="bibr">Harrison et al., 2006; Strange, Duggins, Penny, Dolan, &amp; Friston, 2005</xref>).</p>
      <p>Another interesting question would be to investigate the extent to which the explanatory power of linear rise-to-threshold models is restricted to high-contrast settings in which the time taken for decision is often assumed to dominate the time for detection (<xref rid="b6" ref-type="bibr">Carpenter, 2004</xref>). This could be addressed by explicitly comparing linear-rise models to random-walk (or diffusion) models while systematically modifying the salience of the target (for a debate on the relationship between the two approaches see <xref rid="b8" ref-type="bibr">Carpenter and Reddi (2001)</xref> and <xref rid="b56" ref-type="bibr">Ratcliff (2001)</xref>).</p>
      <p>Furthermore, the way the brain might implement Bayesian inference can be expressed in alternative mathematical ways (<xref rid="b26" ref-type="bibr">Jazayeri &amp; Movshon, 2006</xref>; <xref rid="b37" ref-type="bibr">Ma, Beck, Latham, &amp; Pouget, 2006</xref>; <xref rid="b54" ref-type="bibr">Rao, 2004</xref>). Current linear-rise models assume an implementation that is instantaneous in that the subject’s posterior belief in the competing hypotheses is calculated on the basis of evidence that evolves over time. That is, each piece of new evidence instantaneously leads to an update. Alternatively, Bayesian inference could be expressed in terms of a gradient-ascent scheme on the free energy which would converge to the true posterior probability of either hypothesis.</p>
      <p>Given the dependence of learning on synaptic plasticity and neuromodulatory systems, the modelling approach described in this paper could be of interest for clinical applications, particularly in psychiatry (<xref rid="b78" ref-type="bibr">Stephan, Baldeweg, &amp; Friston, 2006</xref>). One potential long-term target for clinical application of learning models of eye movements is schizophrenia. Among the most promising endophenotypes of schizophrenia are abnormalities both in antisaccade tasks (<xref rid="b40" ref-type="bibr">McDowell et al., 2002</xref>) and learning tasks (<xref rid="b78" ref-type="bibr">Stephan et al., 2006</xref>). These abnormalities are usually observed as subtle statistical discrepancies between groups of healthy subjects and patients. However, to our knowledge, these observations have not yet been successfully used for the development of richer classification systems as well as corresponding subject-specific diagnostics. Further investigation of the release of eye saccades and learning effects from a psychophysical perspective might help to detect systematic differences between healthy and diseased individuals in order to eventually improve early diagnosis. For example, classifiers (albeit more powerful ones than the example used in Section <xref rid="sec3.3" ref-type="sec">3.3</xref>) could be used to map test samples from patients onto classes that correspond to different subgroups of a disease. In this way, Bayesian learning models could become a valuable tool for studying physiological and pathophysiological mechanisms of saccadic eye movements.</p>
    </sec>
  </body>
  <back>
    <fn-group>
      <fn id="N0x1d53730N0x2a5be50">
        <label>☆</label>
        <p>This research has been funded by the Wellcome Trust (VS/06/UCL/A18), the German Academic Exchange Service (DAAD, D/ 06/49008), and the Stiftung Familie Klee (Frankfurt/Main).</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="b1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Neglect as a disorder of prior probability</article-title>
          <source>Neuropsychologia</source>
          <year>2008</year>
          <volume>46</volume>
          <fpage>1566</fpage>
          <lpage>1569</lpage>
          <pub-id pub-id-type="pmid">18215402</pub-id>
        </citation>
      </ref>
      <ref id="b2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Asrress</surname>
              <given-names>K.N.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>Saccadic countermanding: a comparison of central and peripheral stop signals</article-title>
          <source>Vision Research</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>2645</fpage>
          <lpage>2651</lpage>
          <pub-id pub-id-type="pmid">11520510</pub-id>
        </citation>
      </ref>
      <ref id="b3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Basso</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Wurtz</surname>
              <given-names>R.H.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of neuronal activity by target uncertainty</article-title>
          <source>Nature</source>
          <year>1997</year>
          <volume>389</volume>
          <fpage>1966</fpage>
          <lpage>1969</lpage>
        </citation>
      </ref>
      <ref id="b4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Basso</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Wurtz</surname>
              <given-names>R.H.</given-names>
            </name>
          </person-group>
          <article-title>Modulation of neuronal activity in superior colliculus by changes in target probability</article-title>
          <source>Journal of Neuroscience</source>
          <year>1998</year>
          <volume>18</volume>
          <fpage>7519</fpage>
          <pub-id pub-id-type="pmid">9736670</pub-id>
        </citation>
      </ref>
      <ref id="b5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Walton</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Rushworth</surname>
              <given-names>M.F.S.</given-names>
            </name>
          </person-group>
          <article-title>Learning the value of information in an uncertain world</article-title>
          <source>Nature Neuroscience</source>
          <year>2007</year>
          <volume>10</volume>
          <fpage>1214</fpage>
          <lpage>1221</lpage>
        </citation>
      </ref>
      <ref id="b6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>Contrast, probability, and saccadic latency; evidence for independence of detection and decision</article-title>
          <source>Current Biology: CB</source>
          <year>2004</year>
          <volume>14</volume>
          <fpage>1576</fpage>
          <lpage>1580</lpage>
          <pub-id pub-id-type="pmid">15341745</pub-id>
        </citation>
      </ref>
      <ref id="b7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
            <name>
              <surname>McDonald</surname>
              <given-names>S.A.</given-names>
            </name>
          </person-group>
          <article-title>Later predicts saccade latency distributions in reading</article-title>
          <source>Experimental Brain Research</source>
          <year>2007</year>
          <volume>177</volume>
          <fpage>176</fpage>
          <lpage>183</lpage>
        </citation>
      </ref>
      <ref id="b8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
            <name>
              <surname>Reddi</surname>
              <given-names>B.A.J.</given-names>
            </name>
          </person-group>
          <article-title>Reply to ‘putting noise into neurophysiological models of simple decision making’</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>337</fpage>
        </citation>
      </ref>
      <ref id="b9">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>M.L.L.</given-names>
            </name>
          </person-group>
          <article-title>Neural computation of log likelihood in control of saccadic eye movements</article-title>
          <source>Nature</source>
          <year>1995</year>
          <volume>377</volume>
          <fpage>59</fpage>
          <lpage>62</lpage>
          <pub-id pub-id-type="pmid">7659161</pub-id>
        </citation>
      </ref>
      <ref id="b10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Corrado</surname>
              <given-names>G.S.</given-names>
            </name>
            <name>
              <surname>Sugrue</surname>
              <given-names>L.P.</given-names>
            </name>
            <name>
              <surname>Seung</surname>
              <given-names>H.S.</given-names>
            </name>
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Linear-nonlinear-poisson models of primate choice dynamics</article-title>
          <source>Journal of the Experimental Analysis of Behavior</source>
          <year>2005</year>
          <volume>84</volume>
          <fpage>581</fpage>
          <lpage>617</lpage>
          <pub-id pub-id-type="pmid">16596981</pub-id>
        </citation>
      </ref>
      <ref id="b11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fischer</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Biscaldi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Otto</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Saccadic eye movements of dyslexic adult subjects</article-title>
          <source>Neuropsychologia</source>
          <year>1993</year>
          <volume>31</volume>
          <fpage>887</fpage>
          <lpage>906</lpage>
          <pub-id pub-id-type="pmid">8232847</pub-id>
        </citation>
      </ref>
      <ref id="b12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gitelman</surname>
              <given-names>D.R.</given-names>
            </name>
          </person-group>
          <article-title>Ilab: A program for postexperimental eye movement analysis</article-title>
          <source>Behavior Research Methods, Instruments, &amp; Computers</source>
          <year>2002</year>
          <volume>34</volume>
          <fpage>605</fpage>
          <lpage>612</lpage>
        </citation>
      </ref>
      <ref id="b13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Making choices: The neurophysiology of visual-saccadic decision making</article-title>
          <source>Trends in Neurosciences</source>
          <year>2001</year>
          <volume>24</volume>
          <fpage>654</fpage>
          <lpage>659</lpage>
          <pub-id pub-id-type="pmid">11672810</pub-id>
        </citation>
      </ref>
      <ref id="b14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>The neurobiology of visual-saccadic decision making</article-title>
          <source>Annual Review of Neuroscience</source>
          <year>2003</year>
          <volume>26</volume>
          <fpage>133</fpage>
          <lpage>179</lpage>
        </citation>
      </ref>
      <ref id="b15">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gold</surname>
              <given-names>J.I.</given-names>
            </name>
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Representation of a perceptual decision in developing oculomotor commands</article-title>
          <source>Nature</source>
          <year>2000</year>
          <volume>404</volume>
          <fpage>390</fpage>
          <lpage>394</lpage>
          <pub-id pub-id-type="pmid">10746726</pub-id>
        </citation>
      </ref>
      <ref id="b16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gold</surname>
              <given-names>J.I.</given-names>
            </name>
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Neural computations that underlie decisions about sensory stimuli</article-title>
          <source>Trends in Cognitive Sciences</source>
          <year>2001</year>
          <volume>5</volume>
          <fpage>10</fpage>
          <lpage>16</lpage>
          <pub-id pub-id-type="pmid">11164731</pub-id>
        </citation>
      </ref>
      <ref id="b17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gold</surname>
              <given-names>J.I.</given-names>
            </name>
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Banburismus and the brain: Decoding the relationship between sensory stimuli, decisions, and reward</article-title>
          <source>Neuron</source>
          <year>2002</year>
          <volume>36</volume>
          <fpage>299</fpage>
          <lpage>308</lpage>
          <pub-id pub-id-type="pmid">12383783</pub-id>
        </citation>
      </ref>
      <ref id="b18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grice</surname>
              <given-names>G.R.</given-names>
            </name>
          </person-group>
          <article-title>Stimulus intensity and response evocation</article-title>
          <source>Psychological Review</source>
          <year>1968</year>
          <volume>75</volume>
          <fpage>359</fpage>
          <lpage>373</lpage>
          <pub-id pub-id-type="pmid">4879423</pub-id>
        </citation>
      </ref>
      <ref id="b19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hanes</surname>
              <given-names>D.P.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>Countermanding saccades in humans</article-title>
          <source>Vision Research</source>
          <year>1999</year>
          <volume>39</volume>
          <fpage>2777</fpage>
          <lpage>2791</lpage>
          <pub-id pub-id-type="pmid">10492837</pub-id>
        </citation>
      </ref>
      <ref id="b20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hanes</surname>
              <given-names>D.P.</given-names>
            </name>
            <name>
              <surname>Patterson</surname>
              <given-names>W.F.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Role of frontal eye fields in countermanding saccades: Visual, movement, and fixation activity</article-title>
          <source>Journal of Neurophysiology</source>
          <year>1998</year>
          <volume>79</volume>
          <fpage>817</fpage>
          <lpage>834</lpage>
          <pub-id pub-id-type="pmid">9463444</pub-id>
        </citation>
      </ref>
      <ref id="b21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hanes</surname>
              <given-names>D.P.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Neural control of voluntary movement initiation</article-title>
          <source>Science</source>
          <year>1996</year>
          <volume>274</volume>
          <fpage>427</fpage>
          <pub-id pub-id-type="pmid">8832893</pub-id>
        </citation>
      </ref>
      <ref id="b22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hanes</surname>
              <given-names>D.P.</given-names>
            </name>
            <name>
              <surname>Thompson</surname>
              <given-names>K.G.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Relationship of presaccadic activity in frontal eye field and supplementary eye field to saccade initiation in macaque: Poisson spike train analysis</article-title>
          <source>Experimental Brain Research</source>
          <year>1995</year>
          <volume>103</volume>
          <fpage>85</fpage>
          <lpage>96</lpage>
        </citation>
      </ref>
      <ref id="b23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Harrison</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>Duggins</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Encoding uncertainty in the hippocampus</article-title>
          <source>Neural Networks</source>
          <year>2006</year>
          <volume>19</volume>
          <fpage>535</fpage>
          <lpage>546</lpage>
          <pub-id pub-id-type="pmid">16527453</pub-id>
        </citation>
      </ref>
      <ref id="b24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Herrnstein</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>Relative and absolute strength of response as a function of frequency of reinforcement</article-title>
          <source>Journal of the Experimental Analysis of Behavior</source>
          <year>1961</year>
          <volume>4</volume>
          <fpage>267</fpage>
          <lpage>272</lpage>
          <pub-id pub-id-type="pmid">13713775</pub-id>
        </citation>
      </ref>
      <ref id="b25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jain</surname>
              <given-names>A.K.</given-names>
            </name>
            <name>
              <surname>Duin</surname>
              <given-names>R.P.W.</given-names>
            </name>
            <name>
              <surname>Mao</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Statistical pattern recognition: A review</article-title>
          <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
          <year>2000</year>
          <volume>22</volume>
          <fpage>4</fpage>
          <lpage>37</lpage>
        </citation>
      </ref>
      <ref id="b26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jazayeri</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Optimal representation of sensory information by neural populations</article-title>
          <source>Nature</source>
          <year>2006</year>
          <volume>200</volume>
          <fpage>6</fpage>
        </citation>
      </ref>
      <ref id="b27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kass</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Raftery</surname>
              <given-names>A.E.</given-names>
            </name>
          </person-group>
          <article-title>Bayes factors</article-title>
          <source>Journal of the American Statistical Association</source>
          <year>1995</year>
          <volume>90</volume>
          <fpage>773</fpage>
          <lpage>795</lpage>
        </citation>
      </ref>
      <ref id="b28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kim</surname>
              <given-names>J.N.</given-names>
            </name>
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title>
          <source>Nature Neuroscience</source>
          <year>1999</year>
          <volume>2</volume>
          <fpage>176</fpage>
          <lpage>185</lpage>
        </citation>
      </ref>
      <ref id="b29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knill</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Pouget</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The Bayesian brain: The role of uncertainty in neural coding and computation</article-title>
          <source>Trends in Neurosciences</source>
          <year>2004</year>
          <volume>27</volume>
          <fpage>712</fpage>
          <lpage>719</lpage>
          <pub-id pub-id-type="pmid">15541511</pub-id>
        </citation>
      </ref>
      <ref id="b30">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kurata</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Aizawa</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Influences of motor instructions on the reaction times of saccadic eye movements</article-title>
          <source>Neuroscience Research</source>
          <year>2004</year>
          <volume>48</volume>
          <fpage>447</fpage>
          <lpage>455</lpage>
          <pub-id pub-id-type="pmid">15041198</pub-id>
        </citation>
      </ref>
      <ref id="b31">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lau</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic response-by-response models of matching behavior in rhesus monkeys</article-title>
          <source>Journal of the Experimental Analysis of Behavior</source>
          <year>2005</year>
          <volume>84</volume>
          <fpage>555</fpage>
          <lpage>579</lpage>
          <pub-id pub-id-type="pmid">16596980</pub-id>
        </citation>
      </ref>
      <ref id="b32">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Leach</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.</given-names>
            </name>
          </person-group>
          <article-title>Saccadic choice with asynchronous targets: Evidence for independent randomisation</article-title>
          <source>Vision Research</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>3437</fpage>
          <lpage>3445</lpage>
          <pub-id pub-id-type="pmid">11718785</pub-id>
        </citation>
      </ref>
      <ref id="b33">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Loon</surname>
              <given-names>E.M.V.</given-names>
            </name>
            <name>
              <surname>Hooge</surname>
              <given-names>I.T.C.</given-names>
            </name>
            <name>
              <surname>Berg</surname>
              <given-names>A.V.V.den</given-names>
            </name>
          </person-group>
          <article-title>The timing of sequences of saccades in visual search</article-title>
          <source>Proceedings. Biological Sciences/The Royal Society</source>
          <year>2002</year>
          <volume>269</volume>
          <fpage>1571</fpage>
          <lpage>1579</lpage>
          <pub-id pub-id-type="pmid">12184827</pub-id>
        </citation>
      </ref>
      <ref id="b34">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Luce</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <article-title>Detection and recognition</article-title>
          <source>Handbook of mathematical psychology</source>
          <volume>Vol. 1</volume>
          <year>1963</year>
          <fpage>103</fpage>
          <lpage>189</lpage>
        </citation>
      </ref>
      <ref id="b35">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Luce</surname>
              <given-names>R.D.</given-names>
            </name>
          </person-group>
          <article-title>Response times: Their role in inferring elementary mental organization</article-title>
          <year>1986</year>
          <publisher-name>Oxford University Press</publisher-name>
          <publisher-loc>USA</publisher-loc>
        </citation>
      </ref>
      <ref id="b36">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ludwig</surname>
              <given-names>C.J.H.</given-names>
            </name>
            <name>
              <surname>Gilchrist</surname>
              <given-names>I.D.</given-names>
            </name>
            <name>
              <surname>McSorley</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Baddeley</surname>
              <given-names>R.J.</given-names>
            </name>
          </person-group>
          <article-title>The temporal impulse response underlying saccadic decisions</article-title>
          <source>Journal of Neuroscience</source>
          <year>2005</year>
          <volume>25</volume>
          <fpage>9907</fpage>
          <lpage>9912</lpage>
          <pub-id pub-id-type="pmid">16251438</pub-id>
        </citation>
      </ref>
      <ref id="b37">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ma</surname>
              <given-names>W.J.</given-names>
            </name>
            <name>
              <surname>Beck</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Latham</surname>
              <given-names>P.E.</given-names>
            </name>
            <name>
              <surname>Pouget</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian inference with probabilistic population codes</article-title>
          <source>Nature Neuroscience</source>
          <year>2006</year>
          <volume>9</volume>
          <fpage>1432</fpage>
          <lpage>1438</lpage>
        </citation>
      </ref>
      <ref id="b38">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maddox</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Toward a unified theory of decision criterion learning in perceptual categorization</article-title>
          <source>Journal of the Experimental Analysis of Behavior</source>
          <year>2002</year>
          <volume>78</volume>
          <fpage>567</fpage>
          <pub-id pub-id-type="pmid">12507020</pub-id>
        </citation>
      </ref>
      <ref id="b39">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Madelain</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Champrenaut</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Chauvin</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Control of sensorimotor variability by consequences</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2007</year>
          <volume>98</volume>
          <fpage>2255</fpage>
          <lpage>2265</lpage>
          <pub-id pub-id-type="pmid">17699687</pub-id>
        </citation>
      </ref>
      <ref id="b40">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McDowell</surname>
              <given-names>J.E.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>G.G.</given-names>
            </name>
            <name>
              <surname>Paulus</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Martinez</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Stewart</surname>
              <given-names>S.E.</given-names>
            </name>
            <name>
              <surname>Dubowitz</surname>
              <given-names>D.J.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of refixation saccades and antisaccades in normal and schizophrenia subjects</article-title>
          <source>Biological Psychiatry</source>
          <year>2002</year>
          <volume>51</volume>
          <fpage>216</fpage>
          <lpage>223</lpage>
          <pub-id pub-id-type="pmid">11839364</pub-id>
        </citation>
      </ref>
      <ref id="b41">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>McMillen</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>The dynamics of choice among multiple alternatives</article-title>
          <source>Journal of Mathematical Psychology</source>
          <year>2006</year>
          <volume>50</volume>
          <fpage>30</fpage>
          <lpage>57</lpage>
        </citation>
      </ref>
      <ref id="b42">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Minka</surname>
              <given-names>T.P.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian inference, entropy, and the multinomial distribution</article-title>
          <year>2001</year>
          <publisher-name>Microsoft Research</publisher-name>
          <publisher-loc>Cambridge, UK</publisher-loc>
        </citation>
      </ref>
      <ref id="b43">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nakahara</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Nakamura</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Hikosaka</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Extended later model can account for trial-by-trial variability of both pre- and post-processes</article-title>
          <source>Neural Networks</source>
          <year>2006</year>
          <volume>19</volume>
          <fpage>1027</fpage>
          <lpage>1046</lpage>
          <pub-id pub-id-type="pmid">16971090</pub-id>
        </citation>
      </ref>
      <ref id="b44">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Nazir</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Jacobs</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>The effects of target discriminability and retinal eccentricity on saccade latencies: An analysis in terms of variable-criterion theory</article-title>
          <source>Psychological Research</source>
          <year>1991</year>
          <volume>53</volume>
          <fpage>281</fpage>
          <lpage>289</lpage>
          <pub-id pub-id-type="pmid">1792299</pub-id>
        </citation>
      </ref>
      <ref id="b45">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Deciding about motion: Linking perception to action</article-title>
          <source>Journal of Comparative Physiology A</source>
          <year>1997</year>
          <volume>181</volume>
          <fpage>5</fpage>
          <lpage>12</lpage>
        </citation>
      </ref>
      <ref id="b46">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
            <name>
              <surname>Britten</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Neuronal correlates of a perceptual decision</article-title>
          <source>Nature</source>
          <year>1989</year>
          <volume>341</volume>
          <fpage>52</fpage>
          <lpage>54</lpage>
          <pub-id pub-id-type="pmid">2770878</pub-id>
        </citation>
      </ref>
      <ref id="b47">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
            <name>
              <surname>Britten</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Salzman</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>Neuronal mechanisms of motion perception</article-title>
          <source>Cold Spring Harbor Symposia on Quantitative Biology</source>
          <year>1990</year>
          <volume>55</volume>
          <fpage>697</fpage>
          <lpage>705</lpage>
        </citation>
      </ref>
      <ref id="b48">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
            <name>
              <surname>Pare</surname>
              <given-names>E.B.</given-names>
            </name>
          </person-group>
          <article-title>A selective impairment of motion perception following lesions of the middle temporal visual area (mt)</article-title>
          <source>Journal of Neuroscience</source>
          <year>1988</year>
          <volume>8</volume>
          <fpage>2201</fpage>
          <lpage>2211</lpage>
          <pub-id pub-id-type="pmid">3385495</pub-id>
        </citation>
      </ref>
      <ref id="b49">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oswal</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ogden</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>The time course of stimulus expectation in a saccadic decision task</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2007</year>
          <volume>97</volume>
          <fpage>2722</fpage>
          <lpage>2730</lpage>
          <pub-id pub-id-type="pmid">17267751</pub-id>
        </citation>
      </ref>
      <ref id="b50">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Papoulis</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Probability, random variables, and stochastic processes</article-title>
          <year>1991</year>
          <publisher-name>McGraw-Hill</publisher-name>
          <publisher-loc>New York</publisher-loc>
        </citation>
      </ref>
      <ref id="b51">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Penny</surname>
              <given-names>W.D.</given-names>
            </name>
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Mechelli</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Comparing dynamic causal models</article-title>
          <source>Neuroimage</source>
          <year>2004</year>
          <volume>22</volume>
          <fpage>1157</fpage>
          <lpage>1172</lpage>
          <pub-id pub-id-type="pmid">15219588</pub-id>
        </citation>
      </ref>
      <ref id="b52">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Platt</surname>
              <given-names>M.L.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of decisions</article-title>
          <source>Current Opinion in Neurobiology</source>
          <year>2002</year>
          <volume>12</volume>
          <fpage>141</fpage>
          <lpage>148</lpage>
          <pub-id pub-id-type="pmid">12015229</pub-id>
        </citation>
      </ref>
      <ref id="b53">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Platt</surname>
              <given-names>M.L.</given-names>
            </name>
            <name>
              <surname>Glimcher</surname>
              <given-names>P.W.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of decision variables in parietal cortex</article-title>
          <source>Nature</source>
          <year>1999</year>
          <volume>400</volume>
          <fpage>233</fpage>
          <lpage>238</lpage>
          <pub-id pub-id-type="pmid">10421364</pub-id>
        </citation>
      </ref>
      <ref id="b54">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rao</surname>
              <given-names>R.P.N.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian computation in recurrent neural circuits</article-title>
          <source>Neural Computation</source>
          <year>2004</year>
          <volume>16</volume>
          <fpage>1</fpage>
          <lpage>38</lpage>
          <pub-id pub-id-type="pmid">15006021</pub-id>
        </citation>
      </ref>
      <ref id="b55">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>A theory of memory retrieval</article-title>
          <source>Psychological Review</source>
          <year>1978</year>
          <volume>85</volume>
          <fpage>59</fpage>
          <lpage>108</lpage>
        </citation>
      </ref>
      <ref id="b56">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Putting noise into neurophysiological models of simple decision making</article-title>
          <source>Nature Neuroscience</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>336</fpage>
        </citation>
      </ref>
      <ref id="b57">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Cherian</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Segraves</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A comparison of macaque behavior and superior colliculus neuronal activity to predictions from models of two-choice decisions</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2003</year>
          <volume>90</volume>
          <fpage>1392</fpage>
          <lpage>1407</lpage>
          <pub-id pub-id-type="pmid">12761282</pub-id>
        </citation>
      </ref>
      <ref id="b58">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Rouder</surname>
              <given-names>J.N.</given-names>
            </name>
          </person-group>
          <article-title>Modeling response times for two-choice decisions</article-title>
          <source>Psychological Science</source>
          <year>1998</year>
          <volume>9</volume>
          <fpage>347</fpage>
          <lpage>356</lpage>
        </citation>
      </ref>
      <ref id="b59">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>P.L.</given-names>
            </name>
          </person-group>
          <article-title>A comparison of sequential sampling models for two-choice reaction time</article-title>
          <source>Psychological review</source>
          <year>2004</year>
          <volume>111</volume>
          <fpage>333</fpage>
          <lpage>367</lpage>
          <pub-id pub-id-type="pmid">15065913</pub-id>
        </citation>
      </ref>
      <ref id="b60">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Zandt</surname>
              <given-names>T.van</given-names>
            </name>
            <name>
              <surname>McKoon</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Connectionist and diffusion models of reaction time</article-title>
          <source>Psychological review</source>
          <year>1999</year>
          <volume>106</volume>
          <fpage>261</fpage>
          <lpage>300</lpage>
          <pub-id pub-id-type="pmid">10378014</pub-id>
        </citation>
      </ref>
      <ref id="b61">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Reddi</surname>
              <given-names>B.A.J.</given-names>
            </name>
          </person-group>
          <article-title>Decision making: The two stages of neuronal judgement</article-title>
          <source>Current Biology</source>
          <year>2001</year>
          <volume>11</volume>
          <fpage>603</fpage>
          <lpage>606</lpage>
        </citation>
      </ref>
      <ref id="b62">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Reddi</surname>
              <given-names>B.A.J.</given-names>
            </name>
            <name>
              <surname>Asrress</surname>
              <given-names>K.N.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>Accuracy, information, and response time in a saccadic decision task</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2003</year>
          <volume>90</volume>
          <fpage>3538</fpage>
          <lpage>3546</lpage>
          <pub-id pub-id-type="pmid">12815017</pub-id>
        </citation>
      </ref>
      <ref id="b63">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Reddi</surname>
              <given-names>B.A.J.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>The influence of urgency on decision time</article-title>
          <source>Nature Neuroscience</source>
          <year>2000</year>
          <volume>3</volume>
          <fpage>827</fpage>
          <lpage>830</lpage>
        </citation>
      </ref>
      <ref id="b64">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Robinson</surname>
              <given-names>D.A.</given-names>
            </name>
          </person-group>
          <article-title>Models of the saccadic eye movement control system</article-title>
          <source>Biological Cybernetics</source>
          <year>1973</year>
          <volume>14</volume>
          <fpage>71</fpage>
          <lpage>83</lpage>
        </citation>
      </ref>
      <ref id="b65">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Roitman</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
          </person-group>
          <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>
          <source>Journal of Neuroscience</source>
          <year>2002</year>
          <volume>22</volume>
          <fpage>9475</fpage>
          <pub-id pub-id-type="pmid">12417672</pub-id>
        </citation>
      </ref>
      <ref id="b66">
        <citation citation-type="other">Romaya, J. (2000). Cogent 2000. This experiment was realised using Cogent 2000 developed by the Cogent 2000 team at the FIL and the ICN and Cogent Graphics developed by John Romaya at the ION at the Wellcome Department of Imaging Neuroscience</citation>
      </ref>
      <ref id="b67">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Salzman</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Britten</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Cortical microstimulation influences perceptual judgements of motion direction</article-title>
          <source>Nature</source>
          <year>1990</year>
          <volume>346</volume>
          <fpage>174</fpage>
          <lpage>177</lpage>
          <pub-id pub-id-type="pmid">2366872</pub-id>
        </citation>
      </ref>
      <ref id="b68">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Neural basis of deciding, choosing and acting</article-title>
          <source>Nature Reviews Neuroscience</source>
          <year>2001</year>
          <volume>2</volume>
          <fpage>33</fpage>
          <lpage>42</lpage>
        </citation>
      </ref>
      <ref id="b69">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of decision processes: neural and mental chronometry</article-title>
          <source>Current Opinion in Neurobiology</source>
          <year>2003</year>
          <volume>13</volume>
          <fpage>182</fpage>
          <lpage>186</lpage>
          <pub-id pub-id-type="pmid">12744971</pub-id>
        </citation>
      </ref>
      <ref id="b70">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Thompson</surname>
              <given-names>K.G.</given-names>
            </name>
          </person-group>
          <article-title>Neural selection and control of visually guided eye movements</article-title>
          <source>Annual Review of Neuroscience</source>
          <year>1999</year>
          <volume>22</volume>
          <fpage>241</fpage>
          <lpage>259</lpage>
        </citation>
      </ref>
      <ref id="b71">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
            <name>
              <surname>Britten</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
            <name>
              <surname>Movshon</surname>
              <given-names>J.A.</given-names>
            </name>
          </person-group>
          <article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title>
          <source>Journal of Neuroscience</source>
          <year>1996</year>
          <volume>16</volume>
          <fpage>1486</fpage>
          <lpage>1510</lpage>
          <pub-id pub-id-type="pmid">8778300</pub-id>
        </citation>
      </ref>
      <ref id="b72">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
            <name>
              <surname>Gold</surname>
              <given-names>J.I.</given-names>
            </name>
          </person-group>
          <article-title>The neurophysiology of decision-making as a window on cognition</article-title>
          <source>The Cognitive Neurosciences</source>
          <year>2004</year>
          <fpage>1229</fpage>
          <lpage>1241</lpage>
        </citation>
      </ref>
      <ref id="b73">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Motion perception: Seeing and deciding</article-title>
          <source>Proceedings of the National Academy of Sciences of the United States of America</source>
          <year>1996</year>
          <volume>93</volume>
          <fpage>628</fpage>
          <lpage>633</lpage>
          <pub-id pub-id-type="pmid">8570606</pub-id>
        </citation>
      </ref>
      <ref id="b74">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shadlen</surname>
              <given-names>M.N.</given-names>
            </name>
            <name>
              <surname>Newsome</surname>
              <given-names>W.T.</given-names>
            </name>
          </person-group>
          <article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2001</year>
          <volume>86</volume>
          <fpage>1916</fpage>
          <lpage>1936</lpage>
          <pub-id pub-id-type="pmid">11600651</pub-id>
        </citation>
      </ref>
      <ref id="b75">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sinha</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>J.T.G.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>R.H.S.</given-names>
            </name>
          </person-group>
          <article-title>Task switching as a two-stage decision process</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2006</year>
          <volume>95</volume>
          <fpage>3146</fpage>
          <lpage>3153</lpage>
          <pub-id pub-id-type="pmid">16467422</pub-id>
        </citation>
      </ref>
      <ref id="b76">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>Wirth</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Suzuki</surname>
              <given-names>W.A.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>E.N.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian analysis of interleaved learning and response bias in behavioral experiments</article-title>
          <source>Journal of Neurophysiology</source>
          <year>2007</year>
          <volume>97</volume>
          <fpage>2516</fpage>
          <pub-id pub-id-type="pmid">17182907</pub-id>
        </citation>
      </ref>
      <ref id="b77">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>P.L.</given-names>
            </name>
            <name>
              <surname>Ratcliff</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Psychology and neurobiology of simple decisions</article-title>
          <source>Trends in Neurosciences</source>
          <year>2004</year>
          <volume>27</volume>
          <fpage>161</fpage>
          <lpage>168</lpage>
          <pub-id pub-id-type="pmid">15036882</pub-id>
        </citation>
      </ref>
      <ref id="b78">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stephan</surname>
              <given-names>K.E.</given-names>
            </name>
            <name>
              <surname>Baldeweg</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Synaptic plasticity and dysconnection in schizophrenia</article-title>
          <source>Biological Psychiatry</source>
          <year>2006</year>
          <volume>59</volume>
          <fpage>929</fpage>
          <lpage>939</lpage>
          <pub-id pub-id-type="pmid">16427028</pub-id>
        </citation>
      </ref>
      <ref id="b79">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sternberg</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>The discovery of processing stages: Extensions of Donders’ method</article-title>
          <source>Acta Psychologica</source>
          <year>1969</year>
          <volume>30</volume>
          <fpage>276</fpage>
          <lpage>315</lpage>
        </citation>
      </ref>
      <ref id="b80">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sternberg</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Memory scanning: Mental processes revealed by reaction-time experiments</article-title>
          <source>American Science</source>
          <year>1969</year>
          <volume>57</volume>
          <fpage>421</fpage>
          <lpage>457</lpage>
        </citation>
      </ref>
      <ref id="b81">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Strange</surname>
              <given-names>B.A.</given-names>
            </name>
            <name>
              <surname>Duggins</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Penny</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Dolan</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Information theory, novelty and hippocampal responses: Unpredicted or unpredictable?</article-title>
          <source>Neural Networks</source>
          <year>2005</year>
          <volume>18</volume>
          <fpage>225</fpage>
          <lpage>230</lpage>
          <pub-id pub-id-type="pmid">15896570</pub-id>
        </citation>
      </ref>
      <ref id="b82">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thompson</surname>
              <given-names>K.G.</given-names>
            </name>
            <name>
              <surname>Bichot</surname>
              <given-names>N.P.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Dissociation of target selection from saccade planning in macaque frontal eye field</article-title>
          <source>Journal of Neurophysiology</source>
          <year>1997</year>
          <volume>77</volume>
          <fpage>1046</fpage>
          <lpage>1050</lpage>
          <pub-id pub-id-type="pmid">9065870</pub-id>
        </citation>
      </ref>
      <ref id="b83">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thompson</surname>
              <given-names>K.G.</given-names>
            </name>
            <name>
              <surname>Hanes</surname>
              <given-names>D.P.</given-names>
            </name>
            <name>
              <surname>Bichot</surname>
              <given-names>N.P.</given-names>
            </name>
            <name>
              <surname>Schall</surname>
              <given-names>J.D.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual and motor processing stages identified in the activity of macaque frontal eye field neurons during visual search</article-title>
          <source>Journal of Neurophysiology</source>
          <year>1996</year>
          <volume>76</volume>
          <fpage>4040</fpage>
          <lpage>4055</lpage>
          <pub-id pub-id-type="pmid">8985899</pub-id>
        </citation>
      </ref>
      <ref id="b84">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Usher</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>McClelland</surname>
              <given-names>J.L.</given-names>
            </name>
          </person-group>
          <article-title>The time course of perceptual choice: The leaky, competing accumulator model</article-title>
          <source>Psychological Review</source>
          <year>2001</year>
          <volume>108</volume>
          <fpage>550</fpage>
          <lpage>592</lpage>
          <pub-id pub-id-type="pmid">11488378</pub-id>
        </citation>
      </ref>
      <ref id="b85">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wald</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Sequential tests of statistical hypotheses</article-title>
          <source>The Annals of Mathematical Statistics</source>
          <year>1945</year>
          <volume>16</volume>
          <fpage>117</fpage>
          <lpage>186</lpage>
        </citation>
      </ref>
    </ref-list>
  </back>
  <floats-wrap>
    <fig id="fig1">
      <label>Fig. 1</label>
      <caption>
        <p>Experimental design. A complete session consists of 5 blocks, each of which contains 150 trials generated from the same block-specific transition matrix. All matrices shown in the main text were used to generate samples in each session. A trial consists of three consecutive stages: a fixation screen (showing a central red fixation dot); a target screen (showing both the fixation dot and an additional leftward or rightward target dot); an inter-trial interval (showing a black screen until the beginning of the next trial).</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig. 2</label>
      <caption>
        <p>Neuronal responses of a decision process and translation into a computational model. (a) Neuronal responses prior to a saccade from three trials. In their experiment, <xref rid="b70" ref-type="bibr">Schall and Thompson (1999)</xref> trained rhesus monkeys to stare at a central fixation stimulus and, as soon as eight secondary targets appeared, to elicit a saccade towards the oddball. The targets were arranged radially around the central fixation stimulus, and the location of the oddball was random. The diagram shows the recorded activity of single movement-related neurons in the saccadic movement maps of the frontal eye fields (FEF). Trials were grouped into those with slow, medium and fast saccades. The three plots show the averaged activity within these groups of trials, in each trial taking the activity from that neuronal response field corresponding to the correct target location. The activity patterns show that there is a fairly constant biophysical threshold at which a saccade is irrevocably elicited (grey bar) whereas the rate at which the signals rise varies between the groups of saccades. (Reprinted, with permission, from the Annual Review of Neuroscience, Volume 22 (c) 1999 by Annual Reviews, <ext-link xlink:href="http://www.annualreviews.org" ext-link-type="uri">www.annualreviews.org</ext-link>) (b) Translation into a computational model of the decision process for a single trial. The rising activation in the FEFs is modelled as a linearly rising decision signal S. It starts off at an initial level <mml:math id="M151" altimg="si2.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math> and rises at a variable rate until reaching threshold <mml:math id="M152" altimg="si3.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math> at time τ.</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig. 3</label>
      <caption>
        <p>Intra-trial model parameterization. The proposed intra-trial model has three free parameters, represented by grey arrows. (i) ρ and (ii) σ determine the mean and the standard deviation of the normally distributed slope of the decision signal that corresponds to the true target location of the current trial. The larger ρ, the shorter the predicted saccade latency τ. The larger σ, the larger the variability of the distribution of τ. (iii) ϑ specifies the threshold the decision signal has to reach in order to evoke a saccade. The larger ϑ, the longer the latency and the less the influence of the initial value <mml:math id="M153" altimg="si13.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math>.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig. 4</label>
      <caption>
        <p>Log prior ratios predicted by the alternative inter-trial models. Each diagram is based on the combination of a particular block structure (transition-oriented, state-oriented, or uniform) and a particular inter-trial model (‘transition’ model, ‘state’ model, or ‘uniform’ model). For each trial, the diagrams show the target location (black dots), with high and low markers indicating leftward and rightward targets. Furthermore, they show the log ratio between the prior probability of the true and the false target location (grey squares) as well as a prediction for this log ratio, generated by the respective inter-trial model (black crosses). Since the models are always initialized with uniform priors, the predicted log ratio for trial <mml:math id="M154" altimg="si14.gif" display="inline" overflow="scroll"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math> is <mml:math id="M155" altimg="si15.gif" display="inline" overflow="scroll"><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>/</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>. The upper left diagram, for example, shows how the ‘transition’ model gradually adapts to the transition-oriented block structure underlying the observed sequence of trials. By contrast, the central diagram in the left column shows that the ‘state’ model is incapable of learning the structure of a transition-oriented block.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Fig. 5</label>
      <caption>
        <p>Histogram of latencies and reciprocals. The diagrams are based on 28 blocks containing 3 866 trials from subject S-1. While the latencies themselves have often been described as log normally distributed (<xref rid="b14" ref-type="bibr">Glimcher, 2003</xref>), their reciprocals can be approximated by a normal distribution (<xref rid="b9" ref-type="bibr">Carpenter &amp; Williams, 1995</xref>).</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <fig id="fig6">
      <label>Fig. 6</label>
      <caption>
        <p>Saccade latencies and error bars. (a) Saccade latencies versus true state probabilities, based on all trials from state-oriented blocks across all subjects. (b) Saccade latencies versus true transition probabilities, based on all transition-oriented blocks across all subjects. Both diagrams show how saccade latencies decrease with increasing true probability of the respective target location.</p>
      </caption>
      <graphic xlink:href="gr6"/>
    </fig>
    <fig id="fig7">
      <label>Fig. 7</label>
      <caption>
        <p>Averaged observed and predicted latencies. The diagram shows saccade latencies from an additional experimental session subject S-1 was engaged in. The dataset consists of 10 transition-oriented blocks, each designed to contain an identical left/right sequence of 150 target locations. The diagram shows the trial-by-trial target locations as separate lines of black dots at the bottom (leftward targets: lower line; rightward targets: upper line). The observed latencies, averaged over these 10 sessions, are plotted in black, and their respective model predictions in grey. Observations and predictions of trials in which the target location has stayed on the same side are shown as small black dots and grey circles, respectively. Observations and predictions of trials in which the target location has just switched to the other side are depicted as black crosses and grey squares, respectively. Predicted reaction times (grey circles and squares) show two key features of an ideal observer who is sensitive to transition probabilities. First, whenever there is a sequence of trials with identical target locations (a ‘run’), reaction times drop continuously as the estimated prior probability of that target location increases. Second, whenever the target changes to the other side (a ‘switch’), there is a single long-reaction-time trial, followed by a return to the previous, lower level of reaction times.</p>
      </caption>
      <graphic xlink:href="gr7"/>
    </fig>
    <fig id="fig8">
      <label>Fig. 8</label>
      <caption>
        <p>Averaged observed versus predicted reciprocal latencies from <xref rid="fig7" ref-type="fig">Fig. 7</xref>. In each of the diagrams, predicted reciprocal latencies (y-axis) are plotted against their observations (x-axis). The diagrams are based on the ‘transition,’ the ‘state,’ and the ‘uniform’ model, respectively, applied to the same dataset as in <xref rid="fig7" ref-type="fig">Fig. 7</xref>. Thus, the x-coordinates of the data points are the same in all three diagrams, whereas their y-coordinates differ. Predictions were generated by the alternative models after being individually fitted to the data. The main diagonal represents a perfect match between observations and predictions.</p>
      </caption>
      <graphic xlink:href="gr8"/>
    </fig>
    <fig id="fig9">
      <label>Fig. 9</label>
      <caption>
        <p>Negative log likelihood of the inter-trial models fitted to alternative subsets of the data. Each diagram shows the negative likelihood of the ‘uniform,’ the ‘state,’ and the ‘transition’ model when fitted to the data of a particular subject (rows) confronted with a sequence of target locations generated from a uniform, state-oriented, or transition-oriented block (columns). The rightmost column shows the negative likelihood of the model fitted to all blocks of a particular subject. The smaller the negative log likelihood, the better the model fit.</p>
      </caption>
      <graphic xlink:href="gr9"/>
    </fig>
    <table-wrap position="float" id="tbl1">
      <label>Table 1</label>
      <caption>
        <p>Example of a sequence of target locations generated from the transition matrix <mml:math id="M156" altimg="si20.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0.7</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mn>0.3</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>0.3</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mn>0.7</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math></p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Trial</th>
            <th align="left">1</th>
            <th align="left">2</th>
            <th align="left">3</th>
            <th align="left">4</th>
            <th align="left">5</th>
            <th align="left">6</th>
            <th align="left">…</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Target probabilities</td>
            <td align="left">
              <mml:math id="M157" altimg="si21.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.5</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.5</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M158" altimg="si22.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M159" altimg="si23.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M160" altimg="si24.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M161" altimg="si25.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M162" altimg="si26.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M163" altimg="si27.gif" display="inline" overflow="scroll">
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mn>0.7</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>0.3</mml:mn>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </td>
          </tr>
          <tr>
            <td align="left">Target location drawn</td>
            <td align="left">
              <mml:math id="M164" altimg="si28.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Left</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>1</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M165" altimg="si29.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Left</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>1</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M166" altimg="si30.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Left</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>1</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M167" altimg="si31.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Right</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>2</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M168" altimg="si32.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Right</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>2</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">
              <mml:math id="M169" altimg="si33.gif" display="inline" overflow="scroll">
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd columnalign="center">
                      <mml:mstyle mathvariant="normal">
                        <mml:mi>Left</mml:mi>
                      </mml:mstyle>
                      <mml:mspace class="nbsp"/>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mn>1</mml:mn>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:math>
            </td>
            <td align="left">…</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>On trial 1, the target location is always drawn from a uniform distribution <mml:math id="M170" altimg="si34.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math>. On all subsequent trials, its probability distribution depends on the target location of the previous trial.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="tbl2">
      <?landscape?>
      <label>Table 2</label>
      <caption>
        <p>Number of blocks (B) and trials (T) with successfully extracted saccade latencies, per subject and type of transition matrix</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Subject</th>
            <th colspan="2" align="left">Uniform<hr/></th>
            <th colspan="2" align="left">Weak state orientation<hr/></th>
            <th colspan="2" align="left">Strong state orientation<hr/></th>
            <th colspan="2" align="left">Unstable transition orientation<hr/></th>
            <th colspan="2" align="left">Stable transition orientation<hr/></th>
            <th colspan="2" align="left">All<hr/></th>
          </tr>
          <tr>
            <th align="left"/>
            <th align="left">B</th>
            <th align="left">T</th>
            <th align="left">B</th>
            <th align="left">T</th>
            <th align="left">B</th>
            <th align="left">T</th>
            <th align="left">B</th>
            <th align="left">T</th>
            <th align="left">B</th>
            <th align="left">T</th>
            <th align="left">B</th>
            <th align="left">T</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">S-1</td>
            <td align="left">7</td>
            <td align="left">948</td>
            <td align="left">7</td>
            <td align="left">985</td>
            <td align="left">4</td>
            <td align="left">557</td>
            <td align="left">5</td>
            <td align="left">691</td>
            <td align="left">5</td>
            <td align="left">685</td>
            <td align="left">28</td>
            <td align="left">3866</td>
          </tr>
          <tr>
            <td align="left">S-2</td>
            <td align="left">12</td>
            <td align="left">1727</td>
            <td align="left">12</td>
            <td align="left">1736</td>
            <td align="left">11</td>
            <td align="left">1554</td>
            <td align="left">11</td>
            <td align="left">1558</td>
            <td align="left">9</td>
            <td align="left">1285</td>
            <td align="left">55</td>
            <td align="left">7860</td>
          </tr>
          <tr>
            <td align="left">S-3</td>
            <td align="left">11</td>
            <td align="left">1599</td>
            <td align="left">11</td>
            <td align="left">1594</td>
            <td align="left">12</td>
            <td align="left">1779</td>
            <td align="left">12</td>
            <td align="left">1755</td>
            <td align="left">11</td>
            <td align="left">1625</td>
            <td align="left">57</td>
            <td align="left">8352</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap position="float" id="tbl3">
      <label>Table 3</label>
      <caption>
        <p>Maximum likelihood parameter estimation for different inter-trial models (values rounded to 3 significant figures)</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Inter-trial model</th>
            <th colspan="3" align="left">Subject S-1<hr/></th>
            <th colspan="3" align="left">Subject S-2<hr/></th>
            <th colspan="3" align="left">Subject S-3<hr/></th>
          </tr>
          <tr>
            <th align="left"/>
            <th align="left">ρ</th>
            <th align="left">ϑ</th>
            <th align="left">
              <mml:math id="M171" altimg="si37.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:mi>σ</mml:mi>
              </mml:math>
            </th>
            <th align="left">ρ</th>
            <th align="left">ϑ</th>
            <th align="left">
              <mml:math id="M172" altimg="si40.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:mi>σ</mml:mi>
              </mml:math>
            </th>
            <th align="left">ρ</th>
            <th align="left">ϑ</th>
            <th align="left">
              <mml:math id="M173" altimg="si43.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:mi>σ</mml:mi>
              </mml:math>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">Uniform model</td>
            <td align="left">0.0766</td>
            <td align="left">24.03</td>
            <td align="left">−4.18</td>
            <td align="left">0.0327</td>
            <td align="char">7.87</td>
            <td align="left">−5.06</td>
            <td align="left">0.0615</td>
            <td align="left">13.7</td>
            <td align="left">−4.95</td>
          </tr>
          <tr>
            <td align="left">State model</td>
            <td align="left">0.199</td>
            <td align="left">59.6</td>
            <td align="left">−3.28</td>
            <td align="left">0.126</td>
            <td align="char">29.6</td>
            <td align="left">−3.77</td>
            <td align="left">0.631</td>
            <td align="left">113</td>
            <td align="left">−2.85</td>
          </tr>
          <tr>
            <td align="left">Transition model</td>
            <td align="left">0.0724</td>
            <td align="left">23.5</td>
            <td align="left">−4.26</td>
            <td align="left">0.109</td>
            <td align="char">26.1</td>
            <td align="left">−3.92</td>
            <td align="left">1.37</td>
            <td align="left">200</td>
            <td align="left">−2.28</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap position="float" id="tbl4">
      <label>Table 4</label>
      <caption>
        <p>Parameter estimation for subsequent classification, based on a subset of the original data (S-1: 6 out of 8 blocks. S-2: 9 out of 12 blocks. S-3: 9 out of 12 blocks)</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Class</th>
            <th align="left">Training sample y</th>
            <th align="left">Parameter estimate <mml:math id="M174" altimg="si45.gif" display="inline" overflow="scroll"><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mo>,</mml:mo><mml:mo>ln</mml:mo><mml:mi>σ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></th>
            <th align="left">
              <mml:math id="M175" altimg="si46.gif" display="inline" overflow="scroll">
                <mml:mi mathvariant="double-struck">P</mml:mi>
                <mml:mrow>
                  <mml:mo>(</mml:mo>
                  <mml:mi>C</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mi>c</mml:mi>
                  <mml:mo>)</mml:mo>
                </mml:mrow>
              </mml:math>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">
              <mml:math id="M176" altimg="si47.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
            <td align="left">3049 out of 3866 trials</td>
            <td align="left">0.0724, 23.5, −4.26</td>
            <td align="left">0.333</td>
          </tr>
          <tr>
            <td align="left">
              <mml:math id="M177" altimg="si48.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
            <td align="left">5999 out of 7860 trials</td>
            <td align="left">0.116, 27.5, −3.89</td>
            <td align="left">0.333</td>
          </tr>
          <tr>
            <td align="left">
              <mml:math id="M178" altimg="si49.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>3</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
            <td align="left">6l35 out of 8352 trials</td>
            <td align="left">1.543, 216.32, −2.147</td>
            <td align="left">0.333</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap position="float" id="tbl5">
      <label>Table 5</label>
      <caption>
        <p>Classification results</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="left">Subject</th>
            <th align="left">Test sample y</th>
            <th align="left">
              <mml:math id="M179" altimg="si51.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>30</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </th>
            <th align="left">
              <mml:math id="M180" altimg="si52.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>31</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </th>
            <th align="left">
              <mml:math id="M181" altimg="si53.gif" display="inline" overflow="scroll">
                <mml:mo>ln</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>32</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </th>
            <th align="left">
              <mml:math id="M182" altimg="si54.gif" display="inline" overflow="scroll">
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo>∗</mml:mo>
                  </mml:mrow>
                </mml:msup>
              </mml:math>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left">S-1</td>
            <td align="left">817 trials</td>
            <td align="left"><bold>0.495</bold>×<bold>10</bold><sup><bold>4</bold></sup></td>
            <td align="left">0.395×10 <sup>4</sup></td>
            <td align="left">0.234×10 <sup>4</sup></td>
            <td align="left">
              <mml:math id="M183" altimg="si55.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
          </tr>
          <tr>
            <td align="left">S-2</td>
            <td align="left">1861 trials</td>
            <td align="left">0.873×10<sup>4</sup></td>
            <td align="left"><bold>1.05</bold> ×<bold>10</bold><sup><bold>4</bold></sup></td>
            <td align="left">0.957×10 <sup>4</sup></td>
            <td align="left">
              <mml:math id="M184" altimg="si56.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
          </tr>
          <tr>
            <td align="left">S-3</td>
            <td align="left">2217 trials</td>
            <td align="left">0.880×10<sup>4</sup></td>
            <td align="left">1.33×10 <sup>4</sup></td>
            <td align="left"><bold>1.39</bold> ×<bold>10</bold><sup><bold>4</bold></sup></td>
            <td align="left">
              <mml:math id="M185" altimg="si57.gif" display="inline" overflow="scroll">
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>3</mml:mn>
                  </mml:mrow>
                </mml:msub>
              </mml:math>
            </td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>The classifier was run on three test samples taken from the three subjects. It computed the joint probabilities <mml:math id="M186" altimg="si58.gif" display="inline" overflow="scroll"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow></mml:math> for all classes <mml:math id="M187" altimg="si59.gif" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math>, and assigned each test sample to the class <mml:math id="M188" altimg="si60.gif" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:math> that maximized this joint probability (printed in <bold>bold</bold> font).</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <boxed-text id="tbxI">
      <label>Box I</label>
      <p>
        <disp-formula>
          <mml:math id="M189" altimg="si61.gif" display="block" overflow="scroll">
            <mml:mtext/>
          </mml:math>
        </disp-formula>
      </p>
    </boxed-text>
  </floats-wrap>
</article>